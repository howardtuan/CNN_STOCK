{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from contextlib import contextmanager\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "class Config:\n",
    "    USE_GPU = True\n",
    "    USE_RANDOM_SPLIT = False\n",
    "    USE_DATAPARALLEL = True\n",
    "    SEED = 42\n",
    "    NUM_EPOCHS = 30\n",
    "    LEARNING_RATE = 0.00001\n",
    "    BATCH_SIZE = 128\n",
    "    IMG_HEIGHT = {5: 32, 20: 64, 60: 96}\n",
    "    IMG_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "    IMG_CHANNELS = 1\n",
    "    \n",
    "    # Early stopping\n",
    "    EARLY_STOPPING_PATIENCE = 2  \n",
    "    MIN_DELTA = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setting\n",
    "def setup_gpu():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    torch.manual_seed(Config.SEED)\n",
    "    \n",
    "    if Config.USE_GPU:\n",
    "        def query_gpu(qargs=[]):\n",
    "            qargs = ['index', 'gpu_name', 'memory.free'] + qargs\n",
    "            cmd = 'nvidia-smi --query-gpu={} --format=csv,noheader'.format(','.join(qargs))\n",
    "            results = os.popen(cmd).readlines()\n",
    "            return results\n",
    "\n",
    "        def select_gpu(results, thres=4096):\n",
    "            available = []\n",
    "            try:\n",
    "                for i, line in enumerate(results):\n",
    "                    if int(re.findall(r'(.*), (.*?) MiB', line)[0][-1]) > thres:\n",
    "                        available.append(i)\n",
    "                return available\n",
    "            except:\n",
    "                return ''\n",
    "\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(gpu) for gpu in select_gpu(query_gpu())])\n",
    "\n",
    "    if not torch.cuda.is_available() and Config.USE_GPU:\n",
    "        raise RuntimeError(\"此程式需要 GPU 才能運行！請確認 CUDA 環境是否正確安裝。\")\n",
    "\n",
    "    return torch.device('cuda:0' if torch.cuda.is_available() and Config.USE_GPU else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, filename='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Load the model with robust key mapping\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to load state dict into\n",
    "        filename (str, optional): Filename to load the model from. Defaults to 'best_model.pth'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Loaded model, optimizer state dict, epoch, loss\n",
    "    \"\"\"\n",
    "    # Ensure we load into the base model if it's wrapped in DataParallel\n",
    "    base_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(filename)\n",
    "    \n",
    "    # Create a mapping for state dict keys\n",
    "    state_dict_mapping = {\n",
    "        'conv1.Conv.weight': 'conv1.0.weight',\n",
    "        'conv1.Conv.bias': 'conv1.0.bias',\n",
    "        'conv1.BN.weight': 'conv1.1.weight',\n",
    "        'conv1.BN.bias': 'conv1.1.bias',\n",
    "        'conv1.BN.running_mean': 'conv1.1.running_mean',\n",
    "        'conv1.BN.running_var': 'conv1.1.running_var',\n",
    "        \n",
    "        'conv2.Conv.weight': 'conv2.0.weight',\n",
    "        'conv2.Conv.bias': 'conv2.0.bias',\n",
    "        'conv2.BN.weight': 'conv2.1.weight',\n",
    "        'conv2.BN.bias': 'conv2.1.bias',\n",
    "        'conv2.BN.running_mean': 'conv2.1.running_mean',\n",
    "        'conv2.BN.running_var': 'conv2.1.running_var',\n",
    "        \n",
    "        'FC.weight': 'FC.weight',\n",
    "        'FC.bias': 'FC.bias'\n",
    "    }\n",
    "    \n",
    "    # Prepare the state dict for loading\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for saved_key, model_key in state_dict_mapping.items():\n",
    "        if saved_key in model_state_dict:\n",
    "            new_state_dict[model_key] = model_state_dict[saved_key]\n",
    "    \n",
    "    # Load the state dict with strict=False to allow some flexibility\n",
    "    base_model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    return (\n",
    "        base_model, \n",
    "        checkpoint.get('optimizer_state_dict'), \n",
    "        checkpoint.get('epoch'), \n",
    "        checkpoint.get('loss')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARE\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = pd.read_excel(labels_file)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((Config.IMG_HEIGHT[5], Config.IMG_WIDTH[5])),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self._get_valid_image_path(idx)\n",
    "        image = self._load_and_transform_image(img_path)\n",
    "        label = int(self.labels.iloc[idx, 1])\n",
    "        return image, label\n",
    "\n",
    "    def _get_valid_image_path(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels.iloc[idx, 0])\n",
    "        if not os.path.exists(img_path):\n",
    "            for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:\n",
    "                test_path = img_path + ext\n",
    "                if os.path.exists(test_path):\n",
    "                    return test_path\n",
    "        return img_path\n",
    "\n",
    "    def _load_and_transform_image(self, img_path):\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('1')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new('1', (Config.IMG_WIDTH[5], Config.IMG_HEIGHT[5]), 0)\n",
    "\n",
    "        try:\n",
    "            return self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error transforming image {img_path}: {e}\")\n",
    "            blank = Image.new('1', (Config.IMG_WIDTH[5], Config.IMG_HEIGHT[5]), 0)\n",
    "            return self.transform(blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT_SELECTED = 32\n",
    "IMG_WIDTH_SELECTED = 15\n",
    "\n",
    "class CNN5d(nn.Module):\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)  # 修正\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN5d, self).__init__()\n",
    "        self.conv1 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))),\n",
    "            ('BN', nn.BatchNorm2d(64, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2, 1)))\n",
    "        ]))\n",
    "        self.conv1 = self.conv1.apply(self.init_weights)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(OrderedDict([\n",
    "            ('Conv', nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))),\n",
    "            ('BN', nn.BatchNorm2d(128, affine=True)),\n",
    "            ('ReLU', nn.ReLU()),\n",
    "            ('Max-Pool', nn.MaxPool2d((2, 1)))\n",
    "        ]))\n",
    "        self.conv2 = self.conv2.apply(self.init_weights)\n",
    "        \n",
    "        # 計算攤平大小\n",
    "        dummy_input = torch.zeros(1, 1, IMG_HEIGHT_SELECTED, IMG_WIDTH_SELECTED)\n",
    "        flattened_size = self.conv2(self.conv1(dummy_input)).view(1, -1).shape[1]\n",
    "\n",
    "        self.DropOut = nn.Dropout(p=0.5)\n",
    "        self.FC = nn.Linear(flattened_size, 2)\n",
    "        self.FC.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # 輸入數據應為 [N, 32, 15]\n",
    "        if x.ndim == 4:  # 若有多餘維度，去掉\n",
    "            x = x.squeeze(1)\n",
    "        x = x.unsqueeze(1).to(torch.float32)  # 增加通道維度，變為 [N, 1, 32, 15]\n",
    "        x = self.conv1(x)  # 通過卷積層\n",
    "        x = self.conv2(x)  # 通過第二層卷積\n",
    "        x = self.DropOut(x.view(x.shape[0], -1))  # 攤平\n",
    "        x = self.FC(x)  # 全連接層\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{Config.NUM_EPOCHS}], '\n",
    "                  f'Batch [{batch_idx}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_epoch(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    return test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _early_stopping_check(\n",
    "    current_loss, \n",
    "    best_loss, \n",
    "    early_stopping_counter\n",
    "):\n",
    "    \"\"\"   \n",
    "    Args:\n",
    "        current_loss (float): 目前val loss\n",
    "        best_loss (float): 最佳val loss\n",
    "        early_stopping_counter (int): 未改變cnt\n",
    "    \n",
    "    Returns:\n",
    "        bool: early stopping (T/F)\n",
    "    \"\"\"\n",
    "    return (\n",
    "        early_stopping_counter >= Config.EARLY_STOPPING_PATIENCE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, test_loss, filename='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Save the model with consistent state_dict keys\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to save\n",
    "        optimizer (torch.optim.Optimizer): The model's optimizer\n",
    "        epoch (int): Current training epoch\n",
    "        test_loss (float): Current test loss\n",
    "        filename (str, optional): Filename to save the model. Defaults to 'best_model.pth'.\n",
    "    \"\"\"\n",
    "    # Ensure we save the base model if it's wrapped in DataParallel\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "\n",
    "    # Create a state dictionary with consistent key names\n",
    "    state_dict = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': {\n",
    "            'conv1.Conv.weight': model.conv1[0].weight,\n",
    "            'conv1.Conv.bias': model.conv1[0].bias,\n",
    "            'conv1.BN.weight': model.conv1[1].weight,\n",
    "            'conv1.BN.bias': model.conv1[1].bias,\n",
    "            'conv1.BN.running_mean': model.conv1[1].running_mean,\n",
    "            'conv1.BN.running_var': model.conv1[1].running_var,\n",
    "            \n",
    "            'conv2.Conv.weight': model.conv2[0].weight,\n",
    "            'conv2.Conv.bias': model.conv2[0].bias,\n",
    "            'conv2.BN.weight': model.conv2[1].weight,\n",
    "            'conv2.BN.bias': model.conv2[1].bias,\n",
    "            'conv2.BN.running_mean': model.conv2[1].running_mean,\n",
    "            'conv2.BN.running_var': model.conv2[1].running_var,\n",
    "            \n",
    "            'FC.weight': model.FC.weight,\n",
    "            'FC.bias': model.FC.bias\n",
    "        },\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': test_loss,\n",
    "    }\n",
    "\n",
    "    torch.save(state_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_training_log(\n",
    "    epoch, \n",
    "    train_loss, \n",
    "    test_loss, \n",
    "    device, \n",
    "    early_stopping_counter\n",
    "):\n",
    "    \"\"\"\n",
    "    PRINT LOG\n",
    "    \"\"\"\n",
    "    print(f'GPU mem used: {torch.cuda.memory_allocated(device) / 1024**2:.1f}MB')\n",
    "    print(f'Epoch [{epoch+1}], '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, '\n",
    "          f'Early Stopping Counter: {early_stopping_counter}\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the train_model function to use the new save_model function\n",
    "def train_model(model, train_loader, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    best_test_loss = float('inf')\n",
    "\n",
    "    early_stopping_counter = 0\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        train_loss = _train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        test_loss = _validate_epoch(model, test_loader, criterion, device)\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        should_stop = _early_stopping_check(\n",
    "            test_loss,\n",
    "            best_loss,\n",
    "            early_stopping_counter\n",
    "        )\n",
    "\n",
    "        if test_loss < best_loss - Config.MIN_DELTA:\n",
    "            best_loss = test_loss\n",
    "            early_stopping_counter = 0\n",
    "            # Use the new save_model function\n",
    "            save_model(model, optimizer, epoch, test_loss, 'best_model.pth')\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        # TRAINING LOG\n",
    "        _print_training_log(\n",
    "            epoch,\n",
    "            train_loss,\n",
    "            test_loss,\n",
    "            device,\n",
    "            early_stopping_counter\n",
    "        )\n",
    "\n",
    "        if should_stop:\n",
    "            print(f\"Early stopping：{early_stopping_counter} epochs 未改變\")\n",
    "            break\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_best_model(model, optimizer, epoch, test_loss, best_test_loss):\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': test_loss,\n",
    "        }, 'best_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_probability_distribution(probs, labels):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "\n",
    "    plt.boxplot(\n",
    "        [probs[labels == 0][:, 1], probs[labels == 1][:, 1]], \n",
    "        labels=['Class 0', 'Class 1']\n",
    "    )\n",
    "    \n",
    "    plt.title('distribute of category prob')\n",
    "    plt.ylabel('prob of predict as \"1\"')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_confusion_matrix(all_labels, all_preds):\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Class 0', 'Class 1'], \n",
    "                yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_roc_curve(labels, probs):\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, plot_roc=True):\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 儲存結果\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "\n",
    "    _plot_confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    print(\"\\n分類結果:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "\n",
    "    print(\"\\n機率分布統計:\")\n",
    "    for cls in [0, 1]:\n",
    "        cls_probs = all_probs[all_labels == cls]\n",
    "        print(f\"\\nClass {cls} 的機率分布:\")\n",
    "        print(f\"平均機率: {cls_probs.mean(axis=0)}\")\n",
    "        print(f\"機率標準差: {cls_probs.std(axis=0)}\")\n",
    "\n",
    "    # Visualize prob\n",
    "    _plot_probability_distribution(all_probs, all_labels)\n",
    "\n",
    "    # ROC CURVE\n",
    "    if plot_roc:\n",
    "        _plot_roc_curve(all_labels, all_probs[:, 1])\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\n模型ACC : {accuracy:.4f}\")\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用設備: cuda:0\n",
      "Data loading...\n",
      "初始化模型...\n",
      "No saved model found. Training from scratch.\n",
      "Training model...\n",
      "Epoch [1/30], Batch [0/20508], Loss: 1.0371\n",
      "Epoch [1/30], Batch [10/20508], Loss: 1.0321\n",
      "Epoch [1/30], Batch [20/20508], Loss: 0.9477\n",
      "Epoch [1/30], Batch [30/20508], Loss: 1.0269\n",
      "Epoch [1/30], Batch [40/20508], Loss: 0.9455\n",
      "Epoch [1/30], Batch [50/20508], Loss: 1.1469\n",
      "Epoch [1/30], Batch [60/20508], Loss: 0.9068\n",
      "Epoch [1/30], Batch [70/20508], Loss: 0.8849\n",
      "Epoch [1/30], Batch [80/20508], Loss: 0.9843\n",
      "Epoch [1/30], Batch [90/20508], Loss: 1.0832\n",
      "Epoch [1/30], Batch [100/20508], Loss: 1.1899\n",
      "Epoch [1/30], Batch [110/20508], Loss: 0.9179\n",
      "Epoch [1/30], Batch [120/20508], Loss: 0.9884\n",
      "Epoch [1/30], Batch [130/20508], Loss: 1.0366\n",
      "Epoch [1/30], Batch [140/20508], Loss: 1.2121\n",
      "Epoch [1/30], Batch [150/20508], Loss: 0.9957\n",
      "Epoch [1/30], Batch [160/20508], Loss: 1.0048\n",
      "Epoch [1/30], Batch [170/20508], Loss: 1.0581\n",
      "Epoch [1/30], Batch [180/20508], Loss: 0.9085\n",
      "Epoch [1/30], Batch [190/20508], Loss: 0.9147\n",
      "Epoch [1/30], Batch [200/20508], Loss: 1.0625\n",
      "Epoch [1/30], Batch [210/20508], Loss: 0.9090\n",
      "Epoch [1/30], Batch [220/20508], Loss: 1.0935\n",
      "Epoch [1/30], Batch [230/20508], Loss: 1.0256\n",
      "Epoch [1/30], Batch [240/20508], Loss: 1.1046\n",
      "Epoch [1/30], Batch [250/20508], Loss: 0.9818\n",
      "Epoch [1/30], Batch [260/20508], Loss: 1.1109\n",
      "Epoch [1/30], Batch [270/20508], Loss: 0.8743\n",
      "Epoch [1/30], Batch [280/20508], Loss: 0.8427\n",
      "Epoch [1/30], Batch [290/20508], Loss: 1.0210\n",
      "Epoch [1/30], Batch [300/20508], Loss: 1.0225\n",
      "Epoch [1/30], Batch [310/20508], Loss: 1.1247\n",
      "Epoch [1/30], Batch [320/20508], Loss: 1.0796\n",
      "Epoch [1/30], Batch [330/20508], Loss: 0.9320\n",
      "Epoch [1/30], Batch [340/20508], Loss: 0.8925\n",
      "Epoch [1/30], Batch [350/20508], Loss: 1.0781\n",
      "Epoch [1/30], Batch [360/20508], Loss: 0.9461\n",
      "Epoch [1/30], Batch [370/20508], Loss: 1.0119\n",
      "Epoch [1/30], Batch [380/20508], Loss: 0.9975\n",
      "Epoch [1/30], Batch [390/20508], Loss: 1.0292\n",
      "Epoch [1/30], Batch [400/20508], Loss: 0.9590\n",
      "Epoch [1/30], Batch [410/20508], Loss: 0.8952\n",
      "Epoch [1/30], Batch [420/20508], Loss: 1.0734\n",
      "Epoch [1/30], Batch [430/20508], Loss: 0.9401\n",
      "Epoch [1/30], Batch [440/20508], Loss: 0.9748\n",
      "Epoch [1/30], Batch [450/20508], Loss: 0.9154\n",
      "Epoch [1/30], Batch [460/20508], Loss: 0.9675\n",
      "Epoch [1/30], Batch [470/20508], Loss: 0.8326\n",
      "Epoch [1/30], Batch [480/20508], Loss: 0.9793\n",
      "Epoch [1/30], Batch [490/20508], Loss: 0.8879\n",
      "Epoch [1/30], Batch [500/20508], Loss: 1.0327\n",
      "Epoch [1/30], Batch [510/20508], Loss: 0.9294\n",
      "Epoch [1/30], Batch [520/20508], Loss: 1.0079\n",
      "Epoch [1/30], Batch [530/20508], Loss: 1.1126\n",
      "Epoch [1/30], Batch [540/20508], Loss: 1.0796\n",
      "Epoch [1/30], Batch [550/20508], Loss: 1.0329\n",
      "Epoch [1/30], Batch [560/20508], Loss: 0.8276\n",
      "Epoch [1/30], Batch [570/20508], Loss: 0.9160\n",
      "Epoch [1/30], Batch [580/20508], Loss: 1.0972\n",
      "Epoch [1/30], Batch [590/20508], Loss: 1.1389\n",
      "Epoch [1/30], Batch [600/20508], Loss: 0.9882\n",
      "Epoch [1/30], Batch [610/20508], Loss: 1.0784\n",
      "Epoch [1/30], Batch [620/20508], Loss: 1.0447\n",
      "Epoch [1/30], Batch [630/20508], Loss: 0.9625\n",
      "Epoch [1/30], Batch [640/20508], Loss: 0.9060\n",
      "Epoch [1/30], Batch [650/20508], Loss: 0.9784\n",
      "Epoch [1/30], Batch [660/20508], Loss: 1.1960\n",
      "Epoch [1/30], Batch [670/20508], Loss: 0.8988\n",
      "Epoch [1/30], Batch [680/20508], Loss: 0.9183\n",
      "Epoch [1/30], Batch [690/20508], Loss: 1.0646\n",
      "Epoch [1/30], Batch [700/20508], Loss: 0.9985\n",
      "Epoch [1/30], Batch [710/20508], Loss: 0.9105\n",
      "Epoch [1/30], Batch [720/20508], Loss: 0.8133\n",
      "Epoch [1/30], Batch [730/20508], Loss: 0.8871\n",
      "Epoch [1/30], Batch [740/20508], Loss: 0.9719\n",
      "Epoch [1/30], Batch [750/20508], Loss: 0.9603\n",
      "Epoch [1/30], Batch [760/20508], Loss: 0.9772\n",
      "Epoch [1/30], Batch [770/20508], Loss: 0.9496\n",
      "Epoch [1/30], Batch [780/20508], Loss: 1.0297\n",
      "Epoch [1/30], Batch [790/20508], Loss: 0.8627\n",
      "Epoch [1/30], Batch [800/20508], Loss: 0.9798\n",
      "Epoch [1/30], Batch [810/20508], Loss: 0.9644\n",
      "Epoch [1/30], Batch [820/20508], Loss: 1.0446\n",
      "Epoch [1/30], Batch [830/20508], Loss: 0.9535\n",
      "Epoch [1/30], Batch [840/20508], Loss: 1.0683\n",
      "Epoch [1/30], Batch [850/20508], Loss: 1.0059\n",
      "Epoch [1/30], Batch [860/20508], Loss: 1.0090\n",
      "Epoch [1/30], Batch [870/20508], Loss: 1.1141\n",
      "Epoch [1/30], Batch [880/20508], Loss: 0.8850\n",
      "Epoch [1/30], Batch [890/20508], Loss: 0.9221\n",
      "Epoch [1/30], Batch [900/20508], Loss: 1.0439\n",
      "Epoch [1/30], Batch [910/20508], Loss: 0.8616\n",
      "Epoch [1/30], Batch [920/20508], Loss: 1.0079\n",
      "Epoch [1/30], Batch [930/20508], Loss: 1.0765\n",
      "Epoch [1/30], Batch [940/20508], Loss: 0.8891\n",
      "Epoch [1/30], Batch [950/20508], Loss: 1.0478\n",
      "Epoch [1/30], Batch [960/20508], Loss: 1.0148\n",
      "Epoch [1/30], Batch [970/20508], Loss: 0.9163\n",
      "Epoch [1/30], Batch [980/20508], Loss: 0.8343\n",
      "Epoch [1/30], Batch [990/20508], Loss: 0.9288\n",
      "Epoch [1/30], Batch [1000/20508], Loss: 0.8813\n",
      "Epoch [1/30], Batch [1010/20508], Loss: 0.9425\n",
      "Epoch [1/30], Batch [1020/20508], Loss: 0.8557\n",
      "Epoch [1/30], Batch [1030/20508], Loss: 1.0444\n",
      "Epoch [1/30], Batch [1040/20508], Loss: 0.8767\n",
      "Epoch [1/30], Batch [1050/20508], Loss: 1.0216\n",
      "Epoch [1/30], Batch [1060/20508], Loss: 0.9887\n",
      "Epoch [1/30], Batch [1070/20508], Loss: 1.0645\n",
      "Epoch [1/30], Batch [1080/20508], Loss: 0.9883\n",
      "Epoch [1/30], Batch [1090/20508], Loss: 1.0031\n",
      "Epoch [1/30], Batch [1100/20508], Loss: 1.0584\n",
      "Epoch [1/30], Batch [1110/20508], Loss: 0.9191\n",
      "Epoch [1/30], Batch [1120/20508], Loss: 0.8695\n",
      "Epoch [1/30], Batch [1130/20508], Loss: 0.9748\n",
      "Epoch [1/30], Batch [1140/20508], Loss: 0.9664\n",
      "Epoch [1/30], Batch [1150/20508], Loss: 1.0177\n",
      "Epoch [1/30], Batch [1160/20508], Loss: 0.8853\n",
      "Epoch [1/30], Batch [1170/20508], Loss: 0.9329\n",
      "Epoch [1/30], Batch [1180/20508], Loss: 0.9582\n",
      "Epoch [1/30], Batch [1190/20508], Loss: 1.0620\n",
      "Epoch [1/30], Batch [1200/20508], Loss: 0.8961\n",
      "Epoch [1/30], Batch [1210/20508], Loss: 1.0123\n",
      "Epoch [1/30], Batch [1220/20508], Loss: 1.1102\n",
      "Epoch [1/30], Batch [1230/20508], Loss: 1.1071\n",
      "Epoch [1/30], Batch [1240/20508], Loss: 0.8719\n",
      "Epoch [1/30], Batch [1250/20508], Loss: 1.0315\n",
      "Epoch [1/30], Batch [1260/20508], Loss: 0.9183\n",
      "Epoch [1/30], Batch [1270/20508], Loss: 0.9513\n",
      "Epoch [1/30], Batch [1280/20508], Loss: 0.9475\n",
      "Epoch [1/30], Batch [1290/20508], Loss: 0.9751\n",
      "Epoch [1/30], Batch [1300/20508], Loss: 1.0082\n",
      "Epoch [1/30], Batch [1310/20508], Loss: 0.8477\n",
      "Epoch [1/30], Batch [1320/20508], Loss: 0.9658\n",
      "Epoch [1/30], Batch [1330/20508], Loss: 1.0566\n",
      "Epoch [1/30], Batch [1340/20508], Loss: 1.0263\n",
      "Epoch [1/30], Batch [1350/20508], Loss: 0.9542\n",
      "Epoch [1/30], Batch [1360/20508], Loss: 1.0303\n",
      "Epoch [1/30], Batch [1370/20508], Loss: 0.9202\n",
      "Epoch [1/30], Batch [1380/20508], Loss: 0.9807\n",
      "Epoch [1/30], Batch [1390/20508], Loss: 0.9689\n",
      "Epoch [1/30], Batch [1400/20508], Loss: 1.0212\n",
      "Epoch [1/30], Batch [1410/20508], Loss: 0.9111\n",
      "Epoch [1/30], Batch [1420/20508], Loss: 0.9670\n",
      "Epoch [1/30], Batch [1430/20508], Loss: 0.8389\n",
      "Epoch [1/30], Batch [1440/20508], Loss: 0.9446\n",
      "Epoch [1/30], Batch [1450/20508], Loss: 0.9124\n",
      "Epoch [1/30], Batch [1460/20508], Loss: 0.7865\n",
      "Epoch [1/30], Batch [1470/20508], Loss: 1.0401\n",
      "Epoch [1/30], Batch [1480/20508], Loss: 0.9976\n",
      "Epoch [1/30], Batch [1490/20508], Loss: 0.9402\n",
      "Epoch [1/30], Batch [1500/20508], Loss: 0.9049\n",
      "Epoch [1/30], Batch [1510/20508], Loss: 0.8993\n",
      "Epoch [1/30], Batch [1520/20508], Loss: 1.0119\n",
      "Epoch [1/30], Batch [1530/20508], Loss: 0.9005\n",
      "Epoch [1/30], Batch [1540/20508], Loss: 0.9196\n",
      "Epoch [1/30], Batch [1550/20508], Loss: 0.8736\n",
      "Epoch [1/30], Batch [1560/20508], Loss: 1.0095\n",
      "Epoch [1/30], Batch [1570/20508], Loss: 1.0847\n",
      "Epoch [1/30], Batch [1580/20508], Loss: 0.9394\n",
      "Epoch [1/30], Batch [1590/20508], Loss: 0.9112\n",
      "Epoch [1/30], Batch [1600/20508], Loss: 0.9568\n",
      "Epoch [1/30], Batch [1610/20508], Loss: 1.1129\n",
      "Epoch [1/30], Batch [1620/20508], Loss: 0.8679\n",
      "Epoch [1/30], Batch [1630/20508], Loss: 1.0197\n",
      "Epoch [1/30], Batch [1640/20508], Loss: 0.9014\n",
      "Epoch [1/30], Batch [1650/20508], Loss: 1.0364\n",
      "Epoch [1/30], Batch [1660/20508], Loss: 0.9662\n",
      "Epoch [1/30], Batch [1670/20508], Loss: 0.9507\n",
      "Epoch [1/30], Batch [1680/20508], Loss: 0.9813\n",
      "Epoch [1/30], Batch [1690/20508], Loss: 0.8400\n",
      "Epoch [1/30], Batch [1700/20508], Loss: 0.9705\n",
      "Epoch [1/30], Batch [1710/20508], Loss: 1.0545\n",
      "Epoch [1/30], Batch [1720/20508], Loss: 0.8481\n",
      "Epoch [1/30], Batch [1730/20508], Loss: 1.0010\n",
      "Epoch [1/30], Batch [1740/20508], Loss: 0.9431\n",
      "Epoch [1/30], Batch [1750/20508], Loss: 0.9437\n",
      "Epoch [1/30], Batch [1760/20508], Loss: 0.9758\n",
      "Epoch [1/30], Batch [1770/20508], Loss: 0.9965\n",
      "Epoch [1/30], Batch [1780/20508], Loss: 0.8480\n",
      "Epoch [1/30], Batch [1790/20508], Loss: 1.0323\n",
      "Epoch [1/30], Batch [1800/20508], Loss: 0.9098\n",
      "Epoch [1/30], Batch [1810/20508], Loss: 0.8959\n",
      "Epoch [1/30], Batch [1820/20508], Loss: 0.9685\n",
      "Epoch [1/30], Batch [1830/20508], Loss: 0.9343\n",
      "Epoch [1/30], Batch [1840/20508], Loss: 0.9396\n",
      "Epoch [1/30], Batch [1850/20508], Loss: 0.8583\n",
      "Epoch [1/30], Batch [1860/20508], Loss: 1.0095\n",
      "Epoch [1/30], Batch [1870/20508], Loss: 0.8981\n",
      "Epoch [1/30], Batch [1880/20508], Loss: 1.0048\n",
      "Epoch [1/30], Batch [1890/20508], Loss: 1.0417\n",
      "Epoch [1/30], Batch [1900/20508], Loss: 1.0109\n",
      "Epoch [1/30], Batch [1910/20508], Loss: 0.8680\n",
      "Epoch [1/30], Batch [1920/20508], Loss: 0.8971\n",
      "Epoch [1/30], Batch [1930/20508], Loss: 0.8110\n",
      "Epoch [1/30], Batch [1940/20508], Loss: 0.9150\n",
      "Epoch [1/30], Batch [1950/20508], Loss: 1.1162\n",
      "Epoch [1/30], Batch [1960/20508], Loss: 0.9956\n",
      "Epoch [1/30], Batch [1970/20508], Loss: 0.9060\n",
      "Epoch [1/30], Batch [1980/20508], Loss: 0.8524\n",
      "Epoch [1/30], Batch [1990/20508], Loss: 0.8586\n",
      "Epoch [1/30], Batch [2000/20508], Loss: 0.9718\n",
      "Epoch [1/30], Batch [2010/20508], Loss: 0.9720\n",
      "Epoch [1/30], Batch [2020/20508], Loss: 0.7697\n",
      "Epoch [1/30], Batch [2030/20508], Loss: 0.8837\n",
      "Epoch [1/30], Batch [2040/20508], Loss: 0.8363\n",
      "Epoch [1/30], Batch [2050/20508], Loss: 0.8704\n",
      "Epoch [1/30], Batch [2060/20508], Loss: 0.9963\n",
      "Epoch [1/30], Batch [2070/20508], Loss: 0.9511\n",
      "Epoch [1/30], Batch [2080/20508], Loss: 0.8025\n",
      "Epoch [1/30], Batch [2090/20508], Loss: 0.8694\n",
      "Epoch [1/30], Batch [2100/20508], Loss: 0.8974\n",
      "Epoch [1/30], Batch [2110/20508], Loss: 0.9248\n",
      "Epoch [1/30], Batch [2120/20508], Loss: 0.9649\n",
      "Epoch [1/30], Batch [2130/20508], Loss: 0.8277\n",
      "Epoch [1/30], Batch [2140/20508], Loss: 0.9837\n",
      "Epoch [1/30], Batch [2150/20508], Loss: 0.8535\n",
      "Epoch [1/30], Batch [2160/20508], Loss: 0.9526\n",
      "Epoch [1/30], Batch [2170/20508], Loss: 0.8810\n",
      "Epoch [1/30], Batch [2180/20508], Loss: 0.9667\n",
      "Epoch [1/30], Batch [2190/20508], Loss: 0.9225\n",
      "Epoch [1/30], Batch [2200/20508], Loss: 0.9188\n",
      "Epoch [1/30], Batch [2210/20508], Loss: 0.7884\n",
      "Epoch [1/30], Batch [2220/20508], Loss: 0.8469\n",
      "Epoch [1/30], Batch [2230/20508], Loss: 0.9360\n",
      "Epoch [1/30], Batch [2240/20508], Loss: 0.8633\n",
      "Epoch [1/30], Batch [2250/20508], Loss: 0.8896\n",
      "Epoch [1/30], Batch [2260/20508], Loss: 0.9048\n",
      "Epoch [1/30], Batch [2270/20508], Loss: 0.9366\n",
      "Epoch [1/30], Batch [2280/20508], Loss: 0.8715\n",
      "Epoch [1/30], Batch [2290/20508], Loss: 0.9713\n",
      "Epoch [1/30], Batch [2300/20508], Loss: 0.8499\n",
      "Epoch [1/30], Batch [2310/20508], Loss: 1.0108\n",
      "Epoch [1/30], Batch [2320/20508], Loss: 0.9565\n",
      "Epoch [1/30], Batch [2330/20508], Loss: 1.0018\n",
      "Epoch [1/30], Batch [2340/20508], Loss: 0.9268\n",
      "Epoch [1/30], Batch [2350/20508], Loss: 0.9131\n",
      "Epoch [1/30], Batch [2360/20508], Loss: 0.9508\n",
      "Epoch [1/30], Batch [2370/20508], Loss: 0.7965\n",
      "Epoch [1/30], Batch [2380/20508], Loss: 0.8404\n",
      "Epoch [1/30], Batch [2390/20508], Loss: 0.9182\n",
      "Epoch [1/30], Batch [2400/20508], Loss: 0.8136\n",
      "Epoch [1/30], Batch [2410/20508], Loss: 0.8756\n",
      "Epoch [1/30], Batch [2420/20508], Loss: 0.9219\n",
      "Epoch [1/30], Batch [2430/20508], Loss: 0.9580\n",
      "Epoch [1/30], Batch [2440/20508], Loss: 0.8782\n",
      "Epoch [1/30], Batch [2450/20508], Loss: 0.8630\n",
      "Epoch [1/30], Batch [2460/20508], Loss: 0.8274\n",
      "Epoch [1/30], Batch [2470/20508], Loss: 0.8730\n",
      "Epoch [1/30], Batch [2480/20508], Loss: 0.9521\n",
      "Epoch [1/30], Batch [2490/20508], Loss: 0.8518\n",
      "Epoch [1/30], Batch [2500/20508], Loss: 0.9513\n",
      "Epoch [1/30], Batch [2510/20508], Loss: 0.8503\n",
      "Epoch [1/30], Batch [2520/20508], Loss: 1.0613\n",
      "Epoch [1/30], Batch [2530/20508], Loss: 0.8835\n",
      "Epoch [1/30], Batch [2540/20508], Loss: 0.8203\n",
      "Epoch [1/30], Batch [2550/20508], Loss: 0.8742\n",
      "Epoch [1/30], Batch [2560/20508], Loss: 0.8447\n",
      "Epoch [1/30], Batch [2570/20508], Loss: 0.9309\n",
      "Epoch [1/30], Batch [2580/20508], Loss: 0.9139\n",
      "Epoch [1/30], Batch [2590/20508], Loss: 0.9547\n",
      "Epoch [1/30], Batch [2600/20508], Loss: 1.0151\n",
      "Epoch [1/30], Batch [2610/20508], Loss: 0.8931\n",
      "Epoch [1/30], Batch [2620/20508], Loss: 0.9331\n",
      "Epoch [1/30], Batch [2630/20508], Loss: 0.8788\n",
      "Epoch [1/30], Batch [2640/20508], Loss: 0.9326\n",
      "Epoch [1/30], Batch [2650/20508], Loss: 0.8873\n",
      "Epoch [1/30], Batch [2660/20508], Loss: 0.9990\n",
      "Epoch [1/30], Batch [2670/20508], Loss: 0.8389\n",
      "Epoch [1/30], Batch [2680/20508], Loss: 1.0172\n",
      "Epoch [1/30], Batch [2690/20508], Loss: 0.6955\n",
      "Epoch [1/30], Batch [2700/20508], Loss: 0.8802\n",
      "Epoch [1/30], Batch [2710/20508], Loss: 0.7052\n",
      "Epoch [1/30], Batch [2720/20508], Loss: 0.8496\n",
      "Epoch [1/30], Batch [2730/20508], Loss: 0.8752\n",
      "Epoch [1/30], Batch [2740/20508], Loss: 0.8581\n",
      "Epoch [1/30], Batch [2750/20508], Loss: 0.8877\n",
      "Epoch [1/30], Batch [2760/20508], Loss: 0.8783\n",
      "Epoch [1/30], Batch [2770/20508], Loss: 0.9952\n",
      "Epoch [1/30], Batch [2780/20508], Loss: 0.9547\n",
      "Epoch [1/30], Batch [2790/20508], Loss: 0.9244\n",
      "Epoch [1/30], Batch [2800/20508], Loss: 0.9602\n",
      "Epoch [1/30], Batch [2810/20508], Loss: 0.8955\n",
      "Epoch [1/30], Batch [2820/20508], Loss: 0.8774\n",
      "Epoch [1/30], Batch [2830/20508], Loss: 0.8265\n",
      "Epoch [1/30], Batch [2840/20508], Loss: 0.9364\n",
      "Epoch [1/30], Batch [2850/20508], Loss: 0.7545\n",
      "Epoch [1/30], Batch [2860/20508], Loss: 0.9675\n",
      "Epoch [1/30], Batch [2870/20508], Loss: 0.8742\n",
      "Epoch [1/30], Batch [2880/20508], Loss: 0.8101\n",
      "Epoch [1/30], Batch [2890/20508], Loss: 0.9838\n",
      "Epoch [1/30], Batch [2900/20508], Loss: 0.7761\n",
      "Epoch [1/30], Batch [2910/20508], Loss: 0.9004\n",
      "Epoch [1/30], Batch [2920/20508], Loss: 0.8846\n",
      "Epoch [1/30], Batch [2930/20508], Loss: 0.7829\n",
      "Epoch [1/30], Batch [2940/20508], Loss: 0.8699\n",
      "Epoch [1/30], Batch [2950/20508], Loss: 1.0385\n",
      "Epoch [1/30], Batch [2960/20508], Loss: 0.9583\n",
      "Epoch [1/30], Batch [2970/20508], Loss: 0.8330\n",
      "Epoch [1/30], Batch [2980/20508], Loss: 0.8076\n",
      "Epoch [1/30], Batch [2990/20508], Loss: 0.8977\n",
      "Epoch [1/30], Batch [3000/20508], Loss: 0.9628\n",
      "Epoch [1/30], Batch [3010/20508], Loss: 0.9211\n",
      "Epoch [1/30], Batch [3020/20508], Loss: 0.9221\n",
      "Epoch [1/30], Batch [3030/20508], Loss: 0.9242\n",
      "Epoch [1/30], Batch [3040/20508], Loss: 0.9235\n",
      "Epoch [1/30], Batch [3050/20508], Loss: 0.9129\n",
      "Epoch [1/30], Batch [3060/20508], Loss: 0.8770\n",
      "Epoch [1/30], Batch [3070/20508], Loss: 0.8466\n",
      "Epoch [1/30], Batch [3080/20508], Loss: 0.8672\n",
      "Epoch [1/30], Batch [3090/20508], Loss: 0.9188\n",
      "Epoch [1/30], Batch [3100/20508], Loss: 0.7946\n",
      "Epoch [1/30], Batch [3110/20508], Loss: 0.9160\n",
      "Epoch [1/30], Batch [3120/20508], Loss: 0.9353\n",
      "Epoch [1/30], Batch [3130/20508], Loss: 0.8682\n",
      "Epoch [1/30], Batch [3140/20508], Loss: 0.8192\n",
      "Epoch [1/30], Batch [3150/20508], Loss: 0.9778\n",
      "Epoch [1/30], Batch [3160/20508], Loss: 0.9962\n",
      "Epoch [1/30], Batch [3170/20508], Loss: 0.9738\n",
      "Epoch [1/30], Batch [3180/20508], Loss: 0.9145\n",
      "Epoch [1/30], Batch [3190/20508], Loss: 0.9227\n",
      "Epoch [1/30], Batch [3200/20508], Loss: 0.8482\n",
      "Epoch [1/30], Batch [3210/20508], Loss: 1.0055\n",
      "Epoch [1/30], Batch [3220/20508], Loss: 0.8404\n",
      "Epoch [1/30], Batch [3230/20508], Loss: 0.8438\n",
      "Epoch [1/30], Batch [3240/20508], Loss: 0.9093\n",
      "Epoch [1/30], Batch [3250/20508], Loss: 0.9557\n",
      "Epoch [1/30], Batch [3260/20508], Loss: 1.0427\n",
      "Epoch [1/30], Batch [3270/20508], Loss: 0.9241\n",
      "Epoch [1/30], Batch [3280/20508], Loss: 0.8237\n",
      "Epoch [1/30], Batch [3290/20508], Loss: 0.9568\n",
      "Epoch [1/30], Batch [3300/20508], Loss: 0.9769\n",
      "Epoch [1/30], Batch [3310/20508], Loss: 0.8588\n",
      "Epoch [1/30], Batch [3320/20508], Loss: 0.8296\n",
      "Epoch [1/30], Batch [3330/20508], Loss: 0.8477\n",
      "Epoch [1/30], Batch [3340/20508], Loss: 0.9134\n",
      "Epoch [1/30], Batch [3350/20508], Loss: 0.9934\n",
      "Epoch [1/30], Batch [3360/20508], Loss: 0.9524\n",
      "Epoch [1/30], Batch [3370/20508], Loss: 1.0274\n",
      "Epoch [1/30], Batch [3380/20508], Loss: 0.9794\n",
      "Epoch [1/30], Batch [3390/20508], Loss: 0.9177\n",
      "Epoch [1/30], Batch [3400/20508], Loss: 0.8012\n",
      "Epoch [1/30], Batch [3410/20508], Loss: 0.8433\n",
      "Epoch [1/30], Batch [3420/20508], Loss: 0.8483\n",
      "Epoch [1/30], Batch [3430/20508], Loss: 0.7931\n",
      "Epoch [1/30], Batch [3440/20508], Loss: 0.8537\n",
      "Epoch [1/30], Batch [3450/20508], Loss: 0.8043\n",
      "Epoch [1/30], Batch [3460/20508], Loss: 0.8499\n",
      "Epoch [1/30], Batch [3470/20508], Loss: 0.8088\n",
      "Epoch [1/30], Batch [3480/20508], Loss: 0.9041\n",
      "Epoch [1/30], Batch [3490/20508], Loss: 0.8098\n",
      "Epoch [1/30], Batch [3500/20508], Loss: 0.8237\n",
      "Epoch [1/30], Batch [3510/20508], Loss: 0.9677\n",
      "Epoch [1/30], Batch [3520/20508], Loss: 0.8398\n",
      "Epoch [1/30], Batch [3530/20508], Loss: 0.8624\n",
      "Epoch [1/30], Batch [3540/20508], Loss: 0.8986\n",
      "Epoch [1/30], Batch [3550/20508], Loss: 0.9049\n",
      "Epoch [1/30], Batch [3560/20508], Loss: 0.8537\n",
      "Epoch [1/30], Batch [3570/20508], Loss: 0.9226\n",
      "Epoch [1/30], Batch [3580/20508], Loss: 0.8727\n",
      "Epoch [1/30], Batch [3590/20508], Loss: 0.9015\n",
      "Epoch [1/30], Batch [3600/20508], Loss: 0.7961\n",
      "Epoch [1/30], Batch [3610/20508], Loss: 0.9205\n",
      "Epoch [1/30], Batch [3620/20508], Loss: 0.7581\n",
      "Epoch [1/30], Batch [3630/20508], Loss: 0.9578\n",
      "Epoch [1/30], Batch [3640/20508], Loss: 0.9851\n",
      "Epoch [1/30], Batch [3650/20508], Loss: 0.8171\n",
      "Epoch [1/30], Batch [3660/20508], Loss: 0.9372\n",
      "Epoch [1/30], Batch [3670/20508], Loss: 0.7917\n",
      "Epoch [1/30], Batch [3680/20508], Loss: 0.7632\n",
      "Epoch [1/30], Batch [3690/20508], Loss: 0.9638\n",
      "Epoch [1/30], Batch [3700/20508], Loss: 0.8464\n",
      "Epoch [1/30], Batch [3710/20508], Loss: 0.8263\n",
      "Epoch [1/30], Batch [3720/20508], Loss: 0.8502\n",
      "Epoch [1/30], Batch [3730/20508], Loss: 0.7865\n",
      "Epoch [1/30], Batch [3740/20508], Loss: 0.7834\n",
      "Epoch [1/30], Batch [3750/20508], Loss: 0.8112\n",
      "Epoch [1/30], Batch [3760/20508], Loss: 0.8865\n",
      "Epoch [1/30], Batch [3770/20508], Loss: 0.8787\n",
      "Epoch [1/30], Batch [3780/20508], Loss: 0.7673\n",
      "Epoch [1/30], Batch [3790/20508], Loss: 0.8794\n",
      "Epoch [1/30], Batch [3800/20508], Loss: 0.8081\n",
      "Epoch [1/30], Batch [3810/20508], Loss: 0.8709\n",
      "Epoch [1/30], Batch [3820/20508], Loss: 0.7262\n",
      "Epoch [1/30], Batch [3830/20508], Loss: 0.8490\n",
      "Epoch [1/30], Batch [3840/20508], Loss: 0.8500\n",
      "Epoch [1/30], Batch [3850/20508], Loss: 0.8513\n",
      "Epoch [1/30], Batch [3860/20508], Loss: 0.7978\n",
      "Epoch [1/30], Batch [3870/20508], Loss: 0.8059\n",
      "Epoch [1/30], Batch [3880/20508], Loss: 0.8043\n",
      "Epoch [1/30], Batch [3890/20508], Loss: 0.9349\n",
      "Epoch [1/30], Batch [3900/20508], Loss: 0.9422\n",
      "Epoch [1/30], Batch [3910/20508], Loss: 0.8548\n",
      "Epoch [1/30], Batch [3920/20508], Loss: 0.8026\n",
      "Epoch [1/30], Batch [3930/20508], Loss: 0.8342\n",
      "Epoch [1/30], Batch [3940/20508], Loss: 0.8198\n",
      "Epoch [1/30], Batch [3950/20508], Loss: 0.8915\n",
      "Epoch [1/30], Batch [3960/20508], Loss: 0.8950\n",
      "Epoch [1/30], Batch [3970/20508], Loss: 0.8625\n",
      "Epoch [1/30], Batch [3980/20508], Loss: 0.8379\n",
      "Epoch [1/30], Batch [3990/20508], Loss: 0.8981\n",
      "Epoch [1/30], Batch [4000/20508], Loss: 0.7934\n",
      "Epoch [1/30], Batch [4010/20508], Loss: 0.8197\n",
      "Epoch [1/30], Batch [4020/20508], Loss: 0.8640\n",
      "Epoch [1/30], Batch [4030/20508], Loss: 0.8777\n",
      "Epoch [1/30], Batch [4040/20508], Loss: 0.8811\n",
      "Epoch [1/30], Batch [4050/20508], Loss: 0.9477\n",
      "Epoch [1/30], Batch [4060/20508], Loss: 0.8245\n",
      "Epoch [1/30], Batch [4070/20508], Loss: 0.8407\n",
      "Epoch [1/30], Batch [4080/20508], Loss: 0.8311\n",
      "Epoch [1/30], Batch [4090/20508], Loss: 0.9227\n",
      "Epoch [1/30], Batch [4100/20508], Loss: 0.7673\n",
      "Epoch [1/30], Batch [4110/20508], Loss: 0.9158\n",
      "Epoch [1/30], Batch [4120/20508], Loss: 0.7825\n",
      "Epoch [1/30], Batch [4130/20508], Loss: 0.7124\n",
      "Epoch [1/30], Batch [4140/20508], Loss: 0.9520\n",
      "Epoch [1/30], Batch [4150/20508], Loss: 0.8830\n",
      "Epoch [1/30], Batch [4160/20508], Loss: 0.8480\n",
      "Epoch [1/30], Batch [4170/20508], Loss: 0.8951\n",
      "Epoch [1/30], Batch [4180/20508], Loss: 0.8146\n",
      "Epoch [1/30], Batch [4190/20508], Loss: 0.9174\n",
      "Epoch [1/30], Batch [4200/20508], Loss: 0.9110\n",
      "Epoch [1/30], Batch [4210/20508], Loss: 0.8447\n",
      "Epoch [1/30], Batch [4220/20508], Loss: 0.7886\n",
      "Epoch [1/30], Batch [4230/20508], Loss: 0.7703\n",
      "Epoch [1/30], Batch [4240/20508], Loss: 0.8232\n",
      "Epoch [1/30], Batch [4250/20508], Loss: 0.9529\n",
      "Epoch [1/30], Batch [4260/20508], Loss: 0.7988\n",
      "Epoch [1/30], Batch [4270/20508], Loss: 0.9268\n",
      "Epoch [1/30], Batch [4280/20508], Loss: 0.8217\n",
      "Epoch [1/30], Batch [4290/20508], Loss: 0.8037\n",
      "Epoch [1/30], Batch [4300/20508], Loss: 0.8484\n",
      "Epoch [1/30], Batch [4310/20508], Loss: 0.8309\n",
      "Epoch [1/30], Batch [4320/20508], Loss: 0.8227\n",
      "Epoch [1/30], Batch [4330/20508], Loss: 0.9622\n",
      "Epoch [1/30], Batch [4340/20508], Loss: 0.8678\n",
      "Epoch [1/30], Batch [4350/20508], Loss: 0.7953\n",
      "Epoch [1/30], Batch [4360/20508], Loss: 0.8486\n",
      "Epoch [1/30], Batch [4370/20508], Loss: 0.8415\n",
      "Epoch [1/30], Batch [4380/20508], Loss: 0.8828\n",
      "Epoch [1/30], Batch [4390/20508], Loss: 0.7949\n",
      "Epoch [1/30], Batch [4400/20508], Loss: 0.9114\n",
      "Epoch [1/30], Batch [4410/20508], Loss: 0.8850\n",
      "Epoch [1/30], Batch [4420/20508], Loss: 0.7444\n",
      "Epoch [1/30], Batch [4430/20508], Loss: 0.7545\n",
      "Epoch [1/30], Batch [4440/20508], Loss: 0.8897\n",
      "Epoch [1/30], Batch [4450/20508], Loss: 0.8316\n",
      "Epoch [1/30], Batch [4460/20508], Loss: 0.8354\n",
      "Epoch [1/30], Batch [4470/20508], Loss: 0.8636\n",
      "Epoch [1/30], Batch [4480/20508], Loss: 0.8698\n",
      "Epoch [1/30], Batch [4490/20508], Loss: 0.8139\n",
      "Epoch [1/30], Batch [4500/20508], Loss: 0.9215\n",
      "Epoch [1/30], Batch [4510/20508], Loss: 0.8514\n",
      "Epoch [1/30], Batch [4520/20508], Loss: 0.6977\n",
      "Epoch [1/30], Batch [4530/20508], Loss: 0.8193\n",
      "Epoch [1/30], Batch [4540/20508], Loss: 0.7356\n",
      "Epoch [1/30], Batch [4550/20508], Loss: 0.8630\n",
      "Epoch [1/30], Batch [4560/20508], Loss: 0.7717\n",
      "Epoch [1/30], Batch [4570/20508], Loss: 0.8745\n",
      "Epoch [1/30], Batch [4580/20508], Loss: 0.8848\n",
      "Epoch [1/30], Batch [4590/20508], Loss: 0.7687\n",
      "Epoch [1/30], Batch [4600/20508], Loss: 0.7725\n",
      "Epoch [1/30], Batch [4610/20508], Loss: 0.8649\n",
      "Epoch [1/30], Batch [4620/20508], Loss: 0.8042\n",
      "Epoch [1/30], Batch [4630/20508], Loss: 0.7471\n",
      "Epoch [1/30], Batch [4640/20508], Loss: 0.8055\n",
      "Epoch [1/30], Batch [4650/20508], Loss: 0.8817\n",
      "Epoch [1/30], Batch [4660/20508], Loss: 0.8703\n",
      "Epoch [1/30], Batch [4670/20508], Loss: 0.8475\n",
      "Epoch [1/30], Batch [4680/20508], Loss: 0.7427\n",
      "Epoch [1/30], Batch [4690/20508], Loss: 0.8154\n",
      "Epoch [1/30], Batch [4700/20508], Loss: 0.9040\n",
      "Epoch [1/30], Batch [4710/20508], Loss: 0.8699\n",
      "Epoch [1/30], Batch [4720/20508], Loss: 0.9860\n",
      "Epoch [1/30], Batch [4730/20508], Loss: 0.9185\n",
      "Epoch [1/30], Batch [4740/20508], Loss: 0.9674\n",
      "Epoch [1/30], Batch [4750/20508], Loss: 0.7772\n",
      "Epoch [1/30], Batch [4760/20508], Loss: 0.9971\n",
      "Epoch [1/30], Batch [4770/20508], Loss: 0.8653\n",
      "Epoch [1/30], Batch [4780/20508], Loss: 0.7515\n",
      "Epoch [1/30], Batch [4790/20508], Loss: 0.8449\n",
      "Epoch [1/30], Batch [4800/20508], Loss: 0.8298\n",
      "Epoch [1/30], Batch [4810/20508], Loss: 0.8627\n",
      "Epoch [1/30], Batch [4820/20508], Loss: 0.8512\n",
      "Epoch [1/30], Batch [4830/20508], Loss: 0.8400\n",
      "Epoch [1/30], Batch [4840/20508], Loss: 0.7991\n",
      "Epoch [1/30], Batch [4850/20508], Loss: 0.8221\n",
      "Epoch [1/30], Batch [4860/20508], Loss: 0.7686\n",
      "Epoch [1/30], Batch [4870/20508], Loss: 0.7346\n",
      "Epoch [1/30], Batch [4880/20508], Loss: 0.9152\n",
      "Epoch [1/30], Batch [4890/20508], Loss: 0.8058\n",
      "Epoch [1/30], Batch [4900/20508], Loss: 0.7825\n",
      "Epoch [1/30], Batch [4910/20508], Loss: 0.8763\n",
      "Epoch [1/30], Batch [4920/20508], Loss: 0.7008\n",
      "Epoch [1/30], Batch [4930/20508], Loss: 0.8734\n",
      "Epoch [1/30], Batch [4940/20508], Loss: 0.8270\n",
      "Epoch [1/30], Batch [4950/20508], Loss: 0.8295\n",
      "Epoch [1/30], Batch [4960/20508], Loss: 0.8019\n",
      "Epoch [1/30], Batch [4970/20508], Loss: 0.8532\n",
      "Epoch [1/30], Batch [4980/20508], Loss: 0.7884\n",
      "Epoch [1/30], Batch [4990/20508], Loss: 0.8125\n",
      "Epoch [1/30], Batch [5000/20508], Loss: 0.8052\n",
      "Epoch [1/30], Batch [5010/20508], Loss: 0.7827\n",
      "Epoch [1/30], Batch [5020/20508], Loss: 0.8996\n",
      "Epoch [1/30], Batch [5030/20508], Loss: 0.7881\n",
      "Epoch [1/30], Batch [5040/20508], Loss: 0.8589\n",
      "Epoch [1/30], Batch [5050/20508], Loss: 0.8406\n",
      "Epoch [1/30], Batch [5060/20508], Loss: 0.8727\n",
      "Epoch [1/30], Batch [5070/20508], Loss: 0.8923\n",
      "Epoch [1/30], Batch [5080/20508], Loss: 0.7975\n",
      "Epoch [1/30], Batch [5090/20508], Loss: 0.8415\n",
      "Epoch [1/30], Batch [5100/20508], Loss: 0.8624\n",
      "Epoch [1/30], Batch [5110/20508], Loss: 0.8309\n",
      "Epoch [1/30], Batch [5120/20508], Loss: 0.7245\n",
      "Epoch [1/30], Batch [5130/20508], Loss: 0.7620\n",
      "Epoch [1/30], Batch [5140/20508], Loss: 0.8358\n",
      "Epoch [1/30], Batch [5150/20508], Loss: 0.8512\n",
      "Epoch [1/30], Batch [5160/20508], Loss: 0.7639\n",
      "Epoch [1/30], Batch [5170/20508], Loss: 0.9479\n",
      "Epoch [1/30], Batch [5180/20508], Loss: 0.8593\n",
      "Epoch [1/30], Batch [5190/20508], Loss: 0.8324\n",
      "Epoch [1/30], Batch [5200/20508], Loss: 0.8003\n",
      "Epoch [1/30], Batch [5210/20508], Loss: 0.8366\n",
      "Epoch [1/30], Batch [5220/20508], Loss: 0.8335\n",
      "Epoch [1/30], Batch [5230/20508], Loss: 0.9069\n",
      "Epoch [1/30], Batch [5240/20508], Loss: 0.8276\n",
      "Epoch [1/30], Batch [5250/20508], Loss: 0.8654\n",
      "Epoch [1/30], Batch [5260/20508], Loss: 0.9419\n",
      "Epoch [1/30], Batch [5270/20508], Loss: 0.8149\n",
      "Epoch [1/30], Batch [5280/20508], Loss: 0.7513\n",
      "Epoch [1/30], Batch [5290/20508], Loss: 0.8226\n",
      "Epoch [1/30], Batch [5300/20508], Loss: 0.8584\n",
      "Epoch [1/30], Batch [5310/20508], Loss: 0.8909\n",
      "Epoch [1/30], Batch [5320/20508], Loss: 0.8396\n",
      "Epoch [1/30], Batch [5330/20508], Loss: 0.8658\n",
      "Epoch [1/30], Batch [5340/20508], Loss: 0.8303\n",
      "Epoch [1/30], Batch [5350/20508], Loss: 0.8518\n",
      "Epoch [1/30], Batch [5360/20508], Loss: 0.8428\n",
      "Epoch [1/30], Batch [5370/20508], Loss: 0.7987\n",
      "Epoch [1/30], Batch [5380/20508], Loss: 0.8930\n",
      "Epoch [1/30], Batch [5390/20508], Loss: 0.8067\n",
      "Epoch [1/30], Batch [5400/20508], Loss: 0.8103\n",
      "Epoch [1/30], Batch [5410/20508], Loss: 0.7860\n",
      "Epoch [1/30], Batch [5420/20508], Loss: 0.7369\n",
      "Epoch [1/30], Batch [5430/20508], Loss: 0.7311\n",
      "Epoch [1/30], Batch [5440/20508], Loss: 0.7851\n",
      "Epoch [1/30], Batch [5450/20508], Loss: 0.7264\n",
      "Epoch [1/30], Batch [5460/20508], Loss: 0.8747\n",
      "Epoch [1/30], Batch [5470/20508], Loss: 0.8437\n",
      "Epoch [1/30], Batch [5480/20508], Loss: 0.7379\n",
      "Epoch [1/30], Batch [5490/20508], Loss: 0.8917\n",
      "Epoch [1/30], Batch [5500/20508], Loss: 0.7605\n",
      "Epoch [1/30], Batch [5510/20508], Loss: 0.8004\n",
      "Epoch [1/30], Batch [5520/20508], Loss: 0.8082\n",
      "Epoch [1/30], Batch [5530/20508], Loss: 0.9222\n",
      "Epoch [1/30], Batch [5540/20508], Loss: 0.8244\n",
      "Epoch [1/30], Batch [5550/20508], Loss: 0.8415\n",
      "Epoch [1/30], Batch [5560/20508], Loss: 0.8231\n",
      "Epoch [1/30], Batch [5570/20508], Loss: 0.7658\n",
      "Epoch [1/30], Batch [5580/20508], Loss: 0.8261\n",
      "Epoch [1/30], Batch [5590/20508], Loss: 0.7837\n",
      "Epoch [1/30], Batch [5600/20508], Loss: 0.7762\n",
      "Epoch [1/30], Batch [5610/20508], Loss: 0.7931\n",
      "Epoch [1/30], Batch [5620/20508], Loss: 0.7667\n",
      "Epoch [1/30], Batch [5630/20508], Loss: 0.8728\n",
      "Epoch [1/30], Batch [5640/20508], Loss: 0.8254\n",
      "Epoch [1/30], Batch [5650/20508], Loss: 0.8003\n",
      "Epoch [1/30], Batch [5660/20508], Loss: 0.7011\n",
      "Epoch [1/30], Batch [5670/20508], Loss: 0.8558\n",
      "Epoch [1/30], Batch [5680/20508], Loss: 0.7792\n",
      "Epoch [1/30], Batch [5690/20508], Loss: 0.7636\n",
      "Epoch [1/30], Batch [5700/20508], Loss: 0.7808\n",
      "Epoch [1/30], Batch [5710/20508], Loss: 0.8009\n",
      "Epoch [1/30], Batch [5720/20508], Loss: 0.7686\n",
      "Epoch [1/30], Batch [5730/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [5740/20508], Loss: 0.7599\n",
      "Epoch [1/30], Batch [5750/20508], Loss: 0.8383\n",
      "Epoch [1/30], Batch [5760/20508], Loss: 0.8768\n",
      "Epoch [1/30], Batch [5770/20508], Loss: 0.8216\n",
      "Epoch [1/30], Batch [5780/20508], Loss: 0.8176\n",
      "Epoch [1/30], Batch [5790/20508], Loss: 0.8182\n",
      "Epoch [1/30], Batch [5800/20508], Loss: 0.8017\n",
      "Epoch [1/30], Batch [5810/20508], Loss: 0.7906\n",
      "Epoch [1/30], Batch [5820/20508], Loss: 0.8836\n",
      "Epoch [1/30], Batch [5830/20508], Loss: 0.8568\n",
      "Epoch [1/30], Batch [5840/20508], Loss: 0.7822\n",
      "Epoch [1/30], Batch [5850/20508], Loss: 0.8124\n",
      "Epoch [1/30], Batch [5860/20508], Loss: 0.7807\n",
      "Epoch [1/30], Batch [5870/20508], Loss: 0.7524\n",
      "Epoch [1/30], Batch [5880/20508], Loss: 0.7918\n",
      "Epoch [1/30], Batch [5890/20508], Loss: 0.7560\n",
      "Epoch [1/30], Batch [5900/20508], Loss: 0.7381\n",
      "Epoch [1/30], Batch [5910/20508], Loss: 0.8565\n",
      "Epoch [1/30], Batch [5920/20508], Loss: 0.7751\n",
      "Epoch [1/30], Batch [5930/20508], Loss: 0.8342\n",
      "Epoch [1/30], Batch [5940/20508], Loss: 0.7502\n",
      "Epoch [1/30], Batch [5950/20508], Loss: 0.7492\n",
      "Epoch [1/30], Batch [5960/20508], Loss: 0.7764\n",
      "Epoch [1/30], Batch [5970/20508], Loss: 0.6862\n",
      "Epoch [1/30], Batch [5980/20508], Loss: 0.8379\n",
      "Epoch [1/30], Batch [5990/20508], Loss: 0.7653\n",
      "Epoch [1/30], Batch [6000/20508], Loss: 0.9171\n",
      "Epoch [1/30], Batch [6010/20508], Loss: 0.8286\n",
      "Epoch [1/30], Batch [6020/20508], Loss: 0.8333\n",
      "Epoch [1/30], Batch [6030/20508], Loss: 0.7799\n",
      "Epoch [1/30], Batch [6040/20508], Loss: 0.8596\n",
      "Epoch [1/30], Batch [6050/20508], Loss: 0.7640\n",
      "Epoch [1/30], Batch [6060/20508], Loss: 0.9231\n",
      "Epoch [1/30], Batch [6070/20508], Loss: 0.8591\n",
      "Epoch [1/30], Batch [6080/20508], Loss: 0.8140\n",
      "Epoch [1/30], Batch [6090/20508], Loss: 0.7781\n",
      "Epoch [1/30], Batch [6100/20508], Loss: 0.8100\n",
      "Epoch [1/30], Batch [6110/20508], Loss: 0.8178\n",
      "Epoch [1/30], Batch [6120/20508], Loss: 0.8526\n",
      "Epoch [1/30], Batch [6130/20508], Loss: 0.7794\n",
      "Epoch [1/30], Batch [6140/20508], Loss: 0.7705\n",
      "Epoch [1/30], Batch [6150/20508], Loss: 0.8534\n",
      "Epoch [1/30], Batch [6160/20508], Loss: 0.9025\n",
      "Epoch [1/30], Batch [6170/20508], Loss: 0.8177\n",
      "Epoch [1/30], Batch [6180/20508], Loss: 0.8211\n",
      "Epoch [1/30], Batch [6190/20508], Loss: 0.8448\n",
      "Epoch [1/30], Batch [6200/20508], Loss: 0.7443\n",
      "Epoch [1/30], Batch [6210/20508], Loss: 0.8502\n",
      "Epoch [1/30], Batch [6220/20508], Loss: 0.7658\n",
      "Epoch [1/30], Batch [6230/20508], Loss: 0.7555\n",
      "Epoch [1/30], Batch [6240/20508], Loss: 0.7408\n",
      "Epoch [1/30], Batch [6250/20508], Loss: 0.7886\n",
      "Epoch [1/30], Batch [6260/20508], Loss: 0.8361\n",
      "Epoch [1/30], Batch [6270/20508], Loss: 0.7973\n",
      "Epoch [1/30], Batch [6280/20508], Loss: 0.8782\n",
      "Epoch [1/30], Batch [6290/20508], Loss: 0.7436\n",
      "Epoch [1/30], Batch [6300/20508], Loss: 0.7780\n",
      "Epoch [1/30], Batch [6310/20508], Loss: 0.8014\n",
      "Epoch [1/30], Batch [6320/20508], Loss: 0.7749\n",
      "Epoch [1/30], Batch [6330/20508], Loss: 0.7834\n",
      "Epoch [1/30], Batch [6340/20508], Loss: 0.8534\n",
      "Epoch [1/30], Batch [6350/20508], Loss: 0.7147\n",
      "Epoch [1/30], Batch [6360/20508], Loss: 0.8705\n",
      "Epoch [1/30], Batch [6370/20508], Loss: 0.8547\n",
      "Epoch [1/30], Batch [6380/20508], Loss: 0.8082\n",
      "Epoch [1/30], Batch [6390/20508], Loss: 0.9046\n",
      "Epoch [1/30], Batch [6400/20508], Loss: 0.9300\n",
      "Epoch [1/30], Batch [6410/20508], Loss: 0.7854\n",
      "Epoch [1/30], Batch [6420/20508], Loss: 0.8490\n",
      "Epoch [1/30], Batch [6430/20508], Loss: 0.8597\n",
      "Epoch [1/30], Batch [6440/20508], Loss: 0.8391\n",
      "Epoch [1/30], Batch [6450/20508], Loss: 0.6953\n",
      "Epoch [1/30], Batch [6460/20508], Loss: 0.8521\n",
      "Epoch [1/30], Batch [6470/20508], Loss: 0.7770\n",
      "Epoch [1/30], Batch [6480/20508], Loss: 0.8007\n",
      "Epoch [1/30], Batch [6490/20508], Loss: 0.7187\n",
      "Epoch [1/30], Batch [6500/20508], Loss: 0.7813\n",
      "Epoch [1/30], Batch [6510/20508], Loss: 0.8486\n",
      "Epoch [1/30], Batch [6520/20508], Loss: 0.8524\n",
      "Epoch [1/30], Batch [6530/20508], Loss: 0.7730\n",
      "Epoch [1/30], Batch [6540/20508], Loss: 0.7317\n",
      "Epoch [1/30], Batch [6550/20508], Loss: 0.7512\n",
      "Epoch [1/30], Batch [6560/20508], Loss: 0.7780\n",
      "Epoch [1/30], Batch [6570/20508], Loss: 0.7880\n",
      "Epoch [1/30], Batch [6580/20508], Loss: 0.8030\n",
      "Epoch [1/30], Batch [6590/20508], Loss: 0.7728\n",
      "Epoch [1/30], Batch [6600/20508], Loss: 0.7946\n",
      "Epoch [1/30], Batch [6610/20508], Loss: 0.8123\n",
      "Epoch [1/30], Batch [6620/20508], Loss: 0.8228\n",
      "Epoch [1/30], Batch [6630/20508], Loss: 0.7953\n",
      "Epoch [1/30], Batch [6640/20508], Loss: 0.8214\n",
      "Epoch [1/30], Batch [6650/20508], Loss: 0.8037\n",
      "Epoch [1/30], Batch [6660/20508], Loss: 0.8166\n",
      "Epoch [1/30], Batch [6670/20508], Loss: 0.7654\n",
      "Epoch [1/30], Batch [6680/20508], Loss: 0.8388\n",
      "Epoch [1/30], Batch [6690/20508], Loss: 0.7659\n",
      "Epoch [1/30], Batch [6700/20508], Loss: 0.7485\n",
      "Epoch [1/30], Batch [6710/20508], Loss: 0.8065\n",
      "Epoch [1/30], Batch [6720/20508], Loss: 0.8198\n",
      "Epoch [1/30], Batch [6730/20508], Loss: 0.8428\n",
      "Epoch [1/30], Batch [6740/20508], Loss: 0.7168\n",
      "Epoch [1/30], Batch [6750/20508], Loss: 0.8010\n",
      "Epoch [1/30], Batch [6760/20508], Loss: 0.7934\n",
      "Epoch [1/30], Batch [6770/20508], Loss: 0.7913\n",
      "Epoch [1/30], Batch [6780/20508], Loss: 0.7745\n",
      "Epoch [1/30], Batch [6790/20508], Loss: 0.7251\n",
      "Epoch [1/30], Batch [6800/20508], Loss: 0.8099\n",
      "Epoch [1/30], Batch [6810/20508], Loss: 0.8201\n",
      "Epoch [1/30], Batch [6820/20508], Loss: 0.8335\n",
      "Epoch [1/30], Batch [6830/20508], Loss: 0.7808\n",
      "Epoch [1/30], Batch [6840/20508], Loss: 0.8268\n",
      "Epoch [1/30], Batch [6850/20508], Loss: 0.7323\n",
      "Epoch [1/30], Batch [6860/20508], Loss: 0.8045\n",
      "Epoch [1/30], Batch [6870/20508], Loss: 0.7430\n",
      "Epoch [1/30], Batch [6880/20508], Loss: 0.7885\n",
      "Epoch [1/30], Batch [6890/20508], Loss: 0.8111\n",
      "Epoch [1/30], Batch [6900/20508], Loss: 0.8587\n",
      "Epoch [1/30], Batch [6910/20508], Loss: 0.7794\n",
      "Epoch [1/30], Batch [6920/20508], Loss: 0.8683\n",
      "Epoch [1/30], Batch [6930/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [6940/20508], Loss: 0.7896\n",
      "Epoch [1/30], Batch [6950/20508], Loss: 0.8001\n",
      "Epoch [1/30], Batch [6960/20508], Loss: 0.8259\n",
      "Epoch [1/30], Batch [6970/20508], Loss: 0.8644\n",
      "Epoch [1/30], Batch [6980/20508], Loss: 0.8036\n",
      "Epoch [1/30], Batch [6990/20508], Loss: 0.7901\n",
      "Epoch [1/30], Batch [7000/20508], Loss: 0.7848\n",
      "Epoch [1/30], Batch [7010/20508], Loss: 0.8198\n",
      "Epoch [1/30], Batch [7020/20508], Loss: 0.8410\n",
      "Epoch [1/30], Batch [7030/20508], Loss: 0.8132\n",
      "Epoch [1/30], Batch [7040/20508], Loss: 0.8003\n",
      "Epoch [1/30], Batch [7050/20508], Loss: 0.7325\n",
      "Epoch [1/30], Batch [7060/20508], Loss: 0.7315\n",
      "Epoch [1/30], Batch [7070/20508], Loss: 0.8290\n",
      "Epoch [1/30], Batch [7080/20508], Loss: 0.7875\n",
      "Epoch [1/30], Batch [7090/20508], Loss: 0.8327\n",
      "Epoch [1/30], Batch [7100/20508], Loss: 0.7678\n",
      "Epoch [1/30], Batch [7110/20508], Loss: 0.7697\n",
      "Epoch [1/30], Batch [7120/20508], Loss: 0.7852\n",
      "Epoch [1/30], Batch [7130/20508], Loss: 0.7918\n",
      "Epoch [1/30], Batch [7140/20508], Loss: 0.7060\n",
      "Epoch [1/30], Batch [7150/20508], Loss: 0.7918\n",
      "Epoch [1/30], Batch [7160/20508], Loss: 0.7882\n",
      "Epoch [1/30], Batch [7170/20508], Loss: 0.7821\n",
      "Epoch [1/30], Batch [7180/20508], Loss: 0.7791\n",
      "Epoch [1/30], Batch [7190/20508], Loss: 0.8073\n",
      "Epoch [1/30], Batch [7200/20508], Loss: 0.7611\n",
      "Epoch [1/30], Batch [7210/20508], Loss: 0.7258\n",
      "Epoch [1/30], Batch [7220/20508], Loss: 0.7284\n",
      "Epoch [1/30], Batch [7230/20508], Loss: 0.8372\n",
      "Epoch [1/30], Batch [7240/20508], Loss: 0.8572\n",
      "Epoch [1/30], Batch [7250/20508], Loss: 0.8731\n",
      "Epoch [1/30], Batch [7260/20508], Loss: 0.8267\n",
      "Epoch [1/30], Batch [7270/20508], Loss: 0.7226\n",
      "Epoch [1/30], Batch [7280/20508], Loss: 0.8396\n",
      "Epoch [1/30], Batch [7290/20508], Loss: 0.7845\n",
      "Epoch [1/30], Batch [7300/20508], Loss: 0.7796\n",
      "Epoch [1/30], Batch [7310/20508], Loss: 0.7774\n",
      "Epoch [1/30], Batch [7320/20508], Loss: 0.7558\n",
      "Epoch [1/30], Batch [7330/20508], Loss: 0.8063\n",
      "Epoch [1/30], Batch [7340/20508], Loss: 0.8297\n",
      "Epoch [1/30], Batch [7350/20508], Loss: 0.7526\n",
      "Epoch [1/30], Batch [7360/20508], Loss: 0.8177\n",
      "Epoch [1/30], Batch [7370/20508], Loss: 0.8316\n",
      "Epoch [1/30], Batch [7380/20508], Loss: 0.7344\n",
      "Epoch [1/30], Batch [7390/20508], Loss: 0.8032\n",
      "Epoch [1/30], Batch [7400/20508], Loss: 0.7399\n",
      "Epoch [1/30], Batch [7410/20508], Loss: 0.7357\n",
      "Epoch [1/30], Batch [7420/20508], Loss: 0.7569\n",
      "Epoch [1/30], Batch [7430/20508], Loss: 0.7545\n",
      "Epoch [1/30], Batch [7440/20508], Loss: 0.7293\n",
      "Epoch [1/30], Batch [7450/20508], Loss: 0.7992\n",
      "Epoch [1/30], Batch [7460/20508], Loss: 0.7268\n",
      "Epoch [1/30], Batch [7470/20508], Loss: 0.8016\n",
      "Epoch [1/30], Batch [7480/20508], Loss: 0.8179\n",
      "Epoch [1/30], Batch [7490/20508], Loss: 0.6796\n",
      "Epoch [1/30], Batch [7500/20508], Loss: 0.8169\n",
      "Epoch [1/30], Batch [7510/20508], Loss: 0.7944\n",
      "Epoch [1/30], Batch [7520/20508], Loss: 0.7905\n",
      "Epoch [1/30], Batch [7530/20508], Loss: 0.7988\n",
      "Epoch [1/30], Batch [7540/20508], Loss: 0.7588\n",
      "Epoch [1/30], Batch [7550/20508], Loss: 0.7773\n",
      "Epoch [1/30], Batch [7560/20508], Loss: 0.7825\n",
      "Epoch [1/30], Batch [7570/20508], Loss: 0.9413\n",
      "Epoch [1/30], Batch [7580/20508], Loss: 0.7976\n",
      "Epoch [1/30], Batch [7590/20508], Loss: 0.7539\n",
      "Epoch [1/30], Batch [7600/20508], Loss: 0.7239\n",
      "Epoch [1/30], Batch [7610/20508], Loss: 0.7942\n",
      "Epoch [1/30], Batch [7620/20508], Loss: 0.8381\n",
      "Epoch [1/30], Batch [7630/20508], Loss: 0.7946\n",
      "Epoch [1/30], Batch [7640/20508], Loss: 0.7990\n",
      "Epoch [1/30], Batch [7650/20508], Loss: 0.8299\n",
      "Epoch [1/30], Batch [7660/20508], Loss: 0.7976\n",
      "Epoch [1/30], Batch [7670/20508], Loss: 0.7107\n",
      "Epoch [1/30], Batch [7680/20508], Loss: 0.8389\n",
      "Epoch [1/30], Batch [7690/20508], Loss: 0.8060\n",
      "Epoch [1/30], Batch [7700/20508], Loss: 0.7530\n",
      "Epoch [1/30], Batch [7710/20508], Loss: 0.8177\n",
      "Epoch [1/30], Batch [7720/20508], Loss: 0.7367\n",
      "Epoch [1/30], Batch [7730/20508], Loss: 0.7415\n",
      "Epoch [1/30], Batch [7740/20508], Loss: 0.7207\n",
      "Epoch [1/30], Batch [7750/20508], Loss: 0.7649\n",
      "Epoch [1/30], Batch [7760/20508], Loss: 0.8635\n",
      "Epoch [1/30], Batch [7770/20508], Loss: 0.7478\n",
      "Epoch [1/30], Batch [7780/20508], Loss: 0.7788\n",
      "Epoch [1/30], Batch [7790/20508], Loss: 0.7926\n",
      "Epoch [1/30], Batch [7800/20508], Loss: 0.7935\n",
      "Epoch [1/30], Batch [7810/20508], Loss: 0.7554\n",
      "Epoch [1/30], Batch [7820/20508], Loss: 0.7723\n",
      "Epoch [1/30], Batch [7830/20508], Loss: 0.7557\n",
      "Epoch [1/30], Batch [7840/20508], Loss: 0.7935\n",
      "Epoch [1/30], Batch [7850/20508], Loss: 0.7450\n",
      "Epoch [1/30], Batch [7860/20508], Loss: 0.7884\n",
      "Epoch [1/30], Batch [7870/20508], Loss: 0.7727\n",
      "Epoch [1/30], Batch [7880/20508], Loss: 0.6991\n",
      "Epoch [1/30], Batch [7890/20508], Loss: 0.7302\n",
      "Epoch [1/30], Batch [7900/20508], Loss: 0.7725\n",
      "Epoch [1/30], Batch [7910/20508], Loss: 0.7555\n",
      "Epoch [1/30], Batch [7920/20508], Loss: 0.7774\n",
      "Epoch [1/30], Batch [7930/20508], Loss: 0.7695\n",
      "Epoch [1/30], Batch [7940/20508], Loss: 0.7981\n",
      "Epoch [1/30], Batch [7950/20508], Loss: 0.8002\n",
      "Epoch [1/30], Batch [7960/20508], Loss: 0.7592\n",
      "Epoch [1/30], Batch [7970/20508], Loss: 0.7940\n",
      "Epoch [1/30], Batch [7980/20508], Loss: 0.8445\n",
      "Epoch [1/30], Batch [7990/20508], Loss: 0.8058\n",
      "Epoch [1/30], Batch [8000/20508], Loss: 0.7235\n",
      "Epoch [1/30], Batch [8010/20508], Loss: 0.8027\n",
      "Epoch [1/30], Batch [8020/20508], Loss: 0.7843\n",
      "Epoch [1/30], Batch [8030/20508], Loss: 0.7427\n",
      "Epoch [1/30], Batch [8040/20508], Loss: 0.8066\n",
      "Epoch [1/30], Batch [8050/20508], Loss: 0.8266\n",
      "Epoch [1/30], Batch [8060/20508], Loss: 0.7629\n",
      "Epoch [1/30], Batch [8070/20508], Loss: 0.7585\n",
      "Epoch [1/30], Batch [8080/20508], Loss: 0.7688\n",
      "Epoch [1/30], Batch [8090/20508], Loss: 0.7617\n",
      "Epoch [1/30], Batch [8100/20508], Loss: 0.8151\n",
      "Epoch [1/30], Batch [8110/20508], Loss: 0.7686\n",
      "Epoch [1/30], Batch [8120/20508], Loss: 0.7235\n",
      "Epoch [1/30], Batch [8130/20508], Loss: 0.7032\n",
      "Epoch [1/30], Batch [8140/20508], Loss: 0.7629\n",
      "Epoch [1/30], Batch [8150/20508], Loss: 0.8903\n",
      "Epoch [1/30], Batch [8160/20508], Loss: 0.7636\n",
      "Epoch [1/30], Batch [8170/20508], Loss: 0.7637\n",
      "Epoch [1/30], Batch [8180/20508], Loss: 0.8651\n",
      "Epoch [1/30], Batch [8190/20508], Loss: 0.8714\n",
      "Epoch [1/30], Batch [8200/20508], Loss: 0.7619\n",
      "Epoch [1/30], Batch [8210/20508], Loss: 0.7966\n",
      "Epoch [1/30], Batch [8220/20508], Loss: 0.8066\n",
      "Epoch [1/30], Batch [8230/20508], Loss: 0.8009\n",
      "Epoch [1/30], Batch [8240/20508], Loss: 0.8243\n",
      "Epoch [1/30], Batch [8250/20508], Loss: 0.7685\n",
      "Epoch [1/30], Batch [8260/20508], Loss: 0.7609\n",
      "Epoch [1/30], Batch [8270/20508], Loss: 0.7823\n",
      "Epoch [1/30], Batch [8280/20508], Loss: 0.7589\n",
      "Epoch [1/30], Batch [8290/20508], Loss: 0.7746\n",
      "Epoch [1/30], Batch [8300/20508], Loss: 0.7187\n",
      "Epoch [1/30], Batch [8310/20508], Loss: 0.7044\n",
      "Epoch [1/30], Batch [8320/20508], Loss: 0.8365\n",
      "Epoch [1/30], Batch [8330/20508], Loss: 0.7802\n",
      "Epoch [1/30], Batch [8340/20508], Loss: 0.7836\n",
      "Epoch [1/30], Batch [8350/20508], Loss: 0.7784\n",
      "Epoch [1/30], Batch [8360/20508], Loss: 0.7725\n",
      "Epoch [1/30], Batch [8370/20508], Loss: 0.7907\n",
      "Epoch [1/30], Batch [8380/20508], Loss: 0.7099\n",
      "Epoch [1/30], Batch [8390/20508], Loss: 0.7724\n",
      "Epoch [1/30], Batch [8400/20508], Loss: 0.8438\n",
      "Epoch [1/30], Batch [8410/20508], Loss: 0.7492\n",
      "Epoch [1/30], Batch [8420/20508], Loss: 0.8220\n",
      "Epoch [1/30], Batch [8430/20508], Loss: 0.8246\n",
      "Epoch [1/30], Batch [8440/20508], Loss: 0.7655\n",
      "Epoch [1/30], Batch [8450/20508], Loss: 0.8220\n",
      "Epoch [1/30], Batch [8460/20508], Loss: 0.7728\n",
      "Epoch [1/30], Batch [8470/20508], Loss: 0.7773\n",
      "Epoch [1/30], Batch [8480/20508], Loss: 0.7173\n",
      "Epoch [1/30], Batch [8490/20508], Loss: 0.8203\n",
      "Epoch [1/30], Batch [8500/20508], Loss: 0.8082\n",
      "Epoch [1/30], Batch [8510/20508], Loss: 0.7353\n",
      "Epoch [1/30], Batch [8520/20508], Loss: 0.8170\n",
      "Epoch [1/30], Batch [8530/20508], Loss: 0.7543\n",
      "Epoch [1/30], Batch [8540/20508], Loss: 0.8111\n",
      "Epoch [1/30], Batch [8550/20508], Loss: 0.7331\n",
      "Epoch [1/30], Batch [8560/20508], Loss: 0.7912\n",
      "Epoch [1/30], Batch [8570/20508], Loss: 0.6961\n",
      "Epoch [1/30], Batch [8580/20508], Loss: 0.7402\n",
      "Epoch [1/30], Batch [8590/20508], Loss: 0.7173\n",
      "Epoch [1/30], Batch [8600/20508], Loss: 0.7690\n",
      "Epoch [1/30], Batch [8610/20508], Loss: 0.8085\n",
      "Epoch [1/30], Batch [8620/20508], Loss: 0.7149\n",
      "Epoch [1/30], Batch [8630/20508], Loss: 0.8081\n",
      "Epoch [1/30], Batch [8640/20508], Loss: 0.7644\n",
      "Epoch [1/30], Batch [8650/20508], Loss: 0.7969\n",
      "Epoch [1/30], Batch [8660/20508], Loss: 0.7422\n",
      "Epoch [1/30], Batch [8670/20508], Loss: 0.8010\n",
      "Epoch [1/30], Batch [8680/20508], Loss: 0.8269\n",
      "Epoch [1/30], Batch [8690/20508], Loss: 0.7174\n",
      "Epoch [1/30], Batch [8700/20508], Loss: 0.7843\n",
      "Epoch [1/30], Batch [8710/20508], Loss: 0.7537\n",
      "Epoch [1/30], Batch [8720/20508], Loss: 0.7955\n",
      "Epoch [1/30], Batch [8730/20508], Loss: 0.7027\n",
      "Epoch [1/30], Batch [8740/20508], Loss: 0.7956\n",
      "Epoch [1/30], Batch [8750/20508], Loss: 0.7836\n",
      "Epoch [1/30], Batch [8760/20508], Loss: 0.7683\n",
      "Epoch [1/30], Batch [8770/20508], Loss: 0.7072\n",
      "Epoch [1/30], Batch [8780/20508], Loss: 0.7549\n",
      "Epoch [1/30], Batch [8790/20508], Loss: 0.7177\n",
      "Epoch [1/30], Batch [8800/20508], Loss: 0.8739\n",
      "Epoch [1/30], Batch [8810/20508], Loss: 0.6941\n",
      "Epoch [1/30], Batch [8820/20508], Loss: 0.6814\n",
      "Epoch [1/30], Batch [8830/20508], Loss: 0.7005\n",
      "Epoch [1/30], Batch [8840/20508], Loss: 0.8108\n",
      "Epoch [1/30], Batch [8850/20508], Loss: 0.7953\n",
      "Epoch [1/30], Batch [8860/20508], Loss: 0.7315\n",
      "Epoch [1/30], Batch [8870/20508], Loss: 0.7454\n",
      "Epoch [1/30], Batch [8880/20508], Loss: 0.8944\n",
      "Epoch [1/30], Batch [8890/20508], Loss: 0.8083\n",
      "Epoch [1/30], Batch [8900/20508], Loss: 0.7674\n",
      "Epoch [1/30], Batch [8910/20508], Loss: 0.7748\n",
      "Epoch [1/30], Batch [8920/20508], Loss: 0.7857\n",
      "Epoch [1/30], Batch [8930/20508], Loss: 0.7412\n",
      "Epoch [1/30], Batch [8940/20508], Loss: 0.7925\n",
      "Epoch [1/30], Batch [8950/20508], Loss: 0.7848\n",
      "Epoch [1/30], Batch [8960/20508], Loss: 0.7444\n",
      "Epoch [1/30], Batch [8970/20508], Loss: 0.7883\n",
      "Epoch [1/30], Batch [8980/20508], Loss: 0.7738\n",
      "Epoch [1/30], Batch [8990/20508], Loss: 0.7845\n",
      "Epoch [1/30], Batch [9000/20508], Loss: 0.7699\n",
      "Epoch [1/30], Batch [9010/20508], Loss: 0.7430\n",
      "Epoch [1/30], Batch [9020/20508], Loss: 0.8778\n",
      "Epoch [1/30], Batch [9030/20508], Loss: 0.7952\n",
      "Epoch [1/30], Batch [9040/20508], Loss: 0.7688\n",
      "Epoch [1/30], Batch [9050/20508], Loss: 0.6917\n",
      "Epoch [1/30], Batch [9060/20508], Loss: 0.8343\n",
      "Epoch [1/30], Batch [9070/20508], Loss: 0.7454\n",
      "Epoch [1/30], Batch [9080/20508], Loss: 0.7592\n",
      "Epoch [1/30], Batch [9090/20508], Loss: 0.7759\n",
      "Epoch [1/30], Batch [9100/20508], Loss: 0.7530\n",
      "Epoch [1/30], Batch [9110/20508], Loss: 0.7641\n",
      "Epoch [1/30], Batch [9120/20508], Loss: 0.8277\n",
      "Epoch [1/30], Batch [9130/20508], Loss: 0.7804\n",
      "Epoch [1/30], Batch [9140/20508], Loss: 0.7805\n",
      "Epoch [1/30], Batch [9150/20508], Loss: 0.7297\n",
      "Epoch [1/30], Batch [9160/20508], Loss: 0.7662\n",
      "Epoch [1/30], Batch [9170/20508], Loss: 0.7223\n",
      "Epoch [1/30], Batch [9180/20508], Loss: 0.7435\n",
      "Epoch [1/30], Batch [9190/20508], Loss: 0.7653\n",
      "Epoch [1/30], Batch [9200/20508], Loss: 0.7021\n",
      "Epoch [1/30], Batch [9210/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [9220/20508], Loss: 0.7043\n",
      "Epoch [1/30], Batch [9230/20508], Loss: 0.7669\n",
      "Epoch [1/30], Batch [9240/20508], Loss: 0.7470\n",
      "Epoch [1/30], Batch [9250/20508], Loss: 0.7313\n",
      "Epoch [1/30], Batch [9260/20508], Loss: 0.8402\n",
      "Epoch [1/30], Batch [9270/20508], Loss: 0.7771\n",
      "Epoch [1/30], Batch [9280/20508], Loss: 0.8120\n",
      "Epoch [1/30], Batch [9290/20508], Loss: 0.7556\n",
      "Epoch [1/30], Batch [9300/20508], Loss: 0.7202\n",
      "Epoch [1/30], Batch [9310/20508], Loss: 0.6902\n",
      "Epoch [1/30], Batch [9320/20508], Loss: 0.8079\n",
      "Epoch [1/30], Batch [9330/20508], Loss: 0.7921\n",
      "Epoch [1/30], Batch [9340/20508], Loss: 0.6785\n",
      "Epoch [1/30], Batch [9350/20508], Loss: 0.7870\n",
      "Epoch [1/30], Batch [9360/20508], Loss: 0.7957\n",
      "Epoch [1/30], Batch [9370/20508], Loss: 0.6632\n",
      "Epoch [1/30], Batch [9380/20508], Loss: 0.8552\n",
      "Epoch [1/30], Batch [9390/20508], Loss: 0.8411\n",
      "Epoch [1/30], Batch [9400/20508], Loss: 0.7011\n",
      "Epoch [1/30], Batch [9410/20508], Loss: 0.7909\n",
      "Epoch [1/30], Batch [9420/20508], Loss: 0.7522\n",
      "Epoch [1/30], Batch [9430/20508], Loss: 0.7487\n",
      "Epoch [1/30], Batch [9440/20508], Loss: 0.7333\n",
      "Epoch [1/30], Batch [9450/20508], Loss: 0.7692\n",
      "Epoch [1/30], Batch [9460/20508], Loss: 0.7364\n",
      "Epoch [1/30], Batch [9470/20508], Loss: 0.7214\n",
      "Epoch [1/30], Batch [9480/20508], Loss: 0.8163\n",
      "Epoch [1/30], Batch [9490/20508], Loss: 0.6753\n",
      "Epoch [1/30], Batch [9500/20508], Loss: 0.7926\n",
      "Epoch [1/30], Batch [9510/20508], Loss: 0.7698\n",
      "Epoch [1/30], Batch [9520/20508], Loss: 0.7348\n",
      "Epoch [1/30], Batch [9530/20508], Loss: 0.7273\n",
      "Epoch [1/30], Batch [9540/20508], Loss: 0.7295\n",
      "Epoch [1/30], Batch [9550/20508], Loss: 0.7755\n",
      "Epoch [1/30], Batch [9560/20508], Loss: 0.7712\n",
      "Epoch [1/30], Batch [9570/20508], Loss: 0.7458\n",
      "Epoch [1/30], Batch [9580/20508], Loss: 0.7552\n",
      "Epoch [1/30], Batch [9590/20508], Loss: 0.7408\n",
      "Epoch [1/30], Batch [9600/20508], Loss: 0.7259\n",
      "Epoch [1/30], Batch [9610/20508], Loss: 0.7935\n",
      "Epoch [1/30], Batch [9620/20508], Loss: 0.7986\n",
      "Epoch [1/30], Batch [9630/20508], Loss: 0.7787\n",
      "Epoch [1/30], Batch [9640/20508], Loss: 0.8420\n",
      "Epoch [1/30], Batch [9650/20508], Loss: 0.6790\n",
      "Epoch [1/30], Batch [9660/20508], Loss: 0.7050\n",
      "Epoch [1/30], Batch [9670/20508], Loss: 0.7981\n",
      "Epoch [1/30], Batch [9680/20508], Loss: 0.7598\n",
      "Epoch [1/30], Batch [9690/20508], Loss: 0.7882\n",
      "Epoch [1/30], Batch [9700/20508], Loss: 0.7692\n",
      "Epoch [1/30], Batch [9710/20508], Loss: 0.7417\n",
      "Epoch [1/30], Batch [9720/20508], Loss: 0.7532\n",
      "Epoch [1/30], Batch [9730/20508], Loss: 0.7737\n",
      "Epoch [1/30], Batch [9740/20508], Loss: 0.7765\n",
      "Epoch [1/30], Batch [9750/20508], Loss: 0.7719\n",
      "Epoch [1/30], Batch [9760/20508], Loss: 0.7777\n",
      "Epoch [1/30], Batch [9770/20508], Loss: 0.7659\n",
      "Epoch [1/30], Batch [9780/20508], Loss: 0.7042\n",
      "Epoch [1/30], Batch [9790/20508], Loss: 0.7624\n",
      "Epoch [1/30], Batch [9800/20508], Loss: 0.8302\n",
      "Epoch [1/30], Batch [9810/20508], Loss: 0.6922\n",
      "Epoch [1/30], Batch [9820/20508], Loss: 0.7748\n",
      "Epoch [1/30], Batch [9830/20508], Loss: 0.7700\n",
      "Epoch [1/30], Batch [9840/20508], Loss: 0.7247\n",
      "Epoch [1/30], Batch [9850/20508], Loss: 0.7176\n",
      "Epoch [1/30], Batch [9860/20508], Loss: 0.7687\n",
      "Epoch [1/30], Batch [9870/20508], Loss: 0.7112\n",
      "Epoch [1/30], Batch [9880/20508], Loss: 0.7942\n",
      "Epoch [1/30], Batch [9890/20508], Loss: 0.7682\n",
      "Epoch [1/30], Batch [9900/20508], Loss: 0.7759\n",
      "Epoch [1/30], Batch [9910/20508], Loss: 0.7583\n",
      "Epoch [1/30], Batch [9920/20508], Loss: 0.7512\n",
      "Epoch [1/30], Batch [9930/20508], Loss: 0.6847\n",
      "Epoch [1/30], Batch [9940/20508], Loss: 0.7383\n",
      "Epoch [1/30], Batch [9950/20508], Loss: 0.7478\n",
      "Epoch [1/30], Batch [9960/20508], Loss: 0.7361\n",
      "Epoch [1/30], Batch [9970/20508], Loss: 0.6962\n",
      "Epoch [1/30], Batch [9980/20508], Loss: 0.8026\n",
      "Epoch [1/30], Batch [9990/20508], Loss: 0.7291\n",
      "Epoch [1/30], Batch [10000/20508], Loss: 0.7367\n",
      "Epoch [1/30], Batch [10010/20508], Loss: 0.7356\n",
      "Epoch [1/30], Batch [10020/20508], Loss: 0.7601\n",
      "Epoch [1/30], Batch [10030/20508], Loss: 0.7775\n",
      "Epoch [1/30], Batch [10040/20508], Loss: 0.7858\n",
      "Epoch [1/30], Batch [10050/20508], Loss: 0.7872\n",
      "Epoch [1/30], Batch [10060/20508], Loss: 0.7370\n",
      "Epoch [1/30], Batch [10070/20508], Loss: 0.6697\n",
      "Epoch [1/30], Batch [10080/20508], Loss: 0.7592\n",
      "Epoch [1/30], Batch [10090/20508], Loss: 0.7578\n",
      "Epoch [1/30], Batch [10100/20508], Loss: 0.7713\n",
      "Epoch [1/30], Batch [10110/20508], Loss: 0.7118\n",
      "Epoch [1/30], Batch [10120/20508], Loss: 0.7206\n",
      "Epoch [1/30], Batch [10130/20508], Loss: 0.7392\n",
      "Epoch [1/30], Batch [10140/20508], Loss: 0.7601\n",
      "Epoch [1/30], Batch [10150/20508], Loss: 0.7964\n",
      "Epoch [1/30], Batch [10160/20508], Loss: 0.7259\n",
      "Epoch [1/30], Batch [10170/20508], Loss: 0.7355\n",
      "Epoch [1/30], Batch [10180/20508], Loss: 0.7072\n",
      "Epoch [1/30], Batch [10190/20508], Loss: 0.7449\n",
      "Epoch [1/30], Batch [10200/20508], Loss: 0.7957\n",
      "Epoch [1/30], Batch [10210/20508], Loss: 0.7999\n",
      "Epoch [1/30], Batch [10220/20508], Loss: 0.7292\n",
      "Epoch [1/30], Batch [10230/20508], Loss: 0.7519\n",
      "Epoch [1/30], Batch [10240/20508], Loss: 0.7420\n",
      "Epoch [1/30], Batch [10250/20508], Loss: 0.7704\n",
      "Epoch [1/30], Batch [10260/20508], Loss: 0.7511\n",
      "Epoch [1/30], Batch [10270/20508], Loss: 0.7686\n",
      "Epoch [1/30], Batch [10280/20508], Loss: 0.7627\n",
      "Epoch [1/30], Batch [10290/20508], Loss: 0.7701\n",
      "Epoch [1/30], Batch [10300/20508], Loss: 0.7245\n",
      "Epoch [1/30], Batch [10310/20508], Loss: 0.7726\n",
      "Epoch [1/30], Batch [10320/20508], Loss: 0.7478\n",
      "Epoch [1/30], Batch [10330/20508], Loss: 0.7995\n",
      "Epoch [1/30], Batch [10340/20508], Loss: 0.7431\n",
      "Epoch [1/30], Batch [10350/20508], Loss: 0.7380\n",
      "Epoch [1/30], Batch [10360/20508], Loss: 0.7140\n",
      "Epoch [1/30], Batch [10370/20508], Loss: 0.6881\n",
      "Epoch [1/30], Batch [10380/20508], Loss: 0.7658\n",
      "Epoch [1/30], Batch [10390/20508], Loss: 0.7426\n",
      "Epoch [1/30], Batch [10400/20508], Loss: 0.7473\n",
      "Epoch [1/30], Batch [10410/20508], Loss: 0.7090\n",
      "Epoch [1/30], Batch [10420/20508], Loss: 0.7098\n",
      "Epoch [1/30], Batch [10430/20508], Loss: 0.7992\n",
      "Epoch [1/30], Batch [10440/20508], Loss: 0.7350\n",
      "Epoch [1/30], Batch [10450/20508], Loss: 0.7243\n",
      "Epoch [1/30], Batch [10460/20508], Loss: 0.7706\n",
      "Epoch [1/30], Batch [10470/20508], Loss: 0.7325\n",
      "Epoch [1/30], Batch [10480/20508], Loss: 0.7400\n",
      "Epoch [1/30], Batch [10490/20508], Loss: 0.8126\n",
      "Epoch [1/30], Batch [10500/20508], Loss: 0.7695\n",
      "Epoch [1/30], Batch [10510/20508], Loss: 0.7533\n",
      "Epoch [1/30], Batch [10520/20508], Loss: 0.7751\n",
      "Epoch [1/30], Batch [10530/20508], Loss: 0.6775\n",
      "Epoch [1/30], Batch [10540/20508], Loss: 0.7182\n",
      "Epoch [1/30], Batch [10550/20508], Loss: 0.7391\n",
      "Epoch [1/30], Batch [10560/20508], Loss: 0.8101\n",
      "Epoch [1/30], Batch [10570/20508], Loss: 0.7990\n",
      "Epoch [1/30], Batch [10580/20508], Loss: 0.7831\n",
      "Epoch [1/30], Batch [10590/20508], Loss: 0.7816\n",
      "Epoch [1/30], Batch [10600/20508], Loss: 0.7512\n",
      "Epoch [1/30], Batch [10610/20508], Loss: 0.8273\n",
      "Epoch [1/30], Batch [10620/20508], Loss: 0.7740\n",
      "Epoch [1/30], Batch [10630/20508], Loss: 0.6983\n",
      "Epoch [1/30], Batch [10640/20508], Loss: 0.7664\n",
      "Epoch [1/30], Batch [10650/20508], Loss: 0.7517\n",
      "Epoch [1/30], Batch [10660/20508], Loss: 0.7782\n",
      "Epoch [1/30], Batch [10670/20508], Loss: 0.7718\n",
      "Epoch [1/30], Batch [10680/20508], Loss: 0.8072\n",
      "Epoch [1/30], Batch [10690/20508], Loss: 0.7181\n",
      "Epoch [1/30], Batch [10700/20508], Loss: 0.7231\n",
      "Epoch [1/30], Batch [10710/20508], Loss: 0.7421\n",
      "Epoch [1/30], Batch [10720/20508], Loss: 0.7321\n",
      "Epoch [1/30], Batch [10730/20508], Loss: 0.7825\n",
      "Epoch [1/30], Batch [10740/20508], Loss: 0.7475\n",
      "Epoch [1/30], Batch [10750/20508], Loss: 0.6704\n",
      "Epoch [1/30], Batch [10760/20508], Loss: 0.7377\n",
      "Epoch [1/30], Batch [10770/20508], Loss: 0.7803\n",
      "Epoch [1/30], Batch [10780/20508], Loss: 0.8102\n",
      "Epoch [1/30], Batch [10790/20508], Loss: 0.6549\n",
      "Epoch [1/30], Batch [10800/20508], Loss: 0.7421\n",
      "Epoch [1/30], Batch [10810/20508], Loss: 0.6755\n",
      "Epoch [1/30], Batch [10820/20508], Loss: 0.7281\n",
      "Epoch [1/30], Batch [10830/20508], Loss: 0.7636\n",
      "Epoch [1/30], Batch [10840/20508], Loss: 0.7677\n",
      "Epoch [1/30], Batch [10850/20508], Loss: 0.7012\n",
      "Epoch [1/30], Batch [10860/20508], Loss: 0.7758\n",
      "Epoch [1/30], Batch [10870/20508], Loss: 0.8181\n",
      "Epoch [1/30], Batch [10880/20508], Loss: 0.7084\n",
      "Epoch [1/30], Batch [10890/20508], Loss: 0.7778\n",
      "Epoch [1/30], Batch [10900/20508], Loss: 0.7859\n",
      "Epoch [1/30], Batch [10910/20508], Loss: 0.7399\n",
      "Epoch [1/30], Batch [10920/20508], Loss: 0.7369\n",
      "Epoch [1/30], Batch [10930/20508], Loss: 0.7010\n",
      "Epoch [1/30], Batch [10940/20508], Loss: 0.7447\n",
      "Epoch [1/30], Batch [10950/20508], Loss: 0.8107\n",
      "Epoch [1/30], Batch [10960/20508], Loss: 0.7377\n",
      "Epoch [1/30], Batch [10970/20508], Loss: 0.7718\n",
      "Epoch [1/30], Batch [10980/20508], Loss: 0.7509\n",
      "Epoch [1/30], Batch [10990/20508], Loss: 0.7686\n",
      "Epoch [1/30], Batch [11000/20508], Loss: 0.7214\n",
      "Epoch [1/30], Batch [11010/20508], Loss: 0.7537\n",
      "Epoch [1/30], Batch [11020/20508], Loss: 0.7051\n",
      "Epoch [1/30], Batch [11030/20508], Loss: 0.7396\n",
      "Epoch [1/30], Batch [11040/20508], Loss: 0.7392\n",
      "Epoch [1/30], Batch [11050/20508], Loss: 0.7185\n",
      "Epoch [1/30], Batch [11060/20508], Loss: 0.6946\n",
      "Epoch [1/30], Batch [11070/20508], Loss: 0.7540\n",
      "Epoch [1/30], Batch [11080/20508], Loss: 0.7503\n",
      "Epoch [1/30], Batch [11090/20508], Loss: 0.7183\n",
      "Epoch [1/30], Batch [11100/20508], Loss: 0.7029\n",
      "Epoch [1/30], Batch [11110/20508], Loss: 0.7510\n",
      "Epoch [1/30], Batch [11120/20508], Loss: 0.7410\n",
      "Epoch [1/30], Batch [11130/20508], Loss: 0.7142\n",
      "Epoch [1/30], Batch [11140/20508], Loss: 0.7145\n",
      "Epoch [1/30], Batch [11150/20508], Loss: 0.7522\n",
      "Epoch [1/30], Batch [11160/20508], Loss: 0.7358\n",
      "Epoch [1/30], Batch [11170/20508], Loss: 0.7679\n",
      "Epoch [1/30], Batch [11180/20508], Loss: 0.7707\n",
      "Epoch [1/30], Batch [11190/20508], Loss: 0.7601\n",
      "Epoch [1/30], Batch [11200/20508], Loss: 0.6874\n",
      "Epoch [1/30], Batch [11210/20508], Loss: 0.7795\n",
      "Epoch [1/30], Batch [11220/20508], Loss: 0.7613\n",
      "Epoch [1/30], Batch [11230/20508], Loss: 0.8186\n",
      "Epoch [1/30], Batch [11240/20508], Loss: 0.7704\n",
      "Epoch [1/30], Batch [11250/20508], Loss: 0.7757\n",
      "Epoch [1/30], Batch [11260/20508], Loss: 0.6778\n",
      "Epoch [1/30], Batch [11270/20508], Loss: 0.7173\n",
      "Epoch [1/30], Batch [11280/20508], Loss: 0.8239\n",
      "Epoch [1/30], Batch [11290/20508], Loss: 0.7102\n",
      "Epoch [1/30], Batch [11300/20508], Loss: 0.7168\n",
      "Epoch [1/30], Batch [11310/20508], Loss: 0.7200\n",
      "Epoch [1/30], Batch [11320/20508], Loss: 0.7250\n",
      "Epoch [1/30], Batch [11330/20508], Loss: 0.7319\n",
      "Epoch [1/30], Batch [11340/20508], Loss: 0.7549\n",
      "Epoch [1/30], Batch [11350/20508], Loss: 0.7130\n",
      "Epoch [1/30], Batch [11360/20508], Loss: 0.7204\n",
      "Epoch [1/30], Batch [11370/20508], Loss: 0.7665\n",
      "Epoch [1/30], Batch [11380/20508], Loss: 0.6822\n",
      "Epoch [1/30], Batch [11390/20508], Loss: 0.7500\n",
      "Epoch [1/30], Batch [11400/20508], Loss: 0.7844\n",
      "Epoch [1/30], Batch [11410/20508], Loss: 0.7557\n",
      "Epoch [1/30], Batch [11420/20508], Loss: 0.7582\n",
      "Epoch [1/30], Batch [11430/20508], Loss: 0.6680\n",
      "Epoch [1/30], Batch [11440/20508], Loss: 0.7243\n",
      "Epoch [1/30], Batch [11450/20508], Loss: 0.7719\n",
      "Epoch [1/30], Batch [11460/20508], Loss: 0.7288\n",
      "Epoch [1/30], Batch [11470/20508], Loss: 0.7455\n",
      "Epoch [1/30], Batch [11480/20508], Loss: 0.7513\n",
      "Epoch [1/30], Batch [11490/20508], Loss: 0.6321\n",
      "Epoch [1/30], Batch [11500/20508], Loss: 0.7204\n",
      "Epoch [1/30], Batch [11510/20508], Loss: 0.7276\n",
      "Epoch [1/30], Batch [11520/20508], Loss: 0.7756\n",
      "Epoch [1/30], Batch [11530/20508], Loss: 0.7848\n",
      "Epoch [1/30], Batch [11540/20508], Loss: 0.7579\n",
      "Epoch [1/30], Batch [11550/20508], Loss: 0.7809\n",
      "Epoch [1/30], Batch [11560/20508], Loss: 0.7547\n",
      "Epoch [1/30], Batch [11570/20508], Loss: 0.7525\n",
      "Epoch [1/30], Batch [11580/20508], Loss: 0.7330\n",
      "Epoch [1/30], Batch [11590/20508], Loss: 0.7978\n",
      "Epoch [1/30], Batch [11600/20508], Loss: 0.6884\n",
      "Epoch [1/30], Batch [11610/20508], Loss: 0.7392\n",
      "Epoch [1/30], Batch [11620/20508], Loss: 0.7049\n",
      "Epoch [1/30], Batch [11630/20508], Loss: 0.7676\n",
      "Epoch [1/30], Batch [11640/20508], Loss: 0.7695\n",
      "Epoch [1/30], Batch [11650/20508], Loss: 0.7354\n",
      "Epoch [1/30], Batch [11660/20508], Loss: 0.7044\n",
      "Epoch [1/30], Batch [11670/20508], Loss: 0.7715\n",
      "Epoch [1/30], Batch [11680/20508], Loss: 0.6991\n",
      "Epoch [1/30], Batch [11690/20508], Loss: 0.7699\n",
      "Epoch [1/30], Batch [11700/20508], Loss: 0.7571\n",
      "Epoch [1/30], Batch [11710/20508], Loss: 0.7335\n",
      "Epoch [1/30], Batch [11720/20508], Loss: 0.7648\n",
      "Epoch [1/30], Batch [11730/20508], Loss: 0.7236\n",
      "Epoch [1/30], Batch [11740/20508], Loss: 0.7021\n",
      "Epoch [1/30], Batch [11750/20508], Loss: 0.7476\n",
      "Epoch [1/30], Batch [11760/20508], Loss: 0.6935\n",
      "Epoch [1/30], Batch [11770/20508], Loss: 0.7582\n",
      "Epoch [1/30], Batch [11780/20508], Loss: 0.7456\n",
      "Epoch [1/30], Batch [11790/20508], Loss: 0.7214\n",
      "Epoch [1/30], Batch [11800/20508], Loss: 0.6940\n",
      "Epoch [1/30], Batch [11810/20508], Loss: 0.7406\n",
      "Epoch [1/30], Batch [11820/20508], Loss: 0.6836\n",
      "Epoch [1/30], Batch [11830/20508], Loss: 0.7702\n",
      "Epoch [1/30], Batch [11840/20508], Loss: 0.7859\n",
      "Epoch [1/30], Batch [11850/20508], Loss: 0.7598\n",
      "Epoch [1/30], Batch [11860/20508], Loss: 0.7949\n",
      "Epoch [1/30], Batch [11870/20508], Loss: 0.7671\n",
      "Epoch [1/30], Batch [11880/20508], Loss: 0.7462\n",
      "Epoch [1/30], Batch [11890/20508], Loss: 0.7613\n",
      "Epoch [1/30], Batch [11900/20508], Loss: 0.7868\n",
      "Epoch [1/30], Batch [11910/20508], Loss: 0.7388\n",
      "Epoch [1/30], Batch [11920/20508], Loss: 0.8030\n",
      "Epoch [1/30], Batch [11930/20508], Loss: 0.7031\n",
      "Epoch [1/30], Batch [11940/20508], Loss: 0.7461\n",
      "Epoch [1/30], Batch [11950/20508], Loss: 0.6882\n",
      "Epoch [1/30], Batch [11960/20508], Loss: 0.7700\n",
      "Epoch [1/30], Batch [11970/20508], Loss: 0.7070\n",
      "Epoch [1/30], Batch [11980/20508], Loss: 0.7175\n",
      "Epoch [1/30], Batch [11990/20508], Loss: 0.7831\n",
      "Epoch [1/30], Batch [12000/20508], Loss: 0.7297\n",
      "Epoch [1/30], Batch [12010/20508], Loss: 0.7814\n",
      "Epoch [1/30], Batch [12020/20508], Loss: 0.6476\n",
      "Epoch [1/30], Batch [12030/20508], Loss: 0.6871\n",
      "Epoch [1/30], Batch [12040/20508], Loss: 0.6690\n",
      "Epoch [1/30], Batch [12050/20508], Loss: 0.7699\n",
      "Epoch [1/30], Batch [12060/20508], Loss: 0.7331\n",
      "Epoch [1/30], Batch [12070/20508], Loss: 0.7615\n",
      "Epoch [1/30], Batch [12080/20508], Loss: 0.7258\n",
      "Epoch [1/30], Batch [12090/20508], Loss: 0.7347\n",
      "Epoch [1/30], Batch [12100/20508], Loss: 0.7619\n",
      "Epoch [1/30], Batch [12110/20508], Loss: 0.7152\n",
      "Epoch [1/30], Batch [12120/20508], Loss: 0.7117\n",
      "Epoch [1/30], Batch [12130/20508], Loss: 0.7551\n",
      "Epoch [1/30], Batch [12140/20508], Loss: 0.7248\n",
      "Epoch [1/30], Batch [12150/20508], Loss: 0.7497\n",
      "Epoch [1/30], Batch [12160/20508], Loss: 0.7278\n",
      "Epoch [1/30], Batch [12170/20508], Loss: 0.7293\n",
      "Epoch [1/30], Batch [12180/20508], Loss: 0.7728\n",
      "Epoch [1/30], Batch [12190/20508], Loss: 0.7938\n",
      "Epoch [1/30], Batch [12200/20508], Loss: 0.7752\n",
      "Epoch [1/30], Batch [12210/20508], Loss: 0.7232\n",
      "Epoch [1/30], Batch [12220/20508], Loss: 0.7012\n",
      "Epoch [1/30], Batch [12230/20508], Loss: 0.6663\n",
      "Epoch [1/30], Batch [12240/20508], Loss: 0.7889\n",
      "Epoch [1/30], Batch [12250/20508], Loss: 0.7621\n",
      "Epoch [1/30], Batch [12260/20508], Loss: 0.7354\n",
      "Epoch [1/30], Batch [12270/20508], Loss: 0.7758\n",
      "Epoch [1/30], Batch [12280/20508], Loss: 0.7747\n",
      "Epoch [1/30], Batch [12290/20508], Loss: 0.7475\n",
      "Epoch [1/30], Batch [12300/20508], Loss: 0.7515\n",
      "Epoch [1/30], Batch [12310/20508], Loss: 0.7638\n",
      "Epoch [1/30], Batch [12320/20508], Loss: 0.7386\n",
      "Epoch [1/30], Batch [12330/20508], Loss: 0.7501\n",
      "Epoch [1/30], Batch [12340/20508], Loss: 0.6734\n",
      "Epoch [1/30], Batch [12350/20508], Loss: 0.6949\n",
      "Epoch [1/30], Batch [12360/20508], Loss: 0.7745\n",
      "Epoch [1/30], Batch [12370/20508], Loss: 0.6900\n",
      "Epoch [1/30], Batch [12380/20508], Loss: 0.7813\n",
      "Epoch [1/30], Batch [12390/20508], Loss: 0.7001\n",
      "Epoch [1/30], Batch [12400/20508], Loss: 0.7189\n",
      "Epoch [1/30], Batch [12410/20508], Loss: 0.7253\n",
      "Epoch [1/30], Batch [12420/20508], Loss: 0.7331\n",
      "Epoch [1/30], Batch [12430/20508], Loss: 0.7520\n",
      "Epoch [1/30], Batch [12440/20508], Loss: 0.7420\n",
      "Epoch [1/30], Batch [12450/20508], Loss: 0.7354\n",
      "Epoch [1/30], Batch [12460/20508], Loss: 0.7353\n",
      "Epoch [1/30], Batch [12470/20508], Loss: 0.7530\n",
      "Epoch [1/30], Batch [12480/20508], Loss: 0.7455\n",
      "Epoch [1/30], Batch [12490/20508], Loss: 0.7340\n",
      "Epoch [1/30], Batch [12500/20508], Loss: 0.7386\n",
      "Epoch [1/30], Batch [12510/20508], Loss: 0.7511\n",
      "Epoch [1/30], Batch [12520/20508], Loss: 0.7479\n",
      "Epoch [1/30], Batch [12530/20508], Loss: 0.7611\n",
      "Epoch [1/30], Batch [12540/20508], Loss: 0.6889\n",
      "Epoch [1/30], Batch [12550/20508], Loss: 0.6814\n",
      "Epoch [1/30], Batch [12560/20508], Loss: 0.7086\n",
      "Epoch [1/30], Batch [12570/20508], Loss: 0.7122\n",
      "Epoch [1/30], Batch [12580/20508], Loss: 0.7309\n",
      "Epoch [1/30], Batch [12590/20508], Loss: 0.7161\n",
      "Epoch [1/30], Batch [12600/20508], Loss: 0.7607\n",
      "Epoch [1/30], Batch [12610/20508], Loss: 0.7280\n",
      "Epoch [1/30], Batch [12620/20508], Loss: 0.7403\n",
      "Epoch [1/30], Batch [12630/20508], Loss: 0.7363\n",
      "Epoch [1/30], Batch [12640/20508], Loss: 0.6832\n",
      "Epoch [1/30], Batch [12650/20508], Loss: 0.7112\n",
      "Epoch [1/30], Batch [12660/20508], Loss: 0.7636\n",
      "Epoch [1/30], Batch [12670/20508], Loss: 0.7216\n",
      "Epoch [1/30], Batch [12680/20508], Loss: 0.7191\n",
      "Epoch [1/30], Batch [12690/20508], Loss: 0.7352\n",
      "Epoch [1/30], Batch [12700/20508], Loss: 0.6959\n",
      "Epoch [1/30], Batch [12710/20508], Loss: 0.7030\n",
      "Epoch [1/30], Batch [12720/20508], Loss: 0.7006\n",
      "Epoch [1/30], Batch [12730/20508], Loss: 0.7903\n",
      "Epoch [1/30], Batch [12740/20508], Loss: 0.8110\n",
      "Epoch [1/30], Batch [12750/20508], Loss: 0.7609\n",
      "Epoch [1/30], Batch [12760/20508], Loss: 0.7585\n",
      "Epoch [1/30], Batch [12770/20508], Loss: 0.6997\n",
      "Epoch [1/30], Batch [12780/20508], Loss: 0.7282\n",
      "Epoch [1/30], Batch [12790/20508], Loss: 0.7421\n",
      "Epoch [1/30], Batch [12800/20508], Loss: 0.7846\n",
      "Epoch [1/30], Batch [12810/20508], Loss: 0.6943\n",
      "Epoch [1/30], Batch [12820/20508], Loss: 0.7065\n",
      "Epoch [1/30], Batch [12830/20508], Loss: 0.7430\n",
      "Epoch [1/30], Batch [12840/20508], Loss: 0.7106\n",
      "Epoch [1/30], Batch [12850/20508], Loss: 0.7404\n",
      "Epoch [1/30], Batch [12860/20508], Loss: 0.7564\n",
      "Epoch [1/30], Batch [12870/20508], Loss: 0.7468\n",
      "Epoch [1/30], Batch [12880/20508], Loss: 0.7407\n",
      "Epoch [1/30], Batch [12890/20508], Loss: 0.7038\n",
      "Epoch [1/30], Batch [12900/20508], Loss: 0.6998\n",
      "Epoch [1/30], Batch [12910/20508], Loss: 0.6995\n",
      "Epoch [1/30], Batch [12920/20508], Loss: 0.7754\n",
      "Epoch [1/30], Batch [12930/20508], Loss: 0.7796\n",
      "Epoch [1/30], Batch [12940/20508], Loss: 0.7384\n",
      "Epoch [1/30], Batch [12950/20508], Loss: 0.7148\n",
      "Epoch [1/30], Batch [12960/20508], Loss: 0.7263\n",
      "Epoch [1/30], Batch [12970/20508], Loss: 0.7551\n",
      "Epoch [1/30], Batch [12980/20508], Loss: 0.7466\n",
      "Epoch [1/30], Batch [12990/20508], Loss: 0.7462\n",
      "Epoch [1/30], Batch [13000/20508], Loss: 0.6961\n",
      "Epoch [1/30], Batch [13010/20508], Loss: 0.7625\n",
      "Epoch [1/30], Batch [13020/20508], Loss: 0.7524\n",
      "Epoch [1/30], Batch [13030/20508], Loss: 0.7382\n",
      "Epoch [1/30], Batch [13040/20508], Loss: 0.7532\n",
      "Epoch [1/30], Batch [13050/20508], Loss: 0.7455\n",
      "Epoch [1/30], Batch [13060/20508], Loss: 0.7328\n",
      "Epoch [1/30], Batch [13070/20508], Loss: 0.7478\n",
      "Epoch [1/30], Batch [13080/20508], Loss: 0.7362\n",
      "Epoch [1/30], Batch [13090/20508], Loss: 0.6797\n",
      "Epoch [1/30], Batch [13100/20508], Loss: 0.7258\n",
      "Epoch [1/30], Batch [13110/20508], Loss: 0.7186\n",
      "Epoch [1/30], Batch [13120/20508], Loss: 0.7212\n",
      "Epoch [1/30], Batch [13130/20508], Loss: 0.6876\n",
      "Epoch [1/30], Batch [13140/20508], Loss: 0.7729\n",
      "Epoch [1/30], Batch [13150/20508], Loss: 0.7302\n",
      "Epoch [1/30], Batch [13160/20508], Loss: 0.7527\n",
      "Epoch [1/30], Batch [13170/20508], Loss: 0.7074\n",
      "Epoch [1/30], Batch [13180/20508], Loss: 0.6882\n",
      "Epoch [1/30], Batch [13190/20508], Loss: 0.7698\n",
      "Epoch [1/30], Batch [13200/20508], Loss: 0.7324\n",
      "Epoch [1/30], Batch [13210/20508], Loss: 0.7338\n",
      "Epoch [1/30], Batch [13220/20508], Loss: 0.7548\n",
      "Epoch [1/30], Batch [13230/20508], Loss: 0.7564\n",
      "Epoch [1/30], Batch [13240/20508], Loss: 0.7684\n",
      "Epoch [1/30], Batch [13250/20508], Loss: 0.7124\n",
      "Epoch [1/30], Batch [13260/20508], Loss: 0.7479\n",
      "Epoch [1/30], Batch [13270/20508], Loss: 0.7176\n",
      "Epoch [1/30], Batch [13280/20508], Loss: 0.6893\n",
      "Epoch [1/30], Batch [13290/20508], Loss: 0.7573\n",
      "Epoch [1/30], Batch [13300/20508], Loss: 0.7241\n",
      "Epoch [1/30], Batch [13310/20508], Loss: 0.6844\n",
      "Epoch [1/30], Batch [13320/20508], Loss: 0.7240\n",
      "Epoch [1/30], Batch [13330/20508], Loss: 0.6935\n",
      "Epoch [1/30], Batch [13340/20508], Loss: 0.6872\n",
      "Epoch [1/30], Batch [13350/20508], Loss: 0.7381\n",
      "Epoch [1/30], Batch [13360/20508], Loss: 0.7105\n",
      "Epoch [1/30], Batch [13370/20508], Loss: 0.6806\n",
      "Epoch [1/30], Batch [13380/20508], Loss: 0.7214\n",
      "Epoch [1/30], Batch [13390/20508], Loss: 0.7306\n",
      "Epoch [1/30], Batch [13400/20508], Loss: 0.7444\n",
      "Epoch [1/30], Batch [13410/20508], Loss: 0.7256\n",
      "Epoch [1/30], Batch [13420/20508], Loss: 0.6987\n",
      "Epoch [1/30], Batch [13430/20508], Loss: 0.7136\n",
      "Epoch [1/30], Batch [13440/20508], Loss: 0.7216\n",
      "Epoch [1/30], Batch [13450/20508], Loss: 0.7218\n",
      "Epoch [1/30], Batch [13460/20508], Loss: 0.7641\n",
      "Epoch [1/30], Batch [13470/20508], Loss: 0.7363\n",
      "Epoch [1/30], Batch [13480/20508], Loss: 0.7287\n",
      "Epoch [1/30], Batch [13490/20508], Loss: 0.6977\n",
      "Epoch [1/30], Batch [13500/20508], Loss: 0.7338\n",
      "Epoch [1/30], Batch [13510/20508], Loss: 0.6737\n",
      "Epoch [1/30], Batch [13520/20508], Loss: 0.7762\n",
      "Epoch [1/30], Batch [13530/20508], Loss: 0.7856\n",
      "Epoch [1/30], Batch [13540/20508], Loss: 0.7638\n",
      "Epoch [1/30], Batch [13550/20508], Loss: 0.7661\n",
      "Epoch [1/30], Batch [13560/20508], Loss: 0.7195\n",
      "Epoch [1/30], Batch [13570/20508], Loss: 0.7240\n",
      "Epoch [1/30], Batch [13580/20508], Loss: 0.7242\n",
      "Epoch [1/30], Batch [13590/20508], Loss: 0.7540\n",
      "Epoch [1/30], Batch [13600/20508], Loss: 0.6954\n",
      "Epoch [1/30], Batch [13610/20508], Loss: 0.7071\n",
      "Epoch [1/30], Batch [13620/20508], Loss: 0.7656\n",
      "Epoch [1/30], Batch [13630/20508], Loss: 0.7544\n",
      "Epoch [1/30], Batch [13640/20508], Loss: 0.7261\n",
      "Epoch [1/30], Batch [13650/20508], Loss: 0.7067\n",
      "Epoch [1/30], Batch [13660/20508], Loss: 0.7345\n",
      "Epoch [1/30], Batch [13670/20508], Loss: 0.7217\n",
      "Epoch [1/30], Batch [13680/20508], Loss: 0.7670\n",
      "Epoch [1/30], Batch [13690/20508], Loss: 0.7356\n",
      "Epoch [1/30], Batch [13700/20508], Loss: 0.7188\n",
      "Epoch [1/30], Batch [13710/20508], Loss: 0.7204\n",
      "Epoch [1/30], Batch [13720/20508], Loss: 0.7320\n",
      "Epoch [1/30], Batch [13730/20508], Loss: 0.7634\n",
      "Epoch [1/30], Batch [13740/20508], Loss: 0.7715\n",
      "Epoch [1/30], Batch [13750/20508], Loss: 0.7310\n",
      "Epoch [1/30], Batch [13760/20508], Loss: 0.7166\n",
      "Epoch [1/30], Batch [13770/20508], Loss: 0.7519\n",
      "Epoch [1/30], Batch [13780/20508], Loss: 0.7707\n",
      "Epoch [1/30], Batch [13790/20508], Loss: 0.7120\n",
      "Epoch [1/30], Batch [13800/20508], Loss: 0.7267\n",
      "Epoch [1/30], Batch [13810/20508], Loss: 0.6864\n",
      "Epoch [1/30], Batch [13820/20508], Loss: 0.7753\n",
      "Epoch [1/30], Batch [13830/20508], Loss: 0.7063\n",
      "Epoch [1/30], Batch [13840/20508], Loss: 0.6976\n",
      "Epoch [1/30], Batch [13850/20508], Loss: 0.7589\n",
      "Epoch [1/30], Batch [13860/20508], Loss: 0.7337\n",
      "Epoch [1/30], Batch [13870/20508], Loss: 0.7455\n",
      "Epoch [1/30], Batch [13880/20508], Loss: 0.7029\n",
      "Epoch [1/30], Batch [13890/20508], Loss: 0.7818\n",
      "Epoch [1/30], Batch [13900/20508], Loss: 0.7649\n",
      "Epoch [1/30], Batch [13910/20508], Loss: 0.7183\n",
      "Epoch [1/30], Batch [13920/20508], Loss: 0.7142\n",
      "Epoch [1/30], Batch [13930/20508], Loss: 0.7303\n",
      "Epoch [1/30], Batch [13940/20508], Loss: 0.7485\n",
      "Epoch [1/30], Batch [13950/20508], Loss: 0.7037\n",
      "Epoch [1/30], Batch [13960/20508], Loss: 0.7274\n",
      "Epoch [1/30], Batch [13970/20508], Loss: 0.7412\n",
      "Epoch [1/30], Batch [13980/20508], Loss: 0.7013\n",
      "Epoch [1/30], Batch [13990/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [14000/20508], Loss: 0.7292\n",
      "Epoch [1/30], Batch [14010/20508], Loss: 0.6703\n",
      "Epoch [1/30], Batch [14020/20508], Loss: 0.7034\n",
      "Epoch [1/30], Batch [14030/20508], Loss: 0.7351\n",
      "Epoch [1/30], Batch [14040/20508], Loss: 0.7615\n",
      "Epoch [1/30], Batch [14050/20508], Loss: 0.7399\n",
      "Epoch [1/30], Batch [14060/20508], Loss: 0.7575\n",
      "Epoch [1/30], Batch [14070/20508], Loss: 0.7433\n",
      "Epoch [1/30], Batch [14080/20508], Loss: 0.7731\n",
      "Epoch [1/30], Batch [14090/20508], Loss: 0.7514\n",
      "Epoch [1/30], Batch [14100/20508], Loss: 0.7190\n",
      "Epoch [1/30], Batch [14110/20508], Loss: 0.7146\n",
      "Epoch [1/30], Batch [14120/20508], Loss: 0.7329\n",
      "Epoch [1/30], Batch [14130/20508], Loss: 0.7509\n",
      "Epoch [1/30], Batch [14140/20508], Loss: 0.7256\n",
      "Epoch [1/30], Batch [14150/20508], Loss: 0.6825\n",
      "Epoch [1/30], Batch [14160/20508], Loss: 0.6954\n",
      "Epoch [1/30], Batch [14170/20508], Loss: 0.7754\n",
      "Epoch [1/30], Batch [14180/20508], Loss: 0.7295\n",
      "Epoch [1/30], Batch [14190/20508], Loss: 0.7240\n",
      "Epoch [1/30], Batch [14200/20508], Loss: 0.7282\n",
      "Epoch [1/30], Batch [14210/20508], Loss: 0.7812\n",
      "Epoch [1/30], Batch [14220/20508], Loss: 0.7443\n",
      "Epoch [1/30], Batch [14230/20508], Loss: 0.6894\n",
      "Epoch [1/30], Batch [14240/20508], Loss: 0.7807\n",
      "Epoch [1/30], Batch [14250/20508], Loss: 0.7120\n",
      "Epoch [1/30], Batch [14260/20508], Loss: 0.7335\n",
      "Epoch [1/30], Batch [14270/20508], Loss: 0.7476\n",
      "Epoch [1/30], Batch [14280/20508], Loss: 0.7412\n",
      "Epoch [1/30], Batch [14290/20508], Loss: 0.7037\n",
      "Epoch [1/30], Batch [14300/20508], Loss: 0.7326\n",
      "Epoch [1/30], Batch [14310/20508], Loss: 0.6832\n",
      "Epoch [1/30], Batch [14320/20508], Loss: 0.7839\n",
      "Epoch [1/30], Batch [14330/20508], Loss: 0.6969\n",
      "Epoch [1/30], Batch [14340/20508], Loss: 0.7020\n",
      "Epoch [1/30], Batch [14350/20508], Loss: 0.7208\n",
      "Epoch [1/30], Batch [14360/20508], Loss: 0.7402\n",
      "Epoch [1/30], Batch [14370/20508], Loss: 0.7345\n",
      "Epoch [1/30], Batch [14380/20508], Loss: 0.7474\n",
      "Epoch [1/30], Batch [14390/20508], Loss: 0.7525\n",
      "Epoch [1/30], Batch [14400/20508], Loss: 0.6963\n",
      "Epoch [1/30], Batch [14410/20508], Loss: 0.7291\n",
      "Epoch [1/30], Batch [14420/20508], Loss: 0.7493\n",
      "Epoch [1/30], Batch [14430/20508], Loss: 0.6970\n",
      "Epoch [1/30], Batch [14440/20508], Loss: 0.7156\n",
      "Epoch [1/30], Batch [14450/20508], Loss: 0.7311\n",
      "Epoch [1/30], Batch [14460/20508], Loss: 0.7406\n",
      "Epoch [1/30], Batch [14470/20508], Loss: 0.7071\n",
      "Epoch [1/30], Batch [14480/20508], Loss: 0.7390\n",
      "Epoch [1/30], Batch [14490/20508], Loss: 0.7216\n",
      "Epoch [1/30], Batch [14500/20508], Loss: 0.7921\n",
      "Epoch [1/30], Batch [14510/20508], Loss: 0.7320\n",
      "Epoch [1/30], Batch [14520/20508], Loss: 0.6943\n",
      "Epoch [1/30], Batch [14530/20508], Loss: 0.7808\n",
      "Epoch [1/30], Batch [14540/20508], Loss: 0.7332\n",
      "Epoch [1/30], Batch [14550/20508], Loss: 0.7800\n",
      "Epoch [1/30], Batch [14560/20508], Loss: 0.7600\n",
      "Epoch [1/30], Batch [14570/20508], Loss: 0.7619\n",
      "Epoch [1/30], Batch [14580/20508], Loss: 0.7019\n",
      "Epoch [1/30], Batch [14590/20508], Loss: 0.8004\n",
      "Epoch [1/30], Batch [14600/20508], Loss: 0.6930\n",
      "Epoch [1/30], Batch [14610/20508], Loss: 0.7677\n",
      "Epoch [1/30], Batch [14620/20508], Loss: 0.7406\n",
      "Epoch [1/30], Batch [14630/20508], Loss: 0.6883\n",
      "Epoch [1/30], Batch [14640/20508], Loss: 0.7314\n",
      "Epoch [1/30], Batch [14650/20508], Loss: 0.7556\n",
      "Epoch [1/30], Batch [14660/20508], Loss: 0.7652\n",
      "Epoch [1/30], Batch [14670/20508], Loss: 0.7351\n",
      "Epoch [1/30], Batch [14680/20508], Loss: 0.6939\n",
      "Epoch [1/30], Batch [14690/20508], Loss: 0.7860\n",
      "Epoch [1/30], Batch [14700/20508], Loss: 0.7408\n",
      "Epoch [1/30], Batch [14710/20508], Loss: 0.7206\n",
      "Epoch [1/30], Batch [14720/20508], Loss: 0.7467\n",
      "Epoch [1/30], Batch [14730/20508], Loss: 0.7404\n",
      "Epoch [1/30], Batch [14740/20508], Loss: 0.7402\n",
      "Epoch [1/30], Batch [14750/20508], Loss: 0.7518\n",
      "Epoch [1/30], Batch [14760/20508], Loss: 0.7037\n",
      "Epoch [1/30], Batch [14770/20508], Loss: 0.7324\n",
      "Epoch [1/30], Batch [14780/20508], Loss: 0.7093\n",
      "Epoch [1/30], Batch [14790/20508], Loss: 0.7334\n",
      "Epoch [1/30], Batch [14800/20508], Loss: 0.7312\n",
      "Epoch [1/30], Batch [14810/20508], Loss: 0.7413\n",
      "Epoch [1/30], Batch [14820/20508], Loss: 0.7661\n",
      "Epoch [1/30], Batch [14830/20508], Loss: 0.6954\n",
      "Epoch [1/30], Batch [14840/20508], Loss: 0.7665\n",
      "Epoch [1/30], Batch [14850/20508], Loss: 0.7325\n",
      "Epoch [1/30], Batch [14860/20508], Loss: 0.7090\n",
      "Epoch [1/30], Batch [14870/20508], Loss: 0.7062\n",
      "Epoch [1/30], Batch [14880/20508], Loss: 0.7251\n",
      "Epoch [1/30], Batch [14890/20508], Loss: 0.7618\n",
      "Epoch [1/30], Batch [14900/20508], Loss: 0.7252\n",
      "Epoch [1/30], Batch [14910/20508], Loss: 0.7442\n",
      "Epoch [1/30], Batch [14920/20508], Loss: 0.7009\n",
      "Epoch [1/30], Batch [14930/20508], Loss: 0.7089\n",
      "Epoch [1/30], Batch [14940/20508], Loss: 0.6874\n",
      "Epoch [1/30], Batch [14950/20508], Loss: 0.7472\n",
      "Epoch [1/30], Batch [14960/20508], Loss: 0.7241\n",
      "Epoch [1/30], Batch [14970/20508], Loss: 0.7158\n",
      "Epoch [1/30], Batch [14980/20508], Loss: 0.7435\n",
      "Epoch [1/30], Batch [14990/20508], Loss: 0.7430\n",
      "Epoch [1/30], Batch [15000/20508], Loss: 0.7717\n",
      "Epoch [1/30], Batch [15010/20508], Loss: 0.7508\n",
      "Epoch [1/30], Batch [15020/20508], Loss: 0.7013\n",
      "Epoch [1/30], Batch [15030/20508], Loss: 0.7253\n",
      "Epoch [1/30], Batch [15040/20508], Loss: 0.7895\n",
      "Epoch [1/30], Batch [15050/20508], Loss: 0.7152\n",
      "Epoch [1/30], Batch [15060/20508], Loss: 0.7098\n",
      "Epoch [1/30], Batch [15070/20508], Loss: 0.6984\n",
      "Epoch [1/30], Batch [15080/20508], Loss: 0.7202\n",
      "Epoch [1/30], Batch [15090/20508], Loss: 0.6727\n",
      "Epoch [1/30], Batch [15100/20508], Loss: 0.6941\n",
      "Epoch [1/30], Batch [15110/20508], Loss: 0.7253\n",
      "Epoch [1/30], Batch [15120/20508], Loss: 0.7150\n",
      "Epoch [1/30], Batch [15130/20508], Loss: 0.7665\n",
      "Epoch [1/30], Batch [15140/20508], Loss: 0.7292\n",
      "Epoch [1/30], Batch [15150/20508], Loss: 0.7286\n",
      "Epoch [1/30], Batch [15160/20508], Loss: 0.6862\n",
      "Epoch [1/30], Batch [15170/20508], Loss: 0.7286\n",
      "Epoch [1/30], Batch [15180/20508], Loss: 0.7229\n",
      "Epoch [1/30], Batch [15190/20508], Loss: 0.7137\n",
      "Epoch [1/30], Batch [15200/20508], Loss: 0.7095\n",
      "Epoch [1/30], Batch [15210/20508], Loss: 0.7376\n",
      "Epoch [1/30], Batch [15220/20508], Loss: 0.7292\n",
      "Epoch [1/30], Batch [15230/20508], Loss: 0.7361\n",
      "Epoch [1/30], Batch [15240/20508], Loss: 0.7318\n",
      "Epoch [1/30], Batch [15250/20508], Loss: 0.7061\n",
      "Epoch [1/30], Batch [15260/20508], Loss: 0.6937\n",
      "Epoch [1/30], Batch [15270/20508], Loss: 0.7366\n",
      "Epoch [1/30], Batch [15280/20508], Loss: 0.7273\n",
      "Epoch [1/30], Batch [15290/20508], Loss: 0.7341\n",
      "Epoch [1/30], Batch [15300/20508], Loss: 0.6881\n",
      "Epoch [1/30], Batch [15310/20508], Loss: 0.6700\n",
      "Epoch [1/30], Batch [15320/20508], Loss: 0.7058\n",
      "Epoch [1/30], Batch [15330/20508], Loss: 0.7270\n",
      "Epoch [1/30], Batch [15340/20508], Loss: 0.7503\n",
      "Epoch [1/30], Batch [15350/20508], Loss: 0.7354\n",
      "Epoch [1/30], Batch [15360/20508], Loss: 0.7495\n",
      "Epoch [1/30], Batch [15370/20508], Loss: 0.6925\n",
      "Epoch [1/30], Batch [15380/20508], Loss: 0.7447\n",
      "Epoch [1/30], Batch [15390/20508], Loss: 0.7512\n",
      "Epoch [1/30], Batch [15400/20508], Loss: 0.7126\n",
      "Epoch [1/30], Batch [15410/20508], Loss: 0.7285\n",
      "Epoch [1/30], Batch [15420/20508], Loss: 0.7272\n",
      "Epoch [1/30], Batch [15430/20508], Loss: 0.7377\n",
      "Epoch [1/30], Batch [15440/20508], Loss: 0.7549\n",
      "Epoch [1/30], Batch [15450/20508], Loss: 0.7235\n",
      "Epoch [1/30], Batch [15460/20508], Loss: 0.7354\n",
      "Epoch [1/30], Batch [15470/20508], Loss: 0.7412\n",
      "Epoch [1/30], Batch [15480/20508], Loss: 0.7074\n",
      "Epoch [1/30], Batch [15490/20508], Loss: 0.7702\n",
      "Epoch [1/30], Batch [15500/20508], Loss: 0.6951\n",
      "Epoch [1/30], Batch [15510/20508], Loss: 0.7558\n",
      "Epoch [1/30], Batch [15520/20508], Loss: 0.7436\n",
      "Epoch [1/30], Batch [15530/20508], Loss: 0.7337\n",
      "Epoch [1/30], Batch [15540/20508], Loss: 0.6804\n",
      "Epoch [1/30], Batch [15550/20508], Loss: 0.7443\n",
      "Epoch [1/30], Batch [15560/20508], Loss: 0.7179\n",
      "Epoch [1/30], Batch [15570/20508], Loss: 0.7309\n",
      "Epoch [1/30], Batch [15580/20508], Loss: 0.7213\n",
      "Epoch [1/30], Batch [15590/20508], Loss: 0.7138\n",
      "Epoch [1/30], Batch [15600/20508], Loss: 0.6923\n",
      "Epoch [1/30], Batch [15610/20508], Loss: 0.7176\n",
      "Epoch [1/30], Batch [15620/20508], Loss: 0.7061\n",
      "Epoch [1/30], Batch [15630/20508], Loss: 0.7124\n",
      "Epoch [1/30], Batch [15640/20508], Loss: 0.7171\n",
      "Epoch [1/30], Batch [15650/20508], Loss: 0.7116\n",
      "Epoch [1/30], Batch [15660/20508], Loss: 0.7568\n",
      "Epoch [1/30], Batch [15670/20508], Loss: 0.7039\n",
      "Epoch [1/30], Batch [15680/20508], Loss: 0.7101\n",
      "Epoch [1/30], Batch [15690/20508], Loss: 0.7119\n",
      "Epoch [1/30], Batch [15700/20508], Loss: 0.7031\n",
      "Epoch [1/30], Batch [15710/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [15720/20508], Loss: 0.7710\n",
      "Epoch [1/30], Batch [15730/20508], Loss: 0.7687\n",
      "Epoch [1/30], Batch [15740/20508], Loss: 0.7297\n",
      "Epoch [1/30], Batch [15750/20508], Loss: 0.6941\n",
      "Epoch [1/30], Batch [15760/20508], Loss: 0.7736\n",
      "Epoch [1/30], Batch [15770/20508], Loss: 0.7310\n",
      "Epoch [1/30], Batch [15780/20508], Loss: 0.6802\n",
      "Epoch [1/30], Batch [15790/20508], Loss: 0.7343\n",
      "Epoch [1/30], Batch [15800/20508], Loss: 0.7127\n",
      "Epoch [1/30], Batch [15810/20508], Loss: 0.7178\n",
      "Epoch [1/30], Batch [15820/20508], Loss: 0.7192\n",
      "Epoch [1/30], Batch [15830/20508], Loss: 0.7115\n",
      "Epoch [1/30], Batch [15840/20508], Loss: 0.6767\n",
      "Epoch [1/30], Batch [15850/20508], Loss: 0.7033\n",
      "Epoch [1/30], Batch [15860/20508], Loss: 0.7192\n",
      "Epoch [1/30], Batch [15870/20508], Loss: 0.7124\n",
      "Epoch [1/30], Batch [15880/20508], Loss: 0.7444\n",
      "Epoch [1/30], Batch [15890/20508], Loss: 0.7467\n",
      "Epoch [1/30], Batch [15900/20508], Loss: 0.7640\n",
      "Epoch [1/30], Batch [15910/20508], Loss: 0.6960\n",
      "Epoch [1/30], Batch [15920/20508], Loss: 0.7330\n",
      "Epoch [1/30], Batch [15930/20508], Loss: 0.7287\n",
      "Epoch [1/30], Batch [15940/20508], Loss: 0.6707\n",
      "Epoch [1/30], Batch [15950/20508], Loss: 0.7026\n",
      "Epoch [1/30], Batch [15960/20508], Loss: 0.6974\n",
      "Epoch [1/30], Batch [15970/20508], Loss: 0.6854\n",
      "Epoch [1/30], Batch [15980/20508], Loss: 0.7359\n",
      "Epoch [1/30], Batch [15990/20508], Loss: 0.7043\n",
      "Epoch [1/30], Batch [16000/20508], Loss: 0.7090\n",
      "Epoch [1/30], Batch [16010/20508], Loss: 0.7121\n",
      "Epoch [1/30], Batch [16020/20508], Loss: 0.7078\n",
      "Epoch [1/30], Batch [16030/20508], Loss: 0.6788\n",
      "Epoch [1/30], Batch [16040/20508], Loss: 0.7287\n",
      "Epoch [1/30], Batch [16050/20508], Loss: 0.7293\n",
      "Epoch [1/30], Batch [16060/20508], Loss: 0.6949\n",
      "Epoch [1/30], Batch [16070/20508], Loss: 0.7137\n",
      "Epoch [1/30], Batch [16080/20508], Loss: 0.7238\n",
      "Epoch [1/30], Batch [16090/20508], Loss: 0.7199\n",
      "Epoch [1/30], Batch [16100/20508], Loss: 0.7246\n",
      "Epoch [1/30], Batch [16110/20508], Loss: 0.7289\n",
      "Epoch [1/30], Batch [16120/20508], Loss: 0.7777\n",
      "Epoch [1/30], Batch [16130/20508], Loss: 0.6950\n",
      "Epoch [1/30], Batch [16140/20508], Loss: 0.6887\n",
      "Epoch [1/30], Batch [16150/20508], Loss: 0.7054\n",
      "Epoch [1/30], Batch [16160/20508], Loss: 0.7380\n",
      "Epoch [1/30], Batch [16170/20508], Loss: 0.7154\n",
      "Epoch [1/30], Batch [16180/20508], Loss: 0.7515\n",
      "Epoch [1/30], Batch [16190/20508], Loss: 0.7084\n",
      "Epoch [1/30], Batch [16200/20508], Loss: 0.7353\n",
      "Epoch [1/30], Batch [16210/20508], Loss: 0.6743\n",
      "Epoch [1/30], Batch [16220/20508], Loss: 0.6963\n",
      "Epoch [1/30], Batch [16230/20508], Loss: 0.7520\n",
      "Epoch [1/30], Batch [16240/20508], Loss: 0.7490\n",
      "Epoch [1/30], Batch [16250/20508], Loss: 0.7262\n",
      "Epoch [1/30], Batch [16260/20508], Loss: 0.7696\n",
      "Epoch [1/30], Batch [16270/20508], Loss: 0.7091\n",
      "Epoch [1/30], Batch [16280/20508], Loss: 0.6903\n",
      "Epoch [1/30], Batch [16290/20508], Loss: 0.7150\n",
      "Epoch [1/30], Batch [16300/20508], Loss: 0.7702\n",
      "Epoch [1/30], Batch [16310/20508], Loss: 0.7661\n",
      "Epoch [1/30], Batch [16320/20508], Loss: 0.6884\n",
      "Epoch [1/30], Batch [16330/20508], Loss: 0.6969\n",
      "Epoch [1/30], Batch [16340/20508], Loss: 0.7325\n",
      "Epoch [1/30], Batch [16350/20508], Loss: 0.7133\n",
      "Epoch [1/30], Batch [16360/20508], Loss: 0.7344\n",
      "Epoch [1/30], Batch [16370/20508], Loss: 0.7169\n",
      "Epoch [1/30], Batch [16380/20508], Loss: 0.7625\n",
      "Epoch [1/30], Batch [16390/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [16400/20508], Loss: 0.7059\n",
      "Epoch [1/30], Batch [16410/20508], Loss: 0.6788\n",
      "Epoch [1/30], Batch [16420/20508], Loss: 0.7650\n",
      "Epoch [1/30], Batch [16430/20508], Loss: 0.6944\n",
      "Epoch [1/30], Batch [16440/20508], Loss: 0.7205\n",
      "Epoch [1/30], Batch [16450/20508], Loss: 0.6601\n",
      "Epoch [1/30], Batch [16460/20508], Loss: 0.6691\n",
      "Epoch [1/30], Batch [16470/20508], Loss: 0.7236\n",
      "Epoch [1/30], Batch [16480/20508], Loss: 0.7284\n",
      "Epoch [1/30], Batch [16490/20508], Loss: 0.7487\n",
      "Epoch [1/30], Batch [16500/20508], Loss: 0.6878\n",
      "Epoch [1/30], Batch [16510/20508], Loss: 0.6977\n",
      "Epoch [1/30], Batch [16520/20508], Loss: 0.7063\n",
      "Epoch [1/30], Batch [16530/20508], Loss: 0.7558\n",
      "Epoch [1/30], Batch [16540/20508], Loss: 0.7450\n",
      "Epoch [1/30], Batch [16550/20508], Loss: 0.6785\n",
      "Epoch [1/30], Batch [16560/20508], Loss: 0.7308\n",
      "Epoch [1/30], Batch [16570/20508], Loss: 0.6907\n",
      "Epoch [1/30], Batch [16580/20508], Loss: 0.7433\n",
      "Epoch [1/30], Batch [16590/20508], Loss: 0.7511\n",
      "Epoch [1/30], Batch [16600/20508], Loss: 0.7798\n",
      "Epoch [1/30], Batch [16610/20508], Loss: 0.7582\n",
      "Epoch [1/30], Batch [16620/20508], Loss: 0.7429\n",
      "Epoch [1/30], Batch [16630/20508], Loss: 0.6906\n",
      "Epoch [1/30], Batch [16640/20508], Loss: 0.6863\n",
      "Epoch [1/30], Batch [16650/20508], Loss: 0.7393\n",
      "Epoch [1/30], Batch [16660/20508], Loss: 0.7535\n",
      "Epoch [1/30], Batch [16670/20508], Loss: 0.7478\n",
      "Epoch [1/30], Batch [16680/20508], Loss: 0.6742\n",
      "Epoch [1/30], Batch [16690/20508], Loss: 0.7200\n",
      "Epoch [1/30], Batch [16700/20508], Loss: 0.6896\n",
      "Epoch [1/30], Batch [16710/20508], Loss: 0.6853\n",
      "Epoch [1/30], Batch [16720/20508], Loss: 0.7159\n",
      "Epoch [1/30], Batch [16730/20508], Loss: 0.7434\n",
      "Epoch [1/30], Batch [16740/20508], Loss: 0.7245\n",
      "Epoch [1/30], Batch [16750/20508], Loss: 0.7466\n",
      "Epoch [1/30], Batch [16760/20508], Loss: 0.7596\n",
      "Epoch [1/30], Batch [16770/20508], Loss: 0.7197\n",
      "Epoch [1/30], Batch [16780/20508], Loss: 0.7027\n",
      "Epoch [1/30], Batch [16790/20508], Loss: 0.7374\n",
      "Epoch [1/30], Batch [16800/20508], Loss: 0.7279\n",
      "Epoch [1/30], Batch [16810/20508], Loss: 0.7206\n",
      "Epoch [1/30], Batch [16820/20508], Loss: 0.7399\n",
      "Epoch [1/30], Batch [16830/20508], Loss: 0.7037\n",
      "Epoch [1/30], Batch [16840/20508], Loss: 0.7089\n",
      "Epoch [1/30], Batch [16850/20508], Loss: 0.7046\n",
      "Epoch [1/30], Batch [16860/20508], Loss: 0.7091\n",
      "Epoch [1/30], Batch [16870/20508], Loss: 0.7100\n",
      "Epoch [1/30], Batch [16880/20508], Loss: 0.7173\n",
      "Epoch [1/30], Batch [16890/20508], Loss: 0.6952\n",
      "Epoch [1/30], Batch [16900/20508], Loss: 0.7250\n",
      "Epoch [1/30], Batch [16910/20508], Loss: 0.7243\n",
      "Epoch [1/30], Batch [16920/20508], Loss: 0.7545\n",
      "Epoch [1/30], Batch [16930/20508], Loss: 0.7626\n",
      "Epoch [1/30], Batch [16940/20508], Loss: 0.6998\n",
      "Epoch [1/30], Batch [16950/20508], Loss: 0.6871\n",
      "Epoch [1/30], Batch [16960/20508], Loss: 0.7388\n",
      "Epoch [1/30], Batch [16970/20508], Loss: 0.7738\n",
      "Epoch [1/30], Batch [16980/20508], Loss: 0.7275\n",
      "Epoch [1/30], Batch [16990/20508], Loss: 0.7424\n",
      "Epoch [1/30], Batch [17000/20508], Loss: 0.7184\n",
      "Epoch [1/30], Batch [17010/20508], Loss: 0.6909\n",
      "Epoch [1/30], Batch [17020/20508], Loss: 0.7563\n",
      "Epoch [1/30], Batch [17030/20508], Loss: 0.7003\n",
      "Epoch [1/30], Batch [17040/20508], Loss: 0.7035\n",
      "Epoch [1/30], Batch [17050/20508], Loss: 0.7201\n",
      "Epoch [1/30], Batch [17060/20508], Loss: 0.7189\n",
      "Epoch [1/30], Batch [17070/20508], Loss: 0.7331\n",
      "Epoch [1/30], Batch [17080/20508], Loss: 0.7222\n",
      "Epoch [1/30], Batch [17090/20508], Loss: 0.7240\n",
      "Epoch [1/30], Batch [17100/20508], Loss: 0.7013\n",
      "Epoch [1/30], Batch [17110/20508], Loss: 0.7234\n",
      "Epoch [1/30], Batch [17120/20508], Loss: 0.7545\n",
      "Epoch [1/30], Batch [17130/20508], Loss: 0.7175\n",
      "Epoch [1/30], Batch [17140/20508], Loss: 0.7305\n",
      "Epoch [1/30], Batch [17150/20508], Loss: 0.7046\n",
      "Epoch [1/30], Batch [17160/20508], Loss: 0.7059\n",
      "Epoch [1/30], Batch [17170/20508], Loss: 0.7324\n",
      "Epoch [1/30], Batch [17180/20508], Loss: 0.7402\n",
      "Epoch [1/30], Batch [17190/20508], Loss: 0.6841\n",
      "Epoch [1/30], Batch [17200/20508], Loss: 0.7057\n",
      "Epoch [1/30], Batch [17210/20508], Loss: 0.7026\n",
      "Epoch [1/30], Batch [17220/20508], Loss: 0.7221\n",
      "Epoch [1/30], Batch [17230/20508], Loss: 0.7443\n",
      "Epoch [1/30], Batch [17240/20508], Loss: 0.7269\n",
      "Epoch [1/30], Batch [17250/20508], Loss: 0.7727\n",
      "Epoch [1/30], Batch [17260/20508], Loss: 0.7641\n",
      "Epoch [1/30], Batch [17270/20508], Loss: 0.7024\n",
      "Epoch [1/30], Batch [17280/20508], Loss: 0.6923\n",
      "Epoch [1/30], Batch [17290/20508], Loss: 0.7151\n",
      "Epoch [1/30], Batch [17300/20508], Loss: 0.7335\n",
      "Epoch [1/30], Batch [17310/20508], Loss: 0.7160\n",
      "Epoch [1/30], Batch [17320/20508], Loss: 0.7048\n",
      "Epoch [1/30], Batch [17330/20508], Loss: 0.7230\n",
      "Epoch [1/30], Batch [17340/20508], Loss: 0.7190\n",
      "Epoch [1/30], Batch [17350/20508], Loss: 0.7000\n",
      "Epoch [1/30], Batch [17360/20508], Loss: 0.7248\n",
      "Epoch [1/30], Batch [17370/20508], Loss: 0.7083\n",
      "Epoch [1/30], Batch [17380/20508], Loss: 0.6928\n",
      "Epoch [1/30], Batch [17390/20508], Loss: 0.6792\n",
      "Epoch [1/30], Batch [17400/20508], Loss: 0.6794\n",
      "Epoch [1/30], Batch [17410/20508], Loss: 0.7299\n",
      "Epoch [1/30], Batch [17420/20508], Loss: 0.7606\n",
      "Epoch [1/30], Batch [17430/20508], Loss: 0.7199\n",
      "Epoch [1/30], Batch [17440/20508], Loss: 0.7210\n",
      "Epoch [1/30], Batch [17450/20508], Loss: 0.7472\n",
      "Epoch [1/30], Batch [17460/20508], Loss: 0.6939\n",
      "Epoch [1/30], Batch [17470/20508], Loss: 0.7057\n",
      "Epoch [1/30], Batch [17480/20508], Loss: 0.7245\n",
      "Epoch [1/30], Batch [17490/20508], Loss: 0.6930\n",
      "Epoch [1/30], Batch [17500/20508], Loss: 0.7297\n",
      "Epoch [1/30], Batch [17510/20508], Loss: 0.7078\n",
      "Epoch [1/30], Batch [17520/20508], Loss: 0.7008\n",
      "Epoch [1/30], Batch [17530/20508], Loss: 0.7016\n",
      "Epoch [1/30], Batch [17540/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [17550/20508], Loss: 0.7154\n",
      "Epoch [1/30], Batch [17560/20508], Loss: 0.7252\n",
      "Epoch [1/30], Batch [17570/20508], Loss: 0.7276\n",
      "Epoch [1/30], Batch [17580/20508], Loss: 0.7540\n",
      "Epoch [1/30], Batch [17590/20508], Loss: 0.6980\n",
      "Epoch [1/30], Batch [17600/20508], Loss: 0.7261\n",
      "Epoch [1/30], Batch [17610/20508], Loss: 0.6976\n",
      "Epoch [1/30], Batch [17620/20508], Loss: 0.6795\n",
      "Epoch [1/30], Batch [17630/20508], Loss: 0.7278\n",
      "Epoch [1/30], Batch [17640/20508], Loss: 0.7179\n",
      "Epoch [1/30], Batch [17650/20508], Loss: 0.7186\n",
      "Epoch [1/30], Batch [17660/20508], Loss: 0.7211\n",
      "Epoch [1/30], Batch [17670/20508], Loss: 0.7051\n",
      "Epoch [1/30], Batch [17680/20508], Loss: 0.7329\n",
      "Epoch [1/30], Batch [17690/20508], Loss: 0.7122\n",
      "Epoch [1/30], Batch [17700/20508], Loss: 0.7258\n",
      "Epoch [1/30], Batch [17710/20508], Loss: 0.7416\n",
      "Epoch [1/30], Batch [17720/20508], Loss: 0.6882\n",
      "Epoch [1/30], Batch [17730/20508], Loss: 0.7199\n",
      "Epoch [1/30], Batch [17740/20508], Loss: 0.7379\n",
      "Epoch [1/30], Batch [17750/20508], Loss: 0.7495\n",
      "Epoch [1/30], Batch [17760/20508], Loss: 0.7176\n",
      "Epoch [1/30], Batch [17770/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [17780/20508], Loss: 0.7254\n",
      "Epoch [1/30], Batch [17790/20508], Loss: 0.7291\n",
      "Epoch [1/30], Batch [17800/20508], Loss: 0.6971\n",
      "Epoch [1/30], Batch [17810/20508], Loss: 0.7095\n",
      "Epoch [1/30], Batch [17820/20508], Loss: 0.7154\n",
      "Epoch [1/30], Batch [17830/20508], Loss: 0.7074\n",
      "Epoch [1/30], Batch [17840/20508], Loss: 0.7348\n",
      "Epoch [1/30], Batch [17850/20508], Loss: 0.7027\n",
      "Epoch [1/30], Batch [17860/20508], Loss: 0.7357\n",
      "Epoch [1/30], Batch [17870/20508], Loss: 0.6990\n",
      "Epoch [1/30], Batch [17880/20508], Loss: 0.7004\n",
      "Epoch [1/30], Batch [17890/20508], Loss: 0.6754\n",
      "Epoch [1/30], Batch [17900/20508], Loss: 0.7234\n",
      "Epoch [1/30], Batch [17910/20508], Loss: 0.6905\n",
      "Epoch [1/30], Batch [17920/20508], Loss: 0.7159\n",
      "Epoch [1/30], Batch [17930/20508], Loss: 0.7219\n",
      "Epoch [1/30], Batch [17940/20508], Loss: 0.7132\n",
      "Epoch [1/30], Batch [17950/20508], Loss: 0.7329\n",
      "Epoch [1/30], Batch [17960/20508], Loss: 0.7314\n",
      "Epoch [1/30], Batch [17970/20508], Loss: 0.7079\n",
      "Epoch [1/30], Batch [17980/20508], Loss: 0.7069\n",
      "Epoch [1/30], Batch [17990/20508], Loss: 0.7541\n",
      "Epoch [1/30], Batch [18000/20508], Loss: 0.6820\n",
      "Epoch [1/30], Batch [18010/20508], Loss: 0.7254\n",
      "Epoch [1/30], Batch [18020/20508], Loss: 0.6673\n",
      "Epoch [1/30], Batch [18030/20508], Loss: 0.6907\n",
      "Epoch [1/30], Batch [18040/20508], Loss: 0.7204\n",
      "Epoch [1/30], Batch [18050/20508], Loss: 0.6581\n",
      "Epoch [1/30], Batch [18060/20508], Loss: 0.7466\n",
      "Epoch [1/30], Batch [18070/20508], Loss: 0.7428\n",
      "Epoch [1/30], Batch [18080/20508], Loss: 0.7085\n",
      "Epoch [1/30], Batch [18090/20508], Loss: 0.7378\n",
      "Epoch [1/30], Batch [18100/20508], Loss: 0.6863\n",
      "Epoch [1/30], Batch [18110/20508], Loss: 0.6826\n",
      "Epoch [1/30], Batch [18120/20508], Loss: 0.7591\n",
      "Epoch [1/30], Batch [18130/20508], Loss: 0.7065\n",
      "Epoch [1/30], Batch [18140/20508], Loss: 0.7414\n",
      "Epoch [1/30], Batch [18150/20508], Loss: 0.6911\n",
      "Epoch [1/30], Batch [18160/20508], Loss: 0.7011\n",
      "Epoch [1/30], Batch [18170/20508], Loss: 0.7156\n",
      "Epoch [1/30], Batch [18180/20508], Loss: 0.7018\n",
      "Epoch [1/30], Batch [18190/20508], Loss: 0.7204\n",
      "Epoch [1/30], Batch [18200/20508], Loss: 0.7211\n",
      "Epoch [1/30], Batch [18210/20508], Loss: 0.6936\n",
      "Epoch [1/30], Batch [18220/20508], Loss: 0.7472\n",
      "Epoch [1/30], Batch [18230/20508], Loss: 0.6903\n",
      "Epoch [1/30], Batch [18240/20508], Loss: 0.6984\n",
      "Epoch [1/30], Batch [18250/20508], Loss: 0.7009\n",
      "Epoch [1/30], Batch [18260/20508], Loss: 0.7022\n",
      "Epoch [1/30], Batch [18270/20508], Loss: 0.7263\n",
      "Epoch [1/30], Batch [18280/20508], Loss: 0.7148\n",
      "Epoch [1/30], Batch [18290/20508], Loss: 0.6769\n",
      "Epoch [1/30], Batch [18300/20508], Loss: 0.7608\n",
      "Epoch [1/30], Batch [18310/20508], Loss: 0.7199\n",
      "Epoch [1/30], Batch [18320/20508], Loss: 0.7184\n",
      "Epoch [1/30], Batch [18330/20508], Loss: 0.7006\n",
      "Epoch [1/30], Batch [18340/20508], Loss: 0.7343\n",
      "Epoch [1/30], Batch [18350/20508], Loss: 0.7257\n",
      "Epoch [1/30], Batch [18360/20508], Loss: 0.7170\n",
      "Epoch [1/30], Batch [18370/20508], Loss: 0.7299\n",
      "Epoch [1/30], Batch [18380/20508], Loss: 0.7285\n",
      "Epoch [1/30], Batch [18390/20508], Loss: 0.7191\n",
      "Epoch [1/30], Batch [18400/20508], Loss: 0.6908\n",
      "Epoch [1/30], Batch [18410/20508], Loss: 0.7340\n",
      "Epoch [1/30], Batch [18420/20508], Loss: 0.7197\n",
      "Epoch [1/30], Batch [18430/20508], Loss: 0.7155\n",
      "Epoch [1/30], Batch [18440/20508], Loss: 0.7373\n",
      "Epoch [1/30], Batch [18450/20508], Loss: 0.7299\n",
      "Epoch [1/30], Batch [18460/20508], Loss: 0.7124\n",
      "Epoch [1/30], Batch [18470/20508], Loss: 0.6974\n",
      "Epoch [1/30], Batch [18480/20508], Loss: 0.6969\n",
      "Epoch [1/30], Batch [18490/20508], Loss: 0.7035\n",
      "Epoch [1/30], Batch [18500/20508], Loss: 0.6972\n",
      "Epoch [1/30], Batch [18510/20508], Loss: 0.6586\n",
      "Epoch [1/30], Batch [18520/20508], Loss: 0.7158\n",
      "Epoch [1/30], Batch [18530/20508], Loss: 0.6892\n",
      "Epoch [1/30], Batch [18540/20508], Loss: 0.7389\n",
      "Epoch [1/30], Batch [18550/20508], Loss: 0.6940\n",
      "Epoch [1/30], Batch [18560/20508], Loss: 0.7265\n",
      "Epoch [1/30], Batch [18570/20508], Loss: 0.7380\n",
      "Epoch [1/30], Batch [18580/20508], Loss: 0.7238\n",
      "Epoch [1/30], Batch [18590/20508], Loss: 0.7255\n",
      "Epoch [1/30], Batch [18600/20508], Loss: 0.7189\n",
      "Epoch [1/30], Batch [18610/20508], Loss: 0.7560\n",
      "Epoch [1/30], Batch [18620/20508], Loss: 0.7352\n",
      "Epoch [1/30], Batch [18630/20508], Loss: 0.6693\n",
      "Epoch [1/30], Batch [18640/20508], Loss: 0.7015\n",
      "Epoch [1/30], Batch [18650/20508], Loss: 0.7260\n",
      "Epoch [1/30], Batch [18660/20508], Loss: 0.7285\n",
      "Epoch [1/30], Batch [18670/20508], Loss: 0.7080\n",
      "Epoch [1/30], Batch [18680/20508], Loss: 0.7084\n",
      "Epoch [1/30], Batch [18690/20508], Loss: 0.6862\n",
      "Epoch [1/30], Batch [18700/20508], Loss: 0.7072\n",
      "Epoch [1/30], Batch [18710/20508], Loss: 0.7168\n",
      "Epoch [1/30], Batch [18720/20508], Loss: 0.7136\n",
      "Epoch [1/30], Batch [18730/20508], Loss: 0.6952\n",
      "Epoch [1/30], Batch [18740/20508], Loss: 0.6838\n",
      "Epoch [1/30], Batch [18750/20508], Loss: 0.7028\n",
      "Epoch [1/30], Batch [18760/20508], Loss: 0.6985\n",
      "Epoch [1/30], Batch [18770/20508], Loss: 0.7485\n",
      "Epoch [1/30], Batch [18780/20508], Loss: 0.7582\n",
      "Epoch [1/30], Batch [18790/20508], Loss: 0.7398\n",
      "Epoch [1/30], Batch [18800/20508], Loss: 0.7037\n",
      "Epoch [1/30], Batch [18810/20508], Loss: 0.6784\n",
      "Epoch [1/30], Batch [18820/20508], Loss: 0.7167\n",
      "Epoch [1/30], Batch [18830/20508], Loss: 0.7315\n",
      "Epoch [1/30], Batch [18840/20508], Loss: 0.7556\n",
      "Epoch [1/30], Batch [18850/20508], Loss: 0.6953\n",
      "Epoch [1/30], Batch [18860/20508], Loss: 0.7021\n",
      "Epoch [1/30], Batch [18870/20508], Loss: 0.7234\n",
      "Epoch [1/30], Batch [18880/20508], Loss: 0.6674\n",
      "Epoch [1/30], Batch [18890/20508], Loss: 0.7058\n",
      "Epoch [1/30], Batch [18900/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [18910/20508], Loss: 0.7187\n",
      "Epoch [1/30], Batch [18920/20508], Loss: 0.7062\n",
      "Epoch [1/30], Batch [18930/20508], Loss: 0.7060\n",
      "Epoch [1/30], Batch [18940/20508], Loss: 0.7031\n",
      "Epoch [1/30], Batch [18950/20508], Loss: 0.6868\n",
      "Epoch [1/30], Batch [18960/20508], Loss: 0.6773\n",
      "Epoch [1/30], Batch [18970/20508], Loss: 0.7048\n",
      "Epoch [1/30], Batch [18980/20508], Loss: 0.7065\n",
      "Epoch [1/30], Batch [18990/20508], Loss: 0.6980\n",
      "Epoch [1/30], Batch [19000/20508], Loss: 0.6944\n",
      "Epoch [1/30], Batch [19010/20508], Loss: 0.7096\n",
      "Epoch [1/30], Batch [19020/20508], Loss: 0.6934\n",
      "Epoch [1/30], Batch [19030/20508], Loss: 0.6781\n",
      "Epoch [1/30], Batch [19040/20508], Loss: 0.7298\n",
      "Epoch [1/30], Batch [19050/20508], Loss: 0.7047\n",
      "Epoch [1/30], Batch [19060/20508], Loss: 0.7290\n",
      "Epoch [1/30], Batch [19070/20508], Loss: 0.6990\n",
      "Epoch [1/30], Batch [19080/20508], Loss: 0.7562\n",
      "Epoch [1/30], Batch [19090/20508], Loss: 0.7178\n",
      "Epoch [1/30], Batch [19100/20508], Loss: 0.7212\n",
      "Epoch [1/30], Batch [19110/20508], Loss: 0.7180\n",
      "Epoch [1/30], Batch [19120/20508], Loss: 0.7340\n",
      "Epoch [1/30], Batch [19130/20508], Loss: 0.7040\n",
      "Epoch [1/30], Batch [19140/20508], Loss: 0.7134\n",
      "Epoch [1/30], Batch [19150/20508], Loss: 0.7180\n",
      "Epoch [1/30], Batch [19160/20508], Loss: 0.7118\n",
      "Epoch [1/30], Batch [19170/20508], Loss: 0.7086\n",
      "Epoch [1/30], Batch [19180/20508], Loss: 0.6719\n",
      "Epoch [1/30], Batch [19190/20508], Loss: 0.7144\n",
      "Epoch [1/30], Batch [19200/20508], Loss: 0.6769\n",
      "Epoch [1/30], Batch [19210/20508], Loss: 0.7177\n",
      "Epoch [1/30], Batch [19220/20508], Loss: 0.7214\n",
      "Epoch [1/30], Batch [19230/20508], Loss: 0.7046\n",
      "Epoch [1/30], Batch [19240/20508], Loss: 0.6983\n",
      "Epoch [1/30], Batch [19250/20508], Loss: 0.7008\n",
      "Epoch [1/30], Batch [19260/20508], Loss: 0.7525\n",
      "Epoch [1/30], Batch [19270/20508], Loss: 0.7256\n",
      "Epoch [1/30], Batch [19280/20508], Loss: 0.7416\n",
      "Epoch [1/30], Batch [19290/20508], Loss: 0.7191\n",
      "Epoch [1/30], Batch [19300/20508], Loss: 0.7242\n",
      "Epoch [1/30], Batch [19310/20508], Loss: 0.6942\n",
      "Epoch [1/30], Batch [19320/20508], Loss: 0.7301\n",
      "Epoch [1/30], Batch [19330/20508], Loss: 0.7305\n",
      "Epoch [1/30], Batch [19340/20508], Loss: 0.6720\n",
      "Epoch [1/30], Batch [19350/20508], Loss: 0.7231\n",
      "Epoch [1/30], Batch [19360/20508], Loss: 0.7120\n",
      "Epoch [1/30], Batch [19370/20508], Loss: 0.7568\n",
      "Epoch [1/30], Batch [19380/20508], Loss: 0.7143\n",
      "Epoch [1/30], Batch [19390/20508], Loss: 0.7060\n",
      "Epoch [1/30], Batch [19400/20508], Loss: 0.7510\n",
      "Epoch [1/30], Batch [19410/20508], Loss: 0.7059\n",
      "Epoch [1/30], Batch [19420/20508], Loss: 0.7250\n",
      "Epoch [1/30], Batch [19430/20508], Loss: 0.7328\n",
      "Epoch [1/30], Batch [19440/20508], Loss: 0.7318\n",
      "Epoch [1/30], Batch [19450/20508], Loss: 0.6644\n",
      "Epoch [1/30], Batch [19460/20508], Loss: 0.7365\n",
      "Epoch [1/30], Batch [19470/20508], Loss: 0.6968\n",
      "Epoch [1/30], Batch [19480/20508], Loss: 0.7277\n",
      "Epoch [1/30], Batch [19490/20508], Loss: 0.7063\n",
      "Epoch [1/30], Batch [19500/20508], Loss: 0.7150\n",
      "Epoch [1/30], Batch [19510/20508], Loss: 0.7401\n",
      "Epoch [1/30], Batch [19520/20508], Loss: 0.7102\n",
      "Epoch [1/30], Batch [19530/20508], Loss: 0.6884\n",
      "Epoch [1/30], Batch [19540/20508], Loss: 0.7027\n",
      "Epoch [1/30], Batch [19550/20508], Loss: 0.7208\n",
      "Epoch [1/30], Batch [19560/20508], Loss: 0.7162\n",
      "Epoch [1/30], Batch [19570/20508], Loss: 0.7167\n",
      "Epoch [1/30], Batch [19580/20508], Loss: 0.7089\n",
      "Epoch [1/30], Batch [19590/20508], Loss: 0.7344\n",
      "Epoch [1/30], Batch [19600/20508], Loss: 0.7362\n",
      "Epoch [1/30], Batch [19610/20508], Loss: 0.7397\n",
      "Epoch [1/30], Batch [19620/20508], Loss: 0.7046\n",
      "Epoch [1/30], Batch [19630/20508], Loss: 0.7232\n",
      "Epoch [1/30], Batch [19640/20508], Loss: 0.6989\n",
      "Epoch [1/30], Batch [19650/20508], Loss: 0.7222\n",
      "Epoch [1/30], Batch [19660/20508], Loss: 0.7015\n",
      "Epoch [1/30], Batch [19670/20508], Loss: 0.7389\n",
      "Epoch [1/30], Batch [19680/20508], Loss: 0.7217\n",
      "Epoch [1/30], Batch [19690/20508], Loss: 0.7049\n",
      "Epoch [1/30], Batch [19700/20508], Loss: 0.7300\n",
      "Epoch [1/30], Batch [19710/20508], Loss: 0.7011\n",
      "Epoch [1/30], Batch [19720/20508], Loss: 0.7450\n",
      "Epoch [1/30], Batch [19730/20508], Loss: 0.7013\n",
      "Epoch [1/30], Batch [19740/20508], Loss: 0.7074\n",
      "Epoch [1/30], Batch [19750/20508], Loss: 0.7105\n",
      "Epoch [1/30], Batch [19760/20508], Loss: 0.7099\n",
      "Epoch [1/30], Batch [19770/20508], Loss: 0.6823\n",
      "Epoch [1/30], Batch [19780/20508], Loss: 0.7303\n",
      "Epoch [1/30], Batch [19790/20508], Loss: 0.6710\n",
      "Epoch [1/30], Batch [19800/20508], Loss: 0.7255\n",
      "Epoch [1/30], Batch [19810/20508], Loss: 0.7241\n",
      "Epoch [1/30], Batch [19820/20508], Loss: 0.7058\n",
      "Epoch [1/30], Batch [19830/20508], Loss: 0.7151\n",
      "Epoch [1/30], Batch [19840/20508], Loss: 0.7237\n",
      "Epoch [1/30], Batch [19850/20508], Loss: 0.6956\n",
      "Epoch [1/30], Batch [19860/20508], Loss: 0.6798\n",
      "Epoch [1/30], Batch [19870/20508], Loss: 0.6729\n",
      "Epoch [1/30], Batch [19880/20508], Loss: 0.6812\n",
      "Epoch [1/30], Batch [19890/20508], Loss: 0.7046\n",
      "Epoch [1/30], Batch [19900/20508], Loss: 0.6872\n",
      "Epoch [1/30], Batch [19910/20508], Loss: 0.6860\n",
      "Epoch [1/30], Batch [19920/20508], Loss: 0.6906\n",
      "Epoch [1/30], Batch [19930/20508], Loss: 0.7178\n",
      "Epoch [1/30], Batch [19940/20508], Loss: 0.7185\n",
      "Epoch [1/30], Batch [19950/20508], Loss: 0.7123\n",
      "Epoch [1/30], Batch [19960/20508], Loss: 0.6752\n",
      "Epoch [1/30], Batch [19970/20508], Loss: 0.6840\n",
      "Epoch [1/30], Batch [19980/20508], Loss: 0.7284\n",
      "Epoch [1/30], Batch [19990/20508], Loss: 0.7171\n",
      "Epoch [1/30], Batch [20000/20508], Loss: 0.7436\n",
      "Epoch [1/30], Batch [20010/20508], Loss: 0.6954\n",
      "Epoch [1/30], Batch [20020/20508], Loss: 0.7086\n",
      "Epoch [1/30], Batch [20030/20508], Loss: 0.7345\n",
      "Epoch [1/30], Batch [20040/20508], Loss: 0.7101\n",
      "Epoch [1/30], Batch [20050/20508], Loss: 0.7308\n",
      "Epoch [1/30], Batch [20060/20508], Loss: 0.7333\n",
      "Epoch [1/30], Batch [20070/20508], Loss: 0.7165\n",
      "Epoch [1/30], Batch [20080/20508], Loss: 0.6852\n",
      "Epoch [1/30], Batch [20090/20508], Loss: 0.6788\n",
      "Epoch [1/30], Batch [20100/20508], Loss: 0.6659\n",
      "Epoch [1/30], Batch [20110/20508], Loss: 0.7435\n",
      "Epoch [1/30], Batch [20120/20508], Loss: 0.7087\n",
      "Epoch [1/30], Batch [20130/20508], Loss: 0.7162\n",
      "Epoch [1/30], Batch [20140/20508], Loss: 0.7266\n",
      "Epoch [1/30], Batch [20150/20508], Loss: 0.7465\n",
      "Epoch [1/30], Batch [20160/20508], Loss: 0.6805\n",
      "Epoch [1/30], Batch [20170/20508], Loss: 0.6993\n",
      "Epoch [1/30], Batch [20180/20508], Loss: 0.6845\n",
      "Epoch [1/30], Batch [20190/20508], Loss: 0.7202\n",
      "Epoch [1/30], Batch [20200/20508], Loss: 0.7398\n",
      "Epoch [1/30], Batch [20210/20508], Loss: 0.6933\n",
      "Epoch [1/30], Batch [20220/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [20230/20508], Loss: 0.7193\n",
      "Epoch [1/30], Batch [20240/20508], Loss: 0.7045\n",
      "Epoch [1/30], Batch [20250/20508], Loss: 0.7045\n",
      "Epoch [1/30], Batch [20260/20508], Loss: 0.7266\n",
      "Epoch [1/30], Batch [20270/20508], Loss: 0.7322\n",
      "Epoch [1/30], Batch [20280/20508], Loss: 0.6990\n",
      "Epoch [1/30], Batch [20290/20508], Loss: 0.7142\n",
      "Epoch [1/30], Batch [20300/20508], Loss: 0.7199\n",
      "Epoch [1/30], Batch [20310/20508], Loss: 0.6901\n",
      "Epoch [1/30], Batch [20320/20508], Loss: 0.6968\n",
      "Epoch [1/30], Batch [20330/20508], Loss: 0.6766\n",
      "Epoch [1/30], Batch [20340/20508], Loss: 0.7027\n",
      "Epoch [1/30], Batch [20350/20508], Loss: 0.6914\n",
      "Epoch [1/30], Batch [20360/20508], Loss: 0.6992\n",
      "Epoch [1/30], Batch [20370/20508], Loss: 0.7168\n",
      "Epoch [1/30], Batch [20380/20508], Loss: 0.7114\n",
      "Epoch [1/30], Batch [20390/20508], Loss: 0.7143\n",
      "Epoch [1/30], Batch [20400/20508], Loss: 0.7132\n",
      "Epoch [1/30], Batch [20410/20508], Loss: 0.7303\n",
      "Epoch [1/30], Batch [20420/20508], Loss: 0.7012\n",
      "Epoch [1/30], Batch [20430/20508], Loss: 0.7302\n",
      "Epoch [1/30], Batch [20440/20508], Loss: 0.7212\n",
      "Epoch [1/30], Batch [20450/20508], Loss: 0.7125\n",
      "Epoch [1/30], Batch [20460/20508], Loss: 0.6976\n",
      "Epoch [1/30], Batch [20470/20508], Loss: 0.7308\n",
      "Epoch [1/30], Batch [20480/20508], Loss: 0.7495\n",
      "Epoch [1/30], Batch [20490/20508], Loss: 0.6612\n",
      "Epoch [1/30], Batch [20500/20508], Loss: 0.7203\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [1], Train Loss: 0.7871, Test Loss: 0.6886, Early Stopping Counter: 0\n",
      "\n",
      "\n",
      "\n",
      "Epoch [2/30], Batch [0/20508], Loss: 0.7268\n",
      "Epoch [2/30], Batch [10/20508], Loss: 0.7439\n",
      "Epoch [2/30], Batch [20/20508], Loss: 0.6738\n",
      "Epoch [2/30], Batch [30/20508], Loss: 0.7245\n",
      "Epoch [2/30], Batch [40/20508], Loss: 0.7087\n",
      "Epoch [2/30], Batch [50/20508], Loss: 0.6941\n",
      "Epoch [2/30], Batch [60/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [70/20508], Loss: 0.7093\n",
      "Epoch [2/30], Batch [80/20508], Loss: 0.7131\n",
      "Epoch [2/30], Batch [90/20508], Loss: 0.7191\n",
      "Epoch [2/30], Batch [100/20508], Loss: 0.7087\n",
      "Epoch [2/30], Batch [110/20508], Loss: 0.6894\n",
      "Epoch [2/30], Batch [120/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [130/20508], Loss: 0.7186\n",
      "Epoch [2/30], Batch [140/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [150/20508], Loss: 0.6968\n",
      "Epoch [2/30], Batch [160/20508], Loss: 0.7165\n",
      "Epoch [2/30], Batch [170/20508], Loss: 0.7017\n",
      "Epoch [2/30], Batch [180/20508], Loss: 0.7303\n",
      "Epoch [2/30], Batch [190/20508], Loss: 0.6833\n",
      "Epoch [2/30], Batch [200/20508], Loss: 0.7337\n",
      "Epoch [2/30], Batch [210/20508], Loss: 0.7544\n",
      "Epoch [2/30], Batch [220/20508], Loss: 0.7077\n",
      "Epoch [2/30], Batch [230/20508], Loss: 0.7375\n",
      "Epoch [2/30], Batch [240/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [250/20508], Loss: 0.7020\n",
      "Epoch [2/30], Batch [260/20508], Loss: 0.7213\n",
      "Epoch [2/30], Batch [270/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [280/20508], Loss: 0.7399\n",
      "Epoch [2/30], Batch [290/20508], Loss: 0.7083\n",
      "Epoch [2/30], Batch [300/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [310/20508], Loss: 0.7314\n",
      "Epoch [2/30], Batch [320/20508], Loss: 0.6924\n",
      "Epoch [2/30], Batch [330/20508], Loss: 0.7189\n",
      "Epoch [2/30], Batch [340/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [350/20508], Loss: 0.7291\n",
      "Epoch [2/30], Batch [360/20508], Loss: 0.6861\n",
      "Epoch [2/30], Batch [370/20508], Loss: 0.7445\n",
      "Epoch [2/30], Batch [380/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [390/20508], Loss: 0.7407\n",
      "Epoch [2/30], Batch [400/20508], Loss: 0.7015\n",
      "Epoch [2/30], Batch [410/20508], Loss: 0.6787\n",
      "Epoch [2/30], Batch [420/20508], Loss: 0.6922\n",
      "Epoch [2/30], Batch [430/20508], Loss: 0.6968\n",
      "Epoch [2/30], Batch [440/20508], Loss: 0.7272\n",
      "Epoch [2/30], Batch [450/20508], Loss: 0.6351\n",
      "Epoch [2/30], Batch [460/20508], Loss: 0.7391\n",
      "Epoch [2/30], Batch [470/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [480/20508], Loss: 0.7059\n",
      "Epoch [2/30], Batch [490/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [500/20508], Loss: 0.7235\n",
      "Epoch [2/30], Batch [510/20508], Loss: 0.6893\n",
      "Epoch [2/30], Batch [520/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [530/20508], Loss: 0.7334\n",
      "Epoch [2/30], Batch [540/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [550/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [560/20508], Loss: 0.7377\n",
      "Epoch [2/30], Batch [570/20508], Loss: 0.7337\n",
      "Epoch [2/30], Batch [580/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [590/20508], Loss: 0.7130\n",
      "Epoch [2/30], Batch [600/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [610/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [620/20508], Loss: 0.7280\n",
      "Epoch [2/30], Batch [630/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [640/20508], Loss: 0.7488\n",
      "Epoch [2/30], Batch [650/20508], Loss: 0.7211\n",
      "Epoch [2/30], Batch [660/20508], Loss: 0.6784\n",
      "Epoch [2/30], Batch [670/20508], Loss: 0.7132\n",
      "Epoch [2/30], Batch [680/20508], Loss: 0.7193\n",
      "Epoch [2/30], Batch [690/20508], Loss: 0.7280\n",
      "Epoch [2/30], Batch [700/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [710/20508], Loss: 0.6991\n",
      "Epoch [2/30], Batch [720/20508], Loss: 0.7321\n",
      "Epoch [2/30], Batch [730/20508], Loss: 0.6794\n",
      "Epoch [2/30], Batch [740/20508], Loss: 0.7275\n",
      "Epoch [2/30], Batch [750/20508], Loss: 0.7479\n",
      "Epoch [2/30], Batch [760/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [770/20508], Loss: 0.7161\n",
      "Epoch [2/30], Batch [780/20508], Loss: 0.6651\n",
      "Epoch [2/30], Batch [790/20508], Loss: 0.6755\n",
      "Epoch [2/30], Batch [800/20508], Loss: 0.6936\n",
      "Epoch [2/30], Batch [810/20508], Loss: 0.7127\n",
      "Epoch [2/30], Batch [820/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [830/20508], Loss: 0.6821\n",
      "Epoch [2/30], Batch [840/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [850/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [860/20508], Loss: 0.7188\n",
      "Epoch [2/30], Batch [870/20508], Loss: 0.6833\n",
      "Epoch [2/30], Batch [880/20508], Loss: 0.6863\n",
      "Epoch [2/30], Batch [890/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [900/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [910/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [920/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [930/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [940/20508], Loss: 0.7139\n",
      "Epoch [2/30], Batch [950/20508], Loss: 0.7186\n",
      "Epoch [2/30], Batch [960/20508], Loss: 0.6945\n",
      "Epoch [2/30], Batch [970/20508], Loss: 0.7266\n",
      "Epoch [2/30], Batch [980/20508], Loss: 0.7355\n",
      "Epoch [2/30], Batch [990/20508], Loss: 0.7205\n",
      "Epoch [2/30], Batch [1000/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [1010/20508], Loss: 0.7267\n",
      "Epoch [2/30], Batch [1020/20508], Loss: 0.7235\n",
      "Epoch [2/30], Batch [1030/20508], Loss: 0.7254\n",
      "Epoch [2/30], Batch [1040/20508], Loss: 0.7093\n",
      "Epoch [2/30], Batch [1050/20508], Loss: 0.7220\n",
      "Epoch [2/30], Batch [1060/20508], Loss: 0.6805\n",
      "Epoch [2/30], Batch [1070/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [1080/20508], Loss: 0.7177\n",
      "Epoch [2/30], Batch [1090/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [1100/20508], Loss: 0.7025\n",
      "Epoch [2/30], Batch [1110/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [1120/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [1130/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [1140/20508], Loss: 0.7153\n",
      "Epoch [2/30], Batch [1150/20508], Loss: 0.7067\n",
      "Epoch [2/30], Batch [1160/20508], Loss: 0.7238\n",
      "Epoch [2/30], Batch [1170/20508], Loss: 0.7208\n",
      "Epoch [2/30], Batch [1180/20508], Loss: 0.6919\n",
      "Epoch [2/30], Batch [1190/20508], Loss: 0.7463\n",
      "Epoch [2/30], Batch [1200/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [1210/20508], Loss: 0.7104\n",
      "Epoch [2/30], Batch [1220/20508], Loss: 0.7338\n",
      "Epoch [2/30], Batch [1230/20508], Loss: 0.6969\n",
      "Epoch [2/30], Batch [1240/20508], Loss: 0.7475\n",
      "Epoch [2/30], Batch [1250/20508], Loss: 0.7044\n",
      "Epoch [2/30], Batch [1260/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [1270/20508], Loss: 0.6855\n",
      "Epoch [2/30], Batch [1280/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [1290/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [1300/20508], Loss: 0.7094\n",
      "Epoch [2/30], Batch [1310/20508], Loss: 0.7263\n",
      "Epoch [2/30], Batch [1320/20508], Loss: 0.7005\n",
      "Epoch [2/30], Batch [1330/20508], Loss: 0.6944\n",
      "Epoch [2/30], Batch [1340/20508], Loss: 0.7037\n",
      "Epoch [2/30], Batch [1350/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [1360/20508], Loss: 0.7082\n",
      "Epoch [2/30], Batch [1370/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [1380/20508], Loss: 0.6672\n",
      "Epoch [2/30], Batch [1390/20508], Loss: 0.7386\n",
      "Epoch [2/30], Batch [1400/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [1410/20508], Loss: 0.7184\n",
      "Epoch [2/30], Batch [1420/20508], Loss: 0.7145\n",
      "Epoch [2/30], Batch [1430/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [1440/20508], Loss: 0.7535\n",
      "Epoch [2/30], Batch [1450/20508], Loss: 0.7050\n",
      "Epoch [2/30], Batch [1460/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [1470/20508], Loss: 0.6634\n",
      "Epoch [2/30], Batch [1480/20508], Loss: 0.6917\n",
      "Epoch [2/30], Batch [1490/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [1500/20508], Loss: 0.6716\n",
      "Epoch [2/30], Batch [1510/20508], Loss: 0.7484\n",
      "Epoch [2/30], Batch [1520/20508], Loss: 0.6676\n",
      "Epoch [2/30], Batch [1530/20508], Loss: 0.6717\n",
      "Epoch [2/30], Batch [1540/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [1550/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [1560/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [1570/20508], Loss: 0.6689\n",
      "Epoch [2/30], Batch [1580/20508], Loss: 0.6789\n",
      "Epoch [2/30], Batch [1590/20508], Loss: 0.6948\n",
      "Epoch [2/30], Batch [1600/20508], Loss: 0.6924\n",
      "Epoch [2/30], Batch [1610/20508], Loss: 0.6954\n",
      "Epoch [2/30], Batch [1620/20508], Loss: 0.7128\n",
      "Epoch [2/30], Batch [1630/20508], Loss: 0.6896\n",
      "Epoch [2/30], Batch [1640/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [1650/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [1660/20508], Loss: 0.6562\n",
      "Epoch [2/30], Batch [1670/20508], Loss: 0.7243\n",
      "Epoch [2/30], Batch [1680/20508], Loss: 0.7303\n",
      "Epoch [2/30], Batch [1690/20508], Loss: 0.6854\n",
      "Epoch [2/30], Batch [1700/20508], Loss: 0.7117\n",
      "Epoch [2/30], Batch [1710/20508], Loss: 0.6900\n",
      "Epoch [2/30], Batch [1720/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [1730/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [1740/20508], Loss: 0.7062\n",
      "Epoch [2/30], Batch [1750/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [1760/20508], Loss: 0.7177\n",
      "Epoch [2/30], Batch [1770/20508], Loss: 0.6895\n",
      "Epoch [2/30], Batch [1780/20508], Loss: 0.7056\n",
      "Epoch [2/30], Batch [1790/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [1800/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [1810/20508], Loss: 0.7652\n",
      "Epoch [2/30], Batch [1820/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [1830/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [1840/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [1850/20508], Loss: 0.7263\n",
      "Epoch [2/30], Batch [1860/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [1870/20508], Loss: 0.7033\n",
      "Epoch [2/30], Batch [1880/20508], Loss: 0.6756\n",
      "Epoch [2/30], Batch [1890/20508], Loss: 0.6782\n",
      "Epoch [2/30], Batch [1900/20508], Loss: 0.7090\n",
      "Epoch [2/30], Batch [1910/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [1920/20508], Loss: 0.7356\n",
      "Epoch [2/30], Batch [1930/20508], Loss: 0.6838\n",
      "Epoch [2/30], Batch [1940/20508], Loss: 0.7218\n",
      "Epoch [2/30], Batch [1950/20508], Loss: 0.6884\n",
      "Epoch [2/30], Batch [1960/20508], Loss: 0.7120\n",
      "Epoch [2/30], Batch [1970/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [1980/20508], Loss: 0.7180\n",
      "Epoch [2/30], Batch [1990/20508], Loss: 0.6738\n",
      "Epoch [2/30], Batch [2000/20508], Loss: 0.7446\n",
      "Epoch [2/30], Batch [2010/20508], Loss: 0.7699\n",
      "Epoch [2/30], Batch [2020/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [2030/20508], Loss: 0.6527\n",
      "Epoch [2/30], Batch [2040/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [2050/20508], Loss: 0.6862\n",
      "Epoch [2/30], Batch [2060/20508], Loss: 0.6959\n",
      "Epoch [2/30], Batch [2070/20508], Loss: 0.7054\n",
      "Epoch [2/30], Batch [2080/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [2090/20508], Loss: 0.7102\n",
      "Epoch [2/30], Batch [2100/20508], Loss: 0.6731\n",
      "Epoch [2/30], Batch [2110/20508], Loss: 0.7154\n",
      "Epoch [2/30], Batch [2120/20508], Loss: 0.6877\n",
      "Epoch [2/30], Batch [2130/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [2140/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [2150/20508], Loss: 0.7316\n",
      "Epoch [2/30], Batch [2160/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [2170/20508], Loss: 0.7312\n",
      "Epoch [2/30], Batch [2180/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [2190/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [2200/20508], Loss: 0.7153\n",
      "Epoch [2/30], Batch [2210/20508], Loss: 0.7811\n",
      "Epoch [2/30], Batch [2220/20508], Loss: 0.6897\n",
      "Epoch [2/30], Batch [2230/20508], Loss: 0.7035\n",
      "Epoch [2/30], Batch [2240/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [2250/20508], Loss: 0.6903\n",
      "Epoch [2/30], Batch [2260/20508], Loss: 0.7129\n",
      "Epoch [2/30], Batch [2270/20508], Loss: 0.7043\n",
      "Epoch [2/30], Batch [2280/20508], Loss: 0.7182\n",
      "Epoch [2/30], Batch [2290/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [2300/20508], Loss: 0.7273\n",
      "Epoch [2/30], Batch [2310/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [2320/20508], Loss: 0.6740\n",
      "Epoch [2/30], Batch [2330/20508], Loss: 0.6880\n",
      "Epoch [2/30], Batch [2340/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [2350/20508], Loss: 0.7209\n",
      "Epoch [2/30], Batch [2360/20508], Loss: 0.7019\n",
      "Epoch [2/30], Batch [2370/20508], Loss: 0.6784\n",
      "Epoch [2/30], Batch [2380/20508], Loss: 0.6969\n",
      "Epoch [2/30], Batch [2390/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [2400/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [2410/20508], Loss: 0.7379\n",
      "Epoch [2/30], Batch [2420/20508], Loss: 0.6996\n",
      "Epoch [2/30], Batch [2430/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [2440/20508], Loss: 0.7329\n",
      "Epoch [2/30], Batch [2450/20508], Loss: 0.7178\n",
      "Epoch [2/30], Batch [2460/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [2470/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [2480/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [2490/20508], Loss: 0.7127\n",
      "Epoch [2/30], Batch [2500/20508], Loss: 0.7333\n",
      "Epoch [2/30], Batch [2510/20508], Loss: 0.7027\n",
      "Epoch [2/30], Batch [2520/20508], Loss: 0.7214\n",
      "Epoch [2/30], Batch [2530/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [2540/20508], Loss: 0.7299\n",
      "Epoch [2/30], Batch [2550/20508], Loss: 0.7110\n",
      "Epoch [2/30], Batch [2560/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [2570/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [2580/20508], Loss: 0.7322\n",
      "Epoch [2/30], Batch [2590/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [2600/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [2610/20508], Loss: 0.7039\n",
      "Epoch [2/30], Batch [2620/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [2630/20508], Loss: 0.6981\n",
      "Epoch [2/30], Batch [2640/20508], Loss: 0.7230\n",
      "Epoch [2/30], Batch [2650/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [2660/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [2670/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [2680/20508], Loss: 0.7241\n",
      "Epoch [2/30], Batch [2690/20508], Loss: 0.6917\n",
      "Epoch [2/30], Batch [2700/20508], Loss: 0.7270\n",
      "Epoch [2/30], Batch [2710/20508], Loss: 0.7065\n",
      "Epoch [2/30], Batch [2720/20508], Loss: 0.6977\n",
      "Epoch [2/30], Batch [2730/20508], Loss: 0.6836\n",
      "Epoch [2/30], Batch [2740/20508], Loss: 0.7132\n",
      "Epoch [2/30], Batch [2750/20508], Loss: 0.6886\n",
      "Epoch [2/30], Batch [2760/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [2770/20508], Loss: 0.7173\n",
      "Epoch [2/30], Batch [2780/20508], Loss: 0.7063\n",
      "Epoch [2/30], Batch [2790/20508], Loss: 0.7031\n",
      "Epoch [2/30], Batch [2800/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [2810/20508], Loss: 0.6763\n",
      "Epoch [2/30], Batch [2820/20508], Loss: 0.7335\n",
      "Epoch [2/30], Batch [2830/20508], Loss: 0.7366\n",
      "Epoch [2/30], Batch [2840/20508], Loss: 0.7239\n",
      "Epoch [2/30], Batch [2850/20508], Loss: 0.6884\n",
      "Epoch [2/30], Batch [2860/20508], Loss: 0.7145\n",
      "Epoch [2/30], Batch [2870/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [2880/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [2890/20508], Loss: 0.6703\n",
      "Epoch [2/30], Batch [2900/20508], Loss: 0.7267\n",
      "Epoch [2/30], Batch [2910/20508], Loss: 0.7186\n",
      "Epoch [2/30], Batch [2920/20508], Loss: 0.7338\n",
      "Epoch [2/30], Batch [2930/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [2940/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [2950/20508], Loss: 0.7360\n",
      "Epoch [2/30], Batch [2960/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [2970/20508], Loss: 0.7054\n",
      "Epoch [2/30], Batch [2980/20508], Loss: 0.7078\n",
      "Epoch [2/30], Batch [2990/20508], Loss: 0.7209\n",
      "Epoch [2/30], Batch [3000/20508], Loss: 0.6949\n",
      "Epoch [2/30], Batch [3010/20508], Loss: 0.7184\n",
      "Epoch [2/30], Batch [3020/20508], Loss: 0.7257\n",
      "Epoch [2/30], Batch [3030/20508], Loss: 0.7054\n",
      "Epoch [2/30], Batch [3040/20508], Loss: 0.6942\n",
      "Epoch [2/30], Batch [3050/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [3060/20508], Loss: 0.7117\n",
      "Epoch [2/30], Batch [3070/20508], Loss: 0.7017\n",
      "Epoch [2/30], Batch [3080/20508], Loss: 0.7139\n",
      "Epoch [2/30], Batch [3090/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [3100/20508], Loss: 0.7129\n",
      "Epoch [2/30], Batch [3110/20508], Loss: 0.6983\n",
      "Epoch [2/30], Batch [3120/20508], Loss: 0.6795\n",
      "Epoch [2/30], Batch [3130/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [3140/20508], Loss: 0.7088\n",
      "Epoch [2/30], Batch [3150/20508], Loss: 0.6811\n",
      "Epoch [2/30], Batch [3160/20508], Loss: 0.7064\n",
      "Epoch [2/30], Batch [3170/20508], Loss: 0.6770\n",
      "Epoch [2/30], Batch [3180/20508], Loss: 0.7073\n",
      "Epoch [2/30], Batch [3190/20508], Loss: 0.6991\n",
      "Epoch [2/30], Batch [3200/20508], Loss: 0.6992\n",
      "Epoch [2/30], Batch [3210/20508], Loss: 0.6973\n",
      "Epoch [2/30], Batch [3220/20508], Loss: 0.7115\n",
      "Epoch [2/30], Batch [3230/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [3240/20508], Loss: 0.7083\n",
      "Epoch [2/30], Batch [3250/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [3260/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [3270/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [3280/20508], Loss: 0.7300\n",
      "Epoch [2/30], Batch [3290/20508], Loss: 0.6928\n",
      "Epoch [2/30], Batch [3300/20508], Loss: 0.7078\n",
      "Epoch [2/30], Batch [3310/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [3320/20508], Loss: 0.6968\n",
      "Epoch [2/30], Batch [3330/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [3340/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [3350/20508], Loss: 0.6791\n",
      "Epoch [2/30], Batch [3360/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [3370/20508], Loss: 0.6805\n",
      "Epoch [2/30], Batch [3380/20508], Loss: 0.7093\n",
      "Epoch [2/30], Batch [3390/20508], Loss: 0.6893\n",
      "Epoch [2/30], Batch [3400/20508], Loss: 0.6942\n",
      "Epoch [2/30], Batch [3410/20508], Loss: 0.7381\n",
      "Epoch [2/30], Batch [3420/20508], Loss: 0.7002\n",
      "Epoch [2/30], Batch [3430/20508], Loss: 0.6806\n",
      "Epoch [2/30], Batch [3440/20508], Loss: 0.6757\n",
      "Epoch [2/30], Batch [3450/20508], Loss: 0.6769\n",
      "Epoch [2/30], Batch [3460/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [3470/20508], Loss: 0.6828\n",
      "Epoch [2/30], Batch [3480/20508], Loss: 0.6823\n",
      "Epoch [2/30], Batch [3490/20508], Loss: 0.6813\n",
      "Epoch [2/30], Batch [3500/20508], Loss: 0.6864\n",
      "Epoch [2/30], Batch [3510/20508], Loss: 0.7197\n",
      "Epoch [2/30], Batch [3520/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [3530/20508], Loss: 0.7172\n",
      "Epoch [2/30], Batch [3540/20508], Loss: 0.7075\n",
      "Epoch [2/30], Batch [3550/20508], Loss: 0.6689\n",
      "Epoch [2/30], Batch [3560/20508], Loss: 0.7086\n",
      "Epoch [2/30], Batch [3570/20508], Loss: 0.6647\n",
      "Epoch [2/30], Batch [3580/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [3590/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [3600/20508], Loss: 0.7202\n",
      "Epoch [2/30], Batch [3610/20508], Loss: 0.7193\n",
      "Epoch [2/30], Batch [3620/20508], Loss: 0.7316\n",
      "Epoch [2/30], Batch [3630/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [3640/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [3650/20508], Loss: 0.7157\n",
      "Epoch [2/30], Batch [3660/20508], Loss: 0.6750\n",
      "Epoch [2/30], Batch [3670/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [3680/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [3690/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [3700/20508], Loss: 0.7092\n",
      "Epoch [2/30], Batch [3710/20508], Loss: 0.7154\n",
      "Epoch [2/30], Batch [3720/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [3730/20508], Loss: 0.7090\n",
      "Epoch [2/30], Batch [3740/20508], Loss: 0.6775\n",
      "Epoch [2/30], Batch [3750/20508], Loss: 0.6830\n",
      "Epoch [2/30], Batch [3760/20508], Loss: 0.7293\n",
      "Epoch [2/30], Batch [3770/20508], Loss: 0.7117\n",
      "Epoch [2/30], Batch [3780/20508], Loss: 0.6863\n",
      "Epoch [2/30], Batch [3790/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [3800/20508], Loss: 0.7037\n",
      "Epoch [2/30], Batch [3810/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [3820/20508], Loss: 0.6797\n",
      "Epoch [2/30], Batch [3830/20508], Loss: 0.7074\n",
      "Epoch [2/30], Batch [3840/20508], Loss: 0.7155\n",
      "Epoch [2/30], Batch [3850/20508], Loss: 0.7156\n",
      "Epoch [2/30], Batch [3860/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [3870/20508], Loss: 0.6988\n",
      "Epoch [2/30], Batch [3880/20508], Loss: 0.7189\n",
      "Epoch [2/30], Batch [3890/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [3900/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [3910/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [3920/20508], Loss: 0.7144\n",
      "Epoch [2/30], Batch [3930/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [3940/20508], Loss: 0.6876\n",
      "Epoch [2/30], Batch [3950/20508], Loss: 0.7321\n",
      "Epoch [2/30], Batch [3960/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [3970/20508], Loss: 0.7083\n",
      "Epoch [2/30], Batch [3980/20508], Loss: 0.7238\n",
      "Epoch [2/30], Batch [3990/20508], Loss: 0.7316\n",
      "Epoch [2/30], Batch [4000/20508], Loss: 0.6809\n",
      "Epoch [2/30], Batch [4010/20508], Loss: 0.6863\n",
      "Epoch [2/30], Batch [4020/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [4030/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [4040/20508], Loss: 0.7088\n",
      "Epoch [2/30], Batch [4050/20508], Loss: 0.7181\n",
      "Epoch [2/30], Batch [4060/20508], Loss: 0.7010\n",
      "Epoch [2/30], Batch [4070/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [4080/20508], Loss: 0.6947\n",
      "Epoch [2/30], Batch [4090/20508], Loss: 0.7011\n",
      "Epoch [2/30], Batch [4100/20508], Loss: 0.7211\n",
      "Epoch [2/30], Batch [4110/20508], Loss: 0.7436\n",
      "Epoch [2/30], Batch [4120/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [4130/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [4140/20508], Loss: 0.7241\n",
      "Epoch [2/30], Batch [4150/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [4160/20508], Loss: 0.7069\n",
      "Epoch [2/30], Batch [4170/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [4180/20508], Loss: 0.6834\n",
      "Epoch [2/30], Batch [4190/20508], Loss: 0.7295\n",
      "Epoch [2/30], Batch [4200/20508], Loss: 0.7105\n",
      "Epoch [2/30], Batch [4210/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [4220/20508], Loss: 0.7268\n",
      "Epoch [2/30], Batch [4230/20508], Loss: 0.7065\n",
      "Epoch [2/30], Batch [4240/20508], Loss: 0.7469\n",
      "Epoch [2/30], Batch [4250/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [4260/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [4270/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [4280/20508], Loss: 0.6776\n",
      "Epoch [2/30], Batch [4290/20508], Loss: 0.6821\n",
      "Epoch [2/30], Batch [4300/20508], Loss: 0.6945\n",
      "Epoch [2/30], Batch [4310/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [4320/20508], Loss: 0.6888\n",
      "Epoch [2/30], Batch [4330/20508], Loss: 0.7143\n",
      "Epoch [2/30], Batch [4340/20508], Loss: 0.6657\n",
      "Epoch [2/30], Batch [4350/20508], Loss: 0.7137\n",
      "Epoch [2/30], Batch [4360/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [4370/20508], Loss: 0.7102\n",
      "Epoch [2/30], Batch [4380/20508], Loss: 0.7087\n",
      "Epoch [2/30], Batch [4390/20508], Loss: 0.7197\n",
      "Epoch [2/30], Batch [4400/20508], Loss: 0.6848\n",
      "Epoch [2/30], Batch [4410/20508], Loss: 0.7107\n",
      "Epoch [2/30], Batch [4420/20508], Loss: 0.7243\n",
      "Epoch [2/30], Batch [4430/20508], Loss: 0.7192\n",
      "Epoch [2/30], Batch [4440/20508], Loss: 0.7347\n",
      "Epoch [2/30], Batch [4450/20508], Loss: 0.7280\n",
      "Epoch [2/30], Batch [4460/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [4470/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [4480/20508], Loss: 0.7121\n",
      "Epoch [2/30], Batch [4490/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [4500/20508], Loss: 0.6884\n",
      "Epoch [2/30], Batch [4510/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [4520/20508], Loss: 0.7213\n",
      "Epoch [2/30], Batch [4530/20508], Loss: 0.7098\n",
      "Epoch [2/30], Batch [4540/20508], Loss: 0.7138\n",
      "Epoch [2/30], Batch [4550/20508], Loss: 0.6991\n",
      "Epoch [2/30], Batch [4560/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [4570/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [4580/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [4590/20508], Loss: 0.7105\n",
      "Epoch [2/30], Batch [4600/20508], Loss: 0.6728\n",
      "Epoch [2/30], Batch [4610/20508], Loss: 0.7227\n",
      "Epoch [2/30], Batch [4620/20508], Loss: 0.7273\n",
      "Epoch [2/30], Batch [4630/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [4640/20508], Loss: 0.6958\n",
      "Epoch [2/30], Batch [4650/20508], Loss: 0.6888\n",
      "Epoch [2/30], Batch [4660/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [4670/20508], Loss: 0.7315\n",
      "Epoch [2/30], Batch [4680/20508], Loss: 0.7051\n",
      "Epoch [2/30], Batch [4690/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [4700/20508], Loss: 0.6941\n",
      "Epoch [2/30], Batch [4710/20508], Loss: 0.7107\n",
      "Epoch [2/30], Batch [4720/20508], Loss: 0.7099\n",
      "Epoch [2/30], Batch [4730/20508], Loss: 0.6699\n",
      "Epoch [2/30], Batch [4740/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [4750/20508], Loss: 0.6827\n",
      "Epoch [2/30], Batch [4760/20508], Loss: 0.7005\n",
      "Epoch [2/30], Batch [4770/20508], Loss: 0.7048\n",
      "Epoch [2/30], Batch [4780/20508], Loss: 0.7134\n",
      "Epoch [2/30], Batch [4790/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [4800/20508], Loss: 0.7104\n",
      "Epoch [2/30], Batch [4810/20508], Loss: 0.7323\n",
      "Epoch [2/30], Batch [4820/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [4830/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [4840/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [4850/20508], Loss: 0.6710\n",
      "Epoch [2/30], Batch [4860/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [4870/20508], Loss: 0.7235\n",
      "Epoch [2/30], Batch [4880/20508], Loss: 0.7069\n",
      "Epoch [2/30], Batch [4890/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [4900/20508], Loss: 0.7350\n",
      "Epoch [2/30], Batch [4910/20508], Loss: 0.7183\n",
      "Epoch [2/30], Batch [4920/20508], Loss: 0.6753\n",
      "Epoch [2/30], Batch [4930/20508], Loss: 0.7020\n",
      "Epoch [2/30], Batch [4940/20508], Loss: 0.7159\n",
      "Epoch [2/30], Batch [4950/20508], Loss: 0.7114\n",
      "Epoch [2/30], Batch [4960/20508], Loss: 0.7162\n",
      "Epoch [2/30], Batch [4970/20508], Loss: 0.6844\n",
      "Epoch [2/30], Batch [4980/20508], Loss: 0.6836\n",
      "Epoch [2/30], Batch [4990/20508], Loss: 0.6854\n",
      "Epoch [2/30], Batch [5000/20508], Loss: 0.7125\n",
      "Epoch [2/30], Batch [5010/20508], Loss: 0.7411\n",
      "Epoch [2/30], Batch [5020/20508], Loss: 0.7173\n",
      "Epoch [2/30], Batch [5030/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [5040/20508], Loss: 0.7216\n",
      "Epoch [2/30], Batch [5050/20508], Loss: 0.7082\n",
      "Epoch [2/30], Batch [5060/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [5070/20508], Loss: 0.7146\n",
      "Epoch [2/30], Batch [5080/20508], Loss: 0.6824\n",
      "Epoch [2/30], Batch [5090/20508], Loss: 0.6811\n",
      "Epoch [2/30], Batch [5100/20508], Loss: 0.6888\n",
      "Epoch [2/30], Batch [5110/20508], Loss: 0.7080\n",
      "Epoch [2/30], Batch [5120/20508], Loss: 0.6859\n",
      "Epoch [2/30], Batch [5130/20508], Loss: 0.6859\n",
      "Epoch [2/30], Batch [5140/20508], Loss: 0.7221\n",
      "Epoch [2/30], Batch [5150/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [5160/20508], Loss: 0.7255\n",
      "Epoch [2/30], Batch [5170/20508], Loss: 0.6657\n",
      "Epoch [2/30], Batch [5180/20508], Loss: 0.7294\n",
      "Epoch [2/30], Batch [5190/20508], Loss: 0.7109\n",
      "Epoch [2/30], Batch [5200/20508], Loss: 0.7259\n",
      "Epoch [2/30], Batch [5210/20508], Loss: 0.7211\n",
      "Epoch [2/30], Batch [5220/20508], Loss: 0.6853\n",
      "Epoch [2/30], Batch [5230/20508], Loss: 0.7051\n",
      "Epoch [2/30], Batch [5240/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [5250/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [5260/20508], Loss: 0.6900\n",
      "Epoch [2/30], Batch [5270/20508], Loss: 0.7255\n",
      "Epoch [2/30], Batch [5280/20508], Loss: 0.6684\n",
      "Epoch [2/30], Batch [5290/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [5300/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [5310/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [5320/20508], Loss: 0.6895\n",
      "Epoch [2/30], Batch [5330/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [5340/20508], Loss: 0.7107\n",
      "Epoch [2/30], Batch [5350/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [5360/20508], Loss: 0.7128\n",
      "Epoch [2/30], Batch [5370/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [5380/20508], Loss: 0.7040\n",
      "Epoch [2/30], Batch [5390/20508], Loss: 0.6646\n",
      "Epoch [2/30], Batch [5400/20508], Loss: 0.7269\n",
      "Epoch [2/30], Batch [5410/20508], Loss: 0.7142\n",
      "Epoch [2/30], Batch [5420/20508], Loss: 0.7051\n",
      "Epoch [2/30], Batch [5430/20508], Loss: 0.7324\n",
      "Epoch [2/30], Batch [5440/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [5450/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [5460/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [5470/20508], Loss: 0.7135\n",
      "Epoch [2/30], Batch [5480/20508], Loss: 0.7024\n",
      "Epoch [2/30], Batch [5490/20508], Loss: 0.7087\n",
      "Epoch [2/30], Batch [5500/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [5510/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [5520/20508], Loss: 0.7169\n",
      "Epoch [2/30], Batch [5530/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [5540/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [5550/20508], Loss: 0.7180\n",
      "Epoch [2/30], Batch [5560/20508], Loss: 0.7150\n",
      "Epoch [2/30], Batch [5570/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [5580/20508], Loss: 0.7019\n",
      "Epoch [2/30], Batch [5590/20508], Loss: 0.6465\n",
      "Epoch [2/30], Batch [5600/20508], Loss: 0.7134\n",
      "Epoch [2/30], Batch [5610/20508], Loss: 0.6722\n",
      "Epoch [2/30], Batch [5620/20508], Loss: 0.6919\n",
      "Epoch [2/30], Batch [5630/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [5640/20508], Loss: 0.7155\n",
      "Epoch [2/30], Batch [5650/20508], Loss: 0.7350\n",
      "Epoch [2/30], Batch [5660/20508], Loss: 0.6735\n",
      "Epoch [2/30], Batch [5670/20508], Loss: 0.6898\n",
      "Epoch [2/30], Batch [5680/20508], Loss: 0.6844\n",
      "Epoch [2/30], Batch [5690/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [5700/20508], Loss: 0.7322\n",
      "Epoch [2/30], Batch [5710/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [5720/20508], Loss: 0.6714\n",
      "Epoch [2/30], Batch [5730/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [5740/20508], Loss: 0.7280\n",
      "Epoch [2/30], Batch [5750/20508], Loss: 0.7028\n",
      "Epoch [2/30], Batch [5760/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [5770/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [5780/20508], Loss: 0.7005\n",
      "Epoch [2/30], Batch [5790/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [5800/20508], Loss: 0.6883\n",
      "Epoch [2/30], Batch [5810/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [5820/20508], Loss: 0.7234\n",
      "Epoch [2/30], Batch [5830/20508], Loss: 0.7067\n",
      "Epoch [2/30], Batch [5840/20508], Loss: 0.7020\n",
      "Epoch [2/30], Batch [5850/20508], Loss: 0.7133\n",
      "Epoch [2/30], Batch [5860/20508], Loss: 0.7301\n",
      "Epoch [2/30], Batch [5870/20508], Loss: 0.7255\n",
      "Epoch [2/30], Batch [5880/20508], Loss: 0.7166\n",
      "Epoch [2/30], Batch [5890/20508], Loss: 0.6831\n",
      "Epoch [2/30], Batch [5900/20508], Loss: 0.6698\n",
      "Epoch [2/30], Batch [5910/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [5920/20508], Loss: 0.6844\n",
      "Epoch [2/30], Batch [5930/20508], Loss: 0.7204\n",
      "Epoch [2/30], Batch [5940/20508], Loss: 0.7094\n",
      "Epoch [2/30], Batch [5950/20508], Loss: 0.7059\n",
      "Epoch [2/30], Batch [5960/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [5970/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [5980/20508], Loss: 0.6886\n",
      "Epoch [2/30], Batch [5990/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [6000/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [6010/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [6020/20508], Loss: 0.7091\n",
      "Epoch [2/30], Batch [6030/20508], Loss: 0.6804\n",
      "Epoch [2/30], Batch [6040/20508], Loss: 0.7276\n",
      "Epoch [2/30], Batch [6050/20508], Loss: 0.7218\n",
      "Epoch [2/30], Batch [6060/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [6070/20508], Loss: 0.7177\n",
      "Epoch [2/30], Batch [6080/20508], Loss: 0.7146\n",
      "Epoch [2/30], Batch [6090/20508], Loss: 0.6981\n",
      "Epoch [2/30], Batch [6100/20508], Loss: 0.7417\n",
      "Epoch [2/30], Batch [6110/20508], Loss: 0.7102\n",
      "Epoch [2/30], Batch [6120/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [6130/20508], Loss: 0.6823\n",
      "Epoch [2/30], Batch [6140/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [6150/20508], Loss: 0.6858\n",
      "Epoch [2/30], Batch [6160/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [6170/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [6180/20508], Loss: 0.6779\n",
      "Epoch [2/30], Batch [6190/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [6200/20508], Loss: 0.7058\n",
      "Epoch [2/30], Batch [6210/20508], Loss: 0.7118\n",
      "Epoch [2/30], Batch [6220/20508], Loss: 0.6872\n",
      "Epoch [2/30], Batch [6230/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [6240/20508], Loss: 0.6855\n",
      "Epoch [2/30], Batch [6250/20508], Loss: 0.6873\n",
      "Epoch [2/30], Batch [6260/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [6270/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [6280/20508], Loss: 0.6873\n",
      "Epoch [2/30], Batch [6290/20508], Loss: 0.6992\n",
      "Epoch [2/30], Batch [6300/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [6310/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [6320/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [6330/20508], Loss: 0.6870\n",
      "Epoch [2/30], Batch [6340/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [6350/20508], Loss: 0.6792\n",
      "Epoch [2/30], Batch [6360/20508], Loss: 0.7202\n",
      "Epoch [2/30], Batch [6370/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [6380/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [6390/20508], Loss: 0.6862\n",
      "Epoch [2/30], Batch [6400/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [6410/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [6420/20508], Loss: 0.6914\n",
      "Epoch [2/30], Batch [6430/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [6440/20508], Loss: 0.6851\n",
      "Epoch [2/30], Batch [6450/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [6460/20508], Loss: 0.7023\n",
      "Epoch [2/30], Batch [6470/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [6480/20508], Loss: 0.6635\n",
      "Epoch [2/30], Batch [6490/20508], Loss: 0.7152\n",
      "Epoch [2/30], Batch [6500/20508], Loss: 0.7195\n",
      "Epoch [2/30], Batch [6510/20508], Loss: 0.6785\n",
      "Epoch [2/30], Batch [6520/20508], Loss: 0.7177\n",
      "Epoch [2/30], Batch [6530/20508], Loss: 0.6968\n",
      "Epoch [2/30], Batch [6540/20508], Loss: 0.6718\n",
      "Epoch [2/30], Batch [6550/20508], Loss: 0.6876\n",
      "Epoch [2/30], Batch [6560/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [6570/20508], Loss: 0.7107\n",
      "Epoch [2/30], Batch [6580/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [6590/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [6600/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [6610/20508], Loss: 0.6743\n",
      "Epoch [2/30], Batch [6620/20508], Loss: 0.7170\n",
      "Epoch [2/30], Batch [6630/20508], Loss: 0.7009\n",
      "Epoch [2/30], Batch [6640/20508], Loss: 0.6914\n",
      "Epoch [2/30], Batch [6650/20508], Loss: 0.7191\n",
      "Epoch [2/30], Batch [6660/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [6670/20508], Loss: 0.7216\n",
      "Epoch [2/30], Batch [6680/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [6690/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [6700/20508], Loss: 0.6823\n",
      "Epoch [2/30], Batch [6710/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [6720/20508], Loss: 0.7334\n",
      "Epoch [2/30], Batch [6730/20508], Loss: 0.7207\n",
      "Epoch [2/30], Batch [6740/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [6750/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [6760/20508], Loss: 0.6790\n",
      "Epoch [2/30], Batch [6770/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [6780/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [6790/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [6800/20508], Loss: 0.7056\n",
      "Epoch [2/30], Batch [6810/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [6820/20508], Loss: 0.7183\n",
      "Epoch [2/30], Batch [6830/20508], Loss: 0.7015\n",
      "Epoch [2/30], Batch [6840/20508], Loss: 0.7149\n",
      "Epoch [2/30], Batch [6850/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [6860/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [6870/20508], Loss: 0.6922\n",
      "Epoch [2/30], Batch [6880/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [6890/20508], Loss: 0.7215\n",
      "Epoch [2/30], Batch [6900/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [6910/20508], Loss: 0.7130\n",
      "Epoch [2/30], Batch [6920/20508], Loss: 0.6767\n",
      "Epoch [2/30], Batch [6930/20508], Loss: 0.7180\n",
      "Epoch [2/30], Batch [6940/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [6950/20508], Loss: 0.7031\n",
      "Epoch [2/30], Batch [6960/20508], Loss: 0.6859\n",
      "Epoch [2/30], Batch [6970/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [6980/20508], Loss: 0.7232\n",
      "Epoch [2/30], Batch [6990/20508], Loss: 0.7020\n",
      "Epoch [2/30], Batch [7000/20508], Loss: 0.7137\n",
      "Epoch [2/30], Batch [7010/20508], Loss: 0.6903\n",
      "Epoch [2/30], Batch [7020/20508], Loss: 0.6756\n",
      "Epoch [2/30], Batch [7030/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [7040/20508], Loss: 0.6776\n",
      "Epoch [2/30], Batch [7050/20508], Loss: 0.7031\n",
      "Epoch [2/30], Batch [7060/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [7070/20508], Loss: 0.7021\n",
      "Epoch [2/30], Batch [7080/20508], Loss: 0.6639\n",
      "Epoch [2/30], Batch [7090/20508], Loss: 0.6893\n",
      "Epoch [2/30], Batch [7100/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [7110/20508], Loss: 0.7247\n",
      "Epoch [2/30], Batch [7120/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [7130/20508], Loss: 0.6655\n",
      "Epoch [2/30], Batch [7140/20508], Loss: 0.7089\n",
      "Epoch [2/30], Batch [7150/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [7160/20508], Loss: 0.7125\n",
      "Epoch [2/30], Batch [7170/20508], Loss: 0.6625\n",
      "Epoch [2/30], Batch [7180/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [7190/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [7200/20508], Loss: 0.7194\n",
      "Epoch [2/30], Batch [7210/20508], Loss: 0.6925\n",
      "Epoch [2/30], Batch [7220/20508], Loss: 0.6741\n",
      "Epoch [2/30], Batch [7230/20508], Loss: 0.7080\n",
      "Epoch [2/30], Batch [7240/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [7250/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [7260/20508], Loss: 0.7074\n",
      "Epoch [2/30], Batch [7270/20508], Loss: 0.7130\n",
      "Epoch [2/30], Batch [7280/20508], Loss: 0.6914\n",
      "Epoch [2/30], Batch [7290/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [7300/20508], Loss: 0.6958\n",
      "Epoch [2/30], Batch [7310/20508], Loss: 0.7099\n",
      "Epoch [2/30], Batch [7320/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [7330/20508], Loss: 0.7319\n",
      "Epoch [2/30], Batch [7340/20508], Loss: 0.7165\n",
      "Epoch [2/30], Batch [7350/20508], Loss: 0.7114\n",
      "Epoch [2/30], Batch [7360/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [7370/20508], Loss: 0.6607\n",
      "Epoch [2/30], Batch [7380/20508], Loss: 0.7149\n",
      "Epoch [2/30], Batch [7390/20508], Loss: 0.7324\n",
      "Epoch [2/30], Batch [7400/20508], Loss: 0.6897\n",
      "Epoch [2/30], Batch [7410/20508], Loss: 0.7077\n",
      "Epoch [2/30], Batch [7420/20508], Loss: 0.7183\n",
      "Epoch [2/30], Batch [7430/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [7440/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [7450/20508], Loss: 0.6919\n",
      "Epoch [2/30], Batch [7460/20508], Loss: 0.6802\n",
      "Epoch [2/30], Batch [7470/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [7480/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [7490/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [7500/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [7510/20508], Loss: 0.6853\n",
      "Epoch [2/30], Batch [7520/20508], Loss: 0.7158\n",
      "Epoch [2/30], Batch [7530/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [7540/20508], Loss: 0.7015\n",
      "Epoch [2/30], Batch [7550/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [7560/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [7570/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [7580/20508], Loss: 0.6883\n",
      "Epoch [2/30], Batch [7590/20508], Loss: 0.7170\n",
      "Epoch [2/30], Batch [7600/20508], Loss: 0.7159\n",
      "Epoch [2/30], Batch [7610/20508], Loss: 0.7019\n",
      "Epoch [2/30], Batch [7620/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [7630/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [7640/20508], Loss: 0.7092\n",
      "Epoch [2/30], Batch [7650/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [7660/20508], Loss: 0.6949\n",
      "Epoch [2/30], Batch [7670/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [7680/20508], Loss: 0.6911\n",
      "Epoch [2/30], Batch [7690/20508], Loss: 0.6783\n",
      "Epoch [2/30], Batch [7700/20508], Loss: 0.7028\n",
      "Epoch [2/30], Batch [7710/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [7720/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [7730/20508], Loss: 0.7299\n",
      "Epoch [2/30], Batch [7740/20508], Loss: 0.7220\n",
      "Epoch [2/30], Batch [7750/20508], Loss: 0.7092\n",
      "Epoch [2/30], Batch [7760/20508], Loss: 0.6939\n",
      "Epoch [2/30], Batch [7770/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [7780/20508], Loss: 0.6878\n",
      "Epoch [2/30], Batch [7790/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [7800/20508], Loss: 0.6807\n",
      "Epoch [2/30], Batch [7810/20508], Loss: 0.6880\n",
      "Epoch [2/30], Batch [7820/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [7830/20508], Loss: 0.7035\n",
      "Epoch [2/30], Batch [7840/20508], Loss: 0.7135\n",
      "Epoch [2/30], Batch [7850/20508], Loss: 0.6699\n",
      "Epoch [2/30], Batch [7860/20508], Loss: 0.7050\n",
      "Epoch [2/30], Batch [7870/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [7880/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [7890/20508], Loss: 0.7204\n",
      "Epoch [2/30], Batch [7900/20508], Loss: 0.6935\n",
      "Epoch [2/30], Batch [7910/20508], Loss: 0.7050\n",
      "Epoch [2/30], Batch [7920/20508], Loss: 0.7126\n",
      "Epoch [2/30], Batch [7930/20508], Loss: 0.7099\n",
      "Epoch [2/30], Batch [7940/20508], Loss: 0.6944\n",
      "Epoch [2/30], Batch [7950/20508], Loss: 0.7086\n",
      "Epoch [2/30], Batch [7960/20508], Loss: 0.7034\n",
      "Epoch [2/30], Batch [7970/20508], Loss: 0.7117\n",
      "Epoch [2/30], Batch [7980/20508], Loss: 0.6701\n",
      "Epoch [2/30], Batch [7990/20508], Loss: 0.7260\n",
      "Epoch [2/30], Batch [8000/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [8010/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [8020/20508], Loss: 0.6820\n",
      "Epoch [2/30], Batch [8030/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [8040/20508], Loss: 0.7234\n",
      "Epoch [2/30], Batch [8050/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [8060/20508], Loss: 0.6799\n",
      "Epoch [2/30], Batch [8070/20508], Loss: 0.7040\n",
      "Epoch [2/30], Batch [8080/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [8090/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [8100/20508], Loss: 0.7092\n",
      "Epoch [2/30], Batch [8110/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [8120/20508], Loss: 0.7025\n",
      "Epoch [2/30], Batch [8130/20508], Loss: 0.6907\n",
      "Epoch [2/30], Batch [8140/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [8150/20508], Loss: 0.6887\n",
      "Epoch [2/30], Batch [8160/20508], Loss: 0.6850\n",
      "Epoch [2/30], Batch [8170/20508], Loss: 0.6856\n",
      "Epoch [2/30], Batch [8180/20508], Loss: 0.6871\n",
      "Epoch [2/30], Batch [8190/20508], Loss: 0.6758\n",
      "Epoch [2/30], Batch [8200/20508], Loss: 0.6781\n",
      "Epoch [2/30], Batch [8210/20508], Loss: 0.6822\n",
      "Epoch [2/30], Batch [8220/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [8230/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [8240/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [8250/20508], Loss: 0.6915\n",
      "Epoch [2/30], Batch [8260/20508], Loss: 0.7020\n",
      "Epoch [2/30], Batch [8270/20508], Loss: 0.7284\n",
      "Epoch [2/30], Batch [8280/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [8290/20508], Loss: 0.7048\n",
      "Epoch [2/30], Batch [8300/20508], Loss: 0.7180\n",
      "Epoch [2/30], Batch [8310/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [8320/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [8330/20508], Loss: 0.6946\n",
      "Epoch [2/30], Batch [8340/20508], Loss: 0.6887\n",
      "Epoch [2/30], Batch [8350/20508], Loss: 0.6938\n",
      "Epoch [2/30], Batch [8360/20508], Loss: 0.6930\n",
      "Epoch [2/30], Batch [8370/20508], Loss: 0.6954\n",
      "Epoch [2/30], Batch [8380/20508], Loss: 0.7105\n",
      "Epoch [2/30], Batch [8390/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [8400/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [8410/20508], Loss: 0.7068\n",
      "Epoch [2/30], Batch [8420/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [8430/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [8440/20508], Loss: 0.6841\n",
      "Epoch [2/30], Batch [8450/20508], Loss: 0.6993\n",
      "Epoch [2/30], Batch [8460/20508], Loss: 0.7090\n",
      "Epoch [2/30], Batch [8470/20508], Loss: 0.6803\n",
      "Epoch [2/30], Batch [8480/20508], Loss: 0.7207\n",
      "Epoch [2/30], Batch [8490/20508], Loss: 0.7044\n",
      "Epoch [2/30], Batch [8500/20508], Loss: 0.7086\n",
      "Epoch [2/30], Batch [8510/20508], Loss: 0.6954\n",
      "Epoch [2/30], Batch [8520/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [8530/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [8540/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [8550/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [8560/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [8570/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [8580/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [8590/20508], Loss: 0.6863\n",
      "Epoch [2/30], Batch [8600/20508], Loss: 0.6896\n",
      "Epoch [2/30], Batch [8610/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [8620/20508], Loss: 0.6836\n",
      "Epoch [2/30], Batch [8630/20508], Loss: 0.7289\n",
      "Epoch [2/30], Batch [8640/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [8650/20508], Loss: 0.6945\n",
      "Epoch [2/30], Batch [8660/20508], Loss: 0.6988\n",
      "Epoch [2/30], Batch [8670/20508], Loss: 0.6732\n",
      "Epoch [2/30], Batch [8680/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [8690/20508], Loss: 0.6977\n",
      "Epoch [2/30], Batch [8700/20508], Loss: 0.7015\n",
      "Epoch [2/30], Batch [8710/20508], Loss: 0.6894\n",
      "Epoch [2/30], Batch [8720/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [8730/20508], Loss: 0.7088\n",
      "Epoch [2/30], Batch [8740/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [8750/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [8760/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [8770/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [8780/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [8790/20508], Loss: 0.7241\n",
      "Epoch [2/30], Batch [8800/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [8810/20508], Loss: 0.7085\n",
      "Epoch [2/30], Batch [8820/20508], Loss: 0.6894\n",
      "Epoch [2/30], Batch [8830/20508], Loss: 0.7119\n",
      "Epoch [2/30], Batch [8840/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [8850/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [8860/20508], Loss: 0.7035\n",
      "Epoch [2/30], Batch [8870/20508], Loss: 0.6793\n",
      "Epoch [2/30], Batch [8880/20508], Loss: 0.6944\n",
      "Epoch [2/30], Batch [8890/20508], Loss: 0.6925\n",
      "Epoch [2/30], Batch [8900/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [8910/20508], Loss: 0.7131\n",
      "Epoch [2/30], Batch [8920/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [8930/20508], Loss: 0.7048\n",
      "Epoch [2/30], Batch [8940/20508], Loss: 0.6861\n",
      "Epoch [2/30], Batch [8950/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [8960/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [8970/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [8980/20508], Loss: 0.6691\n",
      "Epoch [2/30], Batch [8990/20508], Loss: 0.7025\n",
      "Epoch [2/30], Batch [9000/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [9010/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [9020/20508], Loss: 0.6736\n",
      "Epoch [2/30], Batch [9030/20508], Loss: 0.7374\n",
      "Epoch [2/30], Batch [9040/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [9050/20508], Loss: 0.7128\n",
      "Epoch [2/30], Batch [9060/20508], Loss: 0.6849\n",
      "Epoch [2/30], Batch [9070/20508], Loss: 0.7116\n",
      "Epoch [2/30], Batch [9080/20508], Loss: 0.6870\n",
      "Epoch [2/30], Batch [9090/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [9100/20508], Loss: 0.7228\n",
      "Epoch [2/30], Batch [9110/20508], Loss: 0.6733\n",
      "Epoch [2/30], Batch [9120/20508], Loss: 0.6779\n",
      "Epoch [2/30], Batch [9130/20508], Loss: 0.6668\n",
      "Epoch [2/30], Batch [9140/20508], Loss: 0.6847\n",
      "Epoch [2/30], Batch [9150/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [9160/20508], Loss: 0.6959\n",
      "Epoch [2/30], Batch [9170/20508], Loss: 0.7002\n",
      "Epoch [2/30], Batch [9180/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [9190/20508], Loss: 0.7016\n",
      "Epoch [2/30], Batch [9200/20508], Loss: 0.6876\n",
      "Epoch [2/30], Batch [9210/20508], Loss: 0.6873\n",
      "Epoch [2/30], Batch [9220/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [9230/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [9240/20508], Loss: 0.7002\n",
      "Epoch [2/30], Batch [9250/20508], Loss: 0.7166\n",
      "Epoch [2/30], Batch [9260/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [9270/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [9280/20508], Loss: 0.6911\n",
      "Epoch [2/30], Batch [9290/20508], Loss: 0.6749\n",
      "Epoch [2/30], Batch [9300/20508], Loss: 0.6972\n",
      "Epoch [2/30], Batch [9310/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [9320/20508], Loss: 0.7161\n",
      "Epoch [2/30], Batch [9330/20508], Loss: 0.7095\n",
      "Epoch [2/30], Batch [9340/20508], Loss: 0.6852\n",
      "Epoch [2/30], Batch [9350/20508], Loss: 0.7179\n",
      "Epoch [2/30], Batch [9360/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [9370/20508], Loss: 0.7081\n",
      "Epoch [2/30], Batch [9380/20508], Loss: 0.7436\n",
      "Epoch [2/30], Batch [9390/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [9400/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [9410/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [9420/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [9430/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [9440/20508], Loss: 0.6925\n",
      "Epoch [2/30], Batch [9450/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [9460/20508], Loss: 0.6979\n",
      "Epoch [2/30], Batch [9470/20508], Loss: 0.6723\n",
      "Epoch [2/30], Batch [9480/20508], Loss: 0.6748\n",
      "Epoch [2/30], Batch [9490/20508], Loss: 0.6764\n",
      "Epoch [2/30], Batch [9500/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [9510/20508], Loss: 0.7257\n",
      "Epoch [2/30], Batch [9520/20508], Loss: 0.7064\n",
      "Epoch [2/30], Batch [9530/20508], Loss: 0.6769\n",
      "Epoch [2/30], Batch [9540/20508], Loss: 0.6898\n",
      "Epoch [2/30], Batch [9550/20508], Loss: 0.6780\n",
      "Epoch [2/30], Batch [9560/20508], Loss: 0.6668\n",
      "Epoch [2/30], Batch [9570/20508], Loss: 0.6960\n",
      "Epoch [2/30], Batch [9580/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [9590/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [9600/20508], Loss: 0.6890\n",
      "Epoch [2/30], Batch [9610/20508], Loss: 0.7102\n",
      "Epoch [2/30], Batch [9620/20508], Loss: 0.6734\n",
      "Epoch [2/30], Batch [9630/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [9640/20508], Loss: 0.7236\n",
      "Epoch [2/30], Batch [9650/20508], Loss: 0.6822\n",
      "Epoch [2/30], Batch [9660/20508], Loss: 0.6922\n",
      "Epoch [2/30], Batch [9670/20508], Loss: 0.6733\n",
      "Epoch [2/30], Batch [9680/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [9690/20508], Loss: 0.6831\n",
      "Epoch [2/30], Batch [9700/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [9710/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [9720/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [9730/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [9740/20508], Loss: 0.7092\n",
      "Epoch [2/30], Batch [9750/20508], Loss: 0.6947\n",
      "Epoch [2/30], Batch [9760/20508], Loss: 0.7113\n",
      "Epoch [2/30], Batch [9770/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [9780/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [9790/20508], Loss: 0.6930\n",
      "Epoch [2/30], Batch [9800/20508], Loss: 0.7069\n",
      "Epoch [2/30], Batch [9810/20508], Loss: 0.6894\n",
      "Epoch [2/30], Batch [9820/20508], Loss: 0.6948\n",
      "Epoch [2/30], Batch [9830/20508], Loss: 0.6853\n",
      "Epoch [2/30], Batch [9840/20508], Loss: 0.7149\n",
      "Epoch [2/30], Batch [9850/20508], Loss: 0.6824\n",
      "Epoch [2/30], Batch [9860/20508], Loss: 0.6936\n",
      "Epoch [2/30], Batch [9870/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [9880/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [9890/20508], Loss: 0.6790\n",
      "Epoch [2/30], Batch [9900/20508], Loss: 0.6849\n",
      "Epoch [2/30], Batch [9910/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [9920/20508], Loss: 0.6992\n",
      "Epoch [2/30], Batch [9930/20508], Loss: 0.6885\n",
      "Epoch [2/30], Batch [9940/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [9950/20508], Loss: 0.7192\n",
      "Epoch [2/30], Batch [9960/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [9970/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [9980/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [9990/20508], Loss: 0.6702\n",
      "Epoch [2/30], Batch [10000/20508], Loss: 0.7031\n",
      "Epoch [2/30], Batch [10010/20508], Loss: 0.6939\n",
      "Epoch [2/30], Batch [10020/20508], Loss: 0.7078\n",
      "Epoch [2/30], Batch [10030/20508], Loss: 0.6804\n",
      "Epoch [2/30], Batch [10040/20508], Loss: 0.6533\n",
      "Epoch [2/30], Batch [10050/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [10060/20508], Loss: 0.6857\n",
      "Epoch [2/30], Batch [10070/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [10080/20508], Loss: 0.7081\n",
      "Epoch [2/30], Batch [10090/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [10100/20508], Loss: 0.6786\n",
      "Epoch [2/30], Batch [10110/20508], Loss: 0.7109\n",
      "Epoch [2/30], Batch [10120/20508], Loss: 0.7178\n",
      "Epoch [2/30], Batch [10130/20508], Loss: 0.6756\n",
      "Epoch [2/30], Batch [10140/20508], Loss: 0.6805\n",
      "Epoch [2/30], Batch [10150/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [10160/20508], Loss: 0.7110\n",
      "Epoch [2/30], Batch [10170/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [10180/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [10190/20508], Loss: 0.6898\n",
      "Epoch [2/30], Batch [10200/20508], Loss: 0.6991\n",
      "Epoch [2/30], Batch [10210/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [10220/20508], Loss: 0.7035\n",
      "Epoch [2/30], Batch [10230/20508], Loss: 0.7234\n",
      "Epoch [2/30], Batch [10240/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [10250/20508], Loss: 0.6771\n",
      "Epoch [2/30], Batch [10260/20508], Loss: 0.7062\n",
      "Epoch [2/30], Batch [10270/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [10280/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [10290/20508], Loss: 0.7154\n",
      "Epoch [2/30], Batch [10300/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [10310/20508], Loss: 0.7124\n",
      "Epoch [2/30], Batch [10320/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [10330/20508], Loss: 0.6865\n",
      "Epoch [2/30], Batch [10340/20508], Loss: 0.7104\n",
      "Epoch [2/30], Batch [10350/20508], Loss: 0.7027\n",
      "Epoch [2/30], Batch [10360/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [10370/20508], Loss: 0.6938\n",
      "Epoch [2/30], Batch [10380/20508], Loss: 0.7150\n",
      "Epoch [2/30], Batch [10390/20508], Loss: 0.6828\n",
      "Epoch [2/30], Batch [10400/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [10410/20508], Loss: 0.6788\n",
      "Epoch [2/30], Batch [10420/20508], Loss: 0.7107\n",
      "Epoch [2/30], Batch [10430/20508], Loss: 0.6917\n",
      "Epoch [2/30], Batch [10440/20508], Loss: 0.7175\n",
      "Epoch [2/30], Batch [10450/20508], Loss: 0.6815\n",
      "Epoch [2/30], Batch [10460/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [10470/20508], Loss: 0.6660\n",
      "Epoch [2/30], Batch [10480/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [10490/20508], Loss: 0.6797\n",
      "Epoch [2/30], Batch [10500/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [10510/20508], Loss: 0.6721\n",
      "Epoch [2/30], Batch [10520/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [10530/20508], Loss: 0.7167\n",
      "Epoch [2/30], Batch [10540/20508], Loss: 0.6733\n",
      "Epoch [2/30], Batch [10550/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [10560/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [10570/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [10580/20508], Loss: 0.6870\n",
      "Epoch [2/30], Batch [10590/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [10600/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [10610/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [10620/20508], Loss: 0.6690\n",
      "Epoch [2/30], Batch [10630/20508], Loss: 0.6612\n",
      "Epoch [2/30], Batch [10640/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [10650/20508], Loss: 0.6802\n",
      "Epoch [2/30], Batch [10660/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [10670/20508], Loss: 0.6833\n",
      "Epoch [2/30], Batch [10680/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [10690/20508], Loss: 0.6937\n",
      "Epoch [2/30], Batch [10700/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [10710/20508], Loss: 0.6979\n",
      "Epoch [2/30], Batch [10720/20508], Loss: 0.6855\n",
      "Epoch [2/30], Batch [10730/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [10740/20508], Loss: 0.6778\n",
      "Epoch [2/30], Batch [10750/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [10760/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [10770/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [10780/20508], Loss: 0.6847\n",
      "Epoch [2/30], Batch [10790/20508], Loss: 0.7409\n",
      "Epoch [2/30], Batch [10800/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [10810/20508], Loss: 0.6866\n",
      "Epoch [2/30], Batch [10820/20508], Loss: 0.6987\n",
      "Epoch [2/30], Batch [10830/20508], Loss: 0.7202\n",
      "Epoch [2/30], Batch [10840/20508], Loss: 0.7177\n",
      "Epoch [2/30], Batch [10850/20508], Loss: 0.6755\n",
      "Epoch [2/30], Batch [10860/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [10870/20508], Loss: 0.7021\n",
      "Epoch [2/30], Batch [10880/20508], Loss: 0.6765\n",
      "Epoch [2/30], Batch [10890/20508], Loss: 0.7228\n",
      "Epoch [2/30], Batch [10900/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [10910/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [10920/20508], Loss: 0.6884\n",
      "Epoch [2/30], Batch [10930/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [10940/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [10950/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [10960/20508], Loss: 0.6799\n",
      "Epoch [2/30], Batch [10970/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [10980/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [10990/20508], Loss: 0.7181\n",
      "Epoch [2/30], Batch [11000/20508], Loss: 0.6872\n",
      "Epoch [2/30], Batch [11010/20508], Loss: 0.6824\n",
      "Epoch [2/30], Batch [11020/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [11030/20508], Loss: 0.7124\n",
      "Epoch [2/30], Batch [11040/20508], Loss: 0.6886\n",
      "Epoch [2/30], Batch [11050/20508], Loss: 0.6698\n",
      "Epoch [2/30], Batch [11060/20508], Loss: 0.7023\n",
      "Epoch [2/30], Batch [11070/20508], Loss: 0.7054\n",
      "Epoch [2/30], Batch [11080/20508], Loss: 0.7233\n",
      "Epoch [2/30], Batch [11090/20508], Loss: 0.6815\n",
      "Epoch [2/30], Batch [11100/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [11110/20508], Loss: 0.6887\n",
      "Epoch [2/30], Batch [11120/20508], Loss: 0.7010\n",
      "Epoch [2/30], Batch [11130/20508], Loss: 0.6842\n",
      "Epoch [2/30], Batch [11140/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [11150/20508], Loss: 0.6754\n",
      "Epoch [2/30], Batch [11160/20508], Loss: 0.6846\n",
      "Epoch [2/30], Batch [11170/20508], Loss: 0.6627\n",
      "Epoch [2/30], Batch [11180/20508], Loss: 0.7136\n",
      "Epoch [2/30], Batch [11190/20508], Loss: 0.6764\n",
      "Epoch [2/30], Batch [11200/20508], Loss: 0.7076\n",
      "Epoch [2/30], Batch [11210/20508], Loss: 0.6996\n",
      "Epoch [2/30], Batch [11220/20508], Loss: 0.7034\n",
      "Epoch [2/30], Batch [11230/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [11240/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [11250/20508], Loss: 0.6858\n",
      "Epoch [2/30], Batch [11260/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [11270/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [11280/20508], Loss: 0.6761\n",
      "Epoch [2/30], Batch [11290/20508], Loss: 0.7074\n",
      "Epoch [2/30], Batch [11300/20508], Loss: 0.7164\n",
      "Epoch [2/30], Batch [11310/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [11320/20508], Loss: 0.6852\n",
      "Epoch [2/30], Batch [11330/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [11340/20508], Loss: 0.7218\n",
      "Epoch [2/30], Batch [11350/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [11360/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [11370/20508], Loss: 0.7149\n",
      "Epoch [2/30], Batch [11380/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [11390/20508], Loss: 0.7103\n",
      "Epoch [2/30], Batch [11400/20508], Loss: 0.6727\n",
      "Epoch [2/30], Batch [11410/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [11420/20508], Loss: 0.7025\n",
      "Epoch [2/30], Batch [11430/20508], Loss: 0.7081\n",
      "Epoch [2/30], Batch [11440/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [11450/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [11460/20508], Loss: 0.6828\n",
      "Epoch [2/30], Batch [11470/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [11480/20508], Loss: 0.7159\n",
      "Epoch [2/30], Batch [11490/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [11500/20508], Loss: 0.7115\n",
      "Epoch [2/30], Batch [11510/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [11520/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [11530/20508], Loss: 0.6656\n",
      "Epoch [2/30], Batch [11540/20508], Loss: 0.6736\n",
      "Epoch [2/30], Batch [11550/20508], Loss: 0.7326\n",
      "Epoch [2/30], Batch [11560/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [11570/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [11580/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [11590/20508], Loss: 0.6734\n",
      "Epoch [2/30], Batch [11600/20508], Loss: 0.7118\n",
      "Epoch [2/30], Batch [11610/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [11620/20508], Loss: 0.7194\n",
      "Epoch [2/30], Batch [11630/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [11640/20508], Loss: 0.7166\n",
      "Epoch [2/30], Batch [11650/20508], Loss: 0.7037\n",
      "Epoch [2/30], Batch [11660/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [11670/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [11680/20508], Loss: 0.7069\n",
      "Epoch [2/30], Batch [11690/20508], Loss: 0.7205\n",
      "Epoch [2/30], Batch [11700/20508], Loss: 0.6942\n",
      "Epoch [2/30], Batch [11710/20508], Loss: 0.7133\n",
      "Epoch [2/30], Batch [11720/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [11730/20508], Loss: 0.6883\n",
      "Epoch [2/30], Batch [11740/20508], Loss: 0.7185\n",
      "Epoch [2/30], Batch [11750/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [11760/20508], Loss: 0.6603\n",
      "Epoch [2/30], Batch [11770/20508], Loss: 0.6838\n",
      "Epoch [2/30], Batch [11780/20508], Loss: 0.7151\n",
      "Epoch [2/30], Batch [11790/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [11800/20508], Loss: 0.6799\n",
      "Epoch [2/30], Batch [11810/20508], Loss: 0.6946\n",
      "Epoch [2/30], Batch [11820/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [11830/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [11840/20508], Loss: 0.6811\n",
      "Epoch [2/30], Batch [11850/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [11860/20508], Loss: 0.7135\n",
      "Epoch [2/30], Batch [11870/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [11880/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [11890/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [11900/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [11910/20508], Loss: 0.6825\n",
      "Epoch [2/30], Batch [11920/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [11930/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [11940/20508], Loss: 0.6983\n",
      "Epoch [2/30], Batch [11950/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [11960/20508], Loss: 0.6651\n",
      "Epoch [2/30], Batch [11970/20508], Loss: 0.6859\n",
      "Epoch [2/30], Batch [11980/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [11990/20508], Loss: 0.7138\n",
      "Epoch [2/30], Batch [12000/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [12010/20508], Loss: 0.6928\n",
      "Epoch [2/30], Batch [12020/20508], Loss: 0.7133\n",
      "Epoch [2/30], Batch [12030/20508], Loss: 0.7232\n",
      "Epoch [2/30], Batch [12040/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [12050/20508], Loss: 0.6648\n",
      "Epoch [2/30], Batch [12060/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [12070/20508], Loss: 0.6927\n",
      "Epoch [2/30], Batch [12080/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [12090/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [12100/20508], Loss: 0.7308\n",
      "Epoch [2/30], Batch [12110/20508], Loss: 0.6784\n",
      "Epoch [2/30], Batch [12120/20508], Loss: 0.7067\n",
      "Epoch [2/30], Batch [12130/20508], Loss: 0.7175\n",
      "Epoch [2/30], Batch [12140/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [12150/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [12160/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [12170/20508], Loss: 0.6592\n",
      "Epoch [2/30], Batch [12180/20508], Loss: 0.6958\n",
      "Epoch [2/30], Batch [12190/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [12200/20508], Loss: 0.7068\n",
      "Epoch [2/30], Batch [12210/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [12220/20508], Loss: 0.6757\n",
      "Epoch [2/30], Batch [12230/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [12240/20508], Loss: 0.7207\n",
      "Epoch [2/30], Batch [12250/20508], Loss: 0.7081\n",
      "Epoch [2/30], Batch [12260/20508], Loss: 0.6925\n",
      "Epoch [2/30], Batch [12270/20508], Loss: 0.7063\n",
      "Epoch [2/30], Batch [12280/20508], Loss: 0.6873\n",
      "Epoch [2/30], Batch [12290/20508], Loss: 0.6947\n",
      "Epoch [2/30], Batch [12300/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [12310/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [12320/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [12330/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [12340/20508], Loss: 0.6949\n",
      "Epoch [2/30], Batch [12350/20508], Loss: 0.7102\n",
      "Epoch [2/30], Batch [12360/20508], Loss: 0.6946\n",
      "Epoch [2/30], Batch [12370/20508], Loss: 0.6917\n",
      "Epoch [2/30], Batch [12380/20508], Loss: 0.6818\n",
      "Epoch [2/30], Batch [12390/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [12400/20508], Loss: 0.6526\n",
      "Epoch [2/30], Batch [12410/20508], Loss: 0.6987\n",
      "Epoch [2/30], Batch [12420/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [12430/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [12440/20508], Loss: 0.6858\n",
      "Epoch [2/30], Batch [12450/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [12460/20508], Loss: 0.7261\n",
      "Epoch [2/30], Batch [12470/20508], Loss: 0.6878\n",
      "Epoch [2/30], Batch [12480/20508], Loss: 0.6842\n",
      "Epoch [2/30], Batch [12490/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [12500/20508], Loss: 0.6801\n",
      "Epoch [2/30], Batch [12510/20508], Loss: 0.6947\n",
      "Epoch [2/30], Batch [12520/20508], Loss: 0.7128\n",
      "Epoch [2/30], Batch [12530/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [12540/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [12550/20508], Loss: 0.6725\n",
      "Epoch [2/30], Batch [12560/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [12570/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [12580/20508], Loss: 0.6699\n",
      "Epoch [2/30], Batch [12590/20508], Loss: 0.6874\n",
      "Epoch [2/30], Batch [12600/20508], Loss: 0.6801\n",
      "Epoch [2/30], Batch [12610/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [12620/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [12630/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [12640/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [12650/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [12660/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [12670/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [12680/20508], Loss: 0.6844\n",
      "Epoch [2/30], Batch [12690/20508], Loss: 0.6854\n",
      "Epoch [2/30], Batch [12700/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [12710/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [12720/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [12730/20508], Loss: 0.6891\n",
      "Epoch [2/30], Batch [12740/20508], Loss: 0.6846\n",
      "Epoch [2/30], Batch [12750/20508], Loss: 0.6803\n",
      "Epoch [2/30], Batch [12760/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [12770/20508], Loss: 0.6902\n",
      "Epoch [2/30], Batch [12780/20508], Loss: 0.6643\n",
      "Epoch [2/30], Batch [12790/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [12800/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [12810/20508], Loss: 0.6898\n",
      "Epoch [2/30], Batch [12820/20508], Loss: 0.6702\n",
      "Epoch [2/30], Batch [12830/20508], Loss: 0.7198\n",
      "Epoch [2/30], Batch [12840/20508], Loss: 0.7063\n",
      "Epoch [2/30], Batch [12850/20508], Loss: 0.6792\n",
      "Epoch [2/30], Batch [12860/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [12870/20508], Loss: 0.6823\n",
      "Epoch [2/30], Batch [12880/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [12890/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [12900/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [12910/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [12920/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [12930/20508], Loss: 0.6557\n",
      "Epoch [2/30], Batch [12940/20508], Loss: 0.7035\n",
      "Epoch [2/30], Batch [12950/20508], Loss: 0.6890\n",
      "Epoch [2/30], Batch [12960/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [12970/20508], Loss: 0.7146\n",
      "Epoch [2/30], Batch [12980/20508], Loss: 0.7129\n",
      "Epoch [2/30], Batch [12990/20508], Loss: 0.6851\n",
      "Epoch [2/30], Batch [13000/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [13010/20508], Loss: 0.6885\n",
      "Epoch [2/30], Batch [13020/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [13030/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [13040/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [13050/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [13060/20508], Loss: 0.6847\n",
      "Epoch [2/30], Batch [13070/20508], Loss: 0.6887\n",
      "Epoch [2/30], Batch [13080/20508], Loss: 0.6782\n",
      "Epoch [2/30], Batch [13090/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [13100/20508], Loss: 0.7220\n",
      "Epoch [2/30], Batch [13110/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [13120/20508], Loss: 0.6972\n",
      "Epoch [2/30], Batch [13130/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [13140/20508], Loss: 0.6972\n",
      "Epoch [2/30], Batch [13150/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [13160/20508], Loss: 0.7174\n",
      "Epoch [2/30], Batch [13170/20508], Loss: 0.6798\n",
      "Epoch [2/30], Batch [13180/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [13190/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [13200/20508], Loss: 0.7286\n",
      "Epoch [2/30], Batch [13210/20508], Loss: 0.7025\n",
      "Epoch [2/30], Batch [13220/20508], Loss: 0.7237\n",
      "Epoch [2/30], Batch [13230/20508], Loss: 0.6968\n",
      "Epoch [2/30], Batch [13240/20508], Loss: 0.7082\n",
      "Epoch [2/30], Batch [13250/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [13260/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [13270/20508], Loss: 0.6866\n",
      "Epoch [2/30], Batch [13280/20508], Loss: 0.7079\n",
      "Epoch [2/30], Batch [13290/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [13300/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [13310/20508], Loss: 0.7021\n",
      "Epoch [2/30], Batch [13320/20508], Loss: 0.7273\n",
      "Epoch [2/30], Batch [13330/20508], Loss: 0.7016\n",
      "Epoch [2/30], Batch [13340/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [13350/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [13360/20508], Loss: 0.7121\n",
      "Epoch [2/30], Batch [13370/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [13380/20508], Loss: 0.6775\n",
      "Epoch [2/30], Batch [13390/20508], Loss: 0.7249\n",
      "Epoch [2/30], Batch [13400/20508], Loss: 0.6689\n",
      "Epoch [2/30], Batch [13410/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [13420/20508], Loss: 0.6672\n",
      "Epoch [2/30], Batch [13430/20508], Loss: 0.6938\n",
      "Epoch [2/30], Batch [13440/20508], Loss: 0.6780\n",
      "Epoch [2/30], Batch [13450/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [13460/20508], Loss: 0.7017\n",
      "Epoch [2/30], Batch [13470/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [13480/20508], Loss: 0.6959\n",
      "Epoch [2/30], Batch [13490/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [13500/20508], Loss: 0.7002\n",
      "Epoch [2/30], Batch [13510/20508], Loss: 0.6975\n",
      "Epoch [2/30], Batch [13520/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [13530/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [13540/20508], Loss: 0.6739\n",
      "Epoch [2/30], Batch [13550/20508], Loss: 0.7064\n",
      "Epoch [2/30], Batch [13560/20508], Loss: 0.6945\n",
      "Epoch [2/30], Batch [13570/20508], Loss: 0.7033\n",
      "Epoch [2/30], Batch [13580/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [13590/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [13600/20508], Loss: 0.6731\n",
      "Epoch [2/30], Batch [13610/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [13620/20508], Loss: 0.7138\n",
      "Epoch [2/30], Batch [13630/20508], Loss: 0.7060\n",
      "Epoch [2/30], Batch [13640/20508], Loss: 0.6845\n",
      "Epoch [2/30], Batch [13650/20508], Loss: 0.6863\n",
      "Epoch [2/30], Batch [13660/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [13670/20508], Loss: 0.7088\n",
      "Epoch [2/30], Batch [13680/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [13690/20508], Loss: 0.6831\n",
      "Epoch [2/30], Batch [13700/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [13710/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [13720/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [13730/20508], Loss: 0.6781\n",
      "Epoch [2/30], Batch [13740/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [13750/20508], Loss: 0.6802\n",
      "Epoch [2/30], Batch [13760/20508], Loss: 0.7081\n",
      "Epoch [2/30], Batch [13770/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [13780/20508], Loss: 0.7010\n",
      "Epoch [2/30], Batch [13790/20508], Loss: 0.7097\n",
      "Epoch [2/30], Batch [13800/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [13810/20508], Loss: 0.7071\n",
      "Epoch [2/30], Batch [13820/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [13830/20508], Loss: 0.6676\n",
      "Epoch [2/30], Batch [13840/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [13850/20508], Loss: 0.7034\n",
      "Epoch [2/30], Batch [13860/20508], Loss: 0.7075\n",
      "Epoch [2/30], Batch [13870/20508], Loss: 0.6944\n",
      "Epoch [2/30], Batch [13880/20508], Loss: 0.6773\n",
      "Epoch [2/30], Batch [13890/20508], Loss: 0.6858\n",
      "Epoch [2/30], Batch [13900/20508], Loss: 0.7115\n",
      "Epoch [2/30], Batch [13910/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [13920/20508], Loss: 0.6627\n",
      "Epoch [2/30], Batch [13930/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [13940/20508], Loss: 0.6876\n",
      "Epoch [2/30], Batch [13950/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [13960/20508], Loss: 0.7202\n",
      "Epoch [2/30], Batch [13970/20508], Loss: 0.6791\n",
      "Epoch [2/30], Batch [13980/20508], Loss: 0.7227\n",
      "Epoch [2/30], Batch [13990/20508], Loss: 0.6903\n",
      "Epoch [2/30], Batch [14000/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [14010/20508], Loss: 0.6709\n",
      "Epoch [2/30], Batch [14020/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [14030/20508], Loss: 0.6781\n",
      "Epoch [2/30], Batch [14040/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [14050/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [14060/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [14070/20508], Loss: 0.7075\n",
      "Epoch [2/30], Batch [14080/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [14090/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [14100/20508], Loss: 0.7061\n",
      "Epoch [2/30], Batch [14110/20508], Loss: 0.6709\n",
      "Epoch [2/30], Batch [14120/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [14130/20508], Loss: 0.7247\n",
      "Epoch [2/30], Batch [14140/20508], Loss: 0.6744\n",
      "Epoch [2/30], Batch [14150/20508], Loss: 0.6742\n",
      "Epoch [2/30], Batch [14160/20508], Loss: 0.6826\n",
      "Epoch [2/30], Batch [14170/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [14180/20508], Loss: 0.6751\n",
      "Epoch [2/30], Batch [14190/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [14200/20508], Loss: 0.7086\n",
      "Epoch [2/30], Batch [14210/20508], Loss: 0.6983\n",
      "Epoch [2/30], Batch [14220/20508], Loss: 0.6620\n",
      "Epoch [2/30], Batch [14230/20508], Loss: 0.7143\n",
      "Epoch [2/30], Batch [14240/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [14250/20508], Loss: 0.6797\n",
      "Epoch [2/30], Batch [14260/20508], Loss: 0.7010\n",
      "Epoch [2/30], Batch [14270/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [14280/20508], Loss: 0.7043\n",
      "Epoch [2/30], Batch [14290/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [14300/20508], Loss: 0.6862\n",
      "Epoch [2/30], Batch [14310/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [14320/20508], Loss: 0.6954\n",
      "Epoch [2/30], Batch [14330/20508], Loss: 0.6787\n",
      "Epoch [2/30], Batch [14340/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [14350/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [14360/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [14370/20508], Loss: 0.6988\n",
      "Epoch [2/30], Batch [14380/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [14390/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [14400/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [14410/20508], Loss: 0.6992\n",
      "Epoch [2/30], Batch [14420/20508], Loss: 0.7113\n",
      "Epoch [2/30], Batch [14430/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [14440/20508], Loss: 0.7146\n",
      "Epoch [2/30], Batch [14450/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [14460/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [14470/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [14480/20508], Loss: 0.6833\n",
      "Epoch [2/30], Batch [14490/20508], Loss: 0.6902\n",
      "Epoch [2/30], Batch [14500/20508], Loss: 0.6905\n",
      "Epoch [2/30], Batch [14510/20508], Loss: 0.7069\n",
      "Epoch [2/30], Batch [14520/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [14530/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [14540/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [14550/20508], Loss: 0.6705\n",
      "Epoch [2/30], Batch [14560/20508], Loss: 0.7175\n",
      "Epoch [2/30], Batch [14570/20508], Loss: 0.6788\n",
      "Epoch [2/30], Batch [14580/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [14590/20508], Loss: 0.6945\n",
      "Epoch [2/30], Batch [14600/20508], Loss: 0.6905\n",
      "Epoch [2/30], Batch [14610/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [14620/20508], Loss: 0.6768\n",
      "Epoch [2/30], Batch [14630/20508], Loss: 0.7112\n",
      "Epoch [2/30], Batch [14640/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [14650/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [14660/20508], Loss: 0.6706\n",
      "Epoch [2/30], Batch [14670/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [14680/20508], Loss: 0.7060\n",
      "Epoch [2/30], Batch [14690/20508], Loss: 0.6879\n",
      "Epoch [2/30], Batch [14700/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [14710/20508], Loss: 0.6764\n",
      "Epoch [2/30], Batch [14720/20508], Loss: 0.6846\n",
      "Epoch [2/30], Batch [14730/20508], Loss: 0.6915\n",
      "Epoch [2/30], Batch [14740/20508], Loss: 0.6801\n",
      "Epoch [2/30], Batch [14750/20508], Loss: 0.7119\n",
      "Epoch [2/30], Batch [14760/20508], Loss: 0.6883\n",
      "Epoch [2/30], Batch [14770/20508], Loss: 0.7201\n",
      "Epoch [2/30], Batch [14780/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [14790/20508], Loss: 0.6992\n",
      "Epoch [2/30], Batch [14800/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [14810/20508], Loss: 0.6719\n",
      "Epoch [2/30], Batch [14820/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [14830/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [14840/20508], Loss: 0.6981\n",
      "Epoch [2/30], Batch [14850/20508], Loss: 0.6979\n",
      "Epoch [2/30], Batch [14860/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [14870/20508], Loss: 0.6824\n",
      "Epoch [2/30], Batch [14880/20508], Loss: 0.7327\n",
      "Epoch [2/30], Batch [14890/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [14900/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [14910/20508], Loss: 0.6834\n",
      "Epoch [2/30], Batch [14920/20508], Loss: 0.6712\n",
      "Epoch [2/30], Batch [14930/20508], Loss: 0.6934\n",
      "Epoch [2/30], Batch [14940/20508], Loss: 0.6980\n",
      "Epoch [2/30], Batch [14950/20508], Loss: 0.7131\n",
      "Epoch [2/30], Batch [14960/20508], Loss: 0.6977\n",
      "Epoch [2/30], Batch [14970/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [14980/20508], Loss: 0.6857\n",
      "Epoch [2/30], Batch [14990/20508], Loss: 0.6891\n",
      "Epoch [2/30], Batch [15000/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [15010/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [15020/20508], Loss: 0.7021\n",
      "Epoch [2/30], Batch [15030/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [15040/20508], Loss: 0.6841\n",
      "Epoch [2/30], Batch [15050/20508], Loss: 0.6893\n",
      "Epoch [2/30], Batch [15060/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [15070/20508], Loss: 0.6982\n",
      "Epoch [2/30], Batch [15080/20508], Loss: 0.6843\n",
      "Epoch [2/30], Batch [15090/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [15100/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [15110/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [15120/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [15130/20508], Loss: 0.7067\n",
      "Epoch [2/30], Batch [15140/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [15150/20508], Loss: 0.7095\n",
      "Epoch [2/30], Batch [15160/20508], Loss: 0.6999\n",
      "Epoch [2/30], Batch [15170/20508], Loss: 0.6878\n",
      "Epoch [2/30], Batch [15180/20508], Loss: 0.6770\n",
      "Epoch [2/30], Batch [15190/20508], Loss: 0.6896\n",
      "Epoch [2/30], Batch [15200/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [15210/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [15220/20508], Loss: 0.6902\n",
      "Epoch [2/30], Batch [15230/20508], Loss: 0.6825\n",
      "Epoch [2/30], Batch [15240/20508], Loss: 0.6896\n",
      "Epoch [2/30], Batch [15250/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [15260/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [15270/20508], Loss: 0.7004\n",
      "Epoch [2/30], Batch [15280/20508], Loss: 0.7319\n",
      "Epoch [2/30], Batch [15290/20508], Loss: 0.6822\n",
      "Epoch [2/30], Batch [15300/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [15310/20508], Loss: 0.6852\n",
      "Epoch [2/30], Batch [15320/20508], Loss: 0.6759\n",
      "Epoch [2/30], Batch [15330/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [15340/20508], Loss: 0.7041\n",
      "Epoch [2/30], Batch [15350/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [15360/20508], Loss: 0.7017\n",
      "Epoch [2/30], Batch [15370/20508], Loss: 0.6994\n",
      "Epoch [2/30], Batch [15380/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [15390/20508], Loss: 0.7097\n",
      "Epoch [2/30], Batch [15400/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [15410/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [15420/20508], Loss: 0.6928\n",
      "Epoch [2/30], Batch [15430/20508], Loss: 0.6984\n",
      "Epoch [2/30], Batch [15440/20508], Loss: 0.6702\n",
      "Epoch [2/30], Batch [15450/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [15460/20508], Loss: 0.7019\n",
      "Epoch [2/30], Batch [15470/20508], Loss: 0.6802\n",
      "Epoch [2/30], Batch [15480/20508], Loss: 0.7011\n",
      "Epoch [2/30], Batch [15490/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [15500/20508], Loss: 0.7024\n",
      "Epoch [2/30], Batch [15510/20508], Loss: 0.7356\n",
      "Epoch [2/30], Batch [15520/20508], Loss: 0.6946\n",
      "Epoch [2/30], Batch [15530/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [15540/20508], Loss: 0.7100\n",
      "Epoch [2/30], Batch [15550/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [15560/20508], Loss: 0.6719\n",
      "Epoch [2/30], Batch [15570/20508], Loss: 0.6793\n",
      "Epoch [2/30], Batch [15580/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [15590/20508], Loss: 0.6738\n",
      "Epoch [2/30], Batch [15600/20508], Loss: 0.7073\n",
      "Epoch [2/30], Batch [15610/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [15620/20508], Loss: 0.7138\n",
      "Epoch [2/30], Batch [15630/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [15640/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [15650/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [15660/20508], Loss: 0.7196\n",
      "Epoch [2/30], Batch [15670/20508], Loss: 0.6807\n",
      "Epoch [2/30], Batch [15680/20508], Loss: 0.7170\n",
      "Epoch [2/30], Batch [15690/20508], Loss: 0.7074\n",
      "Epoch [2/30], Batch [15700/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [15710/20508], Loss: 0.7049\n",
      "Epoch [2/30], Batch [15720/20508], Loss: 0.7155\n",
      "Epoch [2/30], Batch [15730/20508], Loss: 0.6821\n",
      "Epoch [2/30], Batch [15740/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [15750/20508], Loss: 0.7007\n",
      "Epoch [2/30], Batch [15760/20508], Loss: 0.6865\n",
      "Epoch [2/30], Batch [15770/20508], Loss: 0.6834\n",
      "Epoch [2/30], Batch [15780/20508], Loss: 0.7212\n",
      "Epoch [2/30], Batch [15790/20508], Loss: 0.6936\n",
      "Epoch [2/30], Batch [15800/20508], Loss: 0.7314\n",
      "Epoch [2/30], Batch [15810/20508], Loss: 0.6857\n",
      "Epoch [2/30], Batch [15820/20508], Loss: 0.7137\n",
      "Epoch [2/30], Batch [15830/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [15840/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [15850/20508], Loss: 0.7206\n",
      "Epoch [2/30], Batch [15860/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [15870/20508], Loss: 0.6764\n",
      "Epoch [2/30], Batch [15880/20508], Loss: 0.6925\n",
      "Epoch [2/30], Batch [15890/20508], Loss: 0.6754\n",
      "Epoch [2/30], Batch [15900/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [15910/20508], Loss: 0.6772\n",
      "Epoch [2/30], Batch [15920/20508], Loss: 0.6953\n",
      "Epoch [2/30], Batch [15930/20508], Loss: 0.6763\n",
      "Epoch [2/30], Batch [15940/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [15950/20508], Loss: 0.6958\n",
      "Epoch [2/30], Batch [15960/20508], Loss: 0.7022\n",
      "Epoch [2/30], Batch [15970/20508], Loss: 0.7019\n",
      "Epoch [2/30], Batch [15980/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [15990/20508], Loss: 0.6974\n",
      "Epoch [2/30], Batch [16000/20508], Loss: 0.7074\n",
      "Epoch [2/30], Batch [16010/20508], Loss: 0.6869\n",
      "Epoch [2/30], Batch [16020/20508], Loss: 0.6997\n",
      "Epoch [2/30], Batch [16030/20508], Loss: 0.6769\n",
      "Epoch [2/30], Batch [16040/20508], Loss: 0.6813\n",
      "Epoch [2/30], Batch [16050/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [16060/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [16070/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [16080/20508], Loss: 0.7051\n",
      "Epoch [2/30], Batch [16090/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [16100/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [16110/20508], Loss: 0.6916\n",
      "Epoch [2/30], Batch [16120/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [16130/20508], Loss: 0.7155\n",
      "Epoch [2/30], Batch [16140/20508], Loss: 0.6803\n",
      "Epoch [2/30], Batch [16150/20508], Loss: 0.7073\n",
      "Epoch [2/30], Batch [16160/20508], Loss: 0.6803\n",
      "Epoch [2/30], Batch [16170/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [16180/20508], Loss: 0.6871\n",
      "Epoch [2/30], Batch [16190/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [16200/20508], Loss: 0.7238\n",
      "Epoch [2/30], Batch [16210/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [16220/20508], Loss: 0.6820\n",
      "Epoch [2/30], Batch [16230/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [16240/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [16250/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [16260/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [16270/20508], Loss: 0.6973\n",
      "Epoch [2/30], Batch [16280/20508], Loss: 0.6853\n",
      "Epoch [2/30], Batch [16290/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [16300/20508], Loss: 0.6854\n",
      "Epoch [2/30], Batch [16310/20508], Loss: 0.7093\n",
      "Epoch [2/30], Batch [16320/20508], Loss: 0.7233\n",
      "Epoch [2/30], Batch [16330/20508], Loss: 0.7024\n",
      "Epoch [2/30], Batch [16340/20508], Loss: 0.6786\n",
      "Epoch [2/30], Batch [16350/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [16360/20508], Loss: 0.7147\n",
      "Epoch [2/30], Batch [16370/20508], Loss: 0.7200\n",
      "Epoch [2/30], Batch [16380/20508], Loss: 0.6795\n",
      "Epoch [2/30], Batch [16390/20508], Loss: 0.6930\n",
      "Epoch [2/30], Batch [16400/20508], Loss: 0.6746\n",
      "Epoch [2/30], Batch [16410/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [16420/20508], Loss: 0.7091\n",
      "Epoch [2/30], Batch [16430/20508], Loss: 0.7058\n",
      "Epoch [2/30], Batch [16440/20508], Loss: 0.6743\n",
      "Epoch [2/30], Batch [16450/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [16460/20508], Loss: 0.6798\n",
      "Epoch [2/30], Batch [16470/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [16480/20508], Loss: 0.6877\n",
      "Epoch [2/30], Batch [16490/20508], Loss: 0.7058\n",
      "Epoch [2/30], Batch [16500/20508], Loss: 0.6724\n",
      "Epoch [2/30], Batch [16510/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [16520/20508], Loss: 0.6716\n",
      "Epoch [2/30], Batch [16530/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [16540/20508], Loss: 0.6850\n",
      "Epoch [2/30], Batch [16550/20508], Loss: 0.7103\n",
      "Epoch [2/30], Batch [16560/20508], Loss: 0.6838\n",
      "Epoch [2/30], Batch [16570/20508], Loss: 0.6965\n",
      "Epoch [2/30], Batch [16580/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [16590/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [16600/20508], Loss: 0.6774\n",
      "Epoch [2/30], Batch [16610/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [16620/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [16630/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [16640/20508], Loss: 0.6987\n",
      "Epoch [2/30], Batch [16650/20508], Loss: 0.6991\n",
      "Epoch [2/30], Batch [16660/20508], Loss: 0.6931\n",
      "Epoch [2/30], Batch [16670/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [16680/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [16690/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [16700/20508], Loss: 0.6878\n",
      "Epoch [2/30], Batch [16710/20508], Loss: 0.6809\n",
      "Epoch [2/30], Batch [16720/20508], Loss: 0.7090\n",
      "Epoch [2/30], Batch [16730/20508], Loss: 0.6952\n",
      "Epoch [2/30], Batch [16740/20508], Loss: 0.6868\n",
      "Epoch [2/30], Batch [16750/20508], Loss: 0.6972\n",
      "Epoch [2/30], Batch [16760/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [16770/20508], Loss: 0.6824\n",
      "Epoch [2/30], Batch [16780/20508], Loss: 0.7034\n",
      "Epoch [2/30], Batch [16790/20508], Loss: 0.6972\n",
      "Epoch [2/30], Batch [16800/20508], Loss: 0.7093\n",
      "Epoch [2/30], Batch [16810/20508], Loss: 0.7225\n",
      "Epoch [2/30], Batch [16820/20508], Loss: 0.6777\n",
      "Epoch [2/30], Batch [16830/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [16840/20508], Loss: 0.7169\n",
      "Epoch [2/30], Batch [16850/20508], Loss: 0.6770\n",
      "Epoch [2/30], Batch [16860/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [16870/20508], Loss: 0.6774\n",
      "Epoch [2/30], Batch [16880/20508], Loss: 0.6730\n",
      "Epoch [2/30], Batch [16890/20508], Loss: 0.6828\n",
      "Epoch [2/30], Batch [16900/20508], Loss: 0.6892\n",
      "Epoch [2/30], Batch [16910/20508], Loss: 0.6830\n",
      "Epoch [2/30], Batch [16920/20508], Loss: 0.6930\n",
      "Epoch [2/30], Batch [16930/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [16940/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [16950/20508], Loss: 0.7089\n",
      "Epoch [2/30], Batch [16960/20508], Loss: 0.6939\n",
      "Epoch [2/30], Batch [16970/20508], Loss: 0.7087\n",
      "Epoch [2/30], Batch [16980/20508], Loss: 0.6870\n",
      "Epoch [2/30], Batch [16990/20508], Loss: 0.7058\n",
      "Epoch [2/30], Batch [17000/20508], Loss: 0.6840\n",
      "Epoch [2/30], Batch [17010/20508], Loss: 0.6882\n",
      "Epoch [2/30], Batch [17020/20508], Loss: 0.6866\n",
      "Epoch [2/30], Batch [17030/20508], Loss: 0.6926\n",
      "Epoch [2/30], Batch [17040/20508], Loss: 0.6844\n",
      "Epoch [2/30], Batch [17050/20508], Loss: 0.7031\n",
      "Epoch [2/30], Batch [17060/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [17070/20508], Loss: 0.6795\n",
      "Epoch [2/30], Batch [17080/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [17090/20508], Loss: 0.7330\n",
      "Epoch [2/30], Batch [17100/20508], Loss: 0.6708\n",
      "Epoch [2/30], Batch [17110/20508], Loss: 0.6969\n",
      "Epoch [2/30], Batch [17120/20508], Loss: 0.6750\n",
      "Epoch [2/30], Batch [17130/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [17140/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [17150/20508], Loss: 0.7084\n",
      "Epoch [2/30], Batch [17160/20508], Loss: 0.6890\n",
      "Epoch [2/30], Batch [17170/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [17180/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [17190/20508], Loss: 0.6697\n",
      "Epoch [2/30], Batch [17200/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [17210/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [17220/20508], Loss: 0.7080\n",
      "Epoch [2/30], Batch [17230/20508], Loss: 0.6940\n",
      "Epoch [2/30], Batch [17240/20508], Loss: 0.6846\n",
      "Epoch [2/30], Batch [17250/20508], Loss: 0.7075\n",
      "Epoch [2/30], Batch [17260/20508], Loss: 0.6840\n",
      "Epoch [2/30], Batch [17270/20508], Loss: 0.6918\n",
      "Epoch [2/30], Batch [17280/20508], Loss: 0.6698\n",
      "Epoch [2/30], Batch [17290/20508], Loss: 0.6765\n",
      "Epoch [2/30], Batch [17300/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [17310/20508], Loss: 0.6923\n",
      "Epoch [2/30], Batch [17320/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [17330/20508], Loss: 0.6736\n",
      "Epoch [2/30], Batch [17340/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [17350/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [17360/20508], Loss: 0.7057\n",
      "Epoch [2/30], Batch [17370/20508], Loss: 0.6691\n",
      "Epoch [2/30], Batch [17380/20508], Loss: 0.7178\n",
      "Epoch [2/30], Batch [17390/20508], Loss: 0.7048\n",
      "Epoch [2/30], Batch [17400/20508], Loss: 0.7146\n",
      "Epoch [2/30], Batch [17410/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [17420/20508], Loss: 0.6895\n",
      "Epoch [2/30], Batch [17430/20508], Loss: 0.7016\n",
      "Epoch [2/30], Batch [17440/20508], Loss: 0.7005\n",
      "Epoch [2/30], Batch [17450/20508], Loss: 0.6747\n",
      "Epoch [2/30], Batch [17460/20508], Loss: 0.6878\n",
      "Epoch [2/30], Batch [17470/20508], Loss: 0.6976\n",
      "Epoch [2/30], Batch [17480/20508], Loss: 0.6865\n",
      "Epoch [2/30], Batch [17490/20508], Loss: 0.7178\n",
      "Epoch [2/30], Batch [17500/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [17510/20508], Loss: 0.6874\n",
      "Epoch [2/30], Batch [17520/20508], Loss: 0.7023\n",
      "Epoch [2/30], Batch [17530/20508], Loss: 0.6635\n",
      "Epoch [2/30], Batch [17540/20508], Loss: 0.6739\n",
      "Epoch [2/30], Batch [17550/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [17560/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [17570/20508], Loss: 0.6849\n",
      "Epoch [2/30], Batch [17580/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [17590/20508], Loss: 0.6874\n",
      "Epoch [2/30], Batch [17600/20508], Loss: 0.6956\n",
      "Epoch [2/30], Batch [17610/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [17620/20508], Loss: 0.6834\n",
      "Epoch [2/30], Batch [17630/20508], Loss: 0.6806\n",
      "Epoch [2/30], Batch [17640/20508], Loss: 0.7122\n",
      "Epoch [2/30], Batch [17650/20508], Loss: 0.6825\n",
      "Epoch [2/30], Batch [17660/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [17670/20508], Loss: 0.7073\n",
      "Epoch [2/30], Batch [17680/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [17690/20508], Loss: 0.7085\n",
      "Epoch [2/30], Batch [17700/20508], Loss: 0.6922\n",
      "Epoch [2/30], Batch [17710/20508], Loss: 0.6996\n",
      "Epoch [2/30], Batch [17720/20508], Loss: 0.7149\n",
      "Epoch [2/30], Batch [17730/20508], Loss: 0.6939\n",
      "Epoch [2/30], Batch [17740/20508], Loss: 0.6811\n",
      "Epoch [2/30], Batch [17750/20508], Loss: 0.7047\n",
      "Epoch [2/30], Batch [17760/20508], Loss: 0.6832\n",
      "Epoch [2/30], Batch [17770/20508], Loss: 0.6810\n",
      "Epoch [2/30], Batch [17780/20508], Loss: 0.6705\n",
      "Epoch [2/30], Batch [17790/20508], Loss: 0.6825\n",
      "Epoch [2/30], Batch [17800/20508], Loss: 0.7055\n",
      "Epoch [2/30], Batch [17810/20508], Loss: 0.7024\n",
      "Epoch [2/30], Batch [17820/20508], Loss: 0.6518\n",
      "Epoch [2/30], Batch [17830/20508], Loss: 0.6942\n",
      "Epoch [2/30], Batch [17840/20508], Loss: 0.7106\n",
      "Epoch [2/30], Batch [17850/20508], Loss: 0.7009\n",
      "Epoch [2/30], Batch [17860/20508], Loss: 0.7062\n",
      "Epoch [2/30], Batch [17870/20508], Loss: 0.6960\n",
      "Epoch [2/30], Batch [17880/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [17890/20508], Loss: 0.7108\n",
      "Epoch [2/30], Batch [17900/20508], Loss: 0.6943\n",
      "Epoch [2/30], Batch [17910/20508], Loss: 0.6794\n",
      "Epoch [2/30], Batch [17920/20508], Loss: 0.7001\n",
      "Epoch [2/30], Batch [17930/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [17940/20508], Loss: 0.6891\n",
      "Epoch [2/30], Batch [17950/20508], Loss: 0.6899\n",
      "Epoch [2/30], Batch [17960/20508], Loss: 0.7286\n",
      "Epoch [2/30], Batch [17970/20508], Loss: 0.6977\n",
      "Epoch [2/30], Batch [17980/20508], Loss: 0.6753\n",
      "Epoch [2/30], Batch [17990/20508], Loss: 0.7018\n",
      "Epoch [2/30], Batch [18000/20508], Loss: 0.7046\n",
      "Epoch [2/30], Batch [18010/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [18020/20508], Loss: 0.6989\n",
      "Epoch [2/30], Batch [18030/20508], Loss: 0.6743\n",
      "Epoch [2/30], Batch [18040/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [18050/20508], Loss: 0.7061\n",
      "Epoch [2/30], Batch [18060/20508], Loss: 0.6904\n",
      "Epoch [2/30], Batch [18070/20508], Loss: 0.7029\n",
      "Epoch [2/30], Batch [18080/20508], Loss: 0.6785\n",
      "Epoch [2/30], Batch [18090/20508], Loss: 0.7190\n",
      "Epoch [2/30], Batch [18100/20508], Loss: 0.6911\n",
      "Epoch [2/30], Batch [18110/20508], Loss: 0.7012\n",
      "Epoch [2/30], Batch [18120/20508], Loss: 0.6995\n",
      "Epoch [2/30], Batch [18130/20508], Loss: 0.7052\n",
      "Epoch [2/30], Batch [18140/20508], Loss: 0.6906\n",
      "Epoch [2/30], Batch [18150/20508], Loss: 0.7063\n",
      "Epoch [2/30], Batch [18160/20508], Loss: 0.6913\n",
      "Epoch [2/30], Batch [18170/20508], Loss: 0.6969\n",
      "Epoch [2/30], Batch [18180/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [18190/20508], Loss: 0.6891\n",
      "Epoch [2/30], Batch [18200/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [18210/20508], Loss: 0.7030\n",
      "Epoch [2/30], Batch [18220/20508], Loss: 0.7200\n",
      "Epoch [2/30], Batch [18230/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [18240/20508], Loss: 0.6767\n",
      "Epoch [2/30], Batch [18250/20508], Loss: 0.6747\n",
      "Epoch [2/30], Batch [18260/20508], Loss: 0.7040\n",
      "Epoch [2/30], Batch [18270/20508], Loss: 0.7048\n",
      "Epoch [2/30], Batch [18280/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [18290/20508], Loss: 0.7013\n",
      "Epoch [2/30], Batch [18300/20508], Loss: 0.6909\n",
      "Epoch [2/30], Batch [18310/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [18320/20508], Loss: 0.6969\n",
      "Epoch [2/30], Batch [18330/20508], Loss: 0.6951\n",
      "Epoch [2/30], Batch [18340/20508], Loss: 0.6959\n",
      "Epoch [2/30], Batch [18350/20508], Loss: 0.6687\n",
      "Epoch [2/30], Batch [18360/20508], Loss: 0.6987\n",
      "Epoch [2/30], Batch [18370/20508], Loss: 0.6793\n",
      "Epoch [2/30], Batch [18380/20508], Loss: 0.6941\n",
      "Epoch [2/30], Batch [18390/20508], Loss: 0.6754\n",
      "Epoch [2/30], Batch [18400/20508], Loss: 0.7011\n",
      "Epoch [2/30], Batch [18410/20508], Loss: 0.7064\n",
      "Epoch [2/30], Batch [18420/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [18430/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [18440/20508], Loss: 0.6660\n",
      "Epoch [2/30], Batch [18450/20508], Loss: 0.6496\n",
      "Epoch [2/30], Batch [18460/20508], Loss: 0.7070\n",
      "Epoch [2/30], Batch [18470/20508], Loss: 0.6867\n",
      "Epoch [2/30], Batch [18480/20508], Loss: 0.6864\n",
      "Epoch [2/30], Batch [18490/20508], Loss: 0.6851\n",
      "Epoch [2/30], Batch [18500/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [18510/20508], Loss: 0.6928\n",
      "Epoch [2/30], Batch [18520/20508], Loss: 0.6699\n",
      "Epoch [2/30], Batch [18530/20508], Loss: 0.7083\n",
      "Epoch [2/30], Batch [18540/20508], Loss: 0.6706\n",
      "Epoch [2/30], Batch [18550/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [18560/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [18570/20508], Loss: 0.7014\n",
      "Epoch [2/30], Batch [18580/20508], Loss: 0.6933\n",
      "Epoch [2/30], Batch [18590/20508], Loss: 0.7099\n",
      "Epoch [2/30], Batch [18600/20508], Loss: 0.7050\n",
      "Epoch [2/30], Batch [18610/20508], Loss: 0.7010\n",
      "Epoch [2/30], Batch [18620/20508], Loss: 0.6795\n",
      "Epoch [2/30], Batch [18630/20508], Loss: 0.6944\n",
      "Epoch [2/30], Batch [18640/20508], Loss: 0.6670\n",
      "Epoch [2/30], Batch [18650/20508], Loss: 0.7039\n",
      "Epoch [2/30], Batch [18660/20508], Loss: 0.7082\n",
      "Epoch [2/30], Batch [18670/20508], Loss: 0.6801\n",
      "Epoch [2/30], Batch [18680/20508], Loss: 0.7155\n",
      "Epoch [2/30], Batch [18690/20508], Loss: 0.7157\n",
      "Epoch [2/30], Batch [18700/20508], Loss: 0.7030\n",
      "Epoch [2/30], Batch [18710/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [18720/20508], Loss: 0.7135\n",
      "Epoch [2/30], Batch [18730/20508], Loss: 0.7027\n",
      "Epoch [2/30], Batch [18740/20508], Loss: 0.7084\n",
      "Epoch [2/30], Batch [18750/20508], Loss: 0.6932\n",
      "Epoch [2/30], Batch [18760/20508], Loss: 0.6747\n",
      "Epoch [2/30], Batch [18770/20508], Loss: 0.6768\n",
      "Epoch [2/30], Batch [18780/20508], Loss: 0.7075\n",
      "Epoch [2/30], Batch [18790/20508], Loss: 0.6860\n",
      "Epoch [2/30], Batch [18800/20508], Loss: 0.6960\n",
      "Epoch [2/30], Batch [18810/20508], Loss: 0.6786\n",
      "Epoch [2/30], Batch [18820/20508], Loss: 0.6826\n",
      "Epoch [2/30], Batch [18830/20508], Loss: 0.7226\n",
      "Epoch [2/30], Batch [18840/20508], Loss: 0.7223\n",
      "Epoch [2/30], Batch [18850/20508], Loss: 0.7003\n",
      "Epoch [2/30], Batch [18860/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [18870/20508], Loss: 0.6986\n",
      "Epoch [2/30], Batch [18880/20508], Loss: 0.6900\n",
      "Epoch [2/30], Batch [18890/20508], Loss: 0.6836\n",
      "Epoch [2/30], Batch [18900/20508], Loss: 0.6810\n",
      "Epoch [2/30], Batch [18910/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [18920/20508], Loss: 0.6885\n",
      "Epoch [2/30], Batch [18930/20508], Loss: 0.6963\n",
      "Epoch [2/30], Batch [18940/20508], Loss: 0.7172\n",
      "Epoch [2/30], Batch [18950/20508], Loss: 0.7268\n",
      "Epoch [2/30], Batch [18960/20508], Loss: 0.6955\n",
      "Epoch [2/30], Batch [18970/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [18980/20508], Loss: 0.6870\n",
      "Epoch [2/30], Batch [18990/20508], Loss: 0.7050\n",
      "Epoch [2/30], Batch [19000/20508], Loss: 0.6990\n",
      "Epoch [2/30], Batch [19010/20508], Loss: 0.6917\n",
      "Epoch [2/30], Batch [19020/20508], Loss: 0.7139\n",
      "Epoch [2/30], Batch [19030/20508], Loss: 0.6712\n",
      "Epoch [2/30], Batch [19040/20508], Loss: 0.6829\n",
      "Epoch [2/30], Batch [19050/20508], Loss: 0.7045\n",
      "Epoch [2/30], Batch [19060/20508], Loss: 0.7101\n",
      "Epoch [2/30], Batch [19070/20508], Loss: 0.7011\n",
      "Epoch [2/30], Batch [19080/20508], Loss: 0.6957\n",
      "Epoch [2/30], Batch [19090/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [19100/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [19110/20508], Loss: 0.6906\n",
      "Epoch [2/30], Batch [19120/20508], Loss: 0.7111\n",
      "Epoch [2/30], Batch [19130/20508], Loss: 0.6929\n",
      "Epoch [2/30], Batch [19140/20508], Loss: 0.7032\n",
      "Epoch [2/30], Batch [19150/20508], Loss: 0.6854\n",
      "Epoch [2/30], Batch [19160/20508], Loss: 0.6842\n",
      "Epoch [2/30], Batch [19170/20508], Loss: 0.6985\n",
      "Epoch [2/30], Batch [19180/20508], Loss: 0.6784\n",
      "Epoch [2/30], Batch [19190/20508], Loss: 0.6981\n",
      "Epoch [2/30], Batch [19200/20508], Loss: 0.6967\n",
      "Epoch [2/30], Batch [19210/20508], Loss: 0.7012\n",
      "Epoch [2/30], Batch [19220/20508], Loss: 0.6797\n",
      "Epoch [2/30], Batch [19230/20508], Loss: 0.6660\n",
      "Epoch [2/30], Batch [19240/20508], Loss: 0.7000\n",
      "Epoch [2/30], Batch [19250/20508], Loss: 0.7061\n",
      "Epoch [2/30], Batch [19260/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [19270/20508], Loss: 0.6910\n",
      "Epoch [2/30], Batch [19280/20508], Loss: 0.7066\n",
      "Epoch [2/30], Batch [19290/20508], Loss: 0.6921\n",
      "Epoch [2/30], Batch [19300/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [19310/20508], Loss: 0.6849\n",
      "Epoch [2/30], Batch [19320/20508], Loss: 0.6961\n",
      "Epoch [2/30], Batch [19330/20508], Loss: 0.6966\n",
      "Epoch [2/30], Batch [19340/20508], Loss: 0.6949\n",
      "Epoch [2/30], Batch [19350/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [19360/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [19370/20508], Loss: 0.6889\n",
      "Epoch [2/30], Batch [19380/20508], Loss: 0.6706\n",
      "Epoch [2/30], Batch [19390/20508], Loss: 0.6912\n",
      "Epoch [2/30], Batch [19400/20508], Loss: 0.6950\n",
      "Epoch [2/30], Batch [19410/20508], Loss: 0.6886\n",
      "Epoch [2/30], Batch [19420/20508], Loss: 0.6646\n",
      "Epoch [2/30], Batch [19430/20508], Loss: 0.6880\n",
      "Epoch [2/30], Batch [19440/20508], Loss: 0.6839\n",
      "Epoch [2/30], Batch [19450/20508], Loss: 0.6723\n",
      "Epoch [2/30], Batch [19460/20508], Loss: 0.7129\n",
      "Epoch [2/30], Batch [19470/20508], Loss: 0.7036\n",
      "Epoch [2/30], Batch [19480/20508], Loss: 0.6903\n",
      "Epoch [2/30], Batch [19490/20508], Loss: 0.6831\n",
      "Epoch [2/30], Batch [19500/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [19510/20508], Loss: 0.6871\n",
      "Epoch [2/30], Batch [19520/20508], Loss: 0.6888\n",
      "Epoch [2/30], Batch [19530/20508], Loss: 0.6954\n",
      "Epoch [2/30], Batch [19540/20508], Loss: 0.6979\n",
      "Epoch [2/30], Batch [19550/20508], Loss: 0.6903\n",
      "Epoch [2/30], Batch [19560/20508], Loss: 0.6906\n",
      "Epoch [2/30], Batch [19570/20508], Loss: 0.6814\n",
      "Epoch [2/30], Batch [19580/20508], Loss: 0.6998\n",
      "Epoch [2/30], Batch [19590/20508], Loss: 0.6773\n",
      "Epoch [2/30], Batch [19600/20508], Loss: 0.6828\n",
      "Epoch [2/30], Batch [19610/20508], Loss: 0.6962\n",
      "Epoch [2/30], Batch [19620/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [19630/20508], Loss: 0.6808\n",
      "Epoch [2/30], Batch [19640/20508], Loss: 0.7042\n",
      "Epoch [2/30], Batch [19650/20508], Loss: 0.6971\n",
      "Epoch [2/30], Batch [19660/20508], Loss: 0.7006\n",
      "Epoch [2/30], Batch [19670/20508], Loss: 0.6853\n",
      "Epoch [2/30], Batch [19680/20508], Loss: 0.7123\n",
      "Epoch [2/30], Batch [19690/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [19700/20508], Loss: 0.6906\n",
      "Epoch [2/30], Batch [19710/20508], Loss: 0.6876\n",
      "Epoch [2/30], Batch [19720/20508], Loss: 0.6908\n",
      "Epoch [2/30], Batch [19730/20508], Loss: 0.7060\n",
      "Epoch [2/30], Batch [19740/20508], Loss: 0.6988\n",
      "Epoch [2/30], Batch [19750/20508], Loss: 0.6936\n",
      "Epoch [2/30], Batch [19760/20508], Loss: 0.7158\n",
      "Epoch [2/30], Batch [19770/20508], Loss: 0.6837\n",
      "Epoch [2/30], Batch [19780/20508], Loss: 0.7049\n",
      "Epoch [2/30], Batch [19790/20508], Loss: 0.6864\n",
      "Epoch [2/30], Batch [19800/20508], Loss: 0.6886\n",
      "Epoch [2/30], Batch [19810/20508], Loss: 0.7137\n",
      "Epoch [2/30], Batch [19820/20508], Loss: 0.7053\n",
      "Epoch [2/30], Batch [19830/20508], Loss: 0.6874\n",
      "Epoch [2/30], Batch [19840/20508], Loss: 0.6964\n",
      "Epoch [2/30], Batch [19850/20508], Loss: 0.6871\n",
      "Epoch [2/30], Batch [19860/20508], Loss: 0.6831\n",
      "Epoch [2/30], Batch [19870/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [19880/20508], Loss: 0.6786\n",
      "Epoch [2/30], Batch [19890/20508], Loss: 0.7080\n",
      "Epoch [2/30], Batch [19900/20508], Loss: 0.7015\n",
      "Epoch [2/30], Batch [19910/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [19920/20508], Loss: 0.6850\n",
      "Epoch [2/30], Batch [19930/20508], Loss: 0.6873\n",
      "Epoch [2/30], Batch [19940/20508], Loss: 0.6901\n",
      "Epoch [2/30], Batch [19950/20508], Loss: 0.6880\n",
      "Epoch [2/30], Batch [19960/20508], Loss: 0.6977\n",
      "Epoch [2/30], Batch [19970/20508], Loss: 0.7026\n",
      "Epoch [2/30], Batch [19980/20508], Loss: 0.6747\n",
      "Epoch [2/30], Batch [19990/20508], Loss: 0.7037\n",
      "Epoch [2/30], Batch [20000/20508], Loss: 0.6950\n",
      "Epoch [2/30], Batch [20010/20508], Loss: 0.6746\n",
      "Epoch [2/30], Batch [20020/20508], Loss: 0.6826\n",
      "Epoch [2/30], Batch [20030/20508], Loss: 0.6752\n",
      "Epoch [2/30], Batch [20040/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [20050/20508], Loss: 0.6825\n",
      "Epoch [2/30], Batch [20060/20508], Loss: 0.6734\n",
      "Epoch [2/30], Batch [20070/20508], Loss: 0.7011\n",
      "Epoch [2/30], Batch [20080/20508], Loss: 0.6970\n",
      "Epoch [2/30], Batch [20090/20508], Loss: 0.7002\n",
      "Epoch [2/30], Batch [20100/20508], Loss: 0.6897\n",
      "Epoch [2/30], Batch [20110/20508], Loss: 0.6775\n",
      "Epoch [2/30], Batch [20120/20508], Loss: 0.7157\n",
      "Epoch [2/30], Batch [20130/20508], Loss: 0.7179\n",
      "Epoch [2/30], Batch [20140/20508], Loss: 0.7008\n",
      "Epoch [2/30], Batch [20150/20508], Loss: 0.6810\n",
      "Epoch [2/30], Batch [20160/20508], Loss: 0.6905\n",
      "Epoch [2/30], Batch [20170/20508], Loss: 0.6877\n",
      "Epoch [2/30], Batch [20180/20508], Loss: 0.6881\n",
      "Epoch [2/30], Batch [20190/20508], Loss: 0.6907\n",
      "Epoch [2/30], Batch [20200/20508], Loss: 0.7082\n",
      "Epoch [2/30], Batch [20210/20508], Loss: 0.6661\n",
      "Epoch [2/30], Batch [20220/20508], Loss: 0.6989\n",
      "Epoch [2/30], Batch [20230/20508], Loss: 0.6851\n",
      "Epoch [2/30], Batch [20240/20508], Loss: 0.6796\n",
      "Epoch [2/30], Batch [20250/20508], Loss: 0.7148\n",
      "Epoch [2/30], Batch [20260/20508], Loss: 0.7038\n",
      "Epoch [2/30], Batch [20270/20508], Loss: 0.6710\n",
      "Epoch [2/30], Batch [20280/20508], Loss: 0.7125\n",
      "Epoch [2/30], Batch [20290/20508], Loss: 0.6902\n",
      "Epoch [2/30], Batch [20300/20508], Loss: 0.7043\n",
      "Epoch [2/30], Batch [20310/20508], Loss: 0.6920\n",
      "Epoch [2/30], Batch [20320/20508], Loss: 0.6798\n",
      "Epoch [2/30], Batch [20330/20508], Loss: 0.7065\n",
      "Epoch [2/30], Batch [20340/20508], Loss: 0.6936\n",
      "Epoch [2/30], Batch [20350/20508], Loss: 0.6890\n",
      "Epoch [2/30], Batch [20360/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [20370/20508], Loss: 0.6875\n",
      "Epoch [2/30], Batch [20380/20508], Loss: 0.7196\n",
      "Epoch [2/30], Batch [20390/20508], Loss: 0.7091\n",
      "Epoch [2/30], Batch [20400/20508], Loss: 0.6788\n",
      "Epoch [2/30], Batch [20410/20508], Loss: 0.6833\n",
      "Epoch [2/30], Batch [20420/20508], Loss: 0.6887\n",
      "Epoch [2/30], Batch [20430/20508], Loss: 0.6981\n",
      "Epoch [2/30], Batch [20440/20508], Loss: 0.6816\n",
      "Epoch [2/30], Batch [20450/20508], Loss: 0.6841\n",
      "Epoch [2/30], Batch [20460/20508], Loss: 0.6811\n",
      "Epoch [2/30], Batch [20470/20508], Loss: 0.7054\n",
      "Epoch [2/30], Batch [20480/20508], Loss: 0.6978\n",
      "Epoch [2/30], Batch [20490/20508], Loss: 0.6769\n",
      "Epoch [2/30], Batch [20500/20508], Loss: 0.6762\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [2], Train Loss: 0.6979, Test Loss: 0.6875, Early Stopping Counter: 0\n",
      "\n",
      "\n",
      "\n",
      "Epoch [3/30], Batch [0/20508], Loss: 0.6944\n",
      "Epoch [3/30], Batch [10/20508], Loss: 0.6963\n",
      "Epoch [3/30], Batch [20/20508], Loss: 0.6638\n",
      "Epoch [3/30], Batch [30/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [40/20508], Loss: 0.7184\n",
      "Epoch [3/30], Batch [50/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [60/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [70/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [80/20508], Loss: 0.6890\n",
      "Epoch [3/30], Batch [90/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [100/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [110/20508], Loss: 0.6688\n",
      "Epoch [3/30], Batch [120/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [130/20508], Loss: 0.6846\n",
      "Epoch [3/30], Batch [140/20508], Loss: 0.7154\n",
      "Epoch [3/30], Batch [150/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [160/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [170/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [180/20508], Loss: 0.7049\n",
      "Epoch [3/30], Batch [190/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [200/20508], Loss: 0.7135\n",
      "Epoch [3/30], Batch [210/20508], Loss: 0.6905\n",
      "Epoch [3/30], Batch [220/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [230/20508], Loss: 0.6978\n",
      "Epoch [3/30], Batch [240/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [250/20508], Loss: 0.7007\n",
      "Epoch [3/30], Batch [260/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [270/20508], Loss: 0.7184\n",
      "Epoch [3/30], Batch [280/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [290/20508], Loss: 0.6968\n",
      "Epoch [3/30], Batch [300/20508], Loss: 0.7225\n",
      "Epoch [3/30], Batch [310/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [320/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [330/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [340/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [350/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [360/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [370/20508], Loss: 0.6845\n",
      "Epoch [3/30], Batch [380/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [390/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [400/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [410/20508], Loss: 0.6820\n",
      "Epoch [3/30], Batch [420/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [430/20508], Loss: 0.6573\n",
      "Epoch [3/30], Batch [440/20508], Loss: 0.7047\n",
      "Epoch [3/30], Batch [450/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [460/20508], Loss: 0.6764\n",
      "Epoch [3/30], Batch [470/20508], Loss: 0.6765\n",
      "Epoch [3/30], Batch [480/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [490/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [500/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [510/20508], Loss: 0.7083\n",
      "Epoch [3/30], Batch [520/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [530/20508], Loss: 0.7067\n",
      "Epoch [3/30], Batch [540/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [550/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [560/20508], Loss: 0.6974\n",
      "Epoch [3/30], Batch [570/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [580/20508], Loss: 0.6890\n",
      "Epoch [3/30], Batch [590/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [600/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [610/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [620/20508], Loss: 0.6912\n",
      "Epoch [3/30], Batch [630/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [640/20508], Loss: 0.6711\n",
      "Epoch [3/30], Batch [650/20508], Loss: 0.7083\n",
      "Epoch [3/30], Batch [660/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [670/20508], Loss: 0.7073\n",
      "Epoch [3/30], Batch [680/20508], Loss: 0.7045\n",
      "Epoch [3/30], Batch [690/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [700/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [710/20508], Loss: 0.7098\n",
      "Epoch [3/30], Batch [720/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [730/20508], Loss: 0.7049\n",
      "Epoch [3/30], Batch [740/20508], Loss: 0.7178\n",
      "Epoch [3/30], Batch [750/20508], Loss: 0.6705\n",
      "Epoch [3/30], Batch [760/20508], Loss: 0.6854\n",
      "Epoch [3/30], Batch [770/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [780/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [790/20508], Loss: 0.6744\n",
      "Epoch [3/30], Batch [800/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [810/20508], Loss: 0.6892\n",
      "Epoch [3/30], Batch [820/20508], Loss: 0.7011\n",
      "Epoch [3/30], Batch [830/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [840/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [850/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [860/20508], Loss: 0.7176\n",
      "Epoch [3/30], Batch [870/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [880/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [890/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [900/20508], Loss: 0.6844\n",
      "Epoch [3/30], Batch [910/20508], Loss: 0.7056\n",
      "Epoch [3/30], Batch [920/20508], Loss: 0.7044\n",
      "Epoch [3/30], Batch [930/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [940/20508], Loss: 0.6963\n",
      "Epoch [3/30], Batch [950/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [960/20508], Loss: 0.6947\n",
      "Epoch [3/30], Batch [970/20508], Loss: 0.7172\n",
      "Epoch [3/30], Batch [980/20508], Loss: 0.7089\n",
      "Epoch [3/30], Batch [990/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [1000/20508], Loss: 0.7068\n",
      "Epoch [3/30], Batch [1010/20508], Loss: 0.6963\n",
      "Epoch [3/30], Batch [1020/20508], Loss: 0.7010\n",
      "Epoch [3/30], Batch [1030/20508], Loss: 0.6762\n",
      "Epoch [3/30], Batch [1040/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [1050/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [1060/20508], Loss: 0.6820\n",
      "Epoch [3/30], Batch [1070/20508], Loss: 0.6790\n",
      "Epoch [3/30], Batch [1080/20508], Loss: 0.7277\n",
      "Epoch [3/30], Batch [1090/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [1100/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [1110/20508], Loss: 0.6890\n",
      "Epoch [3/30], Batch [1120/20508], Loss: 0.7114\n",
      "Epoch [3/30], Batch [1130/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [1140/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [1150/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [1160/20508], Loss: 0.6837\n",
      "Epoch [3/30], Batch [1170/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [1180/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [1190/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [1200/20508], Loss: 0.7013\n",
      "Epoch [3/30], Batch [1210/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [1220/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [1230/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [1240/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [1250/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [1260/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [1270/20508], Loss: 0.6826\n",
      "Epoch [3/30], Batch [1280/20508], Loss: 0.6997\n",
      "Epoch [3/30], Batch [1290/20508], Loss: 0.7067\n",
      "Epoch [3/30], Batch [1300/20508], Loss: 0.6925\n",
      "Epoch [3/30], Batch [1310/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [1320/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [1330/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [1340/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [1350/20508], Loss: 0.6736\n",
      "Epoch [3/30], Batch [1360/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [1370/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [1380/20508], Loss: 0.6648\n",
      "Epoch [3/30], Batch [1390/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [1400/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [1410/20508], Loss: 0.6990\n",
      "Epoch [3/30], Batch [1420/20508], Loss: 0.6687\n",
      "Epoch [3/30], Batch [1430/20508], Loss: 0.6795\n",
      "Epoch [3/30], Batch [1440/20508], Loss: 0.6708\n",
      "Epoch [3/30], Batch [1450/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [1460/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [1470/20508], Loss: 0.6713\n",
      "Epoch [3/30], Batch [1480/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [1490/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [1500/20508], Loss: 0.6726\n",
      "Epoch [3/30], Batch [1510/20508], Loss: 0.7038\n",
      "Epoch [3/30], Batch [1520/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [1530/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [1540/20508], Loss: 0.6883\n",
      "Epoch [3/30], Batch [1550/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [1560/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [1570/20508], Loss: 0.7284\n",
      "Epoch [3/30], Batch [1580/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [1590/20508], Loss: 0.6992\n",
      "Epoch [3/30], Batch [1600/20508], Loss: 0.7133\n",
      "Epoch [3/30], Batch [1610/20508], Loss: 0.6727\n",
      "Epoch [3/30], Batch [1620/20508], Loss: 0.6846\n",
      "Epoch [3/30], Batch [1630/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [1640/20508], Loss: 0.7094\n",
      "Epoch [3/30], Batch [1650/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [1660/20508], Loss: 0.6803\n",
      "Epoch [3/30], Batch [1670/20508], Loss: 0.7228\n",
      "Epoch [3/30], Batch [1680/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [1690/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [1700/20508], Loss: 0.7062\n",
      "Epoch [3/30], Batch [1710/20508], Loss: 0.6750\n",
      "Epoch [3/30], Batch [1720/20508], Loss: 0.7060\n",
      "Epoch [3/30], Batch [1730/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [1740/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [1750/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [1760/20508], Loss: 0.7132\n",
      "Epoch [3/30], Batch [1770/20508], Loss: 0.6735\n",
      "Epoch [3/30], Batch [1780/20508], Loss: 0.6982\n",
      "Epoch [3/30], Batch [1790/20508], Loss: 0.6772\n",
      "Epoch [3/30], Batch [1800/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [1810/20508], Loss: 0.6715\n",
      "Epoch [3/30], Batch [1820/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [1830/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [1840/20508], Loss: 0.7132\n",
      "Epoch [3/30], Batch [1850/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [1860/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [1870/20508], Loss: 0.7078\n",
      "Epoch [3/30], Batch [1880/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [1890/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [1900/20508], Loss: 0.6974\n",
      "Epoch [3/30], Batch [1910/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [1920/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [1930/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [1940/20508], Loss: 0.7043\n",
      "Epoch [3/30], Batch [1950/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [1960/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [1970/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [1980/20508], Loss: 0.6720\n",
      "Epoch [3/30], Batch [1990/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [2000/20508], Loss: 0.6766\n",
      "Epoch [3/30], Batch [2010/20508], Loss: 0.7071\n",
      "Epoch [3/30], Batch [2020/20508], Loss: 0.6752\n",
      "Epoch [3/30], Batch [2030/20508], Loss: 0.6976\n",
      "Epoch [3/30], Batch [2040/20508], Loss: 0.6976\n",
      "Epoch [3/30], Batch [2050/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [2060/20508], Loss: 0.6968\n",
      "Epoch [3/30], Batch [2070/20508], Loss: 0.6823\n",
      "Epoch [3/30], Batch [2080/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [2090/20508], Loss: 0.6780\n",
      "Epoch [3/30], Batch [2100/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [2110/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [2120/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [2130/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [2140/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [2150/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [2160/20508], Loss: 0.6730\n",
      "Epoch [3/30], Batch [2170/20508], Loss: 0.6845\n",
      "Epoch [3/30], Batch [2180/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [2190/20508], Loss: 0.7069\n",
      "Epoch [3/30], Batch [2200/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [2210/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [2220/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [2230/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [2240/20508], Loss: 0.6911\n",
      "Epoch [3/30], Batch [2250/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [2260/20508], Loss: 0.6756\n",
      "Epoch [3/30], Batch [2270/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [2280/20508], Loss: 0.7032\n",
      "Epoch [3/30], Batch [2290/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [2300/20508], Loss: 0.6886\n",
      "Epoch [3/30], Batch [2310/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [2320/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [2330/20508], Loss: 0.7116\n",
      "Epoch [3/30], Batch [2340/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [2350/20508], Loss: 0.6774\n",
      "Epoch [3/30], Batch [2360/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [2370/20508], Loss: 0.7082\n",
      "Epoch [3/30], Batch [2380/20508], Loss: 0.7016\n",
      "Epoch [3/30], Batch [2390/20508], Loss: 0.6727\n",
      "Epoch [3/30], Batch [2400/20508], Loss: 0.6803\n",
      "Epoch [3/30], Batch [2410/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [2420/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [2430/20508], Loss: 0.6978\n",
      "Epoch [3/30], Batch [2440/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [2450/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [2460/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [2470/20508], Loss: 0.7048\n",
      "Epoch [3/30], Batch [2480/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [2490/20508], Loss: 0.6942\n",
      "Epoch [3/30], Batch [2500/20508], Loss: 0.6818\n",
      "Epoch [3/30], Batch [2510/20508], Loss: 0.7026\n",
      "Epoch [3/30], Batch [2520/20508], Loss: 0.7070\n",
      "Epoch [3/30], Batch [2530/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [2540/20508], Loss: 0.6774\n",
      "Epoch [3/30], Batch [2550/20508], Loss: 0.6733\n",
      "Epoch [3/30], Batch [2560/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [2570/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [2580/20508], Loss: 0.7055\n",
      "Epoch [3/30], Batch [2590/20508], Loss: 0.7110\n",
      "Epoch [3/30], Batch [2600/20508], Loss: 0.6945\n",
      "Epoch [3/30], Batch [2610/20508], Loss: 0.7089\n",
      "Epoch [3/30], Batch [2620/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [2630/20508], Loss: 0.6858\n",
      "Epoch [3/30], Batch [2640/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [2650/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [2660/20508], Loss: 0.7102\n",
      "Epoch [3/30], Batch [2670/20508], Loss: 0.6768\n",
      "Epoch [3/30], Batch [2680/20508], Loss: 0.6875\n",
      "Epoch [3/30], Batch [2690/20508], Loss: 0.6786\n",
      "Epoch [3/30], Batch [2700/20508], Loss: 0.7131\n",
      "Epoch [3/30], Batch [2710/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [2720/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [2730/20508], Loss: 0.7092\n",
      "Epoch [3/30], Batch [2740/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [2750/20508], Loss: 0.7102\n",
      "Epoch [3/30], Batch [2760/20508], Loss: 0.7077\n",
      "Epoch [3/30], Batch [2770/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [2780/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [2790/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [2800/20508], Loss: 0.7159\n",
      "Epoch [3/30], Batch [2810/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [2820/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [2830/20508], Loss: 0.6673\n",
      "Epoch [3/30], Batch [2840/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [2850/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [2860/20508], Loss: 0.6898\n",
      "Epoch [3/30], Batch [2870/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [2880/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [2890/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [2900/20508], Loss: 0.7084\n",
      "Epoch [3/30], Batch [2910/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [2920/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [2930/20508], Loss: 0.7029\n",
      "Epoch [3/30], Batch [2940/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [2950/20508], Loss: 0.7067\n",
      "Epoch [3/30], Batch [2960/20508], Loss: 0.7086\n",
      "Epoch [3/30], Batch [2970/20508], Loss: 0.7124\n",
      "Epoch [3/30], Batch [2980/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [2990/20508], Loss: 0.6912\n",
      "Epoch [3/30], Batch [3000/20508], Loss: 0.6781\n",
      "Epoch [3/30], Batch [3010/20508], Loss: 0.7061\n",
      "Epoch [3/30], Batch [3020/20508], Loss: 0.7008\n",
      "Epoch [3/30], Batch [3030/20508], Loss: 0.6930\n",
      "Epoch [3/30], Batch [3040/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [3050/20508], Loss: 0.7059\n",
      "Epoch [3/30], Batch [3060/20508], Loss: 0.7054\n",
      "Epoch [3/30], Batch [3070/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [3080/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [3090/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [3100/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [3110/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [3120/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [3130/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [3140/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [3150/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [3160/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [3170/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [3180/20508], Loss: 0.6931\n",
      "Epoch [3/30], Batch [3190/20508], Loss: 0.7122\n",
      "Epoch [3/30], Batch [3200/20508], Loss: 0.6974\n",
      "Epoch [3/30], Batch [3210/20508], Loss: 0.6826\n",
      "Epoch [3/30], Batch [3220/20508], Loss: 0.7217\n",
      "Epoch [3/30], Batch [3230/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [3240/20508], Loss: 0.7146\n",
      "Epoch [3/30], Batch [3250/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [3260/20508], Loss: 0.7110\n",
      "Epoch [3/30], Batch [3270/20508], Loss: 0.6759\n",
      "Epoch [3/30], Batch [3280/20508], Loss: 0.6896\n",
      "Epoch [3/30], Batch [3290/20508], Loss: 0.7020\n",
      "Epoch [3/30], Batch [3300/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [3310/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [3320/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [3330/20508], Loss: 0.6756\n",
      "Epoch [3/30], Batch [3340/20508], Loss: 0.6927\n",
      "Epoch [3/30], Batch [3350/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [3360/20508], Loss: 0.7059\n",
      "Epoch [3/30], Batch [3370/20508], Loss: 0.7147\n",
      "Epoch [3/30], Batch [3380/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [3390/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [3400/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [3410/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [3420/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [3430/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [3440/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [3450/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [3460/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [3470/20508], Loss: 0.6778\n",
      "Epoch [3/30], Batch [3480/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [3490/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [3500/20508], Loss: 0.6748\n",
      "Epoch [3/30], Batch [3510/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [3520/20508], Loss: 0.6699\n",
      "Epoch [3/30], Batch [3530/20508], Loss: 0.6944\n",
      "Epoch [3/30], Batch [3540/20508], Loss: 0.7218\n",
      "Epoch [3/30], Batch [3550/20508], Loss: 0.7048\n",
      "Epoch [3/30], Batch [3560/20508], Loss: 0.6881\n",
      "Epoch [3/30], Batch [3570/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [3580/20508], Loss: 0.6818\n",
      "Epoch [3/30], Batch [3590/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [3600/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [3610/20508], Loss: 0.7186\n",
      "Epoch [3/30], Batch [3620/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [3630/20508], Loss: 0.6805\n",
      "Epoch [3/30], Batch [3640/20508], Loss: 0.6732\n",
      "Epoch [3/30], Batch [3650/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [3660/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [3670/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [3680/20508], Loss: 0.6805\n",
      "Epoch [3/30], Batch [3690/20508], Loss: 0.7016\n",
      "Epoch [3/30], Batch [3700/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [3710/20508], Loss: 0.6785\n",
      "Epoch [3/30], Batch [3720/20508], Loss: 0.6762\n",
      "Epoch [3/30], Batch [3730/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [3740/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [3750/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [3760/20508], Loss: 0.6712\n",
      "Epoch [3/30], Batch [3770/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [3780/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [3790/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [3800/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [3810/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [3820/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [3830/20508], Loss: 0.6902\n",
      "Epoch [3/30], Batch [3840/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [3850/20508], Loss: 0.7085\n",
      "Epoch [3/30], Batch [3860/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [3870/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [3880/20508], Loss: 0.6911\n",
      "Epoch [3/30], Batch [3890/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [3900/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [3910/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [3920/20508], Loss: 0.7016\n",
      "Epoch [3/30], Batch [3930/20508], Loss: 0.6850\n",
      "Epoch [3/30], Batch [3940/20508], Loss: 0.6913\n",
      "Epoch [3/30], Batch [3950/20508], Loss: 0.7137\n",
      "Epoch [3/30], Batch [3960/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [3970/20508], Loss: 0.6734\n",
      "Epoch [3/30], Batch [3980/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [3990/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [4000/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [4010/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [4020/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [4030/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [4040/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [4050/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [4060/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [4070/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [4080/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [4090/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [4100/20508], Loss: 0.6955\n",
      "Epoch [3/30], Batch [4110/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [4120/20508], Loss: 0.7033\n",
      "Epoch [3/30], Batch [4130/20508], Loss: 0.6800\n",
      "Epoch [3/30], Batch [4140/20508], Loss: 0.6899\n",
      "Epoch [3/30], Batch [4150/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [4160/20508], Loss: 0.6999\n",
      "Epoch [3/30], Batch [4170/20508], Loss: 0.6915\n",
      "Epoch [3/30], Batch [4180/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [4190/20508], Loss: 0.7108\n",
      "Epoch [3/30], Batch [4200/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [4210/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [4220/20508], Loss: 0.6875\n",
      "Epoch [3/30], Batch [4230/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [4240/20508], Loss: 0.6771\n",
      "Epoch [3/30], Batch [4250/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [4260/20508], Loss: 0.6991\n",
      "Epoch [3/30], Batch [4270/20508], Loss: 0.7068\n",
      "Epoch [3/30], Batch [4280/20508], Loss: 0.7087\n",
      "Epoch [3/30], Batch [4290/20508], Loss: 0.7026\n",
      "Epoch [3/30], Batch [4300/20508], Loss: 0.6915\n",
      "Epoch [3/30], Batch [4310/20508], Loss: 0.7150\n",
      "Epoch [3/30], Batch [4320/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [4330/20508], Loss: 0.6758\n",
      "Epoch [3/30], Batch [4340/20508], Loss: 0.7045\n",
      "Epoch [3/30], Batch [4350/20508], Loss: 0.6978\n",
      "Epoch [3/30], Batch [4360/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [4370/20508], Loss: 0.7007\n",
      "Epoch [3/30], Batch [4380/20508], Loss: 0.6713\n",
      "Epoch [3/30], Batch [4390/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [4400/20508], Loss: 0.6925\n",
      "Epoch [3/30], Batch [4410/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [4420/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [4430/20508], Loss: 0.7046\n",
      "Epoch [3/30], Batch [4440/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [4450/20508], Loss: 0.6716\n",
      "Epoch [3/30], Batch [4460/20508], Loss: 0.6804\n",
      "Epoch [3/30], Batch [4470/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [4480/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [4490/20508], Loss: 0.6911\n",
      "Epoch [3/30], Batch [4500/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [4510/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [4520/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [4530/20508], Loss: 0.6757\n",
      "Epoch [3/30], Batch [4540/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [4550/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [4560/20508], Loss: 0.7006\n",
      "Epoch [3/30], Batch [4570/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [4580/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [4590/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [4600/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [4610/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [4620/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [4630/20508], Loss: 0.6883\n",
      "Epoch [3/30], Batch [4640/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [4650/20508], Loss: 0.6984\n",
      "Epoch [3/30], Batch [4660/20508], Loss: 0.7022\n",
      "Epoch [3/30], Batch [4670/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [4680/20508], Loss: 0.7136\n",
      "Epoch [3/30], Batch [4690/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [4700/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [4710/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [4720/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [4730/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [4740/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [4750/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [4760/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [4770/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [4780/20508], Loss: 0.6604\n",
      "Epoch [3/30], Batch [4790/20508], Loss: 0.6986\n",
      "Epoch [3/30], Batch [4800/20508], Loss: 0.6931\n",
      "Epoch [3/30], Batch [4810/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [4820/20508], Loss: 0.6899\n",
      "Epoch [3/30], Batch [4830/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [4840/20508], Loss: 0.6836\n",
      "Epoch [3/30], Batch [4850/20508], Loss: 0.6835\n",
      "Epoch [3/30], Batch [4860/20508], Loss: 0.6963\n",
      "Epoch [3/30], Batch [4870/20508], Loss: 0.6672\n",
      "Epoch [3/30], Batch [4880/20508], Loss: 0.7056\n",
      "Epoch [3/30], Batch [4890/20508], Loss: 0.6952\n",
      "Epoch [3/30], Batch [4900/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [4910/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [4920/20508], Loss: 0.7289\n",
      "Epoch [3/30], Batch [4930/20508], Loss: 0.7049\n",
      "Epoch [3/30], Batch [4940/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [4950/20508], Loss: 0.6761\n",
      "Epoch [3/30], Batch [4960/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [4970/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [4980/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [4990/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [5000/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [5010/20508], Loss: 0.6717\n",
      "Epoch [3/30], Batch [5020/20508], Loss: 0.6875\n",
      "Epoch [3/30], Batch [5030/20508], Loss: 0.6820\n",
      "Epoch [3/30], Batch [5040/20508], Loss: 0.7010\n",
      "Epoch [3/30], Batch [5050/20508], Loss: 0.7124\n",
      "Epoch [3/30], Batch [5060/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [5070/20508], Loss: 0.6897\n",
      "Epoch [3/30], Batch [5080/20508], Loss: 0.6950\n",
      "Epoch [3/30], Batch [5090/20508], Loss: 0.7059\n",
      "Epoch [3/30], Batch [5100/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [5110/20508], Loss: 0.6784\n",
      "Epoch [3/30], Batch [5120/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [5130/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [5140/20508], Loss: 0.6764\n",
      "Epoch [3/30], Batch [5150/20508], Loss: 0.7177\n",
      "Epoch [3/30], Batch [5160/20508], Loss: 0.7142\n",
      "Epoch [3/30], Batch [5170/20508], Loss: 0.6854\n",
      "Epoch [3/30], Batch [5180/20508], Loss: 0.6818\n",
      "Epoch [3/30], Batch [5190/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [5200/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [5210/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [5220/20508], Loss: 0.7129\n",
      "Epoch [3/30], Batch [5230/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [5240/20508], Loss: 0.6850\n",
      "Epoch [3/30], Batch [5250/20508], Loss: 0.7032\n",
      "Epoch [3/30], Batch [5260/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [5270/20508], Loss: 0.7145\n",
      "Epoch [3/30], Batch [5280/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [5290/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [5300/20508], Loss: 0.6775\n",
      "Epoch [3/30], Batch [5310/20508], Loss: 0.6844\n",
      "Epoch [3/30], Batch [5320/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [5330/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [5340/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [5350/20508], Loss: 0.6921\n",
      "Epoch [3/30], Batch [5360/20508], Loss: 0.6947\n",
      "Epoch [3/30], Batch [5370/20508], Loss: 0.6881\n",
      "Epoch [3/30], Batch [5380/20508], Loss: 0.6976\n",
      "Epoch [3/30], Batch [5390/20508], Loss: 0.7078\n",
      "Epoch [3/30], Batch [5400/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [5410/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [5420/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [5430/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [5440/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [5450/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [5460/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [5470/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [5480/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [5490/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [5500/20508], Loss: 0.6915\n",
      "Epoch [3/30], Batch [5510/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [5520/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [5530/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [5540/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [5550/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [5560/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [5570/20508], Loss: 0.6756\n",
      "Epoch [3/30], Batch [5580/20508], Loss: 0.6978\n",
      "Epoch [3/30], Batch [5590/20508], Loss: 0.6743\n",
      "Epoch [3/30], Batch [5600/20508], Loss: 0.6687\n",
      "Epoch [3/30], Batch [5610/20508], Loss: 0.7010\n",
      "Epoch [3/30], Batch [5620/20508], Loss: 0.6818\n",
      "Epoch [3/30], Batch [5630/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [5640/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [5650/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [5660/20508], Loss: 0.6945\n",
      "Epoch [3/30], Batch [5670/20508], Loss: 0.7173\n",
      "Epoch [3/30], Batch [5680/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [5690/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [5700/20508], Loss: 0.6684\n",
      "Epoch [3/30], Batch [5710/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [5720/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [5730/20508], Loss: 0.7128\n",
      "Epoch [3/30], Batch [5740/20508], Loss: 0.6719\n",
      "Epoch [3/30], Batch [5750/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [5760/20508], Loss: 0.7070\n",
      "Epoch [3/30], Batch [5770/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [5780/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [5790/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [5800/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [5810/20508], Loss: 0.7136\n",
      "Epoch [3/30], Batch [5820/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [5830/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [5840/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [5850/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [5860/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [5870/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [5880/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [5890/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [5900/20508], Loss: 0.6696\n",
      "Epoch [3/30], Batch [5910/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [5920/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [5930/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [5940/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [5950/20508], Loss: 0.6768\n",
      "Epoch [3/30], Batch [5960/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [5970/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [5980/20508], Loss: 0.6881\n",
      "Epoch [3/30], Batch [5990/20508], Loss: 0.6675\n",
      "Epoch [3/30], Batch [6000/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [6010/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [6020/20508], Loss: 0.7077\n",
      "Epoch [3/30], Batch [6030/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [6040/20508], Loss: 0.6646\n",
      "Epoch [3/30], Batch [6050/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [6060/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [6070/20508], Loss: 0.7058\n",
      "Epoch [3/30], Batch [6080/20508], Loss: 0.6785\n",
      "Epoch [3/30], Batch [6090/20508], Loss: 0.6788\n",
      "Epoch [3/30], Batch [6100/20508], Loss: 0.6780\n",
      "Epoch [3/30], Batch [6110/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [6120/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [6130/20508], Loss: 0.6685\n",
      "Epoch [3/30], Batch [6140/20508], Loss: 0.6799\n",
      "Epoch [3/30], Batch [6150/20508], Loss: 0.7029\n",
      "Epoch [3/30], Batch [6160/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [6170/20508], Loss: 0.6721\n",
      "Epoch [3/30], Batch [6180/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [6190/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [6200/20508], Loss: 0.7048\n",
      "Epoch [3/30], Batch [6210/20508], Loss: 0.6848\n",
      "Epoch [3/30], Batch [6220/20508], Loss: 0.6990\n",
      "Epoch [3/30], Batch [6230/20508], Loss: 0.6706\n",
      "Epoch [3/30], Batch [6240/20508], Loss: 0.6829\n",
      "Epoch [3/30], Batch [6250/20508], Loss: 0.7072\n",
      "Epoch [3/30], Batch [6260/20508], Loss: 0.6927\n",
      "Epoch [3/30], Batch [6270/20508], Loss: 0.6992\n",
      "Epoch [3/30], Batch [6280/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [6290/20508], Loss: 0.7047\n",
      "Epoch [3/30], Batch [6300/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [6310/20508], Loss: 0.6825\n",
      "Epoch [3/30], Batch [6320/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [6330/20508], Loss: 0.7059\n",
      "Epoch [3/30], Batch [6340/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [6350/20508], Loss: 0.7194\n",
      "Epoch [3/30], Batch [6360/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [6370/20508], Loss: 0.7100\n",
      "Epoch [3/30], Batch [6380/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [6390/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [6400/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [6410/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [6420/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [6430/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [6440/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [6450/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [6460/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [6470/20508], Loss: 0.6772\n",
      "Epoch [3/30], Batch [6480/20508], Loss: 0.7100\n",
      "Epoch [3/30], Batch [6490/20508], Loss: 0.7089\n",
      "Epoch [3/30], Batch [6500/20508], Loss: 0.6976\n",
      "Epoch [3/30], Batch [6510/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [6520/20508], Loss: 0.6712\n",
      "Epoch [3/30], Batch [6530/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [6540/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [6550/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [6560/20508], Loss: 0.7036\n",
      "Epoch [3/30], Batch [6570/20508], Loss: 0.6942\n",
      "Epoch [3/30], Batch [6580/20508], Loss: 0.6821\n",
      "Epoch [3/30], Batch [6590/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [6600/20508], Loss: 0.7160\n",
      "Epoch [3/30], Batch [6610/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [6620/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [6630/20508], Loss: 0.6676\n",
      "Epoch [3/30], Batch [6640/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [6650/20508], Loss: 0.6823\n",
      "Epoch [3/30], Batch [6660/20508], Loss: 0.7043\n",
      "Epoch [3/30], Batch [6670/20508], Loss: 0.7046\n",
      "Epoch [3/30], Batch [6680/20508], Loss: 0.6835\n",
      "Epoch [3/30], Batch [6690/20508], Loss: 0.6762\n",
      "Epoch [3/30], Batch [6700/20508], Loss: 0.7009\n",
      "Epoch [3/30], Batch [6710/20508], Loss: 0.6898\n",
      "Epoch [3/30], Batch [6720/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [6730/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [6740/20508], Loss: 0.6728\n",
      "Epoch [3/30], Batch [6750/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [6760/20508], Loss: 0.6804\n",
      "Epoch [3/30], Batch [6770/20508], Loss: 0.7182\n",
      "Epoch [3/30], Batch [6780/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [6790/20508], Loss: 0.6761\n",
      "Epoch [3/30], Batch [6800/20508], Loss: 0.6754\n",
      "Epoch [3/30], Batch [6810/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [6820/20508], Loss: 0.6773\n",
      "Epoch [3/30], Batch [6830/20508], Loss: 0.6723\n",
      "Epoch [3/30], Batch [6840/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [6850/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [6860/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [6870/20508], Loss: 0.6758\n",
      "Epoch [3/30], Batch [6880/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [6890/20508], Loss: 0.6804\n",
      "Epoch [3/30], Batch [6900/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [6910/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [6920/20508], Loss: 0.7054\n",
      "Epoch [3/30], Batch [6930/20508], Loss: 0.7076\n",
      "Epoch [3/30], Batch [6940/20508], Loss: 0.7064\n",
      "Epoch [3/30], Batch [6950/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [6960/20508], Loss: 0.6695\n",
      "Epoch [3/30], Batch [6970/20508], Loss: 0.6983\n",
      "Epoch [3/30], Batch [6980/20508], Loss: 0.6682\n",
      "Epoch [3/30], Batch [6990/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [7000/20508], Loss: 0.6733\n",
      "Epoch [3/30], Batch [7010/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [7020/20508], Loss: 0.7069\n",
      "Epoch [3/30], Batch [7030/20508], Loss: 0.7085\n",
      "Epoch [3/30], Batch [7040/20508], Loss: 0.6764\n",
      "Epoch [3/30], Batch [7050/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [7060/20508], Loss: 0.6799\n",
      "Epoch [3/30], Batch [7070/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [7080/20508], Loss: 0.6655\n",
      "Epoch [3/30], Batch [7090/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [7100/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [7110/20508], Loss: 0.7101\n",
      "Epoch [3/30], Batch [7120/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [7130/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [7140/20508], Loss: 0.6836\n",
      "Epoch [3/30], Batch [7150/20508], Loss: 0.7080\n",
      "Epoch [3/30], Batch [7160/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [7170/20508], Loss: 0.6941\n",
      "Epoch [3/30], Batch [7180/20508], Loss: 0.6692\n",
      "Epoch [3/30], Batch [7190/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [7200/20508], Loss: 0.6657\n",
      "Epoch [3/30], Batch [7210/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [7220/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [7230/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [7240/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [7250/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [7260/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [7270/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [7280/20508], Loss: 0.7013\n",
      "Epoch [3/30], Batch [7290/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [7300/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [7310/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [7320/20508], Loss: 0.6714\n",
      "Epoch [3/30], Batch [7330/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [7340/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [7350/20508], Loss: 0.6630\n",
      "Epoch [3/30], Batch [7360/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [7370/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [7380/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [7390/20508], Loss: 0.6820\n",
      "Epoch [3/30], Batch [7400/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [7410/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [7420/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [7430/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [7440/20508], Loss: 0.6832\n",
      "Epoch [3/30], Batch [7450/20508], Loss: 0.7200\n",
      "Epoch [3/30], Batch [7460/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [7470/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [7480/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [7490/20508], Loss: 0.6782\n",
      "Epoch [3/30], Batch [7500/20508], Loss: 0.6837\n",
      "Epoch [3/30], Batch [7510/20508], Loss: 0.6780\n",
      "Epoch [3/30], Batch [7520/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [7530/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [7540/20508], Loss: 0.6757\n",
      "Epoch [3/30], Batch [7550/20508], Loss: 0.6703\n",
      "Epoch [3/30], Batch [7560/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [7570/20508], Loss: 0.7016\n",
      "Epoch [3/30], Batch [7580/20508], Loss: 0.6961\n",
      "Epoch [3/30], Batch [7590/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [7600/20508], Loss: 0.6949\n",
      "Epoch [3/30], Batch [7610/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [7620/20508], Loss: 0.7084\n",
      "Epoch [3/30], Batch [7630/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [7640/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [7650/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [7660/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [7670/20508], Loss: 0.6998\n",
      "Epoch [3/30], Batch [7680/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [7690/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [7700/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [7710/20508], Loss: 0.6739\n",
      "Epoch [3/30], Batch [7720/20508], Loss: 0.7063\n",
      "Epoch [3/30], Batch [7730/20508], Loss: 0.7098\n",
      "Epoch [3/30], Batch [7740/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [7750/20508], Loss: 0.6682\n",
      "Epoch [3/30], Batch [7760/20508], Loss: 0.7252\n",
      "Epoch [3/30], Batch [7770/20508], Loss: 0.7060\n",
      "Epoch [3/30], Batch [7780/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [7790/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [7800/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [7810/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [7820/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [7830/20508], Loss: 0.6774\n",
      "Epoch [3/30], Batch [7840/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [7850/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [7860/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [7870/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [7880/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [7890/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [7900/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [7910/20508], Loss: 0.6803\n",
      "Epoch [3/30], Batch [7920/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [7930/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [7940/20508], Loss: 0.6705\n",
      "Epoch [3/30], Batch [7950/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [7960/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [7970/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [7980/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [7990/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [8000/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [8010/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [8020/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [8030/20508], Loss: 0.7120\n",
      "Epoch [3/30], Batch [8040/20508], Loss: 0.6772\n",
      "Epoch [3/30], Batch [8050/20508], Loss: 0.6710\n",
      "Epoch [3/30], Batch [8060/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [8070/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [8080/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [8090/20508], Loss: 0.6667\n",
      "Epoch [3/30], Batch [8100/20508], Loss: 0.6838\n",
      "Epoch [3/30], Batch [8110/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [8120/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [8130/20508], Loss: 0.6947\n",
      "Epoch [3/30], Batch [8140/20508], Loss: 0.6701\n",
      "Epoch [3/30], Batch [8150/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [8160/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [8170/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [8180/20508], Loss: 0.6899\n",
      "Epoch [3/30], Batch [8190/20508], Loss: 0.6945\n",
      "Epoch [3/30], Batch [8200/20508], Loss: 0.7074\n",
      "Epoch [3/30], Batch [8210/20508], Loss: 0.7036\n",
      "Epoch [3/30], Batch [8220/20508], Loss: 0.6881\n",
      "Epoch [3/30], Batch [8230/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [8240/20508], Loss: 0.6710\n",
      "Epoch [3/30], Batch [8250/20508], Loss: 0.7092\n",
      "Epoch [3/30], Batch [8260/20508], Loss: 0.6909\n",
      "Epoch [3/30], Batch [8270/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [8280/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [8290/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [8300/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [8310/20508], Loss: 0.6697\n",
      "Epoch [3/30], Batch [8320/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [8330/20508], Loss: 0.6761\n",
      "Epoch [3/30], Batch [8340/20508], Loss: 0.6531\n",
      "Epoch [3/30], Batch [8350/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [8360/20508], Loss: 0.6992\n",
      "Epoch [3/30], Batch [8370/20508], Loss: 0.6791\n",
      "Epoch [3/30], Batch [8380/20508], Loss: 0.6968\n",
      "Epoch [3/30], Batch [8390/20508], Loss: 0.6767\n",
      "Epoch [3/30], Batch [8400/20508], Loss: 0.6896\n",
      "Epoch [3/30], Batch [8410/20508], Loss: 0.6997\n",
      "Epoch [3/30], Batch [8420/20508], Loss: 0.6710\n",
      "Epoch [3/30], Batch [8430/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [8440/20508], Loss: 0.6851\n",
      "Epoch [3/30], Batch [8450/20508], Loss: 0.6765\n",
      "Epoch [3/30], Batch [8460/20508], Loss: 0.7066\n",
      "Epoch [3/30], Batch [8470/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [8480/20508], Loss: 0.6710\n",
      "Epoch [3/30], Batch [8490/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [8500/20508], Loss: 0.6754\n",
      "Epoch [3/30], Batch [8510/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [8520/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [8530/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [8540/20508], Loss: 0.6704\n",
      "Epoch [3/30], Batch [8550/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [8560/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [8570/20508], Loss: 0.6759\n",
      "Epoch [3/30], Batch [8580/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [8590/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [8600/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [8610/20508], Loss: 0.6930\n",
      "Epoch [3/30], Batch [8620/20508], Loss: 0.7114\n",
      "Epoch [3/30], Batch [8630/20508], Loss: 0.6661\n",
      "Epoch [3/30], Batch [8640/20508], Loss: 0.6646\n",
      "Epoch [3/30], Batch [8650/20508], Loss: 0.6886\n",
      "Epoch [3/30], Batch [8660/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [8670/20508], Loss: 0.6661\n",
      "Epoch [3/30], Batch [8680/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [8690/20508], Loss: 0.6997\n",
      "Epoch [3/30], Batch [8700/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [8710/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [8720/20508], Loss: 0.6766\n",
      "Epoch [3/30], Batch [8730/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [8740/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [8750/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [8760/20508], Loss: 0.6791\n",
      "Epoch [3/30], Batch [8770/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [8780/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [8790/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [8800/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [8810/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [8820/20508], Loss: 0.7135\n",
      "Epoch [3/30], Batch [8830/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [8840/20508], Loss: 0.6821\n",
      "Epoch [3/30], Batch [8850/20508], Loss: 0.6848\n",
      "Epoch [3/30], Batch [8860/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [8870/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [8880/20508], Loss: 0.6791\n",
      "Epoch [3/30], Batch [8890/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [8900/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [8910/20508], Loss: 0.6663\n",
      "Epoch [3/30], Batch [8920/20508], Loss: 0.7086\n",
      "Epoch [3/30], Batch [8930/20508], Loss: 0.6659\n",
      "Epoch [3/30], Batch [8940/20508], Loss: 0.7083\n",
      "Epoch [3/30], Batch [8950/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [8960/20508], Loss: 0.6706\n",
      "Epoch [3/30], Batch [8970/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [8980/20508], Loss: 0.6676\n",
      "Epoch [3/30], Batch [8990/20508], Loss: 0.7058\n",
      "Epoch [3/30], Batch [9000/20508], Loss: 0.7071\n",
      "Epoch [3/30], Batch [9010/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [9020/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [9030/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [9040/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [9050/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [9060/20508], Loss: 0.6715\n",
      "Epoch [3/30], Batch [9070/20508], Loss: 0.6912\n",
      "Epoch [3/30], Batch [9080/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [9090/20508], Loss: 0.6804\n",
      "Epoch [3/30], Batch [9100/20508], Loss: 0.6724\n",
      "Epoch [3/30], Batch [9110/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [9120/20508], Loss: 0.6615\n",
      "Epoch [3/30], Batch [9130/20508], Loss: 0.6998\n",
      "Epoch [3/30], Batch [9140/20508], Loss: 0.7056\n",
      "Epoch [3/30], Batch [9150/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [9160/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [9170/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [9180/20508], Loss: 0.6741\n",
      "Epoch [3/30], Batch [9190/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [9200/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [9210/20508], Loss: 0.6745\n",
      "Epoch [3/30], Batch [9220/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [9230/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [9240/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [9250/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [9260/20508], Loss: 0.6611\n",
      "Epoch [3/30], Batch [9270/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [9280/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [9290/20508], Loss: 0.7239\n",
      "Epoch [3/30], Batch [9300/20508], Loss: 0.7073\n",
      "Epoch [3/30], Batch [9310/20508], Loss: 0.6738\n",
      "Epoch [3/30], Batch [9320/20508], Loss: 0.6741\n",
      "Epoch [3/30], Batch [9330/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [9340/20508], Loss: 0.7058\n",
      "Epoch [3/30], Batch [9350/20508], Loss: 0.6754\n",
      "Epoch [3/30], Batch [9360/20508], Loss: 0.6677\n",
      "Epoch [3/30], Batch [9370/20508], Loss: 0.6775\n",
      "Epoch [3/30], Batch [9380/20508], Loss: 0.6850\n",
      "Epoch [3/30], Batch [9390/20508], Loss: 0.7124\n",
      "Epoch [3/30], Batch [9400/20508], Loss: 0.6729\n",
      "Epoch [3/30], Batch [9410/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [9420/20508], Loss: 0.6725\n",
      "Epoch [3/30], Batch [9430/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [9440/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [9450/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [9460/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [9470/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [9480/20508], Loss: 0.7000\n",
      "Epoch [3/30], Batch [9490/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [9500/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [9510/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [9520/20508], Loss: 0.6960\n",
      "Epoch [3/30], Batch [9530/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [9540/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [9550/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [9560/20508], Loss: 0.6772\n",
      "Epoch [3/30], Batch [9570/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [9580/20508], Loss: 0.7054\n",
      "Epoch [3/30], Batch [9590/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [9600/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [9610/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [9620/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [9630/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [9640/20508], Loss: 0.6944\n",
      "Epoch [3/30], Batch [9650/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [9660/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [9670/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [9680/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [9690/20508], Loss: 0.7122\n",
      "Epoch [3/30], Batch [9700/20508], Loss: 0.7007\n",
      "Epoch [3/30], Batch [9710/20508], Loss: 0.7005\n",
      "Epoch [3/30], Batch [9720/20508], Loss: 0.6699\n",
      "Epoch [3/30], Batch [9730/20508], Loss: 0.7032\n",
      "Epoch [3/30], Batch [9740/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [9750/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [9760/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [9770/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [9780/20508], Loss: 0.6723\n",
      "Epoch [3/30], Batch [9790/20508], Loss: 0.6947\n",
      "Epoch [3/30], Batch [9800/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [9810/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [9820/20508], Loss: 0.6700\n",
      "Epoch [3/30], Batch [9830/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [9840/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [9850/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [9860/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [9870/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [9880/20508], Loss: 0.7131\n",
      "Epoch [3/30], Batch [9890/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [9900/20508], Loss: 0.6727\n",
      "Epoch [3/30], Batch [9910/20508], Loss: 0.6897\n",
      "Epoch [3/30], Batch [9920/20508], Loss: 0.6720\n",
      "Epoch [3/30], Batch [9930/20508], Loss: 0.7078\n",
      "Epoch [3/30], Batch [9940/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [9950/20508], Loss: 0.7089\n",
      "Epoch [3/30], Batch [9960/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [9970/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [9980/20508], Loss: 0.6783\n",
      "Epoch [3/30], Batch [9990/20508], Loss: 0.7115\n",
      "Epoch [3/30], Batch [10000/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [10010/20508], Loss: 0.6720\n",
      "Epoch [3/30], Batch [10020/20508], Loss: 0.6683\n",
      "Epoch [3/30], Batch [10030/20508], Loss: 0.6920\n",
      "Epoch [3/30], Batch [10040/20508], Loss: 0.6795\n",
      "Epoch [3/30], Batch [10050/20508], Loss: 0.7104\n",
      "Epoch [3/30], Batch [10060/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [10070/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [10080/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [10090/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [10100/20508], Loss: 0.6676\n",
      "Epoch [3/30], Batch [10110/20508], Loss: 0.6941\n",
      "Epoch [3/30], Batch [10120/20508], Loss: 0.6949\n",
      "Epoch [3/30], Batch [10130/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [10140/20508], Loss: 0.6892\n",
      "Epoch [3/30], Batch [10150/20508], Loss: 0.6949\n",
      "Epoch [3/30], Batch [10160/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [10170/20508], Loss: 0.6944\n",
      "Epoch [3/30], Batch [10180/20508], Loss: 0.6974\n",
      "Epoch [3/30], Batch [10190/20508], Loss: 0.7071\n",
      "Epoch [3/30], Batch [10200/20508], Loss: 0.6909\n",
      "Epoch [3/30], Batch [10210/20508], Loss: 0.7058\n",
      "Epoch [3/30], Batch [10220/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [10230/20508], Loss: 0.6716\n",
      "Epoch [3/30], Batch [10240/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [10250/20508], Loss: 0.6757\n",
      "Epoch [3/30], Batch [10260/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [10270/20508], Loss: 0.6709\n",
      "Epoch [3/30], Batch [10280/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [10290/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [10300/20508], Loss: 0.7056\n",
      "Epoch [3/30], Batch [10310/20508], Loss: 0.6902\n",
      "Epoch [3/30], Batch [10320/20508], Loss: 0.6944\n",
      "Epoch [3/30], Batch [10330/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [10340/20508], Loss: 0.6720\n",
      "Epoch [3/30], Batch [10350/20508], Loss: 0.7168\n",
      "Epoch [3/30], Batch [10360/20508], Loss: 0.7022\n",
      "Epoch [3/30], Batch [10370/20508], Loss: 0.7034\n",
      "Epoch [3/30], Batch [10380/20508], Loss: 0.6749\n",
      "Epoch [3/30], Batch [10390/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [10400/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [10410/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [10420/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [10430/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [10440/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [10450/20508], Loss: 0.6820\n",
      "Epoch [3/30], Batch [10460/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [10470/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [10480/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [10490/20508], Loss: 0.6747\n",
      "Epoch [3/30], Batch [10500/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [10510/20508], Loss: 0.6733\n",
      "Epoch [3/30], Batch [10520/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [10530/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [10540/20508], Loss: 0.6657\n",
      "Epoch [3/30], Batch [10550/20508], Loss: 0.7029\n",
      "Epoch [3/30], Batch [10560/20508], Loss: 0.6719\n",
      "Epoch [3/30], Batch [10570/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [10580/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [10590/20508], Loss: 0.6739\n",
      "Epoch [3/30], Batch [10600/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [10610/20508], Loss: 0.6778\n",
      "Epoch [3/30], Batch [10620/20508], Loss: 0.6733\n",
      "Epoch [3/30], Batch [10630/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [10640/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [10650/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [10660/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [10670/20508], Loss: 0.6785\n",
      "Epoch [3/30], Batch [10680/20508], Loss: 0.6677\n",
      "Epoch [3/30], Batch [10690/20508], Loss: 0.6674\n",
      "Epoch [3/30], Batch [10700/20508], Loss: 0.7126\n",
      "Epoch [3/30], Batch [10710/20508], Loss: 0.6731\n",
      "Epoch [3/30], Batch [10720/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [10730/20508], Loss: 0.7147\n",
      "Epoch [3/30], Batch [10740/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [10750/20508], Loss: 0.7009\n",
      "Epoch [3/30], Batch [10760/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [10770/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [10780/20508], Loss: 0.7043\n",
      "Epoch [3/30], Batch [10790/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [10800/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [10810/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [10820/20508], Loss: 0.7043\n",
      "Epoch [3/30], Batch [10830/20508], Loss: 0.6890\n",
      "Epoch [3/30], Batch [10840/20508], Loss: 0.6999\n",
      "Epoch [3/30], Batch [10850/20508], Loss: 0.7103\n",
      "Epoch [3/30], Batch [10860/20508], Loss: 0.7041\n",
      "Epoch [3/30], Batch [10870/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [10880/20508], Loss: 0.7100\n",
      "Epoch [3/30], Batch [10890/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [10900/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [10910/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [10920/20508], Loss: 0.6991\n",
      "Epoch [3/30], Batch [10930/20508], Loss: 0.7000\n",
      "Epoch [3/30], Batch [10940/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [10950/20508], Loss: 0.7029\n",
      "Epoch [3/30], Batch [10960/20508], Loss: 0.6789\n",
      "Epoch [3/30], Batch [10970/20508], Loss: 0.6897\n",
      "Epoch [3/30], Batch [10980/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [10990/20508], Loss: 0.6998\n",
      "Epoch [3/30], Batch [11000/20508], Loss: 0.6761\n",
      "Epoch [3/30], Batch [11010/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [11020/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [11030/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [11040/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [11050/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [11060/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [11070/20508], Loss: 0.7006\n",
      "Epoch [3/30], Batch [11080/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [11090/20508], Loss: 0.7129\n",
      "Epoch [3/30], Batch [11100/20508], Loss: 0.7009\n",
      "Epoch [3/30], Batch [11110/20508], Loss: 0.6968\n",
      "Epoch [3/30], Batch [11120/20508], Loss: 0.6997\n",
      "Epoch [3/30], Batch [11130/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [11140/20508], Loss: 0.7112\n",
      "Epoch [3/30], Batch [11150/20508], Loss: 0.6683\n",
      "Epoch [3/30], Batch [11160/20508], Loss: 0.6760\n",
      "Epoch [3/30], Batch [11170/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [11180/20508], Loss: 0.6962\n",
      "Epoch [3/30], Batch [11190/20508], Loss: 0.6898\n",
      "Epoch [3/30], Batch [11200/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [11210/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [11220/20508], Loss: 0.6850\n",
      "Epoch [3/30], Batch [11230/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [11240/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [11250/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [11260/20508], Loss: 0.7088\n",
      "Epoch [3/30], Batch [11270/20508], Loss: 0.6829\n",
      "Epoch [3/30], Batch [11280/20508], Loss: 0.6741\n",
      "Epoch [3/30], Batch [11290/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [11300/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [11310/20508], Loss: 0.6997\n",
      "Epoch [3/30], Batch [11320/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [11330/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [11340/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [11350/20508], Loss: 0.6800\n",
      "Epoch [3/30], Batch [11360/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [11370/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [11380/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [11390/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [11400/20508], Loss: 0.7008\n",
      "Epoch [3/30], Batch [11410/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [11420/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [11430/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [11440/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [11450/20508], Loss: 0.7053\n",
      "Epoch [3/30], Batch [11460/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [11470/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [11480/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [11490/20508], Loss: 0.6872\n",
      "Epoch [3/30], Batch [11500/20508], Loss: 0.7061\n",
      "Epoch [3/30], Batch [11510/20508], Loss: 0.6941\n",
      "Epoch [3/30], Batch [11520/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [11530/20508], Loss: 0.6913\n",
      "Epoch [3/30], Batch [11540/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [11550/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [11560/20508], Loss: 0.6846\n",
      "Epoch [3/30], Batch [11570/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [11580/20508], Loss: 0.6791\n",
      "Epoch [3/30], Batch [11590/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [11600/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [11610/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [11620/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [11630/20508], Loss: 0.7167\n",
      "Epoch [3/30], Batch [11640/20508], Loss: 0.6763\n",
      "Epoch [3/30], Batch [11650/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [11660/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [11670/20508], Loss: 0.6666\n",
      "Epoch [3/30], Batch [11680/20508], Loss: 0.6986\n",
      "Epoch [3/30], Batch [11690/20508], Loss: 0.6796\n",
      "Epoch [3/30], Batch [11700/20508], Loss: 0.7033\n",
      "Epoch [3/30], Batch [11710/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [11720/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [11730/20508], Loss: 0.6735\n",
      "Epoch [3/30], Batch [11740/20508], Loss: 0.7008\n",
      "Epoch [3/30], Batch [11750/20508], Loss: 0.6968\n",
      "Epoch [3/30], Batch [11760/20508], Loss: 0.6781\n",
      "Epoch [3/30], Batch [11770/20508], Loss: 0.7083\n",
      "Epoch [3/30], Batch [11780/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [11790/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [11800/20508], Loss: 0.6825\n",
      "Epoch [3/30], Batch [11810/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [11820/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [11830/20508], Loss: 0.6963\n",
      "Epoch [3/30], Batch [11840/20508], Loss: 0.6961\n",
      "Epoch [3/30], Batch [11850/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [11860/20508], Loss: 0.6913\n",
      "Epoch [3/30], Batch [11870/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [11880/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [11890/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [11900/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [11910/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [11920/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [11930/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [11940/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [11950/20508], Loss: 0.7022\n",
      "Epoch [3/30], Batch [11960/20508], Loss: 0.6712\n",
      "Epoch [3/30], Batch [11970/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [11980/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [11990/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [12000/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [12010/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [12020/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [12030/20508], Loss: 0.7100\n",
      "Epoch [3/30], Batch [12040/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [12050/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [12060/20508], Loss: 0.6843\n",
      "Epoch [3/30], Batch [12070/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [12080/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [12090/20508], Loss: 0.7079\n",
      "Epoch [3/30], Batch [12100/20508], Loss: 0.6909\n",
      "Epoch [3/30], Batch [12110/20508], Loss: 0.6952\n",
      "Epoch [3/30], Batch [12120/20508], Loss: 0.6659\n",
      "Epoch [3/30], Batch [12130/20508], Loss: 0.6735\n",
      "Epoch [3/30], Batch [12140/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [12150/20508], Loss: 0.6983\n",
      "Epoch [3/30], Batch [12160/20508], Loss: 0.6747\n",
      "Epoch [3/30], Batch [12170/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [12180/20508], Loss: 0.6767\n",
      "Epoch [3/30], Batch [12190/20508], Loss: 0.6763\n",
      "Epoch [3/30], Batch [12200/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [12210/20508], Loss: 0.6832\n",
      "Epoch [3/30], Batch [12220/20508], Loss: 0.6803\n",
      "Epoch [3/30], Batch [12230/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [12240/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [12250/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [12260/20508], Loss: 0.7017\n",
      "Epoch [3/30], Batch [12270/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [12280/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [12290/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [12300/20508], Loss: 0.6789\n",
      "Epoch [3/30], Batch [12310/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [12320/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [12330/20508], Loss: 0.6991\n",
      "Epoch [3/30], Batch [12340/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [12350/20508], Loss: 0.6729\n",
      "Epoch [3/30], Batch [12360/20508], Loss: 0.6778\n",
      "Epoch [3/30], Batch [12370/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [12380/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [12390/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [12400/20508], Loss: 0.6745\n",
      "Epoch [3/30], Batch [12410/20508], Loss: 0.6721\n",
      "Epoch [3/30], Batch [12420/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [12430/20508], Loss: 0.6804\n",
      "Epoch [3/30], Batch [12440/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [12450/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [12460/20508], Loss: 0.6905\n",
      "Epoch [3/30], Batch [12470/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [12480/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [12490/20508], Loss: 0.6927\n",
      "Epoch [3/30], Batch [12500/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [12510/20508], Loss: 0.6718\n",
      "Epoch [3/30], Batch [12520/20508], Loss: 0.6768\n",
      "Epoch [3/30], Batch [12530/20508], Loss: 0.6883\n",
      "Epoch [3/30], Batch [12540/20508], Loss: 0.6773\n",
      "Epoch [3/30], Batch [12550/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [12560/20508], Loss: 0.6942\n",
      "Epoch [3/30], Batch [12570/20508], Loss: 0.6935\n",
      "Epoch [3/30], Batch [12580/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [12590/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [12600/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [12610/20508], Loss: 0.6744\n",
      "Epoch [3/30], Batch [12620/20508], Loss: 0.6986\n",
      "Epoch [3/30], Batch [12630/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [12640/20508], Loss: 0.6687\n",
      "Epoch [3/30], Batch [12650/20508], Loss: 0.7068\n",
      "Epoch [3/30], Batch [12660/20508], Loss: 0.7015\n",
      "Epoch [3/30], Batch [12670/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [12680/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [12690/20508], Loss: 0.6786\n",
      "Epoch [3/30], Batch [12700/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [12710/20508], Loss: 0.6780\n",
      "Epoch [3/30], Batch [12720/20508], Loss: 0.6778\n",
      "Epoch [3/30], Batch [12730/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [12740/20508], Loss: 0.7106\n",
      "Epoch [3/30], Batch [12750/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [12760/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [12770/20508], Loss: 0.6896\n",
      "Epoch [3/30], Batch [12780/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [12790/20508], Loss: 0.6986\n",
      "Epoch [3/30], Batch [12800/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [12810/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [12820/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [12830/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [12840/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [12850/20508], Loss: 0.6707\n",
      "Epoch [3/30], Batch [12860/20508], Loss: 0.7142\n",
      "Epoch [3/30], Batch [12870/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [12880/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [12890/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [12900/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [12910/20508], Loss: 0.6930\n",
      "Epoch [3/30], Batch [12920/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [12930/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [12940/20508], Loss: 0.6960\n",
      "Epoch [3/30], Batch [12950/20508], Loss: 0.6702\n",
      "Epoch [3/30], Batch [12960/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [12970/20508], Loss: 0.6823\n",
      "Epoch [3/30], Batch [12980/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [12990/20508], Loss: 0.6962\n",
      "Epoch [3/30], Batch [13000/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [13010/20508], Loss: 0.6821\n",
      "Epoch [3/30], Batch [13020/20508], Loss: 0.6912\n",
      "Epoch [3/30], Batch [13030/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [13040/20508], Loss: 0.6763\n",
      "Epoch [3/30], Batch [13050/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [13060/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [13070/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [13080/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [13090/20508], Loss: 0.6898\n",
      "Epoch [3/30], Batch [13100/20508], Loss: 0.6758\n",
      "Epoch [3/30], Batch [13110/20508], Loss: 0.6984\n",
      "Epoch [3/30], Batch [13120/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [13130/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [13140/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [13150/20508], Loss: 0.6782\n",
      "Epoch [3/30], Batch [13160/20508], Loss: 0.6675\n",
      "Epoch [3/30], Batch [13170/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [13180/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [13190/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [13200/20508], Loss: 0.7084\n",
      "Epoch [3/30], Batch [13210/20508], Loss: 0.6992\n",
      "Epoch [3/30], Batch [13220/20508], Loss: 0.6994\n",
      "Epoch [3/30], Batch [13230/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [13240/20508], Loss: 0.7063\n",
      "Epoch [3/30], Batch [13250/20508], Loss: 0.6765\n",
      "Epoch [3/30], Batch [13260/20508], Loss: 0.7071\n",
      "Epoch [3/30], Batch [13270/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [13280/20508], Loss: 0.6694\n",
      "Epoch [3/30], Batch [13290/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [13300/20508], Loss: 0.7167\n",
      "Epoch [3/30], Batch [13310/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [13320/20508], Loss: 0.6875\n",
      "Epoch [3/30], Batch [13330/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [13340/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [13350/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [13360/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [13370/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [13380/20508], Loss: 0.6789\n",
      "Epoch [3/30], Batch [13390/20508], Loss: 0.7011\n",
      "Epoch [3/30], Batch [13400/20508], Loss: 0.6836\n",
      "Epoch [3/30], Batch [13410/20508], Loss: 0.6787\n",
      "Epoch [3/30], Batch [13420/20508], Loss: 0.6764\n",
      "Epoch [3/30], Batch [13430/20508], Loss: 0.6775\n",
      "Epoch [3/30], Batch [13440/20508], Loss: 0.6998\n",
      "Epoch [3/30], Batch [13450/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [13460/20508], Loss: 0.6775\n",
      "Epoch [3/30], Batch [13470/20508], Loss: 0.6952\n",
      "Epoch [3/30], Batch [13480/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [13490/20508], Loss: 0.6758\n",
      "Epoch [3/30], Batch [13500/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [13510/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [13520/20508], Loss: 0.6920\n",
      "Epoch [3/30], Batch [13530/20508], Loss: 0.7057\n",
      "Epoch [3/30], Batch [13540/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [13550/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [13560/20508], Loss: 0.7076\n",
      "Epoch [3/30], Batch [13570/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [13580/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [13590/20508], Loss: 0.6733\n",
      "Epoch [3/30], Batch [13600/20508], Loss: 0.6984\n",
      "Epoch [3/30], Batch [13610/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [13620/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [13630/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [13640/20508], Loss: 0.6658\n",
      "Epoch [3/30], Batch [13650/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [13660/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [13670/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [13680/20508], Loss: 0.6886\n",
      "Epoch [3/30], Batch [13690/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [13700/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [13710/20508], Loss: 0.6760\n",
      "Epoch [3/30], Batch [13720/20508], Loss: 0.6858\n",
      "Epoch [3/30], Batch [13730/20508], Loss: 0.7008\n",
      "Epoch [3/30], Batch [13740/20508], Loss: 0.6837\n",
      "Epoch [3/30], Batch [13750/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [13760/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [13770/20508], Loss: 0.6701\n",
      "Epoch [3/30], Batch [13780/20508], Loss: 0.7050\n",
      "Epoch [3/30], Batch [13790/20508], Loss: 0.7085\n",
      "Epoch [3/30], Batch [13800/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [13810/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [13820/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [13830/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [13840/20508], Loss: 0.7026\n",
      "Epoch [3/30], Batch [13850/20508], Loss: 0.6646\n",
      "Epoch [3/30], Batch [13860/20508], Loss: 0.6700\n",
      "Epoch [3/30], Batch [13870/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [13880/20508], Loss: 0.7022\n",
      "Epoch [3/30], Batch [13890/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [13900/20508], Loss: 0.7021\n",
      "Epoch [3/30], Batch [13910/20508], Loss: 0.6854\n",
      "Epoch [3/30], Batch [13920/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [13930/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [13940/20508], Loss: 0.6821\n",
      "Epoch [3/30], Batch [13950/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [13960/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [13970/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [13980/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [13990/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [14000/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [14010/20508], Loss: 0.6883\n",
      "Epoch [3/30], Batch [14020/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [14030/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [14040/20508], Loss: 0.7055\n",
      "Epoch [3/30], Batch [14050/20508], Loss: 0.6807\n",
      "Epoch [3/30], Batch [14060/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [14070/20508], Loss: 0.7106\n",
      "Epoch [3/30], Batch [14080/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [14090/20508], Loss: 0.7104\n",
      "Epoch [3/30], Batch [14100/20508], Loss: 0.6732\n",
      "Epoch [3/30], Batch [14110/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [14120/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [14130/20508], Loss: 0.7155\n",
      "Epoch [3/30], Batch [14140/20508], Loss: 0.6663\n",
      "Epoch [3/30], Batch [14150/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [14160/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [14170/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [14180/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [14190/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [14200/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [14210/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [14220/20508], Loss: 0.7004\n",
      "Epoch [3/30], Batch [14230/20508], Loss: 0.6678\n",
      "Epoch [3/30], Batch [14240/20508], Loss: 0.6973\n",
      "Epoch [3/30], Batch [14250/20508], Loss: 0.7164\n",
      "Epoch [3/30], Batch [14260/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [14270/20508], Loss: 0.6805\n",
      "Epoch [3/30], Batch [14280/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [14290/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [14300/20508], Loss: 0.6688\n",
      "Epoch [3/30], Batch [14310/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [14320/20508], Loss: 0.6913\n",
      "Epoch [3/30], Batch [14330/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [14340/20508], Loss: 0.7066\n",
      "Epoch [3/30], Batch [14350/20508], Loss: 0.6907\n",
      "Epoch [3/30], Batch [14360/20508], Loss: 0.6911\n",
      "Epoch [3/30], Batch [14370/20508], Loss: 0.6975\n",
      "Epoch [3/30], Batch [14380/20508], Loss: 0.6974\n",
      "Epoch [3/30], Batch [14390/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [14400/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [14410/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [14420/20508], Loss: 0.6802\n",
      "Epoch [3/30], Batch [14430/20508], Loss: 0.6774\n",
      "Epoch [3/30], Batch [14440/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [14450/20508], Loss: 0.7033\n",
      "Epoch [3/30], Batch [14460/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [14470/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [14480/20508], Loss: 0.7015\n",
      "Epoch [3/30], Batch [14490/20508], Loss: 0.7082\n",
      "Epoch [3/30], Batch [14500/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [14510/20508], Loss: 0.7088\n",
      "Epoch [3/30], Batch [14520/20508], Loss: 0.6813\n",
      "Epoch [3/30], Batch [14530/20508], Loss: 0.6767\n",
      "Epoch [3/30], Batch [14540/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [14550/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [14560/20508], Loss: 0.6955\n",
      "Epoch [3/30], Batch [14570/20508], Loss: 0.6824\n",
      "Epoch [3/30], Batch [14580/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [14590/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [14600/20508], Loss: 0.6761\n",
      "Epoch [3/30], Batch [14610/20508], Loss: 0.6999\n",
      "Epoch [3/30], Batch [14620/20508], Loss: 0.6851\n",
      "Epoch [3/30], Batch [14630/20508], Loss: 0.7195\n",
      "Epoch [3/30], Batch [14640/20508], Loss: 0.6832\n",
      "Epoch [3/30], Batch [14650/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [14660/20508], Loss: 0.6962\n",
      "Epoch [3/30], Batch [14670/20508], Loss: 0.6740\n",
      "Epoch [3/30], Batch [14680/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [14690/20508], Loss: 0.7092\n",
      "Epoch [3/30], Batch [14700/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [14710/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [14720/20508], Loss: 0.6945\n",
      "Epoch [3/30], Batch [14730/20508], Loss: 0.6795\n",
      "Epoch [3/30], Batch [14740/20508], Loss: 0.6816\n",
      "Epoch [3/30], Batch [14750/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [14760/20508], Loss: 0.7044\n",
      "Epoch [3/30], Batch [14770/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [14780/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [14790/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [14800/20508], Loss: 0.6767\n",
      "Epoch [3/30], Batch [14810/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [14820/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [14830/20508], Loss: 0.6808\n",
      "Epoch [3/30], Batch [14840/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [14850/20508], Loss: 0.6881\n",
      "Epoch [3/30], Batch [14860/20508], Loss: 0.7080\n",
      "Epoch [3/30], Batch [14870/20508], Loss: 0.6905\n",
      "Epoch [3/30], Batch [14880/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [14890/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [14900/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [14910/20508], Loss: 0.6691\n",
      "Epoch [3/30], Batch [14920/20508], Loss: 0.6858\n",
      "Epoch [3/30], Batch [14930/20508], Loss: 0.6756\n",
      "Epoch [3/30], Batch [14940/20508], Loss: 0.6762\n",
      "Epoch [3/30], Batch [14950/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [14960/20508], Loss: 0.6786\n",
      "Epoch [3/30], Batch [14970/20508], Loss: 0.7061\n",
      "Epoch [3/30], Batch [14980/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [14990/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [15000/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [15010/20508], Loss: 0.6902\n",
      "Epoch [3/30], Batch [15020/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [15030/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [15040/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [15050/20508], Loss: 0.6751\n",
      "Epoch [3/30], Batch [15060/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [15070/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [15080/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [15090/20508], Loss: 0.6709\n",
      "Epoch [3/30], Batch [15100/20508], Loss: 0.6717\n",
      "Epoch [3/30], Batch [15110/20508], Loss: 0.7011\n",
      "Epoch [3/30], Batch [15120/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [15130/20508], Loss: 0.7062\n",
      "Epoch [3/30], Batch [15140/20508], Loss: 0.7070\n",
      "Epoch [3/30], Batch [15150/20508], Loss: 0.7002\n",
      "Epoch [3/30], Batch [15160/20508], Loss: 0.6848\n",
      "Epoch [3/30], Batch [15170/20508], Loss: 0.6927\n",
      "Epoch [3/30], Batch [15180/20508], Loss: 0.6781\n",
      "Epoch [3/30], Batch [15190/20508], Loss: 0.7049\n",
      "Epoch [3/30], Batch [15200/20508], Loss: 0.6835\n",
      "Epoch [3/30], Batch [15210/20508], Loss: 0.6935\n",
      "Epoch [3/30], Batch [15220/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [15230/20508], Loss: 0.6960\n",
      "Epoch [3/30], Batch [15240/20508], Loss: 0.6808\n",
      "Epoch [3/30], Batch [15250/20508], Loss: 0.6765\n",
      "Epoch [3/30], Batch [15260/20508], Loss: 0.6990\n",
      "Epoch [3/30], Batch [15270/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [15280/20508], Loss: 0.7014\n",
      "Epoch [3/30], Batch [15290/20508], Loss: 0.6808\n",
      "Epoch [3/30], Batch [15300/20508], Loss: 0.6924\n",
      "Epoch [3/30], Batch [15310/20508], Loss: 0.6841\n",
      "Epoch [3/30], Batch [15320/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [15330/20508], Loss: 0.6956\n",
      "Epoch [3/30], Batch [15340/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [15350/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [15360/20508], Loss: 0.7093\n",
      "Epoch [3/30], Batch [15370/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [15380/20508], Loss: 0.7017\n",
      "Epoch [3/30], Batch [15390/20508], Loss: 0.6821\n",
      "Epoch [3/30], Batch [15400/20508], Loss: 0.6925\n",
      "Epoch [3/30], Batch [15410/20508], Loss: 0.7164\n",
      "Epoch [3/30], Batch [15420/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [15430/20508], Loss: 0.6986\n",
      "Epoch [3/30], Batch [15440/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [15450/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [15460/20508], Loss: 0.6759\n",
      "Epoch [3/30], Batch [15470/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [15480/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [15490/20508], Loss: 0.6962\n",
      "Epoch [3/30], Batch [15500/20508], Loss: 0.7143\n",
      "Epoch [3/30], Batch [15510/20508], Loss: 0.7099\n",
      "Epoch [3/30], Batch [15520/20508], Loss: 0.6836\n",
      "Epoch [3/30], Batch [15530/20508], Loss: 0.7133\n",
      "Epoch [3/30], Batch [15540/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [15550/20508], Loss: 0.6851\n",
      "Epoch [3/30], Batch [15560/20508], Loss: 0.6692\n",
      "Epoch [3/30], Batch [15570/20508], Loss: 0.6825\n",
      "Epoch [3/30], Batch [15580/20508], Loss: 0.6796\n",
      "Epoch [3/30], Batch [15590/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [15600/20508], Loss: 0.7077\n",
      "Epoch [3/30], Batch [15610/20508], Loss: 0.6720\n",
      "Epoch [3/30], Batch [15620/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [15630/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [15640/20508], Loss: 0.6624\n",
      "Epoch [3/30], Batch [15650/20508], Loss: 0.7153\n",
      "Epoch [3/30], Batch [15660/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [15670/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [15680/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [15690/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [15700/20508], Loss: 0.6793\n",
      "Epoch [3/30], Batch [15710/20508], Loss: 0.7055\n",
      "Epoch [3/30], Batch [15720/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [15730/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [15740/20508], Loss: 0.6704\n",
      "Epoch [3/30], Batch [15750/20508], Loss: 0.6898\n",
      "Epoch [3/30], Batch [15760/20508], Loss: 0.6835\n",
      "Epoch [3/30], Batch [15770/20508], Loss: 0.7201\n",
      "Epoch [3/30], Batch [15780/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [15790/20508], Loss: 0.7097\n",
      "Epoch [3/30], Batch [15800/20508], Loss: 0.6946\n",
      "Epoch [3/30], Batch [15810/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [15820/20508], Loss: 0.6803\n",
      "Epoch [3/30], Batch [15830/20508], Loss: 0.6715\n",
      "Epoch [3/30], Batch [15840/20508], Loss: 0.6769\n",
      "Epoch [3/30], Batch [15850/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [15860/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [15870/20508], Loss: 0.6832\n",
      "Epoch [3/30], Batch [15880/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [15890/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [15900/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [15910/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [15920/20508], Loss: 0.6888\n",
      "Epoch [3/30], Batch [15930/20508], Loss: 0.6675\n",
      "Epoch [3/30], Batch [15940/20508], Loss: 0.6714\n",
      "Epoch [3/30], Batch [15950/20508], Loss: 0.7015\n",
      "Epoch [3/30], Batch [15960/20508], Loss: 0.6786\n",
      "Epoch [3/30], Batch [15970/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [15980/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [15990/20508], Loss: 0.6782\n",
      "Epoch [3/30], Batch [16000/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [16010/20508], Loss: 0.6687\n",
      "Epoch [3/30], Batch [16020/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [16030/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [16040/20508], Loss: 0.6811\n",
      "Epoch [3/30], Batch [16050/20508], Loss: 0.6760\n",
      "Epoch [3/30], Batch [16060/20508], Loss: 0.6900\n",
      "Epoch [3/30], Batch [16070/20508], Loss: 0.6894\n",
      "Epoch [3/30], Batch [16080/20508], Loss: 0.7073\n",
      "Epoch [3/30], Batch [16090/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [16100/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [16110/20508], Loss: 0.6984\n",
      "Epoch [3/30], Batch [16120/20508], Loss: 0.7038\n",
      "Epoch [3/30], Batch [16130/20508], Loss: 0.6858\n",
      "Epoch [3/30], Batch [16140/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [16150/20508], Loss: 0.6691\n",
      "Epoch [3/30], Batch [16160/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [16170/20508], Loss: 0.6703\n",
      "Epoch [3/30], Batch [16180/20508], Loss: 0.7065\n",
      "Epoch [3/30], Batch [16190/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [16200/20508], Loss: 0.7180\n",
      "Epoch [3/30], Batch [16210/20508], Loss: 0.6896\n",
      "Epoch [3/30], Batch [16220/20508], Loss: 0.6953\n",
      "Epoch [3/30], Batch [16230/20508], Loss: 0.6754\n",
      "Epoch [3/30], Batch [16240/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [16250/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [16260/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [16270/20508], Loss: 0.6744\n",
      "Epoch [3/30], Batch [16280/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [16290/20508], Loss: 0.7194\n",
      "Epoch [3/30], Batch [16300/20508], Loss: 0.7040\n",
      "Epoch [3/30], Batch [16310/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [16320/20508], Loss: 0.6899\n",
      "Epoch [3/30], Batch [16330/20508], Loss: 0.6975\n",
      "Epoch [3/30], Batch [16340/20508], Loss: 0.6755\n",
      "Epoch [3/30], Batch [16350/20508], Loss: 0.6993\n",
      "Epoch [3/30], Batch [16360/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [16370/20508], Loss: 0.6799\n",
      "Epoch [3/30], Batch [16380/20508], Loss: 0.6832\n",
      "Epoch [3/30], Batch [16390/20508], Loss: 0.6861\n",
      "Epoch [3/30], Batch [16400/20508], Loss: 0.7161\n",
      "Epoch [3/30], Batch [16410/20508], Loss: 0.7013\n",
      "Epoch [3/30], Batch [16420/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [16430/20508], Loss: 0.6738\n",
      "Epoch [3/30], Batch [16440/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [16450/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [16460/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [16470/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [16480/20508], Loss: 0.6713\n",
      "Epoch [3/30], Batch [16490/20508], Loss: 0.6960\n",
      "Epoch [3/30], Batch [16500/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [16510/20508], Loss: 0.6776\n",
      "Epoch [3/30], Batch [16520/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [16530/20508], Loss: 0.6993\n",
      "Epoch [3/30], Batch [16540/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [16550/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [16560/20508], Loss: 0.6938\n",
      "Epoch [3/30], Batch [16570/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [16580/20508], Loss: 0.6874\n",
      "Epoch [3/30], Batch [16590/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [16600/20508], Loss: 0.7005\n",
      "Epoch [3/30], Batch [16610/20508], Loss: 0.6763\n",
      "Epoch [3/30], Batch [16620/20508], Loss: 0.6651\n",
      "Epoch [3/30], Batch [16630/20508], Loss: 0.6961\n",
      "Epoch [3/30], Batch [16640/20508], Loss: 0.6707\n",
      "Epoch [3/30], Batch [16650/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [16660/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [16670/20508], Loss: 0.6980\n",
      "Epoch [3/30], Batch [16680/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [16690/20508], Loss: 0.6931\n",
      "Epoch [3/30], Batch [16700/20508], Loss: 0.7036\n",
      "Epoch [3/30], Batch [16710/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [16720/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [16730/20508], Loss: 0.6945\n",
      "Epoch [3/30], Batch [16740/20508], Loss: 0.6730\n",
      "Epoch [3/30], Batch [16750/20508], Loss: 0.6846\n",
      "Epoch [3/30], Batch [16760/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [16770/20508], Loss: 0.6908\n",
      "Epoch [3/30], Batch [16780/20508], Loss: 0.7023\n",
      "Epoch [3/30], Batch [16790/20508], Loss: 0.6691\n",
      "Epoch [3/30], Batch [16800/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [16810/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [16820/20508], Loss: 0.6977\n",
      "Epoch [3/30], Batch [16830/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [16840/20508], Loss: 0.6845\n",
      "Epoch [3/30], Batch [16850/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [16860/20508], Loss: 0.7003\n",
      "Epoch [3/30], Batch [16870/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [16880/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [16890/20508], Loss: 0.6937\n",
      "Epoch [3/30], Batch [16900/20508], Loss: 0.6863\n",
      "Epoch [3/30], Batch [16910/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [16920/20508], Loss: 0.7197\n",
      "Epoch [3/30], Batch [16930/20508], Loss: 0.6896\n",
      "Epoch [3/30], Batch [16940/20508], Loss: 0.6978\n",
      "Epoch [3/30], Batch [16950/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [16960/20508], Loss: 0.6960\n",
      "Epoch [3/30], Batch [16970/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [16980/20508], Loss: 0.6834\n",
      "Epoch [3/30], Batch [16990/20508], Loss: 0.6935\n",
      "Epoch [3/30], Batch [17000/20508], Loss: 0.7022\n",
      "Epoch [3/30], Batch [17010/20508], Loss: 0.7006\n",
      "Epoch [3/30], Batch [17020/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [17030/20508], Loss: 0.6694\n",
      "Epoch [3/30], Batch [17040/20508], Loss: 0.7189\n",
      "Epoch [3/30], Batch [17050/20508], Loss: 0.6778\n",
      "Epoch [3/30], Batch [17060/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [17070/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [17080/20508], Loss: 0.6969\n",
      "Epoch [3/30], Batch [17090/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [17100/20508], Loss: 0.6758\n",
      "Epoch [3/30], Batch [17110/20508], Loss: 0.7056\n",
      "Epoch [3/30], Batch [17120/20508], Loss: 0.6952\n",
      "Epoch [3/30], Batch [17130/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [17140/20508], Loss: 0.6848\n",
      "Epoch [3/30], Batch [17150/20508], Loss: 0.6979\n",
      "Epoch [3/30], Batch [17160/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [17170/20508], Loss: 0.6798\n",
      "Epoch [3/30], Batch [17180/20508], Loss: 0.6835\n",
      "Epoch [3/30], Batch [17190/20508], Loss: 0.6867\n",
      "Epoch [3/30], Batch [17200/20508], Loss: 0.6941\n",
      "Epoch [3/30], Batch [17210/20508], Loss: 0.6872\n",
      "Epoch [3/30], Batch [17220/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [17230/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [17240/20508], Loss: 0.7020\n",
      "Epoch [3/30], Batch [17250/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [17260/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [17270/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [17280/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [17290/20508], Loss: 0.7052\n",
      "Epoch [3/30], Batch [17300/20508], Loss: 0.6930\n",
      "Epoch [3/30], Batch [17310/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [17320/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [17330/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [17340/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [17350/20508], Loss: 0.6890\n",
      "Epoch [3/30], Batch [17360/20508], Loss: 0.6773\n",
      "Epoch [3/30], Batch [17370/20508], Loss: 0.6952\n",
      "Epoch [3/30], Batch [17380/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [17390/20508], Loss: 0.6796\n",
      "Epoch [3/30], Batch [17400/20508], Loss: 0.6822\n",
      "Epoch [3/30], Batch [17410/20508], Loss: 0.7132\n",
      "Epoch [3/30], Batch [17420/20508], Loss: 0.6956\n",
      "Epoch [3/30], Batch [17430/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [17440/20508], Loss: 0.7018\n",
      "Epoch [3/30], Batch [17450/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [17460/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [17470/20508], Loss: 0.6831\n",
      "Epoch [3/30], Batch [17480/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [17490/20508], Loss: 0.6771\n",
      "Epoch [3/30], Batch [17500/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [17510/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [17520/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [17530/20508], Loss: 0.6850\n",
      "Epoch [3/30], Batch [17540/20508], Loss: 0.6742\n",
      "Epoch [3/30], Batch [17550/20508], Loss: 0.6784\n",
      "Epoch [3/30], Batch [17560/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [17570/20508], Loss: 0.6680\n",
      "Epoch [3/30], Batch [17580/20508], Loss: 0.7038\n",
      "Epoch [3/30], Batch [17590/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [17600/20508], Loss: 0.6886\n",
      "Epoch [3/30], Batch [17610/20508], Loss: 0.6897\n",
      "Epoch [3/30], Batch [17620/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [17630/20508], Loss: 0.6982\n",
      "Epoch [3/30], Batch [17640/20508], Loss: 0.6794\n",
      "Epoch [3/30], Batch [17650/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [17660/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [17670/20508], Loss: 0.6787\n",
      "Epoch [3/30], Batch [17680/20508], Loss: 0.7013\n",
      "Epoch [3/30], Batch [17690/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [17700/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [17710/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [17720/20508], Loss: 0.6624\n",
      "Epoch [3/30], Batch [17730/20508], Loss: 0.6651\n",
      "Epoch [3/30], Batch [17740/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [17750/20508], Loss: 0.6836\n",
      "Epoch [3/30], Batch [17760/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [17770/20508], Loss: 0.7080\n",
      "Epoch [3/30], Batch [17780/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [17790/20508], Loss: 0.7001\n",
      "Epoch [3/30], Batch [17800/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [17810/20508], Loss: 0.6962\n",
      "Epoch [3/30], Batch [17820/20508], Loss: 0.7060\n",
      "Epoch [3/30], Batch [17830/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [17840/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [17850/20508], Loss: 0.6950\n",
      "Epoch [3/30], Batch [17860/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [17870/20508], Loss: 0.7028\n",
      "Epoch [3/30], Batch [17880/20508], Loss: 0.7128\n",
      "Epoch [3/30], Batch [17890/20508], Loss: 0.6958\n",
      "Epoch [3/30], Batch [17900/20508], Loss: 0.7007\n",
      "Epoch [3/30], Batch [17910/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [17920/20508], Loss: 0.6825\n",
      "Epoch [3/30], Batch [17930/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [17940/20508], Loss: 0.6926\n",
      "Epoch [3/30], Batch [17950/20508], Loss: 0.6987\n",
      "Epoch [3/30], Batch [17960/20508], Loss: 0.6743\n",
      "Epoch [3/30], Batch [17970/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [17980/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [17990/20508], Loss: 0.6728\n",
      "Epoch [3/30], Batch [18000/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [18010/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [18020/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [18030/20508], Loss: 0.6869\n",
      "Epoch [3/30], Batch [18040/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [18050/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [18060/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [18070/20508], Loss: 0.7018\n",
      "Epoch [3/30], Batch [18080/20508], Loss: 0.6859\n",
      "Epoch [3/30], Batch [18090/20508], Loss: 0.6947\n",
      "Epoch [3/30], Batch [18100/20508], Loss: 0.7072\n",
      "Epoch [3/30], Batch [18110/20508], Loss: 0.6972\n",
      "Epoch [3/30], Batch [18120/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [18130/20508], Loss: 0.7163\n",
      "Epoch [3/30], Batch [18140/20508], Loss: 0.7024\n",
      "Epoch [3/30], Batch [18150/20508], Loss: 0.6920\n",
      "Epoch [3/30], Batch [18160/20508], Loss: 0.6902\n",
      "Epoch [3/30], Batch [18170/20508], Loss: 0.6830\n",
      "Epoch [3/30], Batch [18180/20508], Loss: 0.6985\n",
      "Epoch [3/30], Batch [18190/20508], Loss: 0.7033\n",
      "Epoch [3/30], Batch [18200/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [18210/20508], Loss: 0.7163\n",
      "Epoch [3/30], Batch [18220/20508], Loss: 0.6773\n",
      "Epoch [3/30], Batch [18230/20508], Loss: 0.6827\n",
      "Epoch [3/30], Batch [18240/20508], Loss: 0.7075\n",
      "Epoch [3/30], Batch [18250/20508], Loss: 0.6857\n",
      "Epoch [3/30], Batch [18260/20508], Loss: 0.7070\n",
      "Epoch [3/30], Batch [18270/20508], Loss: 0.6931\n",
      "Epoch [3/30], Batch [18280/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [18290/20508], Loss: 0.7019\n",
      "Epoch [3/30], Batch [18300/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [18310/20508], Loss: 0.7061\n",
      "Epoch [3/30], Batch [18320/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [18330/20508], Loss: 0.7105\n",
      "Epoch [3/30], Batch [18340/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [18350/20508], Loss: 0.6966\n",
      "Epoch [3/30], Batch [18360/20508], Loss: 0.6876\n",
      "Epoch [3/30], Batch [18370/20508], Loss: 0.6996\n",
      "Epoch [3/30], Batch [18380/20508], Loss: 0.7042\n",
      "Epoch [3/30], Batch [18390/20508], Loss: 0.6991\n",
      "Epoch [3/30], Batch [18400/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [18410/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [18420/20508], Loss: 0.6948\n",
      "Epoch [3/30], Batch [18430/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [18440/20508], Loss: 0.6981\n",
      "Epoch [3/30], Batch [18450/20508], Loss: 0.6929\n",
      "Epoch [3/30], Batch [18460/20508], Loss: 0.6691\n",
      "Epoch [3/30], Batch [18470/20508], Loss: 0.7039\n",
      "Epoch [3/30], Batch [18480/20508], Loss: 0.6808\n",
      "Epoch [3/30], Batch [18490/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [18500/20508], Loss: 0.6829\n",
      "Epoch [3/30], Batch [18510/20508], Loss: 0.6917\n",
      "Epoch [3/30], Batch [18520/20508], Loss: 0.6887\n",
      "Epoch [3/30], Batch [18530/20508], Loss: 0.6961\n",
      "Epoch [3/30], Batch [18540/20508], Loss: 0.6860\n",
      "Epoch [3/30], Batch [18550/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [18560/20508], Loss: 0.6817\n",
      "Epoch [3/30], Batch [18570/20508], Loss: 0.6934\n",
      "Epoch [3/30], Batch [18580/20508], Loss: 0.6853\n",
      "Epoch [3/30], Batch [18590/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [18600/20508], Loss: 0.6901\n",
      "Epoch [3/30], Batch [18610/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [18620/20508], Loss: 0.6790\n",
      "Epoch [3/30], Batch [18630/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [18640/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [18650/20508], Loss: 0.6991\n",
      "Epoch [3/30], Batch [18660/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [18670/20508], Loss: 0.6805\n",
      "Epoch [3/30], Batch [18680/20508], Loss: 0.6919\n",
      "Epoch [3/30], Batch [18690/20508], Loss: 0.7027\n",
      "Epoch [3/30], Batch [18700/20508], Loss: 0.6879\n",
      "Epoch [3/30], Batch [18710/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [18720/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [18730/20508], Loss: 0.6845\n",
      "Epoch [3/30], Batch [18740/20508], Loss: 0.6871\n",
      "Epoch [3/30], Batch [18750/20508], Loss: 0.6851\n",
      "Epoch [3/30], Batch [18760/20508], Loss: 0.6771\n",
      "Epoch [3/30], Batch [18770/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [18780/20508], Loss: 0.7051\n",
      "Epoch [3/30], Batch [18790/20508], Loss: 0.6767\n",
      "Epoch [3/30], Batch [18800/20508], Loss: 0.6922\n",
      "Epoch [3/30], Batch [18810/20508], Loss: 0.6801\n",
      "Epoch [3/30], Batch [18820/20508], Loss: 0.7006\n",
      "Epoch [3/30], Batch [18830/20508], Loss: 0.6988\n",
      "Epoch [3/30], Batch [18840/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [18850/20508], Loss: 0.6837\n",
      "Epoch [3/30], Batch [18860/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [18870/20508], Loss: 0.6918\n",
      "Epoch [3/30], Batch [18880/20508], Loss: 0.6903\n",
      "Epoch [3/30], Batch [18890/20508], Loss: 0.6854\n",
      "Epoch [3/30], Batch [18900/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [18910/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [18920/20508], Loss: 0.6921\n",
      "Epoch [3/30], Batch [18930/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [18940/20508], Loss: 0.6995\n",
      "Epoch [3/30], Batch [18950/20508], Loss: 0.6904\n",
      "Epoch [3/30], Batch [18960/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [18970/20508], Loss: 0.6639\n",
      "Epoch [3/30], Batch [18980/20508], Loss: 0.6886\n",
      "Epoch [3/30], Batch [18990/20508], Loss: 0.7073\n",
      "Epoch [3/30], Batch [19000/20508], Loss: 0.6710\n",
      "Epoch [3/30], Batch [19010/20508], Loss: 0.6883\n",
      "Epoch [3/30], Batch [19020/20508], Loss: 0.6739\n",
      "Epoch [3/30], Batch [19030/20508], Loss: 0.6742\n",
      "Epoch [3/30], Batch [19040/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [19050/20508], Loss: 0.7049\n",
      "Epoch [3/30], Batch [19060/20508], Loss: 0.6865\n",
      "Epoch [3/30], Batch [19070/20508], Loss: 0.6844\n",
      "Epoch [3/30], Batch [19080/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [19090/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [19100/20508], Loss: 0.6797\n",
      "Epoch [3/30], Batch [19110/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [19120/20508], Loss: 0.6790\n",
      "Epoch [3/30], Batch [19130/20508], Loss: 0.6971\n",
      "Epoch [3/30], Batch [19140/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [19150/20508], Loss: 0.6975\n",
      "Epoch [3/30], Batch [19160/20508], Loss: 0.6723\n",
      "Epoch [3/30], Batch [19170/20508], Loss: 0.7199\n",
      "Epoch [3/30], Batch [19180/20508], Loss: 0.7067\n",
      "Epoch [3/30], Batch [19190/20508], Loss: 0.6770\n",
      "Epoch [3/30], Batch [19200/20508], Loss: 0.6931\n",
      "Epoch [3/30], Batch [19210/20508], Loss: 0.6740\n",
      "Epoch [3/30], Batch [19220/20508], Loss: 0.6914\n",
      "Epoch [3/30], Batch [19230/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [19240/20508], Loss: 0.7023\n",
      "Epoch [3/30], Batch [19250/20508], Loss: 0.6697\n",
      "Epoch [3/30], Batch [19260/20508], Loss: 0.6695\n",
      "Epoch [3/30], Batch [19270/20508], Loss: 0.6866\n",
      "Epoch [3/30], Batch [19280/20508], Loss: 0.6692\n",
      "Epoch [3/30], Batch [19290/20508], Loss: 0.6989\n",
      "Epoch [3/30], Batch [19300/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [19310/20508], Loss: 0.6676\n",
      "Epoch [3/30], Batch [19320/20508], Loss: 0.7048\n",
      "Epoch [3/30], Batch [19330/20508], Loss: 0.7059\n",
      "Epoch [3/30], Batch [19340/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [19350/20508], Loss: 0.6730\n",
      "Epoch [3/30], Batch [19360/20508], Loss: 0.6818\n",
      "Epoch [3/30], Batch [19370/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [19380/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [19390/20508], Loss: 0.6940\n",
      "Epoch [3/30], Batch [19400/20508], Loss: 0.6992\n",
      "Epoch [3/30], Batch [19410/20508], Loss: 0.6939\n",
      "Epoch [3/30], Batch [19420/20508], Loss: 0.7069\n",
      "Epoch [3/30], Batch [19430/20508], Loss: 0.6951\n",
      "Epoch [3/30], Batch [19440/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [19450/20508], Loss: 0.6942\n",
      "Epoch [3/30], Batch [19460/20508], Loss: 0.6964\n",
      "Epoch [3/30], Batch [19470/20508], Loss: 0.6864\n",
      "Epoch [3/30], Batch [19480/20508], Loss: 0.6943\n",
      "Epoch [3/30], Batch [19490/20508], Loss: 0.6909\n",
      "Epoch [3/30], Batch [19500/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [19510/20508], Loss: 0.6852\n",
      "Epoch [3/30], Batch [19520/20508], Loss: 0.6839\n",
      "Epoch [3/30], Batch [19530/20508], Loss: 0.6920\n",
      "Epoch [3/30], Batch [19540/20508], Loss: 0.6848\n",
      "Epoch [3/30], Batch [19550/20508], Loss: 0.6906\n",
      "Epoch [3/30], Batch [19560/20508], Loss: 0.6847\n",
      "Epoch [3/30], Batch [19570/20508], Loss: 0.6873\n",
      "Epoch [3/30], Batch [19580/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [19590/20508], Loss: 0.7090\n",
      "Epoch [3/30], Batch [19600/20508], Loss: 0.6842\n",
      "Epoch [3/30], Batch [19610/20508], Loss: 0.6928\n",
      "Epoch [3/30], Batch [19620/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [19630/20508], Loss: 0.6893\n",
      "Epoch [3/30], Batch [19640/20508], Loss: 0.6932\n",
      "Epoch [3/30], Batch [19650/20508], Loss: 0.6910\n",
      "Epoch [3/30], Batch [19660/20508], Loss: 0.7030\n",
      "Epoch [3/30], Batch [19670/20508], Loss: 0.6706\n",
      "Epoch [3/30], Batch [19680/20508], Loss: 0.6805\n",
      "Epoch [3/30], Batch [19690/20508], Loss: 0.7079\n",
      "Epoch [3/30], Batch [19700/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [19710/20508], Loss: 0.6933\n",
      "Epoch [3/30], Batch [19720/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [19730/20508], Loss: 0.6766\n",
      "Epoch [3/30], Batch [19740/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [19750/20508], Loss: 0.6976\n",
      "Epoch [3/30], Batch [19760/20508], Loss: 0.7044\n",
      "Epoch [3/30], Batch [19770/20508], Loss: 0.6810\n",
      "Epoch [3/30], Batch [19780/20508], Loss: 0.7236\n",
      "Epoch [3/30], Batch [19790/20508], Loss: 0.6993\n",
      "Epoch [3/30], Batch [19800/20508], Loss: 0.6889\n",
      "Epoch [3/30], Batch [19810/20508], Loss: 0.6955\n",
      "Epoch [3/30], Batch [19820/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [19830/20508], Loss: 0.6783\n",
      "Epoch [3/30], Batch [19840/20508], Loss: 0.7037\n",
      "Epoch [3/30], Batch [19850/20508], Loss: 0.6809\n",
      "Epoch [3/30], Batch [19860/20508], Loss: 0.6806\n",
      "Epoch [3/30], Batch [19870/20508], Loss: 0.7125\n",
      "Epoch [3/30], Batch [19880/20508], Loss: 0.7095\n",
      "Epoch [3/30], Batch [19890/20508], Loss: 0.6786\n",
      "Epoch [3/30], Batch [19900/20508], Loss: 0.6936\n",
      "Epoch [3/30], Batch [19910/20508], Loss: 0.6880\n",
      "Epoch [3/30], Batch [19920/20508], Loss: 0.6957\n",
      "Epoch [3/30], Batch [19930/20508], Loss: 0.7012\n",
      "Epoch [3/30], Batch [19940/20508], Loss: 0.7111\n",
      "Epoch [3/30], Batch [19950/20508], Loss: 0.6868\n",
      "Epoch [3/30], Batch [19960/20508], Loss: 0.6895\n",
      "Epoch [3/30], Batch [19970/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [19980/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [19990/20508], Loss: 0.6819\n",
      "Epoch [3/30], Batch [20000/20508], Loss: 0.6740\n",
      "Epoch [3/30], Batch [20010/20508], Loss: 0.6935\n",
      "Epoch [3/30], Batch [20020/20508], Loss: 0.6923\n",
      "Epoch [3/30], Batch [20030/20508], Loss: 0.6942\n",
      "Epoch [3/30], Batch [20040/20508], Loss: 0.6814\n",
      "Epoch [3/30], Batch [20050/20508], Loss: 0.6967\n",
      "Epoch [3/30], Batch [20060/20508], Loss: 0.6840\n",
      "Epoch [3/30], Batch [20070/20508], Loss: 0.6748\n",
      "Epoch [3/30], Batch [20080/20508], Loss: 0.6884\n",
      "Epoch [3/30], Batch [20090/20508], Loss: 0.6965\n",
      "Epoch [3/30], Batch [20100/20508], Loss: 0.6777\n",
      "Epoch [3/30], Batch [20110/20508], Loss: 0.6959\n",
      "Epoch [3/30], Batch [20120/20508], Loss: 0.6762\n",
      "Epoch [3/30], Batch [20130/20508], Loss: 0.6815\n",
      "Epoch [3/30], Batch [20140/20508], Loss: 0.7025\n",
      "Epoch [3/30], Batch [20150/20508], Loss: 0.6916\n",
      "Epoch [3/30], Batch [20160/20508], Loss: 0.6862\n",
      "Epoch [3/30], Batch [20170/20508], Loss: 0.6659\n",
      "Epoch [3/30], Batch [20180/20508], Loss: 0.6982\n",
      "Epoch [3/30], Batch [20190/20508], Loss: 0.6754\n",
      "Epoch [3/30], Batch [20200/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [20210/20508], Loss: 0.6812\n",
      "Epoch [3/30], Batch [20220/20508], Loss: 0.6909\n",
      "Epoch [3/30], Batch [20230/20508], Loss: 0.6833\n",
      "Epoch [3/30], Batch [20240/20508], Loss: 0.6784\n",
      "Epoch [3/30], Batch [20250/20508], Loss: 0.6870\n",
      "Epoch [3/30], Batch [20260/20508], Loss: 0.6858\n",
      "Epoch [3/30], Batch [20270/20508], Loss: 0.6983\n",
      "Epoch [3/30], Batch [20280/20508], Loss: 0.6796\n",
      "Epoch [3/30], Batch [20290/20508], Loss: 0.6828\n",
      "Epoch [3/30], Batch [20300/20508], Loss: 0.6878\n",
      "Epoch [3/30], Batch [20310/20508], Loss: 0.6740\n",
      "Epoch [3/30], Batch [20320/20508], Loss: 0.6885\n",
      "Epoch [3/30], Batch [20330/20508], Loss: 0.6970\n",
      "Epoch [3/30], Batch [20340/20508], Loss: 0.6779\n",
      "Epoch [3/30], Batch [20350/20508], Loss: 0.6882\n",
      "Epoch [3/30], Batch [20360/20508], Loss: 0.6792\n",
      "Epoch [3/30], Batch [20370/20508], Loss: 0.6686\n",
      "Epoch [3/30], Batch [20380/20508], Loss: 0.6877\n",
      "Epoch [3/30], Batch [20390/20508], Loss: 0.6891\n",
      "Epoch [3/30], Batch [20400/20508], Loss: 0.6799\n",
      "Epoch [3/30], Batch [20410/20508], Loss: 0.6849\n",
      "Epoch [3/30], Batch [20420/20508], Loss: 0.7174\n",
      "Epoch [3/30], Batch [20430/20508], Loss: 0.6856\n",
      "Epoch [3/30], Batch [20440/20508], Loss: 0.7035\n",
      "Epoch [3/30], Batch [20450/20508], Loss: 0.6954\n",
      "Epoch [3/30], Batch [20460/20508], Loss: 0.6741\n",
      "Epoch [3/30], Batch [20470/20508], Loss: 0.6855\n",
      "Epoch [3/30], Batch [20480/20508], Loss: 0.6572\n",
      "Epoch [3/30], Batch [20490/20508], Loss: 0.6955\n",
      "Epoch [3/30], Batch [20500/20508], Loss: 0.7036\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [3], Train Loss: 0.6908, Test Loss: 0.6870, Early Stopping Counter: 0\n",
      "\n",
      "\n",
      "\n",
      "Epoch [4/30], Batch [0/20508], Loss: 0.6668\n",
      "Epoch [4/30], Batch [10/20508], Loss: 0.6732\n",
      "Epoch [4/30], Batch [20/20508], Loss: 0.7051\n",
      "Epoch [4/30], Batch [30/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [40/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [50/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [60/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [70/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [80/20508], Loss: 0.6866\n",
      "Epoch [4/30], Batch [90/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [100/20508], Loss: 0.6904\n",
      "Epoch [4/30], Batch [110/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [120/20508], Loss: 0.7089\n",
      "Epoch [4/30], Batch [130/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [140/20508], Loss: 0.6765\n",
      "Epoch [4/30], Batch [150/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [160/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [170/20508], Loss: 0.6792\n",
      "Epoch [4/30], Batch [180/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [190/20508], Loss: 0.7028\n",
      "Epoch [4/30], Batch [200/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [210/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [220/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [230/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [240/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [250/20508], Loss: 0.7083\n",
      "Epoch [4/30], Batch [260/20508], Loss: 0.6995\n",
      "Epoch [4/30], Batch [270/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [280/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [290/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [300/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [310/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [320/20508], Loss: 0.7125\n",
      "Epoch [4/30], Batch [330/20508], Loss: 0.7070\n",
      "Epoch [4/30], Batch [340/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [350/20508], Loss: 0.7067\n",
      "Epoch [4/30], Batch [360/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [370/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [380/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [390/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [400/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [410/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [420/20508], Loss: 0.7079\n",
      "Epoch [4/30], Batch [430/20508], Loss: 0.6768\n",
      "Epoch [4/30], Batch [440/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [450/20508], Loss: 0.7036\n",
      "Epoch [4/30], Batch [460/20508], Loss: 0.7017\n",
      "Epoch [4/30], Batch [470/20508], Loss: 0.6737\n",
      "Epoch [4/30], Batch [480/20508], Loss: 0.6719\n",
      "Epoch [4/30], Batch [490/20508], Loss: 0.6755\n",
      "Epoch [4/30], Batch [500/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [510/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [520/20508], Loss: 0.7177\n",
      "Epoch [4/30], Batch [530/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [540/20508], Loss: 0.7192\n",
      "Epoch [4/30], Batch [550/20508], Loss: 0.7209\n",
      "Epoch [4/30], Batch [560/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [570/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [580/20508], Loss: 0.6703\n",
      "Epoch [4/30], Batch [590/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [600/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [610/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [620/20508], Loss: 0.6766\n",
      "Epoch [4/30], Batch [630/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [640/20508], Loss: 0.6745\n",
      "Epoch [4/30], Batch [650/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [660/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [670/20508], Loss: 0.6759\n",
      "Epoch [4/30], Batch [680/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [690/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [700/20508], Loss: 0.6990\n",
      "Epoch [4/30], Batch [710/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [720/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [730/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [740/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [750/20508], Loss: 0.6867\n",
      "Epoch [4/30], Batch [760/20508], Loss: 0.6900\n",
      "Epoch [4/30], Batch [770/20508], Loss: 0.6756\n",
      "Epoch [4/30], Batch [780/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [790/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [800/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [810/20508], Loss: 0.7109\n",
      "Epoch [4/30], Batch [820/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [830/20508], Loss: 0.6747\n",
      "Epoch [4/30], Batch [840/20508], Loss: 0.6708\n",
      "Epoch [4/30], Batch [850/20508], Loss: 0.6754\n",
      "Epoch [4/30], Batch [860/20508], Loss: 0.7047\n",
      "Epoch [4/30], Batch [870/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [880/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [890/20508], Loss: 0.6837\n",
      "Epoch [4/30], Batch [900/20508], Loss: 0.6906\n",
      "Epoch [4/30], Batch [910/20508], Loss: 0.6789\n",
      "Epoch [4/30], Batch [920/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [930/20508], Loss: 0.6741\n",
      "Epoch [4/30], Batch [940/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [950/20508], Loss: 0.6772\n",
      "Epoch [4/30], Batch [960/20508], Loss: 0.6975\n",
      "Epoch [4/30], Batch [970/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [980/20508], Loss: 0.6864\n",
      "Epoch [4/30], Batch [990/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [1000/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [1010/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [1020/20508], Loss: 0.7123\n",
      "Epoch [4/30], Batch [1030/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [1040/20508], Loss: 0.6991\n",
      "Epoch [4/30], Batch [1050/20508], Loss: 0.6911\n",
      "Epoch [4/30], Batch [1060/20508], Loss: 0.7270\n",
      "Epoch [4/30], Batch [1070/20508], Loss: 0.7087\n",
      "Epoch [4/30], Batch [1080/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [1090/20508], Loss: 0.6691\n",
      "Epoch [4/30], Batch [1100/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [1110/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [1120/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [1130/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [1140/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [1150/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [1160/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [1170/20508], Loss: 0.7078\n",
      "Epoch [4/30], Batch [1180/20508], Loss: 0.6827\n",
      "Epoch [4/30], Batch [1190/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [1200/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [1210/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [1220/20508], Loss: 0.6981\n",
      "Epoch [4/30], Batch [1230/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [1240/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [1250/20508], Loss: 0.7019\n",
      "Epoch [4/30], Batch [1260/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [1270/20508], Loss: 0.6959\n",
      "Epoch [4/30], Batch [1280/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [1290/20508], Loss: 0.6582\n",
      "Epoch [4/30], Batch [1300/20508], Loss: 0.7073\n",
      "Epoch [4/30], Batch [1310/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [1320/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [1330/20508], Loss: 0.6657\n",
      "Epoch [4/30], Batch [1340/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [1350/20508], Loss: 0.7008\n",
      "Epoch [4/30], Batch [1360/20508], Loss: 0.7051\n",
      "Epoch [4/30], Batch [1370/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [1380/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [1390/20508], Loss: 0.6750\n",
      "Epoch [4/30], Batch [1400/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [1410/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [1420/20508], Loss: 0.6776\n",
      "Epoch [4/30], Batch [1430/20508], Loss: 0.6776\n",
      "Epoch [4/30], Batch [1440/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [1450/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [1460/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [1470/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [1480/20508], Loss: 0.6638\n",
      "Epoch [4/30], Batch [1490/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [1500/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [1510/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [1520/20508], Loss: 0.6755\n",
      "Epoch [4/30], Batch [1530/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [1540/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [1550/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [1560/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [1570/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [1580/20508], Loss: 0.6622\n",
      "Epoch [4/30], Batch [1590/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [1600/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [1610/20508], Loss: 0.6796\n",
      "Epoch [4/30], Batch [1620/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [1630/20508], Loss: 0.7064\n",
      "Epoch [4/30], Batch [1640/20508], Loss: 0.7001\n",
      "Epoch [4/30], Batch [1650/20508], Loss: 0.6935\n",
      "Epoch [4/30], Batch [1660/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [1670/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [1680/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [1690/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [1700/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [1710/20508], Loss: 0.7107\n",
      "Epoch [4/30], Batch [1720/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [1730/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [1740/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [1750/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [1760/20508], Loss: 0.6700\n",
      "Epoch [4/30], Batch [1770/20508], Loss: 0.7025\n",
      "Epoch [4/30], Batch [1780/20508], Loss: 0.7067\n",
      "Epoch [4/30], Batch [1790/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [1800/20508], Loss: 0.7038\n",
      "Epoch [4/30], Batch [1810/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [1820/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [1830/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [1840/20508], Loss: 0.6530\n",
      "Epoch [4/30], Batch [1850/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [1860/20508], Loss: 0.6782\n",
      "Epoch [4/30], Batch [1870/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [1880/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [1890/20508], Loss: 0.6700\n",
      "Epoch [4/30], Batch [1900/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [1910/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [1920/20508], Loss: 0.7057\n",
      "Epoch [4/30], Batch [1930/20508], Loss: 0.7054\n",
      "Epoch [4/30], Batch [1940/20508], Loss: 0.7169\n",
      "Epoch [4/30], Batch [1950/20508], Loss: 0.7059\n",
      "Epoch [4/30], Batch [1960/20508], Loss: 0.6763\n",
      "Epoch [4/30], Batch [1970/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [1980/20508], Loss: 0.7166\n",
      "Epoch [4/30], Batch [1990/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [2000/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [2010/20508], Loss: 0.7132\n",
      "Epoch [4/30], Batch [2020/20508], Loss: 0.6925\n",
      "Epoch [4/30], Batch [2030/20508], Loss: 0.6824\n",
      "Epoch [4/30], Batch [2040/20508], Loss: 0.6828\n",
      "Epoch [4/30], Batch [2050/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [2060/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [2070/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [2080/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [2090/20508], Loss: 0.6776\n",
      "Epoch [4/30], Batch [2100/20508], Loss: 0.6785\n",
      "Epoch [4/30], Batch [2110/20508], Loss: 0.6793\n",
      "Epoch [4/30], Batch [2120/20508], Loss: 0.6961\n",
      "Epoch [4/30], Batch [2130/20508], Loss: 0.6721\n",
      "Epoch [4/30], Batch [2140/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [2150/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [2160/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [2170/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [2180/20508], Loss: 0.6950\n",
      "Epoch [4/30], Batch [2190/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [2200/20508], Loss: 0.7007\n",
      "Epoch [4/30], Batch [2210/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [2220/20508], Loss: 0.6957\n",
      "Epoch [4/30], Batch [2230/20508], Loss: 0.6802\n",
      "Epoch [4/30], Batch [2240/20508], Loss: 0.6783\n",
      "Epoch [4/30], Batch [2250/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [2260/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [2270/20508], Loss: 0.6713\n",
      "Epoch [4/30], Batch [2280/20508], Loss: 0.6648\n",
      "Epoch [4/30], Batch [2290/20508], Loss: 0.7075\n",
      "Epoch [4/30], Batch [2300/20508], Loss: 0.7072\n",
      "Epoch [4/30], Batch [2310/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [2320/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [2330/20508], Loss: 0.6948\n",
      "Epoch [4/30], Batch [2340/20508], Loss: 0.7024\n",
      "Epoch [4/30], Batch [2350/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [2360/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [2370/20508], Loss: 0.7026\n",
      "Epoch [4/30], Batch [2380/20508], Loss: 0.6719\n",
      "Epoch [4/30], Batch [2390/20508], Loss: 0.7060\n",
      "Epoch [4/30], Batch [2400/20508], Loss: 0.6538\n",
      "Epoch [4/30], Batch [2410/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [2420/20508], Loss: 0.6904\n",
      "Epoch [4/30], Batch [2430/20508], Loss: 0.6778\n",
      "Epoch [4/30], Batch [2440/20508], Loss: 0.7018\n",
      "Epoch [4/30], Batch [2450/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [2460/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [2470/20508], Loss: 0.7033\n",
      "Epoch [4/30], Batch [2480/20508], Loss: 0.7227\n",
      "Epoch [4/30], Batch [2490/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [2500/20508], Loss: 0.6725\n",
      "Epoch [4/30], Batch [2510/20508], Loss: 0.7050\n",
      "Epoch [4/30], Batch [2520/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [2530/20508], Loss: 0.7012\n",
      "Epoch [4/30], Batch [2540/20508], Loss: 0.6748\n",
      "Epoch [4/30], Batch [2550/20508], Loss: 0.7025\n",
      "Epoch [4/30], Batch [2560/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [2570/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [2580/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [2590/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [2600/20508], Loss: 0.6803\n",
      "Epoch [4/30], Batch [2610/20508], Loss: 0.6837\n",
      "Epoch [4/30], Batch [2620/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [2630/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [2640/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [2650/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [2660/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [2670/20508], Loss: 0.6743\n",
      "Epoch [4/30], Batch [2680/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [2690/20508], Loss: 0.6910\n",
      "Epoch [4/30], Batch [2700/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [2710/20508], Loss: 0.6910\n",
      "Epoch [4/30], Batch [2720/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [2730/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [2740/20508], Loss: 0.7052\n",
      "Epoch [4/30], Batch [2750/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [2760/20508], Loss: 0.6800\n",
      "Epoch [4/30], Batch [2770/20508], Loss: 0.6808\n",
      "Epoch [4/30], Batch [2780/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [2790/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [2800/20508], Loss: 0.7102\n",
      "Epoch [4/30], Batch [2810/20508], Loss: 0.7087\n",
      "Epoch [4/30], Batch [2820/20508], Loss: 0.7257\n",
      "Epoch [4/30], Batch [2830/20508], Loss: 0.6927\n",
      "Epoch [4/30], Batch [2840/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [2850/20508], Loss: 0.6681\n",
      "Epoch [4/30], Batch [2860/20508], Loss: 0.7029\n",
      "Epoch [4/30], Batch [2870/20508], Loss: 0.6756\n",
      "Epoch [4/30], Batch [2880/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [2890/20508], Loss: 0.6639\n",
      "Epoch [4/30], Batch [2900/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [2910/20508], Loss: 0.6707\n",
      "Epoch [4/30], Batch [2920/20508], Loss: 0.6857\n",
      "Epoch [4/30], Batch [2930/20508], Loss: 0.7030\n",
      "Epoch [4/30], Batch [2940/20508], Loss: 0.6818\n",
      "Epoch [4/30], Batch [2950/20508], Loss: 0.6910\n",
      "Epoch [4/30], Batch [2960/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [2970/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [2980/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [2990/20508], Loss: 0.6996\n",
      "Epoch [4/30], Batch [3000/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [3010/20508], Loss: 0.6771\n",
      "Epoch [4/30], Batch [3020/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [3030/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [3040/20508], Loss: 0.6708\n",
      "Epoch [4/30], Batch [3050/20508], Loss: 0.6730\n",
      "Epoch [4/30], Batch [3060/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [3070/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [3080/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [3090/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [3100/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [3110/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [3120/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [3130/20508], Loss: 0.7003\n",
      "Epoch [4/30], Batch [3140/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [3150/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [3160/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [3170/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [3180/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [3190/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [3200/20508], Loss: 0.6981\n",
      "Epoch [4/30], Batch [3210/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [3220/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [3230/20508], Loss: 0.7113\n",
      "Epoch [4/30], Batch [3240/20508], Loss: 0.7083\n",
      "Epoch [4/30], Batch [3250/20508], Loss: 0.6803\n",
      "Epoch [4/30], Batch [3260/20508], Loss: 0.7017\n",
      "Epoch [4/30], Batch [3270/20508], Loss: 0.6677\n",
      "Epoch [4/30], Batch [3280/20508], Loss: 0.6710\n",
      "Epoch [4/30], Batch [3290/20508], Loss: 0.7029\n",
      "Epoch [4/30], Batch [3300/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [3310/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [3320/20508], Loss: 0.7011\n",
      "Epoch [4/30], Batch [3330/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [3340/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [3350/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [3360/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [3370/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [3380/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [3390/20508], Loss: 0.6800\n",
      "Epoch [4/30], Batch [3400/20508], Loss: 0.6928\n",
      "Epoch [4/30], Batch [3410/20508], Loss: 0.7026\n",
      "Epoch [4/30], Batch [3420/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [3430/20508], Loss: 0.6968\n",
      "Epoch [4/30], Batch [3440/20508], Loss: 0.7138\n",
      "Epoch [4/30], Batch [3450/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [3460/20508], Loss: 0.6904\n",
      "Epoch [4/30], Batch [3470/20508], Loss: 0.7196\n",
      "Epoch [4/30], Batch [3480/20508], Loss: 0.6928\n",
      "Epoch [4/30], Batch [3490/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [3500/20508], Loss: 0.6682\n",
      "Epoch [4/30], Batch [3510/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [3520/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [3530/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [3540/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [3550/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [3560/20508], Loss: 0.7035\n",
      "Epoch [4/30], Batch [3570/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [3580/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [3590/20508], Loss: 0.7057\n",
      "Epoch [4/30], Batch [3600/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [3610/20508], Loss: 0.6640\n",
      "Epoch [4/30], Batch [3620/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [3630/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [3640/20508], Loss: 0.7049\n",
      "Epoch [4/30], Batch [3650/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [3660/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [3670/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [3680/20508], Loss: 0.6866\n",
      "Epoch [4/30], Batch [3690/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [3700/20508], Loss: 0.6982\n",
      "Epoch [4/30], Batch [3710/20508], Loss: 0.6827\n",
      "Epoch [4/30], Batch [3720/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [3730/20508], Loss: 0.7041\n",
      "Epoch [4/30], Batch [3740/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [3750/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [3760/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [3770/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [3780/20508], Loss: 0.6975\n",
      "Epoch [4/30], Batch [3790/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [3800/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [3810/20508], Loss: 0.6901\n",
      "Epoch [4/30], Batch [3820/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [3830/20508], Loss: 0.7009\n",
      "Epoch [4/30], Batch [3840/20508], Loss: 0.6769\n",
      "Epoch [4/30], Batch [3850/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [3860/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [3870/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [3880/20508], Loss: 0.6956\n",
      "Epoch [4/30], Batch [3890/20508], Loss: 0.6955\n",
      "Epoch [4/30], Batch [3900/20508], Loss: 0.6943\n",
      "Epoch [4/30], Batch [3910/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [3920/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [3930/20508], Loss: 0.6867\n",
      "Epoch [4/30], Batch [3940/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [3950/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [3960/20508], Loss: 0.6754\n",
      "Epoch [4/30], Batch [3970/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [3980/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [3990/20508], Loss: 0.6980\n",
      "Epoch [4/30], Batch [4000/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [4010/20508], Loss: 0.7006\n",
      "Epoch [4/30], Batch [4020/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [4030/20508], Loss: 0.7078\n",
      "Epoch [4/30], Batch [4040/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [4050/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [4060/20508], Loss: 0.6692\n",
      "Epoch [4/30], Batch [4070/20508], Loss: 0.6816\n",
      "Epoch [4/30], Batch [4080/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [4090/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [4100/20508], Loss: 0.7200\n",
      "Epoch [4/30], Batch [4110/20508], Loss: 0.6942\n",
      "Epoch [4/30], Batch [4120/20508], Loss: 0.6745\n",
      "Epoch [4/30], Batch [4130/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [4140/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [4150/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [4160/20508], Loss: 0.6752\n",
      "Epoch [4/30], Batch [4170/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [4180/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [4190/20508], Loss: 0.6824\n",
      "Epoch [4/30], Batch [4200/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [4210/20508], Loss: 0.6673\n",
      "Epoch [4/30], Batch [4220/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [4230/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [4240/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [4250/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [4260/20508], Loss: 0.6712\n",
      "Epoch [4/30], Batch [4270/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [4280/20508], Loss: 0.7030\n",
      "Epoch [4/30], Batch [4290/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [4300/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [4310/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [4320/20508], Loss: 0.7067\n",
      "Epoch [4/30], Batch [4330/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [4340/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [4350/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [4360/20508], Loss: 0.6750\n",
      "Epoch [4/30], Batch [4370/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [4380/20508], Loss: 0.6803\n",
      "Epoch [4/30], Batch [4390/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [4400/20508], Loss: 0.6796\n",
      "Epoch [4/30], Batch [4410/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [4420/20508], Loss: 0.7064\n",
      "Epoch [4/30], Batch [4430/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [4440/20508], Loss: 0.6718\n",
      "Epoch [4/30], Batch [4450/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [4460/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [4470/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [4480/20508], Loss: 0.7066\n",
      "Epoch [4/30], Batch [4490/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [4500/20508], Loss: 0.6712\n",
      "Epoch [4/30], Batch [4510/20508], Loss: 0.6910\n",
      "Epoch [4/30], Batch [4520/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [4530/20508], Loss: 0.7077\n",
      "Epoch [4/30], Batch [4540/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [4550/20508], Loss: 0.7197\n",
      "Epoch [4/30], Batch [4560/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [4570/20508], Loss: 0.6968\n",
      "Epoch [4/30], Batch [4580/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [4590/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [4600/20508], Loss: 0.6691\n",
      "Epoch [4/30], Batch [4610/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [4620/20508], Loss: 0.6850\n",
      "Epoch [4/30], Batch [4630/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [4640/20508], Loss: 0.7007\n",
      "Epoch [4/30], Batch [4650/20508], Loss: 0.6724\n",
      "Epoch [4/30], Batch [4660/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [4670/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [4680/20508], Loss: 0.7229\n",
      "Epoch [4/30], Batch [4690/20508], Loss: 0.6723\n",
      "Epoch [4/30], Batch [4700/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [4710/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [4720/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [4730/20508], Loss: 0.6772\n",
      "Epoch [4/30], Batch [4740/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [4750/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [4760/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [4770/20508], Loss: 0.6956\n",
      "Epoch [4/30], Batch [4780/20508], Loss: 0.7019\n",
      "Epoch [4/30], Batch [4790/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [4800/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [4810/20508], Loss: 0.6720\n",
      "Epoch [4/30], Batch [4820/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [4830/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [4840/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [4850/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [4860/20508], Loss: 0.6921\n",
      "Epoch [4/30], Batch [4870/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [4880/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [4890/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [4900/20508], Loss: 0.6948\n",
      "Epoch [4/30], Batch [4910/20508], Loss: 0.6903\n",
      "Epoch [4/30], Batch [4920/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [4930/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [4940/20508], Loss: 0.6942\n",
      "Epoch [4/30], Batch [4950/20508], Loss: 0.7025\n",
      "Epoch [4/30], Batch [4960/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [4970/20508], Loss: 0.7093\n",
      "Epoch [4/30], Batch [4980/20508], Loss: 0.6980\n",
      "Epoch [4/30], Batch [4990/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [5000/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [5010/20508], Loss: 0.6590\n",
      "Epoch [4/30], Batch [5020/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [5030/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [5040/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [5050/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [5060/20508], Loss: 0.6800\n",
      "Epoch [4/30], Batch [5070/20508], Loss: 0.6797\n",
      "Epoch [4/30], Batch [5080/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [5090/20508], Loss: 0.6717\n",
      "Epoch [4/30], Batch [5100/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [5110/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [5120/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [5130/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [5140/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [5150/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [5160/20508], Loss: 0.6698\n",
      "Epoch [4/30], Batch [5170/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [5180/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [5190/20508], Loss: 0.7076\n",
      "Epoch [4/30], Batch [5200/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [5210/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [5220/20508], Loss: 0.6755\n",
      "Epoch [4/30], Batch [5230/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [5240/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [5250/20508], Loss: 0.7008\n",
      "Epoch [4/30], Batch [5260/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [5270/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [5280/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [5290/20508], Loss: 0.6925\n",
      "Epoch [4/30], Batch [5300/20508], Loss: 0.6640\n",
      "Epoch [4/30], Batch [5310/20508], Loss: 0.6677\n",
      "Epoch [4/30], Batch [5320/20508], Loss: 0.7012\n",
      "Epoch [4/30], Batch [5330/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [5340/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [5350/20508], Loss: 0.6921\n",
      "Epoch [4/30], Batch [5360/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [5370/20508], Loss: 0.6990\n",
      "Epoch [4/30], Batch [5380/20508], Loss: 0.6995\n",
      "Epoch [4/30], Batch [5390/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [5400/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [5410/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [5420/20508], Loss: 0.7024\n",
      "Epoch [4/30], Batch [5430/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [5440/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [5450/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [5460/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [5470/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [5480/20508], Loss: 0.6796\n",
      "Epoch [4/30], Batch [5490/20508], Loss: 0.6786\n",
      "Epoch [4/30], Batch [5500/20508], Loss: 0.6818\n",
      "Epoch [4/30], Batch [5510/20508], Loss: 0.6893\n",
      "Epoch [4/30], Batch [5520/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [5530/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [5540/20508], Loss: 0.6769\n",
      "Epoch [4/30], Batch [5550/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [5560/20508], Loss: 0.6776\n",
      "Epoch [4/30], Batch [5570/20508], Loss: 0.7077\n",
      "Epoch [4/30], Batch [5580/20508], Loss: 0.6903\n",
      "Epoch [4/30], Batch [5590/20508], Loss: 0.6764\n",
      "Epoch [4/30], Batch [5600/20508], Loss: 0.6957\n",
      "Epoch [4/30], Batch [5610/20508], Loss: 0.7087\n",
      "Epoch [4/30], Batch [5620/20508], Loss: 0.7003\n",
      "Epoch [4/30], Batch [5630/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [5640/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [5650/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [5660/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [5670/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [5680/20508], Loss: 0.6901\n",
      "Epoch [4/30], Batch [5690/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [5700/20508], Loss: 0.7219\n",
      "Epoch [4/30], Batch [5710/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [5720/20508], Loss: 0.6790\n",
      "Epoch [4/30], Batch [5730/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [5740/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [5750/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [5760/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [5770/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [5780/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [5790/20508], Loss: 0.6687\n",
      "Epoch [4/30], Batch [5800/20508], Loss: 0.6925\n",
      "Epoch [4/30], Batch [5810/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [5820/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [5830/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [5840/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [5850/20508], Loss: 0.6702\n",
      "Epoch [4/30], Batch [5860/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [5870/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [5880/20508], Loss: 0.7097\n",
      "Epoch [4/30], Batch [5890/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [5900/20508], Loss: 0.6901\n",
      "Epoch [4/30], Batch [5910/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [5920/20508], Loss: 0.6906\n",
      "Epoch [4/30], Batch [5930/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [5940/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [5950/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [5960/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [5970/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [5980/20508], Loss: 0.6701\n",
      "Epoch [4/30], Batch [5990/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [6000/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [6010/20508], Loss: 0.6793\n",
      "Epoch [4/30], Batch [6020/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [6030/20508], Loss: 0.6927\n",
      "Epoch [4/30], Batch [6040/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [6050/20508], Loss: 0.6886\n",
      "Epoch [4/30], Batch [6060/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [6070/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [6080/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [6090/20508], Loss: 0.6807\n",
      "Epoch [4/30], Batch [6100/20508], Loss: 0.6697\n",
      "Epoch [4/30], Batch [6110/20508], Loss: 0.6670\n",
      "Epoch [4/30], Batch [6120/20508], Loss: 0.6587\n",
      "Epoch [4/30], Batch [6130/20508], Loss: 0.7034\n",
      "Epoch [4/30], Batch [6140/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [6150/20508], Loss: 0.7026\n",
      "Epoch [4/30], Batch [6160/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [6170/20508], Loss: 0.6585\n",
      "Epoch [4/30], Batch [6180/20508], Loss: 0.6925\n",
      "Epoch [4/30], Batch [6190/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [6200/20508], Loss: 0.6864\n",
      "Epoch [4/30], Batch [6210/20508], Loss: 0.7006\n",
      "Epoch [4/30], Batch [6220/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [6230/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [6240/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [6250/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [6260/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [6270/20508], Loss: 0.6831\n",
      "Epoch [4/30], Batch [6280/20508], Loss: 0.6782\n",
      "Epoch [4/30], Batch [6290/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [6300/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [6310/20508], Loss: 0.7045\n",
      "Epoch [4/30], Batch [6320/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [6330/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [6340/20508], Loss: 0.6906\n",
      "Epoch [4/30], Batch [6350/20508], Loss: 0.6893\n",
      "Epoch [4/30], Batch [6360/20508], Loss: 0.6733\n",
      "Epoch [4/30], Batch [6370/20508], Loss: 0.7045\n",
      "Epoch [4/30], Batch [6380/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [6390/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [6400/20508], Loss: 0.6972\n",
      "Epoch [4/30], Batch [6410/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [6420/20508], Loss: 0.6957\n",
      "Epoch [4/30], Batch [6430/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [6440/20508], Loss: 0.6785\n",
      "Epoch [4/30], Batch [6450/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [6460/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [6470/20508], Loss: 0.6720\n",
      "Epoch [4/30], Batch [6480/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [6490/20508], Loss: 0.6972\n",
      "Epoch [4/30], Batch [6500/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [6510/20508], Loss: 0.7021\n",
      "Epoch [4/30], Batch [6520/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [6530/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [6540/20508], Loss: 0.7014\n",
      "Epoch [4/30], Batch [6550/20508], Loss: 0.7114\n",
      "Epoch [4/30], Batch [6560/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [6570/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [6580/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [6590/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [6600/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [6610/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [6620/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [6630/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [6640/20508], Loss: 0.7092\n",
      "Epoch [4/30], Batch [6650/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [6660/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [6670/20508], Loss: 0.6767\n",
      "Epoch [4/30], Batch [6680/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [6690/20508], Loss: 0.6807\n",
      "Epoch [4/30], Batch [6700/20508], Loss: 0.6789\n",
      "Epoch [4/30], Batch [6710/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [6720/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [6730/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [6740/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [6750/20508], Loss: 0.7158\n",
      "Epoch [4/30], Batch [6760/20508], Loss: 0.7015\n",
      "Epoch [4/30], Batch [6770/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [6780/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [6790/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [6800/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [6810/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [6820/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [6830/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [6840/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [6850/20508], Loss: 0.6432\n",
      "Epoch [4/30], Batch [6860/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [6870/20508], Loss: 0.6886\n",
      "Epoch [4/30], Batch [6880/20508], Loss: 0.6503\n",
      "Epoch [4/30], Batch [6890/20508], Loss: 0.6757\n",
      "Epoch [4/30], Batch [6900/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [6910/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [6920/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [6930/20508], Loss: 0.6676\n",
      "Epoch [4/30], Batch [6940/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [6950/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [6960/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [6970/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [6980/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [6990/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [7000/20508], Loss: 0.6785\n",
      "Epoch [4/30], Batch [7010/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [7020/20508], Loss: 0.6767\n",
      "Epoch [4/30], Batch [7030/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [7040/20508], Loss: 0.6761\n",
      "Epoch [4/30], Batch [7050/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [7060/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [7070/20508], Loss: 0.7029\n",
      "Epoch [4/30], Batch [7080/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [7090/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [7100/20508], Loss: 0.6797\n",
      "Epoch [4/30], Batch [7110/20508], Loss: 0.7194\n",
      "Epoch [4/30], Batch [7120/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [7130/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [7140/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [7150/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [7160/20508], Loss: 0.7061\n",
      "Epoch [4/30], Batch [7170/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [7180/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [7190/20508], Loss: 0.6740\n",
      "Epoch [4/30], Batch [7200/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [7210/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [7220/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [7230/20508], Loss: 0.6906\n",
      "Epoch [4/30], Batch [7240/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [7250/20508], Loss: 0.6807\n",
      "Epoch [4/30], Batch [7260/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [7270/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [7280/20508], Loss: 0.7005\n",
      "Epoch [4/30], Batch [7290/20508], Loss: 0.6714\n",
      "Epoch [4/30], Batch [7300/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [7310/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [7320/20508], Loss: 0.7009\n",
      "Epoch [4/30], Batch [7330/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [7340/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [7350/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [7360/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [7370/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [7380/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [7390/20508], Loss: 0.6740\n",
      "Epoch [4/30], Batch [7400/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [7410/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [7420/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [7430/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [7440/20508], Loss: 0.6693\n",
      "Epoch [4/30], Batch [7450/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [7460/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [7470/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [7480/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [7490/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [7500/20508], Loss: 0.6840\n",
      "Epoch [4/30], Batch [7510/20508], Loss: 0.6757\n",
      "Epoch [4/30], Batch [7520/20508], Loss: 0.6950\n",
      "Epoch [4/30], Batch [7530/20508], Loss: 0.6745\n",
      "Epoch [4/30], Batch [7540/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [7550/20508], Loss: 0.7126\n",
      "Epoch [4/30], Batch [7560/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [7570/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [7580/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [7590/20508], Loss: 0.6664\n",
      "Epoch [4/30], Batch [7600/20508], Loss: 0.6986\n",
      "Epoch [4/30], Batch [7610/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [7620/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [7630/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [7640/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [7650/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [7660/20508], Loss: 0.6702\n",
      "Epoch [4/30], Batch [7670/20508], Loss: 0.6694\n",
      "Epoch [4/30], Batch [7680/20508], Loss: 0.6980\n",
      "Epoch [4/30], Batch [7690/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [7700/20508], Loss: 0.6795\n",
      "Epoch [4/30], Batch [7710/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [7720/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [7730/20508], Loss: 0.7062\n",
      "Epoch [4/30], Batch [7740/20508], Loss: 0.7121\n",
      "Epoch [4/30], Batch [7750/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [7760/20508], Loss: 0.6866\n",
      "Epoch [4/30], Batch [7770/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [7780/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [7790/20508], Loss: 0.6861\n",
      "Epoch [4/30], Batch [7800/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [7810/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [7820/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [7830/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [7840/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [7850/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [7860/20508], Loss: 0.7056\n",
      "Epoch [4/30], Batch [7870/20508], Loss: 0.7120\n",
      "Epoch [4/30], Batch [7880/20508], Loss: 0.7060\n",
      "Epoch [4/30], Batch [7890/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [7900/20508], Loss: 0.7088\n",
      "Epoch [4/30], Batch [7910/20508], Loss: 0.6981\n",
      "Epoch [4/30], Batch [7920/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [7930/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [7940/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [7950/20508], Loss: 0.7056\n",
      "Epoch [4/30], Batch [7960/20508], Loss: 0.6684\n",
      "Epoch [4/30], Batch [7970/20508], Loss: 0.6704\n",
      "Epoch [4/30], Batch [7980/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [7990/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [8000/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [8010/20508], Loss: 0.7053\n",
      "Epoch [4/30], Batch [8020/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [8030/20508], Loss: 0.7159\n",
      "Epoch [4/30], Batch [8040/20508], Loss: 0.7021\n",
      "Epoch [4/30], Batch [8050/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [8060/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [8070/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [8080/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [8090/20508], Loss: 0.7141\n",
      "Epoch [4/30], Batch [8100/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [8110/20508], Loss: 0.7102\n",
      "Epoch [4/30], Batch [8120/20508], Loss: 0.7081\n",
      "Epoch [4/30], Batch [8130/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [8140/20508], Loss: 0.6927\n",
      "Epoch [4/30], Batch [8150/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [8160/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [8170/20508], Loss: 0.7049\n",
      "Epoch [4/30], Batch [8180/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [8190/20508], Loss: 0.6762\n",
      "Epoch [4/30], Batch [8200/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [8210/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [8220/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [8230/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [8240/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [8250/20508], Loss: 0.6788\n",
      "Epoch [4/30], Batch [8260/20508], Loss: 0.6646\n",
      "Epoch [4/30], Batch [8270/20508], Loss: 0.7132\n",
      "Epoch [4/30], Batch [8280/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [8290/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [8300/20508], Loss: 0.6653\n",
      "Epoch [4/30], Batch [8310/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [8320/20508], Loss: 0.6768\n",
      "Epoch [4/30], Batch [8330/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [8340/20508], Loss: 0.7063\n",
      "Epoch [4/30], Batch [8350/20508], Loss: 0.6672\n",
      "Epoch [4/30], Batch [8360/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [8370/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [8380/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [8390/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [8400/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [8410/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [8420/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [8430/20508], Loss: 0.7038\n",
      "Epoch [4/30], Batch [8440/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [8450/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [8460/20508], Loss: 0.6790\n",
      "Epoch [4/30], Batch [8470/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [8480/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [8490/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [8500/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [8510/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [8520/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [8530/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [8540/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [8550/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [8560/20508], Loss: 0.7053\n",
      "Epoch [4/30], Batch [8570/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [8580/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [8590/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [8600/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [8610/20508], Loss: 0.6800\n",
      "Epoch [4/30], Batch [8620/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [8630/20508], Loss: 0.7125\n",
      "Epoch [4/30], Batch [8640/20508], Loss: 0.7149\n",
      "Epoch [4/30], Batch [8650/20508], Loss: 0.6816\n",
      "Epoch [4/30], Batch [8660/20508], Loss: 0.6959\n",
      "Epoch [4/30], Batch [8670/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [8680/20508], Loss: 0.6795\n",
      "Epoch [4/30], Batch [8690/20508], Loss: 0.6867\n",
      "Epoch [4/30], Batch [8700/20508], Loss: 0.7038\n",
      "Epoch [4/30], Batch [8710/20508], Loss: 0.7155\n",
      "Epoch [4/30], Batch [8720/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [8730/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [8740/20508], Loss: 0.6948\n",
      "Epoch [4/30], Batch [8750/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [8760/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [8770/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [8780/20508], Loss: 0.6779\n",
      "Epoch [4/30], Batch [8790/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [8800/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [8810/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [8820/20508], Loss: 0.7036\n",
      "Epoch [4/30], Batch [8830/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [8840/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [8850/20508], Loss: 0.6807\n",
      "Epoch [4/30], Batch [8860/20508], Loss: 0.7045\n",
      "Epoch [4/30], Batch [8870/20508], Loss: 0.7049\n",
      "Epoch [4/30], Batch [8880/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [8890/20508], Loss: 0.6966\n",
      "Epoch [4/30], Batch [8900/20508], Loss: 0.6731\n",
      "Epoch [4/30], Batch [8910/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [8920/20508], Loss: 0.6712\n",
      "Epoch [4/30], Batch [8930/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [8940/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [8950/20508], Loss: 0.6673\n",
      "Epoch [4/30], Batch [8960/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [8970/20508], Loss: 0.7077\n",
      "Epoch [4/30], Batch [8980/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [8990/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [9000/20508], Loss: 0.6954\n",
      "Epoch [4/30], Batch [9010/20508], Loss: 0.7112\n",
      "Epoch [4/30], Batch [9020/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [9030/20508], Loss: 0.6761\n",
      "Epoch [4/30], Batch [9040/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [9050/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [9060/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [9070/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [9080/20508], Loss: 0.7045\n",
      "Epoch [4/30], Batch [9090/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [9100/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [9110/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [9120/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [9130/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [9140/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [9150/20508], Loss: 0.6692\n",
      "Epoch [4/30], Batch [9160/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [9170/20508], Loss: 0.6766\n",
      "Epoch [4/30], Batch [9180/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [9190/20508], Loss: 0.6956\n",
      "Epoch [4/30], Batch [9200/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [9210/20508], Loss: 0.7079\n",
      "Epoch [4/30], Batch [9220/20508], Loss: 0.7013\n",
      "Epoch [4/30], Batch [9230/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [9240/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [9250/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [9260/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [9270/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [9280/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [9290/20508], Loss: 0.6994\n",
      "Epoch [4/30], Batch [9300/20508], Loss: 0.6950\n",
      "Epoch [4/30], Batch [9310/20508], Loss: 0.6785\n",
      "Epoch [4/30], Batch [9320/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [9330/20508], Loss: 0.6753\n",
      "Epoch [4/30], Batch [9340/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [9350/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [9360/20508], Loss: 0.6766\n",
      "Epoch [4/30], Batch [9370/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [9380/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [9390/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [9400/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [9410/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [9420/20508], Loss: 0.7072\n",
      "Epoch [4/30], Batch [9430/20508], Loss: 0.7127\n",
      "Epoch [4/30], Batch [9440/20508], Loss: 0.7020\n",
      "Epoch [4/30], Batch [9450/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [9460/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [9470/20508], Loss: 0.6739\n",
      "Epoch [4/30], Batch [9480/20508], Loss: 0.7014\n",
      "Epoch [4/30], Batch [9490/20508], Loss: 0.6775\n",
      "Epoch [4/30], Batch [9500/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [9510/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [9520/20508], Loss: 0.6904\n",
      "Epoch [4/30], Batch [9530/20508], Loss: 0.6700\n",
      "Epoch [4/30], Batch [9540/20508], Loss: 0.6861\n",
      "Epoch [4/30], Batch [9550/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [9560/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [9570/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [9580/20508], Loss: 0.6961\n",
      "Epoch [4/30], Batch [9590/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [9600/20508], Loss: 0.6935\n",
      "Epoch [4/30], Batch [9610/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [9620/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [9630/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [9640/20508], Loss: 0.7021\n",
      "Epoch [4/30], Batch [9650/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [9660/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [9670/20508], Loss: 0.6827\n",
      "Epoch [4/30], Batch [9680/20508], Loss: 0.6739\n",
      "Epoch [4/30], Batch [9690/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [9700/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [9710/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [9720/20508], Loss: 0.7060\n",
      "Epoch [4/30], Batch [9730/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [9740/20508], Loss: 0.7009\n",
      "Epoch [4/30], Batch [9750/20508], Loss: 0.6848\n",
      "Epoch [4/30], Batch [9760/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [9770/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [9780/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [9790/20508], Loss: 0.6943\n",
      "Epoch [4/30], Batch [9800/20508], Loss: 0.7048\n",
      "Epoch [4/30], Batch [9810/20508], Loss: 0.7055\n",
      "Epoch [4/30], Batch [9820/20508], Loss: 0.6903\n",
      "Epoch [4/30], Batch [9830/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [9840/20508], Loss: 0.7099\n",
      "Epoch [4/30], Batch [9850/20508], Loss: 0.6679\n",
      "Epoch [4/30], Batch [9860/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [9870/20508], Loss: 0.7001\n",
      "Epoch [4/30], Batch [9880/20508], Loss: 0.6995\n",
      "Epoch [4/30], Batch [9890/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [9900/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [9910/20508], Loss: 0.7066\n",
      "Epoch [4/30], Batch [9920/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [9930/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [9940/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [9950/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [9960/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [9970/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [9980/20508], Loss: 0.6961\n",
      "Epoch [4/30], Batch [9990/20508], Loss: 0.6986\n",
      "Epoch [4/30], Batch [10000/20508], Loss: 0.7062\n",
      "Epoch [4/30], Batch [10010/20508], Loss: 0.7067\n",
      "Epoch [4/30], Batch [10020/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [10030/20508], Loss: 0.6831\n",
      "Epoch [4/30], Batch [10040/20508], Loss: 0.6840\n",
      "Epoch [4/30], Batch [10050/20508], Loss: 0.7130\n",
      "Epoch [4/30], Batch [10060/20508], Loss: 0.7086\n",
      "Epoch [4/30], Batch [10070/20508], Loss: 0.6724\n",
      "Epoch [4/30], Batch [10080/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [10090/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [10100/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [10110/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [10120/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [10130/20508], Loss: 0.7102\n",
      "Epoch [4/30], Batch [10140/20508], Loss: 0.6935\n",
      "Epoch [4/30], Batch [10150/20508], Loss: 0.6837\n",
      "Epoch [4/30], Batch [10160/20508], Loss: 0.6808\n",
      "Epoch [4/30], Batch [10170/20508], Loss: 0.6732\n",
      "Epoch [4/30], Batch [10180/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [10190/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [10200/20508], Loss: 0.7009\n",
      "Epoch [4/30], Batch [10210/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [10220/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [10230/20508], Loss: 0.6665\n",
      "Epoch [4/30], Batch [10240/20508], Loss: 0.6789\n",
      "Epoch [4/30], Batch [10250/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [10260/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [10270/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [10280/20508], Loss: 0.7055\n",
      "Epoch [4/30], Batch [10290/20508], Loss: 0.7182\n",
      "Epoch [4/30], Batch [10300/20508], Loss: 0.7024\n",
      "Epoch [4/30], Batch [10310/20508], Loss: 0.7009\n",
      "Epoch [4/30], Batch [10320/20508], Loss: 0.6903\n",
      "Epoch [4/30], Batch [10330/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [10340/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [10350/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [10360/20508], Loss: 0.6793\n",
      "Epoch [4/30], Batch [10370/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [10380/20508], Loss: 0.7087\n",
      "Epoch [4/30], Batch [10390/20508], Loss: 0.6874\n",
      "Epoch [4/30], Batch [10400/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [10410/20508], Loss: 0.7094\n",
      "Epoch [4/30], Batch [10420/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [10430/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [10440/20508], Loss: 0.6783\n",
      "Epoch [4/30], Batch [10450/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [10460/20508], Loss: 0.6942\n",
      "Epoch [4/30], Batch [10470/20508], Loss: 0.6646\n",
      "Epoch [4/30], Batch [10480/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [10490/20508], Loss: 0.6956\n",
      "Epoch [4/30], Batch [10500/20508], Loss: 0.6867\n",
      "Epoch [4/30], Batch [10510/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [10520/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [10530/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [10540/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [10550/20508], Loss: 0.7025\n",
      "Epoch [4/30], Batch [10560/20508], Loss: 0.7101\n",
      "Epoch [4/30], Batch [10570/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [10580/20508], Loss: 0.6817\n",
      "Epoch [4/30], Batch [10590/20508], Loss: 0.6711\n",
      "Epoch [4/30], Batch [10600/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [10610/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [10620/20508], Loss: 0.6802\n",
      "Epoch [4/30], Batch [10630/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [10640/20508], Loss: 0.6991\n",
      "Epoch [4/30], Batch [10650/20508], Loss: 0.6994\n",
      "Epoch [4/30], Batch [10660/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [10670/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [10680/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [10690/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [10700/20508], Loss: 0.6998\n",
      "Epoch [4/30], Batch [10710/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [10720/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [10730/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [10740/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [10750/20508], Loss: 0.6972\n",
      "Epoch [4/30], Batch [10760/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [10770/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [10780/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [10790/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [10800/20508], Loss: 0.7016\n",
      "Epoch [4/30], Batch [10810/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [10820/20508], Loss: 0.6687\n",
      "Epoch [4/30], Batch [10830/20508], Loss: 0.7049\n",
      "Epoch [4/30], Batch [10840/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [10850/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [10860/20508], Loss: 0.6779\n",
      "Epoch [4/30], Batch [10870/20508], Loss: 0.7059\n",
      "Epoch [4/30], Batch [10880/20508], Loss: 0.6755\n",
      "Epoch [4/30], Batch [10890/20508], Loss: 0.6571\n",
      "Epoch [4/30], Batch [10900/20508], Loss: 0.6777\n",
      "Epoch [4/30], Batch [10910/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [10920/20508], Loss: 0.6759\n",
      "Epoch [4/30], Batch [10930/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [10940/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [10950/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [10960/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [10970/20508], Loss: 0.6752\n",
      "Epoch [4/30], Batch [10980/20508], Loss: 0.6990\n",
      "Epoch [4/30], Batch [10990/20508], Loss: 0.6839\n",
      "Epoch [4/30], Batch [11000/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [11010/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [11020/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [11030/20508], Loss: 0.7038\n",
      "Epoch [4/30], Batch [11040/20508], Loss: 0.7105\n",
      "Epoch [4/30], Batch [11050/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [11060/20508], Loss: 0.6786\n",
      "Epoch [4/30], Batch [11070/20508], Loss: 0.6793\n",
      "Epoch [4/30], Batch [11080/20508], Loss: 0.6932\n",
      "Epoch [4/30], Batch [11090/20508], Loss: 0.6750\n",
      "Epoch [4/30], Batch [11100/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [11110/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [11120/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [11130/20508], Loss: 0.6987\n",
      "Epoch [4/30], Batch [11140/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [11150/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [11160/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [11170/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [11180/20508], Loss: 0.6824\n",
      "Epoch [4/30], Batch [11190/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [11200/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [11210/20508], Loss: 0.6840\n",
      "Epoch [4/30], Batch [11220/20508], Loss: 0.6828\n",
      "Epoch [4/30], Batch [11230/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [11240/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [11250/20508], Loss: 0.7021\n",
      "Epoch [4/30], Batch [11260/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [11270/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [11280/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [11290/20508], Loss: 0.6789\n",
      "Epoch [4/30], Batch [11300/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [11310/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [11320/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [11330/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [11340/20508], Loss: 0.6706\n",
      "Epoch [4/30], Batch [11350/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [11360/20508], Loss: 0.6869\n",
      "Epoch [4/30], Batch [11370/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [11380/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [11390/20508], Loss: 0.7057\n",
      "Epoch [4/30], Batch [11400/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [11410/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [11420/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [11430/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [11440/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [11450/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [11460/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [11470/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [11480/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [11490/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [11500/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [11510/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [11520/20508], Loss: 0.7105\n",
      "Epoch [4/30], Batch [11530/20508], Loss: 0.6790\n",
      "Epoch [4/30], Batch [11540/20508], Loss: 0.6728\n",
      "Epoch [4/30], Batch [11550/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [11560/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [11570/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [11580/20508], Loss: 0.6942\n",
      "Epoch [4/30], Batch [11590/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [11600/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [11610/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [11620/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [11630/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [11640/20508], Loss: 0.6818\n",
      "Epoch [4/30], Batch [11650/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [11660/20508], Loss: 0.6656\n",
      "Epoch [4/30], Batch [11670/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [11680/20508], Loss: 0.6754\n",
      "Epoch [4/30], Batch [11690/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [11700/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [11710/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [11720/20508], Loss: 0.6956\n",
      "Epoch [4/30], Batch [11730/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [11740/20508], Loss: 0.6694\n",
      "Epoch [4/30], Batch [11750/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [11760/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [11770/20508], Loss: 0.6719\n",
      "Epoch [4/30], Batch [11780/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [11790/20508], Loss: 0.6955\n",
      "Epoch [4/30], Batch [11800/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [11810/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [11820/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [11830/20508], Loss: 0.6753\n",
      "Epoch [4/30], Batch [11840/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [11850/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [11860/20508], Loss: 0.6788\n",
      "Epoch [4/30], Batch [11870/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [11880/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [11890/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [11900/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [11910/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [11920/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [11930/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [11940/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [11950/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [11960/20508], Loss: 0.6975\n",
      "Epoch [4/30], Batch [11970/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [11980/20508], Loss: 0.6656\n",
      "Epoch [4/30], Batch [11990/20508], Loss: 0.6943\n",
      "Epoch [4/30], Batch [12000/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [12010/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [12020/20508], Loss: 0.6745\n",
      "Epoch [4/30], Batch [12030/20508], Loss: 0.7055\n",
      "Epoch [4/30], Batch [12040/20508], Loss: 0.6921\n",
      "Epoch [4/30], Batch [12050/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [12060/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [12070/20508], Loss: 0.7096\n",
      "Epoch [4/30], Batch [12080/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [12090/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [12100/20508], Loss: 0.6686\n",
      "Epoch [4/30], Batch [12110/20508], Loss: 0.7068\n",
      "Epoch [4/30], Batch [12120/20508], Loss: 0.6737\n",
      "Epoch [4/30], Batch [12130/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [12140/20508], Loss: 0.7001\n",
      "Epoch [4/30], Batch [12150/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [12160/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [12170/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [12180/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [12190/20508], Loss: 0.6781\n",
      "Epoch [4/30], Batch [12200/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [12210/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [12220/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [12230/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [12240/20508], Loss: 0.6788\n",
      "Epoch [4/30], Batch [12250/20508], Loss: 0.7014\n",
      "Epoch [4/30], Batch [12260/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [12270/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [12280/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [12290/20508], Loss: 0.7046\n",
      "Epoch [4/30], Batch [12300/20508], Loss: 0.7047\n",
      "Epoch [4/30], Batch [12310/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [12320/20508], Loss: 0.7050\n",
      "Epoch [4/30], Batch [12330/20508], Loss: 0.7051\n",
      "Epoch [4/30], Batch [12340/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [12350/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [12360/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [12370/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [12380/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [12390/20508], Loss: 0.6823\n",
      "Epoch [4/30], Batch [12400/20508], Loss: 0.6982\n",
      "Epoch [4/30], Batch [12410/20508], Loss: 0.7067\n",
      "Epoch [4/30], Batch [12420/20508], Loss: 0.7045\n",
      "Epoch [4/30], Batch [12430/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [12440/20508], Loss: 0.6864\n",
      "Epoch [4/30], Batch [12450/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [12460/20508], Loss: 0.6715\n",
      "Epoch [4/30], Batch [12470/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [12480/20508], Loss: 0.6671\n",
      "Epoch [4/30], Batch [12490/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [12500/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [12510/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [12520/20508], Loss: 0.6948\n",
      "Epoch [4/30], Batch [12530/20508], Loss: 0.6795\n",
      "Epoch [4/30], Batch [12540/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [12550/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [12560/20508], Loss: 0.7166\n",
      "Epoch [4/30], Batch [12570/20508], Loss: 0.6733\n",
      "Epoch [4/30], Batch [12580/20508], Loss: 0.6857\n",
      "Epoch [4/30], Batch [12590/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [12600/20508], Loss: 0.6698\n",
      "Epoch [4/30], Batch [12610/20508], Loss: 0.6972\n",
      "Epoch [4/30], Batch [12620/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [12630/20508], Loss: 0.6802\n",
      "Epoch [4/30], Batch [12640/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [12650/20508], Loss: 0.6765\n",
      "Epoch [4/30], Batch [12660/20508], Loss: 0.7035\n",
      "Epoch [4/30], Batch [12670/20508], Loss: 0.6772\n",
      "Epoch [4/30], Batch [12680/20508], Loss: 0.6966\n",
      "Epoch [4/30], Batch [12690/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [12700/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [12710/20508], Loss: 0.6800\n",
      "Epoch [4/30], Batch [12720/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [12730/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [12740/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [12750/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [12760/20508], Loss: 0.6911\n",
      "Epoch [4/30], Batch [12770/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [12780/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [12790/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [12800/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [12810/20508], Loss: 0.6790\n",
      "Epoch [4/30], Batch [12820/20508], Loss: 0.6713\n",
      "Epoch [4/30], Batch [12830/20508], Loss: 0.6934\n",
      "Epoch [4/30], Batch [12840/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [12850/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [12860/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [12870/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [12880/20508], Loss: 0.7128\n",
      "Epoch [4/30], Batch [12890/20508], Loss: 0.6696\n",
      "Epoch [4/30], Batch [12900/20508], Loss: 0.7070\n",
      "Epoch [4/30], Batch [12910/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [12920/20508], Loss: 0.6886\n",
      "Epoch [4/30], Batch [12930/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [12940/20508], Loss: 0.7007\n",
      "Epoch [4/30], Batch [12950/20508], Loss: 0.6753\n",
      "Epoch [4/30], Batch [12960/20508], Loss: 0.6801\n",
      "Epoch [4/30], Batch [12970/20508], Loss: 0.6986\n",
      "Epoch [4/30], Batch [12980/20508], Loss: 0.6818\n",
      "Epoch [4/30], Batch [12990/20508], Loss: 0.6986\n",
      "Epoch [4/30], Batch [13000/20508], Loss: 0.6769\n",
      "Epoch [4/30], Batch [13010/20508], Loss: 0.6966\n",
      "Epoch [4/30], Batch [13020/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [13030/20508], Loss: 0.6716\n",
      "Epoch [4/30], Batch [13040/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [13050/20508], Loss: 0.6726\n",
      "Epoch [4/30], Batch [13060/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [13070/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [13080/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [13090/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [13100/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [13110/20508], Loss: 0.6693\n",
      "Epoch [4/30], Batch [13120/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [13130/20508], Loss: 0.7083\n",
      "Epoch [4/30], Batch [13140/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [13150/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [13160/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [13170/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [13180/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [13190/20508], Loss: 0.6767\n",
      "Epoch [4/30], Batch [13200/20508], Loss: 0.7010\n",
      "Epoch [4/30], Batch [13210/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [13220/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [13230/20508], Loss: 0.6928\n",
      "Epoch [4/30], Batch [13240/20508], Loss: 0.6711\n",
      "Epoch [4/30], Batch [13250/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [13260/20508], Loss: 0.7041\n",
      "Epoch [4/30], Batch [13270/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [13280/20508], Loss: 0.6960\n",
      "Epoch [4/30], Batch [13290/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [13300/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [13310/20508], Loss: 0.7030\n",
      "Epoch [4/30], Batch [13320/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [13330/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [13340/20508], Loss: 0.6885\n",
      "Epoch [4/30], Batch [13350/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [13360/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [13370/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [13380/20508], Loss: 0.6817\n",
      "Epoch [4/30], Batch [13390/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [13400/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [13410/20508], Loss: 0.6775\n",
      "Epoch [4/30], Batch [13420/20508], Loss: 0.6646\n",
      "Epoch [4/30], Batch [13430/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [13440/20508], Loss: 0.6987\n",
      "Epoch [4/30], Batch [13450/20508], Loss: 0.6731\n",
      "Epoch [4/30], Batch [13460/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [13470/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [13480/20508], Loss: 0.7039\n",
      "Epoch [4/30], Batch [13490/20508], Loss: 0.6739\n",
      "Epoch [4/30], Batch [13500/20508], Loss: 0.6921\n",
      "Epoch [4/30], Batch [13510/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [13520/20508], Loss: 0.6928\n",
      "Epoch [4/30], Batch [13530/20508], Loss: 0.6628\n",
      "Epoch [4/30], Batch [13540/20508], Loss: 0.6753\n",
      "Epoch [4/30], Batch [13550/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [13560/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [13570/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [13580/20508], Loss: 0.7053\n",
      "Epoch [4/30], Batch [13590/20508], Loss: 0.6818\n",
      "Epoch [4/30], Batch [13600/20508], Loss: 0.6737\n",
      "Epoch [4/30], Batch [13610/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [13620/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [13630/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [13640/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [13650/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [13660/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [13670/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [13680/20508], Loss: 0.6636\n",
      "Epoch [4/30], Batch [13690/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [13700/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [13710/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [13720/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [13730/20508], Loss: 0.6893\n",
      "Epoch [4/30], Batch [13740/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [13750/20508], Loss: 0.6837\n",
      "Epoch [4/30], Batch [13760/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [13770/20508], Loss: 0.6831\n",
      "Epoch [4/30], Batch [13780/20508], Loss: 0.6735\n",
      "Epoch [4/30], Batch [13790/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [13800/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [13810/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [13820/20508], Loss: 0.6874\n",
      "Epoch [4/30], Batch [13830/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [13840/20508], Loss: 0.6578\n",
      "Epoch [4/30], Batch [13850/20508], Loss: 0.6968\n",
      "Epoch [4/30], Batch [13860/20508], Loss: 0.6955\n",
      "Epoch [4/30], Batch [13870/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [13880/20508], Loss: 0.7029\n",
      "Epoch [4/30], Batch [13890/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [13900/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [13910/20508], Loss: 0.6900\n",
      "Epoch [4/30], Batch [13920/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [13930/20508], Loss: 0.7079\n",
      "Epoch [4/30], Batch [13940/20508], Loss: 0.6951\n",
      "Epoch [4/30], Batch [13950/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [13960/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [13970/20508], Loss: 0.6840\n",
      "Epoch [4/30], Batch [13980/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [13990/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [14000/20508], Loss: 0.6841\n",
      "Epoch [4/30], Batch [14010/20508], Loss: 0.7015\n",
      "Epoch [4/30], Batch [14020/20508], Loss: 0.6938\n",
      "Epoch [4/30], Batch [14030/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [14040/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [14050/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [14060/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [14070/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [14080/20508], Loss: 0.6778\n",
      "Epoch [4/30], Batch [14090/20508], Loss: 0.7027\n",
      "Epoch [4/30], Batch [14100/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [14110/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [14120/20508], Loss: 0.6706\n",
      "Epoch [4/30], Batch [14130/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [14140/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [14150/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [14160/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [14170/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [14180/20508], Loss: 0.6850\n",
      "Epoch [4/30], Batch [14190/20508], Loss: 0.6906\n",
      "Epoch [4/30], Batch [14200/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [14210/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [14220/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [14230/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [14240/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [14250/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [14260/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [14270/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [14280/20508], Loss: 0.6803\n",
      "Epoch [4/30], Batch [14290/20508], Loss: 0.6778\n",
      "Epoch [4/30], Batch [14300/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [14310/20508], Loss: 0.7125\n",
      "Epoch [4/30], Batch [14320/20508], Loss: 0.6925\n",
      "Epoch [4/30], Batch [14330/20508], Loss: 0.6641\n",
      "Epoch [4/30], Batch [14340/20508], Loss: 0.6761\n",
      "Epoch [4/30], Batch [14350/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [14360/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [14370/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [14380/20508], Loss: 0.7053\n",
      "Epoch [4/30], Batch [14390/20508], Loss: 0.6893\n",
      "Epoch [4/30], Batch [14400/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [14410/20508], Loss: 0.6641\n",
      "Epoch [4/30], Batch [14420/20508], Loss: 0.6783\n",
      "Epoch [4/30], Batch [14430/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [14440/20508], Loss: 0.6635\n",
      "Epoch [4/30], Batch [14450/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [14460/20508], Loss: 0.6994\n",
      "Epoch [4/30], Batch [14470/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [14480/20508], Loss: 0.6757\n",
      "Epoch [4/30], Batch [14490/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [14500/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [14510/20508], Loss: 0.6733\n",
      "Epoch [4/30], Batch [14520/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [14530/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [14540/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [14550/20508], Loss: 0.6698\n",
      "Epoch [4/30], Batch [14560/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [14570/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [14580/20508], Loss: 0.6689\n",
      "Epoch [4/30], Batch [14590/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [14600/20508], Loss: 0.6738\n",
      "Epoch [4/30], Batch [14610/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [14620/20508], Loss: 0.6763\n",
      "Epoch [4/30], Batch [14630/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [14640/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [14650/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [14660/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [14670/20508], Loss: 0.6754\n",
      "Epoch [4/30], Batch [14680/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [14690/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [14700/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [14710/20508], Loss: 0.6663\n",
      "Epoch [4/30], Batch [14720/20508], Loss: 0.6704\n",
      "Epoch [4/30], Batch [14730/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [14740/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [14750/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [14760/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [14770/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [14780/20508], Loss: 0.6755\n",
      "Epoch [4/30], Batch [14790/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [14800/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [14810/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [14820/20508], Loss: 0.6715\n",
      "Epoch [4/30], Batch [14830/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [14840/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [14850/20508], Loss: 0.6989\n",
      "Epoch [4/30], Batch [14860/20508], Loss: 0.6862\n",
      "Epoch [4/30], Batch [14870/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [14880/20508], Loss: 0.6987\n",
      "Epoch [4/30], Batch [14890/20508], Loss: 0.6711\n",
      "Epoch [4/30], Batch [14900/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [14910/20508], Loss: 0.6655\n",
      "Epoch [4/30], Batch [14920/20508], Loss: 0.7102\n",
      "Epoch [4/30], Batch [14930/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [14940/20508], Loss: 0.6843\n",
      "Epoch [4/30], Batch [14950/20508], Loss: 0.7021\n",
      "Epoch [4/30], Batch [14960/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [14970/20508], Loss: 0.6767\n",
      "Epoch [4/30], Batch [14980/20508], Loss: 0.7061\n",
      "Epoch [4/30], Batch [14990/20508], Loss: 0.6822\n",
      "Epoch [4/30], Batch [15000/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [15010/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [15020/20508], Loss: 0.6968\n",
      "Epoch [4/30], Batch [15030/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [15040/20508], Loss: 0.6620\n",
      "Epoch [4/30], Batch [15050/20508], Loss: 0.6652\n",
      "Epoch [4/30], Batch [15060/20508], Loss: 0.6717\n",
      "Epoch [4/30], Batch [15070/20508], Loss: 0.6774\n",
      "Epoch [4/30], Batch [15080/20508], Loss: 0.6722\n",
      "Epoch [4/30], Batch [15090/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [15100/20508], Loss: 0.6793\n",
      "Epoch [4/30], Batch [15110/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [15120/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [15130/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [15140/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [15150/20508], Loss: 0.6752\n",
      "Epoch [4/30], Batch [15160/20508], Loss: 0.6777\n",
      "Epoch [4/30], Batch [15170/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [15180/20508], Loss: 0.6828\n",
      "Epoch [4/30], Batch [15190/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [15200/20508], Loss: 0.6797\n",
      "Epoch [4/30], Batch [15210/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [15220/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [15230/20508], Loss: 0.6924\n",
      "Epoch [4/30], Batch [15240/20508], Loss: 0.6756\n",
      "Epoch [4/30], Batch [15250/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [15260/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [15270/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [15280/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [15290/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [15300/20508], Loss: 0.6901\n",
      "Epoch [4/30], Batch [15310/20508], Loss: 0.7057\n",
      "Epoch [4/30], Batch [15320/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [15330/20508], Loss: 0.6903\n",
      "Epoch [4/30], Batch [15340/20508], Loss: 0.7080\n",
      "Epoch [4/30], Batch [15350/20508], Loss: 0.6727\n",
      "Epoch [4/30], Batch [15360/20508], Loss: 0.6785\n",
      "Epoch [4/30], Batch [15370/20508], Loss: 0.6719\n",
      "Epoch [4/30], Batch [15380/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [15390/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [15400/20508], Loss: 0.6701\n",
      "Epoch [4/30], Batch [15410/20508], Loss: 0.6729\n",
      "Epoch [4/30], Batch [15420/20508], Loss: 0.7077\n",
      "Epoch [4/30], Batch [15430/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [15440/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [15450/20508], Loss: 0.7013\n",
      "Epoch [4/30], Batch [15460/20508], Loss: 0.6857\n",
      "Epoch [4/30], Batch [15470/20508], Loss: 0.6751\n",
      "Epoch [4/30], Batch [15480/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [15490/20508], Loss: 0.6817\n",
      "Epoch [4/30], Batch [15500/20508], Loss: 0.6747\n",
      "Epoch [4/30], Batch [15510/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [15520/20508], Loss: 0.7005\n",
      "Epoch [4/30], Batch [15530/20508], Loss: 0.6575\n",
      "Epoch [4/30], Batch [15540/20508], Loss: 0.6893\n",
      "Epoch [4/30], Batch [15550/20508], Loss: 0.6683\n",
      "Epoch [4/30], Batch [15560/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [15570/20508], Loss: 0.6827\n",
      "Epoch [4/30], Batch [15580/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [15590/20508], Loss: 0.6693\n",
      "Epoch [4/30], Batch [15600/20508], Loss: 0.6747\n",
      "Epoch [4/30], Batch [15610/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [15620/20508], Loss: 0.6781\n",
      "Epoch [4/30], Batch [15630/20508], Loss: 0.6700\n",
      "Epoch [4/30], Batch [15640/20508], Loss: 0.7041\n",
      "Epoch [4/30], Batch [15650/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [15660/20508], Loss: 0.7028\n",
      "Epoch [4/30], Batch [15670/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [15680/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [15690/20508], Loss: 0.6815\n",
      "Epoch [4/30], Batch [15700/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [15710/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [15720/20508], Loss: 0.6993\n",
      "Epoch [4/30], Batch [15730/20508], Loss: 0.7122\n",
      "Epoch [4/30], Batch [15740/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [15750/20508], Loss: 0.7012\n",
      "Epoch [4/30], Batch [15760/20508], Loss: 0.7069\n",
      "Epoch [4/30], Batch [15770/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [15780/20508], Loss: 0.6739\n",
      "Epoch [4/30], Batch [15790/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [15800/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [15810/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [15820/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [15830/20508], Loss: 0.7017\n",
      "Epoch [4/30], Batch [15840/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [15850/20508], Loss: 0.6805\n",
      "Epoch [4/30], Batch [15860/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [15870/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [15880/20508], Loss: 0.7080\n",
      "Epoch [4/30], Batch [15890/20508], Loss: 0.6672\n",
      "Epoch [4/30], Batch [15900/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [15910/20508], Loss: 0.6954\n",
      "Epoch [4/30], Batch [15920/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [15930/20508], Loss: 0.7250\n",
      "Epoch [4/30], Batch [15940/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [15950/20508], Loss: 0.7143\n",
      "Epoch [4/30], Batch [15960/20508], Loss: 0.7012\n",
      "Epoch [4/30], Batch [15970/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [15980/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [15990/20508], Loss: 0.7025\n",
      "Epoch [4/30], Batch [16000/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [16010/20508], Loss: 0.6633\n",
      "Epoch [4/30], Batch [16020/20508], Loss: 0.6911\n",
      "Epoch [4/30], Batch [16030/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [16040/20508], Loss: 0.6887\n",
      "Epoch [4/30], Batch [16050/20508], Loss: 0.7037\n",
      "Epoch [4/30], Batch [16060/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [16070/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [16080/20508], Loss: 0.6886\n",
      "Epoch [4/30], Batch [16090/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [16100/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [16110/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [16120/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [16130/20508], Loss: 0.6941\n",
      "Epoch [4/30], Batch [16140/20508], Loss: 0.7003\n",
      "Epoch [4/30], Batch [16150/20508], Loss: 0.6831\n",
      "Epoch [4/30], Batch [16160/20508], Loss: 0.6966\n",
      "Epoch [4/30], Batch [16170/20508], Loss: 0.6810\n",
      "Epoch [4/30], Batch [16180/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [16190/20508], Loss: 0.7104\n",
      "Epoch [4/30], Batch [16200/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [16210/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [16220/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [16230/20508], Loss: 0.7032\n",
      "Epoch [4/30], Batch [16240/20508], Loss: 0.7086\n",
      "Epoch [4/30], Batch [16250/20508], Loss: 0.7084\n",
      "Epoch [4/30], Batch [16260/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [16270/20508], Loss: 0.6948\n",
      "Epoch [4/30], Batch [16280/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [16290/20508], Loss: 0.6873\n",
      "Epoch [4/30], Batch [16300/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [16310/20508], Loss: 0.7006\n",
      "Epoch [4/30], Batch [16320/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [16330/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [16340/20508], Loss: 0.6836\n",
      "Epoch [4/30], Batch [16350/20508], Loss: 0.6780\n",
      "Epoch [4/30], Batch [16360/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [16370/20508], Loss: 0.6752\n",
      "Epoch [4/30], Batch [16380/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [16390/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [16400/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [16410/20508], Loss: 0.6768\n",
      "Epoch [4/30], Batch [16420/20508], Loss: 0.6734\n",
      "Epoch [4/30], Batch [16430/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [16440/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [16450/20508], Loss: 0.6788\n",
      "Epoch [4/30], Batch [16460/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [16470/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [16480/20508], Loss: 0.6923\n",
      "Epoch [4/30], Batch [16490/20508], Loss: 0.7008\n",
      "Epoch [4/30], Batch [16500/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [16510/20508], Loss: 0.6981\n",
      "Epoch [4/30], Batch [16520/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [16530/20508], Loss: 0.6897\n",
      "Epoch [4/30], Batch [16540/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [16550/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [16560/20508], Loss: 0.6886\n",
      "Epoch [4/30], Batch [16570/20508], Loss: 0.6675\n",
      "Epoch [4/30], Batch [16580/20508], Loss: 0.6874\n",
      "Epoch [4/30], Batch [16590/20508], Loss: 0.6932\n",
      "Epoch [4/30], Batch [16600/20508], Loss: 0.7126\n",
      "Epoch [4/30], Batch [16610/20508], Loss: 0.6515\n",
      "Epoch [4/30], Batch [16620/20508], Loss: 0.6954\n",
      "Epoch [4/30], Batch [16630/20508], Loss: 0.7153\n",
      "Epoch [4/30], Batch [16640/20508], Loss: 0.7042\n",
      "Epoch [4/30], Batch [16650/20508], Loss: 0.6950\n",
      "Epoch [4/30], Batch [16660/20508], Loss: 0.6881\n",
      "Epoch [4/30], Batch [16670/20508], Loss: 0.6996\n",
      "Epoch [4/30], Batch [16680/20508], Loss: 0.7141\n",
      "Epoch [4/30], Batch [16690/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [16700/20508], Loss: 0.6714\n",
      "Epoch [4/30], Batch [16710/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [16720/20508], Loss: 0.6670\n",
      "Epoch [4/30], Batch [16730/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [16740/20508], Loss: 0.7029\n",
      "Epoch [4/30], Batch [16750/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [16760/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [16770/20508], Loss: 0.7168\n",
      "Epoch [4/30], Batch [16780/20508], Loss: 0.6714\n",
      "Epoch [4/30], Batch [16790/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [16800/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [16810/20508], Loss: 0.6864\n",
      "Epoch [4/30], Batch [16820/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [16830/20508], Loss: 0.6828\n",
      "Epoch [4/30], Batch [16840/20508], Loss: 0.7017\n",
      "Epoch [4/30], Batch [16850/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [16860/20508], Loss: 0.7112\n",
      "Epoch [4/30], Batch [16870/20508], Loss: 0.7124\n",
      "Epoch [4/30], Batch [16880/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [16890/20508], Loss: 0.6850\n",
      "Epoch [4/30], Batch [16900/20508], Loss: 0.6808\n",
      "Epoch [4/30], Batch [16910/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [16920/20508], Loss: 0.6728\n",
      "Epoch [4/30], Batch [16930/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [16940/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [16950/20508], Loss: 0.6720\n",
      "Epoch [4/30], Batch [16960/20508], Loss: 0.7077\n",
      "Epoch [4/30], Batch [16970/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [16980/20508], Loss: 0.6980\n",
      "Epoch [4/30], Batch [16990/20508], Loss: 0.6957\n",
      "Epoch [4/30], Batch [17000/20508], Loss: 0.7018\n",
      "Epoch [4/30], Batch [17010/20508], Loss: 0.6861\n",
      "Epoch [4/30], Batch [17020/20508], Loss: 0.6758\n",
      "Epoch [4/30], Batch [17030/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [17040/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [17050/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [17060/20508], Loss: 0.6895\n",
      "Epoch [4/30], Batch [17070/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [17080/20508], Loss: 0.7034\n",
      "Epoch [4/30], Batch [17090/20508], Loss: 0.6718\n",
      "Epoch [4/30], Batch [17100/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [17110/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [17120/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [17130/20508], Loss: 0.6853\n",
      "Epoch [4/30], Batch [17140/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [17150/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [17160/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [17170/20508], Loss: 0.6706\n",
      "Epoch [4/30], Batch [17180/20508], Loss: 0.7107\n",
      "Epoch [4/30], Batch [17190/20508], Loss: 0.6826\n",
      "Epoch [4/30], Batch [17200/20508], Loss: 0.6834\n",
      "Epoch [4/30], Batch [17210/20508], Loss: 0.7038\n",
      "Epoch [4/30], Batch [17220/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [17230/20508], Loss: 0.7008\n",
      "Epoch [4/30], Batch [17240/20508], Loss: 0.6975\n",
      "Epoch [4/30], Batch [17250/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [17260/20508], Loss: 0.6795\n",
      "Epoch [4/30], Batch [17270/20508], Loss: 0.6792\n",
      "Epoch [4/30], Batch [17280/20508], Loss: 0.6739\n",
      "Epoch [4/30], Batch [17290/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [17300/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [17310/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [17320/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [17330/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [17340/20508], Loss: 0.7002\n",
      "Epoch [4/30], Batch [17350/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [17360/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [17370/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [17380/20508], Loss: 0.6930\n",
      "Epoch [4/30], Batch [17390/20508], Loss: 0.6778\n",
      "Epoch [4/30], Batch [17400/20508], Loss: 0.6817\n",
      "Epoch [4/30], Batch [17410/20508], Loss: 0.7056\n",
      "Epoch [4/30], Batch [17420/20508], Loss: 0.6946\n",
      "Epoch [4/30], Batch [17430/20508], Loss: 0.6884\n",
      "Epoch [4/30], Batch [17440/20508], Loss: 0.6803\n",
      "Epoch [4/30], Batch [17450/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [17460/20508], Loss: 0.6682\n",
      "Epoch [4/30], Batch [17470/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [17480/20508], Loss: 0.6722\n",
      "Epoch [4/30], Batch [17490/20508], Loss: 0.6721\n",
      "Epoch [4/30], Batch [17500/20508], Loss: 0.7023\n",
      "Epoch [4/30], Batch [17510/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [17520/20508], Loss: 0.6838\n",
      "Epoch [4/30], Batch [17530/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [17540/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [17550/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [17560/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [17570/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [17580/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [17590/20508], Loss: 0.6972\n",
      "Epoch [4/30], Batch [17600/20508], Loss: 0.6986\n",
      "Epoch [4/30], Batch [17610/20508], Loss: 0.6699\n",
      "Epoch [4/30], Batch [17620/20508], Loss: 0.7026\n",
      "Epoch [4/30], Batch [17630/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [17640/20508], Loss: 0.6668\n",
      "Epoch [4/30], Batch [17650/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [17660/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [17670/20508], Loss: 0.7064\n",
      "Epoch [4/30], Batch [17680/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [17690/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [17700/20508], Loss: 0.7018\n",
      "Epoch [4/30], Batch [17710/20508], Loss: 0.6964\n",
      "Epoch [4/30], Batch [17720/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [17730/20508], Loss: 0.7020\n",
      "Epoch [4/30], Batch [17740/20508], Loss: 0.6770\n",
      "Epoch [4/30], Batch [17750/20508], Loss: 0.6820\n",
      "Epoch [4/30], Batch [17760/20508], Loss: 0.6944\n",
      "Epoch [4/30], Batch [17770/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [17780/20508], Loss: 0.6988\n",
      "Epoch [4/30], Batch [17790/20508], Loss: 0.6891\n",
      "Epoch [4/30], Batch [17800/20508], Loss: 0.6992\n",
      "Epoch [4/30], Batch [17810/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [17820/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [17830/20508], Loss: 0.7011\n",
      "Epoch [4/30], Batch [17840/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [17850/20508], Loss: 0.7158\n",
      "Epoch [4/30], Batch [17860/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [17870/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [17880/20508], Loss: 0.6982\n",
      "Epoch [4/30], Batch [17890/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [17900/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [17910/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [17920/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [17930/20508], Loss: 0.6991\n",
      "Epoch [4/30], Batch [17940/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [17950/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [17960/20508], Loss: 0.6980\n",
      "Epoch [4/30], Batch [17970/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [17980/20508], Loss: 0.6915\n",
      "Epoch [4/30], Batch [17990/20508], Loss: 0.6998\n",
      "Epoch [4/30], Batch [18000/20508], Loss: 0.6736\n",
      "Epoch [4/30], Batch [18010/20508], Loss: 0.6889\n",
      "Epoch [4/30], Batch [18020/20508], Loss: 0.6844\n",
      "Epoch [4/30], Batch [18030/20508], Loss: 0.7080\n",
      "Epoch [4/30], Batch [18040/20508], Loss: 0.7031\n",
      "Epoch [4/30], Batch [18050/20508], Loss: 0.7006\n",
      "Epoch [4/30], Batch [18060/20508], Loss: 0.6896\n",
      "Epoch [4/30], Batch [18070/20508], Loss: 0.6786\n",
      "Epoch [4/30], Batch [18080/20508], Loss: 0.6722\n",
      "Epoch [4/30], Batch [18090/20508], Loss: 0.6922\n",
      "Epoch [4/30], Batch [18100/20508], Loss: 0.6827\n",
      "Epoch [4/30], Batch [18110/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [18120/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [18130/20508], Loss: 0.6954\n",
      "Epoch [4/30], Batch [18140/20508], Loss: 0.6868\n",
      "Epoch [4/30], Batch [18150/20508], Loss: 0.7003\n",
      "Epoch [4/30], Batch [18160/20508], Loss: 0.7058\n",
      "Epoch [4/30], Batch [18170/20508], Loss: 0.6935\n",
      "Epoch [4/30], Batch [18180/20508], Loss: 0.6914\n",
      "Epoch [4/30], Batch [18190/20508], Loss: 0.6675\n",
      "Epoch [4/30], Batch [18200/20508], Loss: 0.6965\n",
      "Epoch [4/30], Batch [18210/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [18220/20508], Loss: 0.6796\n",
      "Epoch [4/30], Batch [18230/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [18240/20508], Loss: 0.6702\n",
      "Epoch [4/30], Batch [18250/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [18260/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [18270/20508], Loss: 0.6842\n",
      "Epoch [4/30], Batch [18280/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [18290/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [18300/20508], Loss: 0.6792\n",
      "Epoch [4/30], Batch [18310/20508], Loss: 0.7179\n",
      "Epoch [4/30], Batch [18320/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [18330/20508], Loss: 0.6867\n",
      "Epoch [4/30], Batch [18340/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [18350/20508], Loss: 0.6890\n",
      "Epoch [4/30], Batch [18360/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [18370/20508], Loss: 0.6987\n",
      "Epoch [4/30], Batch [18380/20508], Loss: 0.6970\n",
      "Epoch [4/30], Batch [18390/20508], Loss: 0.6813\n",
      "Epoch [4/30], Batch [18400/20508], Loss: 0.6918\n",
      "Epoch [4/30], Batch [18410/20508], Loss: 0.6581\n",
      "Epoch [4/30], Batch [18420/20508], Loss: 0.7134\n",
      "Epoch [4/30], Batch [18430/20508], Loss: 0.6791\n",
      "Epoch [4/30], Batch [18440/20508], Loss: 0.6877\n",
      "Epoch [4/30], Batch [18450/20508], Loss: 0.7027\n",
      "Epoch [4/30], Batch [18460/20508], Loss: 0.6857\n",
      "Epoch [4/30], Batch [18470/20508], Loss: 0.6804\n",
      "Epoch [4/30], Batch [18480/20508], Loss: 0.6966\n",
      "Epoch [4/30], Batch [18490/20508], Loss: 0.6850\n",
      "Epoch [4/30], Batch [18500/20508], Loss: 0.6847\n",
      "Epoch [4/30], Batch [18510/20508], Loss: 0.6917\n",
      "Epoch [4/30], Batch [18520/20508], Loss: 0.6977\n",
      "Epoch [4/30], Batch [18530/20508], Loss: 0.6781\n",
      "Epoch [4/30], Batch [18540/20508], Loss: 0.6999\n",
      "Epoch [4/30], Batch [18550/20508], Loss: 0.6866\n",
      "Epoch [4/30], Batch [18560/20508], Loss: 0.6816\n",
      "Epoch [4/30], Batch [18570/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [18580/20508], Loss: 0.6898\n",
      "Epoch [4/30], Batch [18590/20508], Loss: 0.6973\n",
      "Epoch [4/30], Batch [18600/20508], Loss: 0.6855\n",
      "Epoch [4/30], Batch [18610/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [18620/20508], Loss: 0.6880\n",
      "Epoch [4/30], Batch [18630/20508], Loss: 0.6845\n",
      "Epoch [4/30], Batch [18640/20508], Loss: 0.6830\n",
      "Epoch [4/30], Batch [18650/20508], Loss: 0.6958\n",
      "Epoch [4/30], Batch [18660/20508], Loss: 0.6828\n",
      "Epoch [4/30], Batch [18670/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [18680/20508], Loss: 0.6907\n",
      "Epoch [4/30], Batch [18690/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [18700/20508], Loss: 0.6824\n",
      "Epoch [4/30], Batch [18710/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [18720/20508], Loss: 0.6606\n",
      "Epoch [4/30], Batch [18730/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [18740/20508], Loss: 0.6871\n",
      "Epoch [4/30], Batch [18750/20508], Loss: 0.6983\n",
      "Epoch [4/30], Batch [18760/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [18770/20508], Loss: 0.6987\n",
      "Epoch [4/30], Batch [18780/20508], Loss: 0.6863\n",
      "Epoch [4/30], Batch [18790/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [18800/20508], Loss: 0.6766\n",
      "Epoch [4/30], Batch [18810/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [18820/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [18830/20508], Loss: 0.6911\n",
      "Epoch [4/30], Batch [18840/20508], Loss: 0.7150\n",
      "Epoch [4/30], Batch [18850/20508], Loss: 0.6742\n",
      "Epoch [4/30], Batch [18860/20508], Loss: 0.6702\n",
      "Epoch [4/30], Batch [18870/20508], Loss: 0.6900\n",
      "Epoch [4/30], Batch [18880/20508], Loss: 0.6854\n",
      "Epoch [4/30], Batch [18890/20508], Loss: 0.6570\n",
      "Epoch [4/30], Batch [18900/20508], Loss: 0.6921\n",
      "Epoch [4/30], Batch [18910/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [18920/20508], Loss: 0.6727\n",
      "Epoch [4/30], Batch [18930/20508], Loss: 0.6974\n",
      "Epoch [4/30], Batch [18940/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [18950/20508], Loss: 0.6952\n",
      "Epoch [4/30], Batch [18960/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [18970/20508], Loss: 0.7026\n",
      "Epoch [4/30], Batch [18980/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [18990/20508], Loss: 0.6762\n",
      "Epoch [4/30], Batch [19000/20508], Loss: 0.6899\n",
      "Epoch [4/30], Batch [19010/20508], Loss: 0.6936\n",
      "Epoch [4/30], Batch [19020/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [19030/20508], Loss: 0.7048\n",
      "Epoch [4/30], Batch [19040/20508], Loss: 0.7089\n",
      "Epoch [4/30], Batch [19050/20508], Loss: 0.6883\n",
      "Epoch [4/30], Batch [19060/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [19070/20508], Loss: 0.6916\n",
      "Epoch [4/30], Batch [19080/20508], Loss: 0.6976\n",
      "Epoch [4/30], Batch [19090/20508], Loss: 0.7003\n",
      "Epoch [4/30], Batch [19100/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [19110/20508], Loss: 0.6905\n",
      "Epoch [4/30], Batch [19120/20508], Loss: 0.7091\n",
      "Epoch [4/30], Batch [19130/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [19140/20508], Loss: 0.6787\n",
      "Epoch [4/30], Batch [19150/20508], Loss: 0.6882\n",
      "Epoch [4/30], Batch [19160/20508], Loss: 0.6760\n",
      "Epoch [4/30], Batch [19170/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [19180/20508], Loss: 0.6975\n",
      "Epoch [4/30], Batch [19190/20508], Loss: 0.7049\n",
      "Epoch [4/30], Batch [19200/20508], Loss: 0.7022\n",
      "Epoch [4/30], Batch [19210/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [19220/20508], Loss: 0.6735\n",
      "Epoch [4/30], Batch [19230/20508], Loss: 0.7138\n",
      "Epoch [4/30], Batch [19240/20508], Loss: 0.6984\n",
      "Epoch [4/30], Batch [19250/20508], Loss: 0.6775\n",
      "Epoch [4/30], Batch [19260/20508], Loss: 0.6908\n",
      "Epoch [4/30], Batch [19270/20508], Loss: 0.6940\n",
      "Epoch [4/30], Batch [19280/20508], Loss: 0.6860\n",
      "Epoch [4/30], Batch [19290/20508], Loss: 0.6835\n",
      "Epoch [4/30], Batch [19300/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [19310/20508], Loss: 0.6745\n",
      "Epoch [4/30], Batch [19320/20508], Loss: 0.6979\n",
      "Epoch [4/30], Batch [19330/20508], Loss: 0.6865\n",
      "Epoch [4/30], Batch [19340/20508], Loss: 0.7061\n",
      "Epoch [4/30], Batch [19350/20508], Loss: 0.6919\n",
      "Epoch [4/30], Batch [19360/20508], Loss: 0.6664\n",
      "Epoch [4/30], Batch [19370/20508], Loss: 0.7149\n",
      "Epoch [4/30], Batch [19380/20508], Loss: 0.6701\n",
      "Epoch [4/30], Batch [19390/20508], Loss: 0.7041\n",
      "Epoch [4/30], Batch [19400/20508], Loss: 0.7164\n",
      "Epoch [4/30], Batch [19410/20508], Loss: 0.7085\n",
      "Epoch [4/30], Batch [19420/20508], Loss: 0.6962\n",
      "Epoch [4/30], Batch [19430/20508], Loss: 0.7000\n",
      "Epoch [4/30], Batch [19440/20508], Loss: 0.6722\n",
      "Epoch [4/30], Batch [19450/20508], Loss: 0.6741\n",
      "Epoch [4/30], Batch [19460/20508], Loss: 0.6866\n",
      "Epoch [4/30], Batch [19470/20508], Loss: 0.6794\n",
      "Epoch [4/30], Batch [19480/20508], Loss: 0.6933\n",
      "Epoch [4/30], Batch [19490/20508], Loss: 0.7014\n",
      "Epoch [4/30], Batch [19500/20508], Loss: 0.6812\n",
      "Epoch [4/30], Batch [19510/20508], Loss: 0.6840\n",
      "Epoch [4/30], Batch [19520/20508], Loss: 0.6778\n",
      "Epoch [4/30], Batch [19530/20508], Loss: 0.6982\n",
      "Epoch [4/30], Batch [19540/20508], Loss: 0.6926\n",
      "Epoch [4/30], Batch [19550/20508], Loss: 0.6829\n",
      "Epoch [4/30], Batch [19560/20508], Loss: 0.7040\n",
      "Epoch [4/30], Batch [19570/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [19580/20508], Loss: 0.6768\n",
      "Epoch [4/30], Batch [19590/20508], Loss: 0.6967\n",
      "Epoch [4/30], Batch [19600/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [19610/20508], Loss: 0.7032\n",
      "Epoch [4/30], Batch [19620/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [19630/20508], Loss: 0.6821\n",
      "Epoch [4/30], Batch [19640/20508], Loss: 0.7005\n",
      "Epoch [4/30], Batch [19650/20508], Loss: 0.6912\n",
      "Epoch [4/30], Batch [19660/20508], Loss: 0.7336\n",
      "Epoch [4/30], Batch [19670/20508], Loss: 0.6798\n",
      "Epoch [4/30], Batch [19680/20508], Loss: 0.6900\n",
      "Epoch [4/30], Batch [19690/20508], Loss: 0.6950\n",
      "Epoch [4/30], Batch [19700/20508], Loss: 0.6945\n",
      "Epoch [4/30], Batch [19710/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [19720/20508], Loss: 0.6851\n",
      "Epoch [4/30], Batch [19730/20508], Loss: 0.6957\n",
      "Epoch [4/30], Batch [19740/20508], Loss: 0.7051\n",
      "Epoch [4/30], Batch [19750/20508], Loss: 0.6858\n",
      "Epoch [4/30], Batch [19760/20508], Loss: 0.6876\n",
      "Epoch [4/30], Batch [19770/20508], Loss: 0.6773\n",
      "Epoch [4/30], Batch [19780/20508], Loss: 0.6875\n",
      "Epoch [4/30], Batch [19790/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [19800/20508], Loss: 0.6687\n",
      "Epoch [4/30], Batch [19810/20508], Loss: 0.6939\n",
      "Epoch [4/30], Batch [19820/20508], Loss: 0.6990\n",
      "Epoch [4/30], Batch [19830/20508], Loss: 0.7167\n",
      "Epoch [4/30], Batch [19840/20508], Loss: 0.6852\n",
      "Epoch [4/30], Batch [19850/20508], Loss: 0.6825\n",
      "Epoch [4/30], Batch [19860/20508], Loss: 0.7015\n",
      "Epoch [4/30], Batch [19870/20508], Loss: 0.6748\n",
      "Epoch [4/30], Batch [19880/20508], Loss: 0.7041\n",
      "Epoch [4/30], Batch [19890/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [19900/20508], Loss: 0.6931\n",
      "Epoch [4/30], Batch [19910/20508], Loss: 0.6953\n",
      "Epoch [4/30], Batch [19920/20508], Loss: 0.7089\n",
      "Epoch [4/30], Batch [19930/20508], Loss: 0.6949\n",
      "Epoch [4/30], Batch [19940/20508], Loss: 0.6902\n",
      "Epoch [4/30], Batch [19950/20508], Loss: 0.6991\n",
      "Epoch [4/30], Batch [19960/20508], Loss: 0.6788\n",
      "Epoch [4/30], Batch [19970/20508], Loss: 0.6740\n",
      "Epoch [4/30], Batch [19980/20508], Loss: 0.6872\n",
      "Epoch [4/30], Batch [19990/20508], Loss: 0.6888\n",
      "Epoch [4/30], Batch [20000/20508], Loss: 0.6913\n",
      "Epoch [4/30], Batch [20010/20508], Loss: 0.6909\n",
      "Epoch [4/30], Batch [20020/20508], Loss: 0.7082\n",
      "Epoch [4/30], Batch [20030/20508], Loss: 0.6870\n",
      "Epoch [4/30], Batch [20040/20508], Loss: 0.6837\n",
      "Epoch [4/30], Batch [20050/20508], Loss: 0.6754\n",
      "Epoch [4/30], Batch [20060/20508], Loss: 0.6932\n",
      "Epoch [4/30], Batch [20070/20508], Loss: 0.6878\n",
      "Epoch [4/30], Batch [20080/20508], Loss: 0.6963\n",
      "Epoch [4/30], Batch [20090/20508], Loss: 0.6859\n",
      "Epoch [4/30], Batch [20100/20508], Loss: 0.6833\n",
      "Epoch [4/30], Batch [20110/20508], Loss: 0.6814\n",
      "Epoch [4/30], Batch [20120/20508], Loss: 0.6770\n",
      "Epoch [4/30], Batch [20130/20508], Loss: 0.6799\n",
      "Epoch [4/30], Batch [20140/20508], Loss: 0.7018\n",
      "Epoch [4/30], Batch [20150/20508], Loss: 0.6879\n",
      "Epoch [4/30], Batch [20160/20508], Loss: 0.6786\n",
      "Epoch [4/30], Batch [20170/20508], Loss: 0.7060\n",
      "Epoch [4/30], Batch [20180/20508], Loss: 0.6806\n",
      "Epoch [4/30], Batch [20190/20508], Loss: 0.6759\n",
      "Epoch [4/30], Batch [20200/20508], Loss: 0.6861\n",
      "Epoch [4/30], Batch [20210/20508], Loss: 0.6937\n",
      "Epoch [4/30], Batch [20220/20508], Loss: 0.6819\n",
      "Epoch [4/30], Batch [20230/20508], Loss: 0.6782\n",
      "Epoch [4/30], Batch [20240/20508], Loss: 0.6849\n",
      "Epoch [4/30], Batch [20250/20508], Loss: 0.6929\n",
      "Epoch [4/30], Batch [20260/20508], Loss: 0.6892\n",
      "Epoch [4/30], Batch [20270/20508], Loss: 0.6802\n",
      "Epoch [4/30], Batch [20280/20508], Loss: 0.6856\n",
      "Epoch [4/30], Batch [20290/20508], Loss: 0.6971\n",
      "Epoch [4/30], Batch [20300/20508], Loss: 0.6784\n",
      "Epoch [4/30], Batch [20310/20508], Loss: 0.6894\n",
      "Epoch [4/30], Batch [20320/20508], Loss: 0.6746\n",
      "Epoch [4/30], Batch [20330/20508], Loss: 0.6704\n",
      "Epoch [4/30], Batch [20340/20508], Loss: 0.7047\n",
      "Epoch [4/30], Batch [20350/20508], Loss: 0.6985\n",
      "Epoch [4/30], Batch [20360/20508], Loss: 0.6696\n",
      "Epoch [4/30], Batch [20370/20508], Loss: 0.6920\n",
      "Epoch [4/30], Batch [20380/20508], Loss: 0.7016\n",
      "Epoch [4/30], Batch [20390/20508], Loss: 0.6947\n",
      "Epoch [4/30], Batch [20400/20508], Loss: 0.6832\n",
      "Epoch [4/30], Batch [20410/20508], Loss: 0.6978\n",
      "Epoch [4/30], Batch [20420/20508], Loss: 0.6816\n",
      "Epoch [4/30], Batch [20430/20508], Loss: 0.6807\n",
      "Epoch [4/30], Batch [20440/20508], Loss: 0.6846\n",
      "Epoch [4/30], Batch [20450/20508], Loss: 0.6969\n",
      "Epoch [4/30], Batch [20460/20508], Loss: 0.6770\n",
      "Epoch [4/30], Batch [20470/20508], Loss: 0.6961\n",
      "Epoch [4/30], Batch [20480/20508], Loss: 0.7066\n",
      "Epoch [4/30], Batch [20490/20508], Loss: 0.6811\n",
      "Epoch [4/30], Batch [20500/20508], Loss: 0.6856\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [4], Train Loss: 0.6894, Test Loss: 0.6896, Early Stopping Counter: 1\n",
      "\n",
      "\n",
      "\n",
      "Epoch [5/30], Batch [0/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [10/20508], Loss: 0.7091\n",
      "Epoch [5/30], Batch [20/20508], Loss: 0.6702\n",
      "Epoch [5/30], Batch [30/20508], Loss: 0.6802\n",
      "Epoch [5/30], Batch [40/20508], Loss: 0.7218\n",
      "Epoch [5/30], Batch [50/20508], Loss: 0.6859\n",
      "Epoch [5/30], Batch [60/20508], Loss: 0.7018\n",
      "Epoch [5/30], Batch [70/20508], Loss: 0.7020\n",
      "Epoch [5/30], Batch [80/20508], Loss: 0.6888\n",
      "Epoch [5/30], Batch [90/20508], Loss: 0.7020\n",
      "Epoch [5/30], Batch [100/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [110/20508], Loss: 0.6754\n",
      "Epoch [5/30], Batch [120/20508], Loss: 0.6772\n",
      "Epoch [5/30], Batch [130/20508], Loss: 0.7091\n",
      "Epoch [5/30], Batch [140/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [150/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [160/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [170/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [180/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [190/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [200/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [210/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [220/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [230/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [240/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [250/20508], Loss: 0.7060\n",
      "Epoch [5/30], Batch [260/20508], Loss: 0.6753\n",
      "Epoch [5/30], Batch [270/20508], Loss: 0.6762\n",
      "Epoch [5/30], Batch [280/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [290/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [300/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [310/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [320/20508], Loss: 0.6743\n",
      "Epoch [5/30], Batch [330/20508], Loss: 0.6688\n",
      "Epoch [5/30], Batch [340/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [350/20508], Loss: 0.6869\n",
      "Epoch [5/30], Batch [360/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [370/20508], Loss: 0.6748\n",
      "Epoch [5/30], Batch [380/20508], Loss: 0.6787\n",
      "Epoch [5/30], Batch [390/20508], Loss: 0.6824\n",
      "Epoch [5/30], Batch [400/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [410/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [420/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [430/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [440/20508], Loss: 0.7102\n",
      "Epoch [5/30], Batch [450/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [460/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [470/20508], Loss: 0.6957\n",
      "Epoch [5/30], Batch [480/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [490/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [500/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [510/20508], Loss: 0.6726\n",
      "Epoch [5/30], Batch [520/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [530/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [540/20508], Loss: 0.6749\n",
      "Epoch [5/30], Batch [550/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [560/20508], Loss: 0.6725\n",
      "Epoch [5/30], Batch [570/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [580/20508], Loss: 0.6770\n",
      "Epoch [5/30], Batch [590/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [600/20508], Loss: 0.6799\n",
      "Epoch [5/30], Batch [610/20508], Loss: 0.7148\n",
      "Epoch [5/30], Batch [620/20508], Loss: 0.6738\n",
      "Epoch [5/30], Batch [630/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [640/20508], Loss: 0.7036\n",
      "Epoch [5/30], Batch [650/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [660/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [670/20508], Loss: 0.6667\n",
      "Epoch [5/30], Batch [680/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [690/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [700/20508], Loss: 0.6743\n",
      "Epoch [5/30], Batch [710/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [720/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [730/20508], Loss: 0.6722\n",
      "Epoch [5/30], Batch [740/20508], Loss: 0.7077\n",
      "Epoch [5/30], Batch [750/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [760/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [770/20508], Loss: 0.6980\n",
      "Epoch [5/30], Batch [780/20508], Loss: 0.7068\n",
      "Epoch [5/30], Batch [790/20508], Loss: 0.6751\n",
      "Epoch [5/30], Batch [800/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [810/20508], Loss: 0.6930\n",
      "Epoch [5/30], Batch [820/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [830/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [840/20508], Loss: 0.6805\n",
      "Epoch [5/30], Batch [850/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [860/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [870/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [880/20508], Loss: 0.6825\n",
      "Epoch [5/30], Batch [890/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [900/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [910/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [920/20508], Loss: 0.6820\n",
      "Epoch [5/30], Batch [930/20508], Loss: 0.6701\n",
      "Epoch [5/30], Batch [940/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [950/20508], Loss: 0.6822\n",
      "Epoch [5/30], Batch [960/20508], Loss: 0.6789\n",
      "Epoch [5/30], Batch [970/20508], Loss: 0.6863\n",
      "Epoch [5/30], Batch [980/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [990/20508], Loss: 0.7044\n",
      "Epoch [5/30], Batch [1000/20508], Loss: 0.7045\n",
      "Epoch [5/30], Batch [1010/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [1020/20508], Loss: 0.7064\n",
      "Epoch [5/30], Batch [1030/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [1040/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [1050/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [1060/20508], Loss: 0.7149\n",
      "Epoch [5/30], Batch [1070/20508], Loss: 0.6730\n",
      "Epoch [5/30], Batch [1080/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [1090/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [1100/20508], Loss: 0.6828\n",
      "Epoch [5/30], Batch [1110/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [1120/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [1130/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [1140/20508], Loss: 0.6753\n",
      "Epoch [5/30], Batch [1150/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [1160/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [1170/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [1180/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [1190/20508], Loss: 0.6826\n",
      "Epoch [5/30], Batch [1200/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [1210/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [1220/20508], Loss: 0.6710\n",
      "Epoch [5/30], Batch [1230/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [1240/20508], Loss: 0.7021\n",
      "Epoch [5/30], Batch [1250/20508], Loss: 0.6763\n",
      "Epoch [5/30], Batch [1260/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [1270/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [1280/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [1290/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [1300/20508], Loss: 0.7008\n",
      "Epoch [5/30], Batch [1310/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [1320/20508], Loss: 0.6732\n",
      "Epoch [5/30], Batch [1330/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [1340/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [1350/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [1360/20508], Loss: 0.6618\n",
      "Epoch [5/30], Batch [1370/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [1380/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [1390/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [1400/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [1410/20508], Loss: 0.6985\n",
      "Epoch [5/30], Batch [1420/20508], Loss: 0.6971\n",
      "Epoch [5/30], Batch [1430/20508], Loss: 0.6751\n",
      "Epoch [5/30], Batch [1440/20508], Loss: 0.6971\n",
      "Epoch [5/30], Batch [1450/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [1460/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [1470/20508], Loss: 0.7040\n",
      "Epoch [5/30], Batch [1480/20508], Loss: 0.6971\n",
      "Epoch [5/30], Batch [1490/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [1500/20508], Loss: 0.6762\n",
      "Epoch [5/30], Batch [1510/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [1520/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [1530/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [1540/20508], Loss: 0.6779\n",
      "Epoch [5/30], Batch [1550/20508], Loss: 0.7030\n",
      "Epoch [5/30], Batch [1560/20508], Loss: 0.7116\n",
      "Epoch [5/30], Batch [1570/20508], Loss: 0.6736\n",
      "Epoch [5/30], Batch [1580/20508], Loss: 0.7090\n",
      "Epoch [5/30], Batch [1590/20508], Loss: 0.6764\n",
      "Epoch [5/30], Batch [1600/20508], Loss: 0.6908\n",
      "Epoch [5/30], Batch [1610/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [1620/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [1630/20508], Loss: 0.6506\n",
      "Epoch [5/30], Batch [1640/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [1650/20508], Loss: 0.6750\n",
      "Epoch [5/30], Batch [1660/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [1670/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [1680/20508], Loss: 0.6843\n",
      "Epoch [5/30], Batch [1690/20508], Loss: 0.7019\n",
      "Epoch [5/30], Batch [1700/20508], Loss: 0.7039\n",
      "Epoch [5/30], Batch [1710/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [1720/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [1730/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [1740/20508], Loss: 0.7012\n",
      "Epoch [5/30], Batch [1750/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [1760/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [1770/20508], Loss: 0.6993\n",
      "Epoch [5/30], Batch [1780/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [1790/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [1800/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [1810/20508], Loss: 0.6776\n",
      "Epoch [5/30], Batch [1820/20508], Loss: 0.6825\n",
      "Epoch [5/30], Batch [1830/20508], Loss: 0.7027\n",
      "Epoch [5/30], Batch [1840/20508], Loss: 0.6770\n",
      "Epoch [5/30], Batch [1850/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [1860/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [1870/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [1880/20508], Loss: 0.7020\n",
      "Epoch [5/30], Batch [1890/20508], Loss: 0.6922\n",
      "Epoch [5/30], Batch [1900/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [1910/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [1920/20508], Loss: 0.7011\n",
      "Epoch [5/30], Batch [1930/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [1940/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [1950/20508], Loss: 0.7057\n",
      "Epoch [5/30], Batch [1960/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [1970/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [1980/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [1990/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [2000/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [2010/20508], Loss: 0.6961\n",
      "Epoch [5/30], Batch [2020/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [2030/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [2040/20508], Loss: 0.7200\n",
      "Epoch [5/30], Batch [2050/20508], Loss: 0.6985\n",
      "Epoch [5/30], Batch [2060/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [2070/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [2080/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [2090/20508], Loss: 0.7026\n",
      "Epoch [5/30], Batch [2100/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [2110/20508], Loss: 0.6960\n",
      "Epoch [5/30], Batch [2120/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [2130/20508], Loss: 0.6794\n",
      "Epoch [5/30], Batch [2140/20508], Loss: 0.6998\n",
      "Epoch [5/30], Batch [2150/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [2160/20508], Loss: 0.6678\n",
      "Epoch [5/30], Batch [2170/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [2180/20508], Loss: 0.6964\n",
      "Epoch [5/30], Batch [2190/20508], Loss: 0.6805\n",
      "Epoch [5/30], Batch [2200/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [2210/20508], Loss: 0.7127\n",
      "Epoch [5/30], Batch [2220/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [2230/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [2240/20508], Loss: 0.6740\n",
      "Epoch [5/30], Batch [2250/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [2260/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [2270/20508], Loss: 0.6729\n",
      "Epoch [5/30], Batch [2280/20508], Loss: 0.7008\n",
      "Epoch [5/30], Batch [2290/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [2300/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [2310/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [2320/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [2330/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [2340/20508], Loss: 0.6922\n",
      "Epoch [5/30], Batch [2350/20508], Loss: 0.7032\n",
      "Epoch [5/30], Batch [2360/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [2370/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [2380/20508], Loss: 0.7045\n",
      "Epoch [5/30], Batch [2390/20508], Loss: 0.6735\n",
      "Epoch [5/30], Batch [2400/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [2410/20508], Loss: 0.7057\n",
      "Epoch [5/30], Batch [2420/20508], Loss: 0.6777\n",
      "Epoch [5/30], Batch [2430/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [2440/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [2450/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [2460/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [2470/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [2480/20508], Loss: 0.6670\n",
      "Epoch [5/30], Batch [2490/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [2500/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [2510/20508], Loss: 0.6713\n",
      "Epoch [5/30], Batch [2520/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [2530/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [2540/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [2550/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [2560/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [2570/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [2580/20508], Loss: 0.7016\n",
      "Epoch [5/30], Batch [2590/20508], Loss: 0.6957\n",
      "Epoch [5/30], Batch [2600/20508], Loss: 0.6742\n",
      "Epoch [5/30], Batch [2610/20508], Loss: 0.6572\n",
      "Epoch [5/30], Batch [2620/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [2630/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [2640/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [2650/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [2660/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [2670/20508], Loss: 0.6998\n",
      "Epoch [5/30], Batch [2680/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [2690/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [2700/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [2710/20508], Loss: 0.6751\n",
      "Epoch [5/30], Batch [2720/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [2730/20508], Loss: 0.6767\n",
      "Epoch [5/30], Batch [2740/20508], Loss: 0.7029\n",
      "Epoch [5/30], Batch [2750/20508], Loss: 0.6880\n",
      "Epoch [5/30], Batch [2760/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [2770/20508], Loss: 0.6704\n",
      "Epoch [5/30], Batch [2780/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [2790/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [2800/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [2810/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [2820/20508], Loss: 0.6799\n",
      "Epoch [5/30], Batch [2830/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [2840/20508], Loss: 0.6578\n",
      "Epoch [5/30], Batch [2850/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [2860/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [2870/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [2880/20508], Loss: 0.6668\n",
      "Epoch [5/30], Batch [2890/20508], Loss: 0.7072\n",
      "Epoch [5/30], Batch [2900/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [2910/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [2920/20508], Loss: 0.6798\n",
      "Epoch [5/30], Batch [2930/20508], Loss: 0.6869\n",
      "Epoch [5/30], Batch [2940/20508], Loss: 0.7022\n",
      "Epoch [5/30], Batch [2950/20508], Loss: 0.6845\n",
      "Epoch [5/30], Batch [2960/20508], Loss: 0.6637\n",
      "Epoch [5/30], Batch [2970/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [2980/20508], Loss: 0.6792\n",
      "Epoch [5/30], Batch [2990/20508], Loss: 0.6522\n",
      "Epoch [5/30], Batch [3000/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [3010/20508], Loss: 0.6922\n",
      "Epoch [5/30], Batch [3020/20508], Loss: 0.6989\n",
      "Epoch [5/30], Batch [3030/20508], Loss: 0.7115\n",
      "Epoch [5/30], Batch [3040/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [3050/20508], Loss: 0.6967\n",
      "Epoch [5/30], Batch [3060/20508], Loss: 0.6635\n",
      "Epoch [5/30], Batch [3070/20508], Loss: 0.7101\n",
      "Epoch [5/30], Batch [3080/20508], Loss: 0.6721\n",
      "Epoch [5/30], Batch [3090/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [3100/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [3110/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [3120/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [3130/20508], Loss: 0.6666\n",
      "Epoch [5/30], Batch [3140/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [3150/20508], Loss: 0.7086\n",
      "Epoch [5/30], Batch [3160/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [3170/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [3180/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [3190/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [3200/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [3210/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [3220/20508], Loss: 0.6995\n",
      "Epoch [5/30], Batch [3230/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [3240/20508], Loss: 0.7010\n",
      "Epoch [5/30], Batch [3250/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [3260/20508], Loss: 0.6996\n",
      "Epoch [5/30], Batch [3270/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [3280/20508], Loss: 0.7119\n",
      "Epoch [5/30], Batch [3290/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [3300/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [3310/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [3320/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [3330/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [3340/20508], Loss: 0.6835\n",
      "Epoch [5/30], Batch [3350/20508], Loss: 0.6782\n",
      "Epoch [5/30], Batch [3360/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [3370/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [3380/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [3390/20508], Loss: 0.7004\n",
      "Epoch [5/30], Batch [3400/20508], Loss: 0.7015\n",
      "Epoch [5/30], Batch [3410/20508], Loss: 0.6820\n",
      "Epoch [5/30], Batch [3420/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [3430/20508], Loss: 0.6769\n",
      "Epoch [5/30], Batch [3440/20508], Loss: 0.6770\n",
      "Epoch [5/30], Batch [3450/20508], Loss: 0.6682\n",
      "Epoch [5/30], Batch [3460/20508], Loss: 0.6773\n",
      "Epoch [5/30], Batch [3470/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [3480/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [3490/20508], Loss: 0.7148\n",
      "Epoch [5/30], Batch [3500/20508], Loss: 0.6780\n",
      "Epoch [5/30], Batch [3510/20508], Loss: 0.6761\n",
      "Epoch [5/30], Batch [3520/20508], Loss: 0.6669\n",
      "Epoch [5/30], Batch [3530/20508], Loss: 0.7062\n",
      "Epoch [5/30], Batch [3540/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [3550/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [3560/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [3570/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [3580/20508], Loss: 0.6849\n",
      "Epoch [5/30], Batch [3590/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [3600/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [3610/20508], Loss: 0.6935\n",
      "Epoch [5/30], Batch [3620/20508], Loss: 0.6973\n",
      "Epoch [5/30], Batch [3630/20508], Loss: 0.6786\n",
      "Epoch [5/30], Batch [3640/20508], Loss: 0.6640\n",
      "Epoch [5/30], Batch [3650/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [3660/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [3670/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [3680/20508], Loss: 0.6760\n",
      "Epoch [5/30], Batch [3690/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [3700/20508], Loss: 0.6711\n",
      "Epoch [5/30], Batch [3710/20508], Loss: 0.6992\n",
      "Epoch [5/30], Batch [3720/20508], Loss: 0.7144\n",
      "Epoch [5/30], Batch [3730/20508], Loss: 0.6774\n",
      "Epoch [5/30], Batch [3740/20508], Loss: 0.6682\n",
      "Epoch [5/30], Batch [3750/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [3760/20508], Loss: 0.6716\n",
      "Epoch [5/30], Batch [3770/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [3780/20508], Loss: 0.6724\n",
      "Epoch [5/30], Batch [3790/20508], Loss: 0.7012\n",
      "Epoch [5/30], Batch [3800/20508], Loss: 0.7032\n",
      "Epoch [5/30], Batch [3810/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [3820/20508], Loss: 0.6761\n",
      "Epoch [5/30], Batch [3830/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [3840/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [3850/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [3860/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [3870/20508], Loss: 0.7018\n",
      "Epoch [5/30], Batch [3880/20508], Loss: 0.6762\n",
      "Epoch [5/30], Batch [3890/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [3900/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [3910/20508], Loss: 0.7023\n",
      "Epoch [5/30], Batch [3920/20508], Loss: 0.6710\n",
      "Epoch [5/30], Batch [3930/20508], Loss: 0.7164\n",
      "Epoch [5/30], Batch [3940/20508], Loss: 0.7014\n",
      "Epoch [5/30], Batch [3950/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [3960/20508], Loss: 0.6831\n",
      "Epoch [5/30], Batch [3970/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [3980/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [3990/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [4000/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [4010/20508], Loss: 0.6762\n",
      "Epoch [5/30], Batch [4020/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [4030/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [4040/20508], Loss: 0.6816\n",
      "Epoch [5/30], Batch [4050/20508], Loss: 0.7045\n",
      "Epoch [5/30], Batch [4060/20508], Loss: 0.6817\n",
      "Epoch [5/30], Batch [4070/20508], Loss: 0.7212\n",
      "Epoch [5/30], Batch [4080/20508], Loss: 0.7042\n",
      "Epoch [5/30], Batch [4090/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [4100/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [4110/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [4120/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [4130/20508], Loss: 0.6715\n",
      "Epoch [5/30], Batch [4140/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [4150/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [4160/20508], Loss: 0.6910\n",
      "Epoch [5/30], Batch [4170/20508], Loss: 0.6804\n",
      "Epoch [5/30], Batch [4180/20508], Loss: 0.6974\n",
      "Epoch [5/30], Batch [4190/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [4200/20508], Loss: 0.6970\n",
      "Epoch [5/30], Batch [4210/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [4220/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [4230/20508], Loss: 0.6941\n",
      "Epoch [5/30], Batch [4240/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [4250/20508], Loss: 0.6860\n",
      "Epoch [5/30], Batch [4260/20508], Loss: 0.6704\n",
      "Epoch [5/30], Batch [4270/20508], Loss: 0.7033\n",
      "Epoch [5/30], Batch [4280/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [4290/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [4300/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [4310/20508], Loss: 0.6738\n",
      "Epoch [5/30], Batch [4320/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [4330/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [4340/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [4350/20508], Loss: 0.7009\n",
      "Epoch [5/30], Batch [4360/20508], Loss: 0.7263\n",
      "Epoch [5/30], Batch [4370/20508], Loss: 0.7111\n",
      "Epoch [5/30], Batch [4380/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [4390/20508], Loss: 0.6683\n",
      "Epoch [5/30], Batch [4400/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [4410/20508], Loss: 0.6980\n",
      "Epoch [5/30], Batch [4420/20508], Loss: 0.7049\n",
      "Epoch [5/30], Batch [4430/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [4440/20508], Loss: 0.6930\n",
      "Epoch [5/30], Batch [4450/20508], Loss: 0.6990\n",
      "Epoch [5/30], Batch [4460/20508], Loss: 0.6941\n",
      "Epoch [5/30], Batch [4470/20508], Loss: 0.6980\n",
      "Epoch [5/30], Batch [4480/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [4490/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [4500/20508], Loss: 0.6849\n",
      "Epoch [5/30], Batch [4510/20508], Loss: 0.7145\n",
      "Epoch [5/30], Batch [4520/20508], Loss: 0.6892\n",
      "Epoch [5/30], Batch [4530/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [4540/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [4550/20508], Loss: 0.7062\n",
      "Epoch [5/30], Batch [4560/20508], Loss: 0.6799\n",
      "Epoch [5/30], Batch [4570/20508], Loss: 0.7008\n",
      "Epoch [5/30], Batch [4580/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [4590/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [4600/20508], Loss: 0.6721\n",
      "Epoch [5/30], Batch [4610/20508], Loss: 0.7059\n",
      "Epoch [5/30], Batch [4620/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [4630/20508], Loss: 0.7003\n",
      "Epoch [5/30], Batch [4640/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [4650/20508], Loss: 0.6809\n",
      "Epoch [5/30], Batch [4660/20508], Loss: 0.6809\n",
      "Epoch [5/30], Batch [4670/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [4680/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [4690/20508], Loss: 0.7029\n",
      "Epoch [5/30], Batch [4700/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [4710/20508], Loss: 0.6752\n",
      "Epoch [5/30], Batch [4720/20508], Loss: 0.6777\n",
      "Epoch [5/30], Batch [4730/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [4740/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [4750/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [4760/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [4770/20508], Loss: 0.6960\n",
      "Epoch [5/30], Batch [4780/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [4790/20508], Loss: 0.6728\n",
      "Epoch [5/30], Batch [4800/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [4810/20508], Loss: 0.6987\n",
      "Epoch [5/30], Batch [4820/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [4830/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [4840/20508], Loss: 0.6975\n",
      "Epoch [5/30], Batch [4850/20508], Loss: 0.6970\n",
      "Epoch [5/30], Batch [4860/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [4870/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [4880/20508], Loss: 0.7142\n",
      "Epoch [5/30], Batch [4890/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [4900/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [4910/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [4920/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [4930/20508], Loss: 0.6868\n",
      "Epoch [5/30], Batch [4940/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [4950/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [4960/20508], Loss: 0.6971\n",
      "Epoch [5/30], Batch [4970/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [4980/20508], Loss: 0.7076\n",
      "Epoch [5/30], Batch [4990/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [5000/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [5010/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [5020/20508], Loss: 0.7041\n",
      "Epoch [5/30], Batch [5030/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [5040/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [5050/20508], Loss: 0.6638\n",
      "Epoch [5/30], Batch [5060/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [5070/20508], Loss: 0.7007\n",
      "Epoch [5/30], Batch [5080/20508], Loss: 0.6723\n",
      "Epoch [5/30], Batch [5090/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [5100/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [5110/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [5120/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [5130/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [5140/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [5150/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [5160/20508], Loss: 0.7050\n",
      "Epoch [5/30], Batch [5170/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [5180/20508], Loss: 0.6824\n",
      "Epoch [5/30], Batch [5190/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [5200/20508], Loss: 0.6719\n",
      "Epoch [5/30], Batch [5210/20508], Loss: 0.6633\n",
      "Epoch [5/30], Batch [5220/20508], Loss: 0.6678\n",
      "Epoch [5/30], Batch [5230/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [5240/20508], Loss: 0.7099\n",
      "Epoch [5/30], Batch [5250/20508], Loss: 0.7058\n",
      "Epoch [5/30], Batch [5260/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [5270/20508], Loss: 0.6695\n",
      "Epoch [5/30], Batch [5280/20508], Loss: 0.7307\n",
      "Epoch [5/30], Batch [5290/20508], Loss: 0.7019\n",
      "Epoch [5/30], Batch [5300/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [5310/20508], Loss: 0.7079\n",
      "Epoch [5/30], Batch [5320/20508], Loss: 0.6817\n",
      "Epoch [5/30], Batch [5330/20508], Loss: 0.7085\n",
      "Epoch [5/30], Batch [5340/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [5350/20508], Loss: 0.7135\n",
      "Epoch [5/30], Batch [5360/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [5370/20508], Loss: 0.7065\n",
      "Epoch [5/30], Batch [5380/20508], Loss: 0.7098\n",
      "Epoch [5/30], Batch [5390/20508], Loss: 0.6736\n",
      "Epoch [5/30], Batch [5400/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [5410/20508], Loss: 0.6815\n",
      "Epoch [5/30], Batch [5420/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [5430/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [5440/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [5450/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [5460/20508], Loss: 0.7214\n",
      "Epoch [5/30], Batch [5470/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [5480/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [5490/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [5500/20508], Loss: 0.7028\n",
      "Epoch [5/30], Batch [5510/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [5520/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [5530/20508], Loss: 0.6835\n",
      "Epoch [5/30], Batch [5540/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [5550/20508], Loss: 0.6780\n",
      "Epoch [5/30], Batch [5560/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [5570/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [5580/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [5590/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [5600/20508], Loss: 0.6963\n",
      "Epoch [5/30], Batch [5610/20508], Loss: 0.7040\n",
      "Epoch [5/30], Batch [5620/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [5630/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [5640/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [5650/20508], Loss: 0.6670\n",
      "Epoch [5/30], Batch [5660/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [5670/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [5680/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [5690/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [5700/20508], Loss: 0.6860\n",
      "Epoch [5/30], Batch [5710/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [5720/20508], Loss: 0.6742\n",
      "Epoch [5/30], Batch [5730/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [5740/20508], Loss: 0.6835\n",
      "Epoch [5/30], Batch [5750/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [5760/20508], Loss: 0.7013\n",
      "Epoch [5/30], Batch [5770/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [5780/20508], Loss: 0.7053\n",
      "Epoch [5/30], Batch [5790/20508], Loss: 0.6804\n",
      "Epoch [5/30], Batch [5800/20508], Loss: 0.6828\n",
      "Epoch [5/30], Batch [5810/20508], Loss: 0.6685\n",
      "Epoch [5/30], Batch [5820/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [5830/20508], Loss: 0.6781\n",
      "Epoch [5/30], Batch [5840/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [5850/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [5860/20508], Loss: 0.7022\n",
      "Epoch [5/30], Batch [5870/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [5880/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [5890/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [5900/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [5910/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [5920/20508], Loss: 0.6990\n",
      "Epoch [5/30], Batch [5930/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [5940/20508], Loss: 0.6990\n",
      "Epoch [5/30], Batch [5950/20508], Loss: 0.7028\n",
      "Epoch [5/30], Batch [5960/20508], Loss: 0.6753\n",
      "Epoch [5/30], Batch [5970/20508], Loss: 0.6765\n",
      "Epoch [5/30], Batch [5980/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [5990/20508], Loss: 0.6787\n",
      "Epoch [5/30], Batch [6000/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [6010/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [6020/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [6030/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [6040/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [6050/20508], Loss: 0.6664\n",
      "Epoch [5/30], Batch [6060/20508], Loss: 0.6735\n",
      "Epoch [5/30], Batch [6070/20508], Loss: 0.7045\n",
      "Epoch [5/30], Batch [6080/20508], Loss: 0.6855\n",
      "Epoch [5/30], Batch [6090/20508], Loss: 0.6685\n",
      "Epoch [5/30], Batch [6100/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [6110/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [6120/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [6130/20508], Loss: 0.6780\n",
      "Epoch [5/30], Batch [6140/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [6150/20508], Loss: 0.7070\n",
      "Epoch [5/30], Batch [6160/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [6170/20508], Loss: 0.6863\n",
      "Epoch [5/30], Batch [6180/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [6190/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [6200/20508], Loss: 0.7103\n",
      "Epoch [5/30], Batch [6210/20508], Loss: 0.7096\n",
      "Epoch [5/30], Batch [6220/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [6230/20508], Loss: 0.6935\n",
      "Epoch [5/30], Batch [6240/20508], Loss: 0.6868\n",
      "Epoch [5/30], Batch [6250/20508], Loss: 0.6885\n",
      "Epoch [5/30], Batch [6260/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [6270/20508], Loss: 0.6662\n",
      "Epoch [5/30], Batch [6280/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [6290/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [6300/20508], Loss: 0.6737\n",
      "Epoch [5/30], Batch [6310/20508], Loss: 0.7025\n",
      "Epoch [5/30], Batch [6320/20508], Loss: 0.6989\n",
      "Epoch [5/30], Batch [6330/20508], Loss: 0.6804\n",
      "Epoch [5/30], Batch [6340/20508], Loss: 0.6716\n",
      "Epoch [5/30], Batch [6350/20508], Loss: 0.7030\n",
      "Epoch [5/30], Batch [6360/20508], Loss: 0.6859\n",
      "Epoch [5/30], Batch [6370/20508], Loss: 0.6967\n",
      "Epoch [5/30], Batch [6380/20508], Loss: 0.6747\n",
      "Epoch [5/30], Batch [6390/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [6400/20508], Loss: 0.6785\n",
      "Epoch [5/30], Batch [6410/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [6420/20508], Loss: 0.6787\n",
      "Epoch [5/30], Batch [6430/20508], Loss: 0.7070\n",
      "Epoch [5/30], Batch [6440/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [6450/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [6460/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [6470/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [6480/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [6490/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [6500/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [6510/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [6520/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [6530/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [6540/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [6550/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [6560/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [6570/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [6580/20508], Loss: 0.7025\n",
      "Epoch [5/30], Batch [6590/20508], Loss: 0.6906\n",
      "Epoch [5/30], Batch [6600/20508], Loss: 0.6824\n",
      "Epoch [5/30], Batch [6610/20508], Loss: 0.6712\n",
      "Epoch [5/30], Batch [6620/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [6630/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [6640/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [6650/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [6660/20508], Loss: 0.6884\n",
      "Epoch [5/30], Batch [6670/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [6680/20508], Loss: 0.7043\n",
      "Epoch [5/30], Batch [6690/20508], Loss: 0.6989\n",
      "Epoch [5/30], Batch [6700/20508], Loss: 0.6722\n",
      "Epoch [5/30], Batch [6710/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [6720/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [6730/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [6740/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [6750/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [6760/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [6770/20508], Loss: 0.7158\n",
      "Epoch [5/30], Batch [6780/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [6790/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [6800/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [6810/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [6820/20508], Loss: 0.7027\n",
      "Epoch [5/30], Batch [6830/20508], Loss: 0.6697\n",
      "Epoch [5/30], Batch [6840/20508], Loss: 0.6975\n",
      "Epoch [5/30], Batch [6850/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [6860/20508], Loss: 0.7107\n",
      "Epoch [5/30], Batch [6870/20508], Loss: 0.7044\n",
      "Epoch [5/30], Batch [6880/20508], Loss: 0.7002\n",
      "Epoch [5/30], Batch [6890/20508], Loss: 0.6906\n",
      "Epoch [5/30], Batch [6900/20508], Loss: 0.6672\n",
      "Epoch [5/30], Batch [6910/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [6920/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [6930/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [6940/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [6950/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [6960/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [6970/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [6980/20508], Loss: 0.7043\n",
      "Epoch [5/30], Batch [6990/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [7000/20508], Loss: 0.7012\n",
      "Epoch [5/30], Batch [7010/20508], Loss: 0.6778\n",
      "Epoch [5/30], Batch [7020/20508], Loss: 0.6741\n",
      "Epoch [5/30], Batch [7030/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [7040/20508], Loss: 0.6882\n",
      "Epoch [5/30], Batch [7050/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [7060/20508], Loss: 0.6801\n",
      "Epoch [5/30], Batch [7070/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [7080/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [7090/20508], Loss: 0.7132\n",
      "Epoch [5/30], Batch [7100/20508], Loss: 0.6888\n",
      "Epoch [5/30], Batch [7110/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [7120/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [7130/20508], Loss: 0.6910\n",
      "Epoch [5/30], Batch [7140/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [7150/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [7160/20508], Loss: 0.6650\n",
      "Epoch [5/30], Batch [7170/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [7180/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [7190/20508], Loss: 0.6885\n",
      "Epoch [5/30], Batch [7200/20508], Loss: 0.6771\n",
      "Epoch [5/30], Batch [7210/20508], Loss: 0.7003\n",
      "Epoch [5/30], Batch [7220/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [7230/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [7240/20508], Loss: 0.7055\n",
      "Epoch [5/30], Batch [7250/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [7260/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [7270/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [7280/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [7290/20508], Loss: 0.7071\n",
      "Epoch [5/30], Batch [7300/20508], Loss: 0.6815\n",
      "Epoch [5/30], Batch [7310/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [7320/20508], Loss: 0.7113\n",
      "Epoch [5/30], Batch [7330/20508], Loss: 0.7095\n",
      "Epoch [5/30], Batch [7340/20508], Loss: 0.6673\n",
      "Epoch [5/30], Batch [7350/20508], Loss: 0.7179\n",
      "Epoch [5/30], Batch [7360/20508], Loss: 0.6638\n",
      "Epoch [5/30], Batch [7370/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [7380/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [7390/20508], Loss: 0.6921\n",
      "Epoch [5/30], Batch [7400/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [7410/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [7420/20508], Loss: 0.6995\n",
      "Epoch [5/30], Batch [7430/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [7440/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [7450/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [7460/20508], Loss: 0.6785\n",
      "Epoch [5/30], Batch [7470/20508], Loss: 0.6957\n",
      "Epoch [5/30], Batch [7480/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [7490/20508], Loss: 0.7066\n",
      "Epoch [5/30], Batch [7500/20508], Loss: 0.6675\n",
      "Epoch [5/30], Batch [7510/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [7520/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [7530/20508], Loss: 0.6745\n",
      "Epoch [5/30], Batch [7540/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [7550/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [7560/20508], Loss: 0.7224\n",
      "Epoch [5/30], Batch [7570/20508], Loss: 0.6709\n",
      "Epoch [5/30], Batch [7580/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [7590/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [7600/20508], Loss: 0.6880\n",
      "Epoch [5/30], Batch [7610/20508], Loss: 0.6965\n",
      "Epoch [5/30], Batch [7620/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [7630/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [7640/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [7650/20508], Loss: 0.6778\n",
      "Epoch [5/30], Batch [7660/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [7670/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [7680/20508], Loss: 0.7003\n",
      "Epoch [5/30], Batch [7690/20508], Loss: 0.6807\n",
      "Epoch [5/30], Batch [7700/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [7710/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [7720/20508], Loss: 0.6965\n",
      "Epoch [5/30], Batch [7730/20508], Loss: 0.6834\n",
      "Epoch [5/30], Batch [7740/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [7750/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [7760/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [7770/20508], Loss: 0.6732\n",
      "Epoch [5/30], Batch [7780/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [7790/20508], Loss: 0.7108\n",
      "Epoch [5/30], Batch [7800/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [7810/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [7820/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [7830/20508], Loss: 0.6763\n",
      "Epoch [5/30], Batch [7840/20508], Loss: 0.6978\n",
      "Epoch [5/30], Batch [7850/20508], Loss: 0.7142\n",
      "Epoch [5/30], Batch [7860/20508], Loss: 0.6885\n",
      "Epoch [5/30], Batch [7870/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [7880/20508], Loss: 0.7004\n",
      "Epoch [5/30], Batch [7890/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [7900/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [7910/20508], Loss: 0.6753\n",
      "Epoch [5/30], Batch [7920/20508], Loss: 0.6633\n",
      "Epoch [5/30], Batch [7930/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [7940/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [7950/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [7960/20508], Loss: 0.6922\n",
      "Epoch [5/30], Batch [7970/20508], Loss: 0.6817\n",
      "Epoch [5/30], Batch [7980/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [7990/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [8000/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [8010/20508], Loss: 0.7058\n",
      "Epoch [5/30], Batch [8020/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [8030/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [8040/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [8050/20508], Loss: 0.7168\n",
      "Epoch [5/30], Batch [8060/20508], Loss: 0.6859\n",
      "Epoch [5/30], Batch [8070/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [8080/20508], Loss: 0.6992\n",
      "Epoch [5/30], Batch [8090/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [8100/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [8110/20508], Loss: 0.6792\n",
      "Epoch [5/30], Batch [8120/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [8130/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [8140/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [8150/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [8160/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [8170/20508], Loss: 0.6863\n",
      "Epoch [5/30], Batch [8180/20508], Loss: 0.6967\n",
      "Epoch [5/30], Batch [8190/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [8200/20508], Loss: 0.6908\n",
      "Epoch [5/30], Batch [8210/20508], Loss: 0.7072\n",
      "Epoch [5/30], Batch [8220/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [8230/20508], Loss: 0.6656\n",
      "Epoch [5/30], Batch [8240/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [8250/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [8260/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [8270/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [8280/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [8290/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [8300/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [8310/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [8320/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [8330/20508], Loss: 0.7185\n",
      "Epoch [5/30], Batch [8340/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [8350/20508], Loss: 0.6744\n",
      "Epoch [5/30], Batch [8360/20508], Loss: 0.6762\n",
      "Epoch [5/30], Batch [8370/20508], Loss: 0.6697\n",
      "Epoch [5/30], Batch [8380/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [8390/20508], Loss: 0.6859\n",
      "Epoch [5/30], Batch [8400/20508], Loss: 0.6683\n",
      "Epoch [5/30], Batch [8410/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [8420/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [8430/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [8440/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [8450/20508], Loss: 0.6884\n",
      "Epoch [5/30], Batch [8460/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [8470/20508], Loss: 0.6771\n",
      "Epoch [5/30], Batch [8480/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [8490/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [8500/20508], Loss: 0.7010\n",
      "Epoch [5/30], Batch [8510/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [8520/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [8530/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [8540/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [8550/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [8560/20508], Loss: 0.6817\n",
      "Epoch [5/30], Batch [8570/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [8580/20508], Loss: 0.7077\n",
      "Epoch [5/30], Batch [8590/20508], Loss: 0.7068\n",
      "Epoch [5/30], Batch [8600/20508], Loss: 0.6882\n",
      "Epoch [5/30], Batch [8610/20508], Loss: 0.6888\n",
      "Epoch [5/30], Batch [8620/20508], Loss: 0.6975\n",
      "Epoch [5/30], Batch [8630/20508], Loss: 0.6740\n",
      "Epoch [5/30], Batch [8640/20508], Loss: 0.6752\n",
      "Epoch [5/30], Batch [8650/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [8660/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [8670/20508], Loss: 0.6662\n",
      "Epoch [5/30], Batch [8680/20508], Loss: 0.6775\n",
      "Epoch [5/30], Batch [8690/20508], Loss: 0.6923\n",
      "Epoch [5/30], Batch [8700/20508], Loss: 0.7125\n",
      "Epoch [5/30], Batch [8710/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [8720/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [8730/20508], Loss: 0.6659\n",
      "Epoch [5/30], Batch [8740/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [8750/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [8760/20508], Loss: 0.6743\n",
      "Epoch [5/30], Batch [8770/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [8780/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [8790/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [8800/20508], Loss: 0.6763\n",
      "Epoch [5/30], Batch [8810/20508], Loss: 0.6751\n",
      "Epoch [5/30], Batch [8820/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [8830/20508], Loss: 0.6735\n",
      "Epoch [5/30], Batch [8840/20508], Loss: 0.7075\n",
      "Epoch [5/30], Batch [8850/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [8860/20508], Loss: 0.7188\n",
      "Epoch [5/30], Batch [8870/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [8880/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [8890/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [8900/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [8910/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [8920/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [8930/20508], Loss: 0.6702\n",
      "Epoch [5/30], Batch [8940/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [8950/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [8960/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [8970/20508], Loss: 0.6798\n",
      "Epoch [5/30], Batch [8980/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [8990/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [9000/20508], Loss: 0.6818\n",
      "Epoch [5/30], Batch [9010/20508], Loss: 0.7184\n",
      "Epoch [5/30], Batch [9020/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [9030/20508], Loss: 0.6724\n",
      "Epoch [5/30], Batch [9040/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [9050/20508], Loss: 0.6892\n",
      "Epoch [5/30], Batch [9060/20508], Loss: 0.6996\n",
      "Epoch [5/30], Batch [9070/20508], Loss: 0.6831\n",
      "Epoch [5/30], Batch [9080/20508], Loss: 0.6804\n",
      "Epoch [5/30], Batch [9090/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [9100/20508], Loss: 0.6842\n",
      "Epoch [5/30], Batch [9110/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [9120/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [9130/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [9140/20508], Loss: 0.6773\n",
      "Epoch [5/30], Batch [9150/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [9160/20508], Loss: 0.6842\n",
      "Epoch [5/30], Batch [9170/20508], Loss: 0.6914\n",
      "Epoch [5/30], Batch [9180/20508], Loss: 0.6880\n",
      "Epoch [5/30], Batch [9190/20508], Loss: 0.6794\n",
      "Epoch [5/30], Batch [9200/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [9210/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [9220/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [9230/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [9240/20508], Loss: 0.6970\n",
      "Epoch [5/30], Batch [9250/20508], Loss: 0.6798\n",
      "Epoch [5/30], Batch [9260/20508], Loss: 0.6892\n",
      "Epoch [5/30], Batch [9270/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [9280/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [9290/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [9300/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [9310/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [9320/20508], Loss: 0.6583\n",
      "Epoch [5/30], Batch [9330/20508], Loss: 0.7132\n",
      "Epoch [5/30], Batch [9340/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [9350/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [9360/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [9370/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [9380/20508], Loss: 0.6802\n",
      "Epoch [5/30], Batch [9390/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [9400/20508], Loss: 0.6715\n",
      "Epoch [5/30], Batch [9410/20508], Loss: 0.6914\n",
      "Epoch [5/30], Batch [9420/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [9430/20508], Loss: 0.6880\n",
      "Epoch [5/30], Batch [9440/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [9450/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [9460/20508], Loss: 0.7011\n",
      "Epoch [5/30], Batch [9470/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [9480/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [9490/20508], Loss: 0.6733\n",
      "Epoch [5/30], Batch [9500/20508], Loss: 0.7105\n",
      "Epoch [5/30], Batch [9510/20508], Loss: 0.6833\n",
      "Epoch [5/30], Batch [9520/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [9530/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [9540/20508], Loss: 0.6975\n",
      "Epoch [5/30], Batch [9550/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [9560/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [9570/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [9580/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [9590/20508], Loss: 0.6935\n",
      "Epoch [5/30], Batch [9600/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [9610/20508], Loss: 0.6834\n",
      "Epoch [5/30], Batch [9620/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [9630/20508], Loss: 0.6923\n",
      "Epoch [5/30], Batch [9640/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [9650/20508], Loss: 0.7032\n",
      "Epoch [5/30], Batch [9660/20508], Loss: 0.6965\n",
      "Epoch [5/30], Batch [9670/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [9680/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [9690/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [9700/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [9710/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [9720/20508], Loss: 0.6951\n",
      "Epoch [5/30], Batch [9730/20508], Loss: 0.6656\n",
      "Epoch [5/30], Batch [9740/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [9750/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [9760/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [9770/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [9780/20508], Loss: 0.7039\n",
      "Epoch [5/30], Batch [9790/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [9800/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [9810/20508], Loss: 0.6825\n",
      "Epoch [5/30], Batch [9820/20508], Loss: 0.6646\n",
      "Epoch [5/30], Batch [9830/20508], Loss: 0.6879\n",
      "Epoch [5/30], Batch [9840/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [9850/20508], Loss: 0.7015\n",
      "Epoch [5/30], Batch [9860/20508], Loss: 0.6970\n",
      "Epoch [5/30], Batch [9870/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [9880/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [9890/20508], Loss: 0.6765\n",
      "Epoch [5/30], Batch [9900/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [9910/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [9920/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [9930/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [9940/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [9950/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [9960/20508], Loss: 0.6779\n",
      "Epoch [5/30], Batch [9970/20508], Loss: 0.6792\n",
      "Epoch [5/30], Batch [9980/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [9990/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [10000/20508], Loss: 0.6998\n",
      "Epoch [5/30], Batch [10010/20508], Loss: 0.6951\n",
      "Epoch [5/30], Batch [10020/20508], Loss: 0.7025\n",
      "Epoch [5/30], Batch [10030/20508], Loss: 0.6996\n",
      "Epoch [5/30], Batch [10040/20508], Loss: 0.7087\n",
      "Epoch [5/30], Batch [10050/20508], Loss: 0.6727\n",
      "Epoch [5/30], Batch [10060/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [10070/20508], Loss: 0.6711\n",
      "Epoch [5/30], Batch [10080/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [10090/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [10100/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [10110/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [10120/20508], Loss: 0.6833\n",
      "Epoch [5/30], Batch [10130/20508], Loss: 0.6758\n",
      "Epoch [5/30], Batch [10140/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [10150/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [10160/20508], Loss: 0.7100\n",
      "Epoch [5/30], Batch [10170/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [10180/20508], Loss: 0.7162\n",
      "Epoch [5/30], Batch [10190/20508], Loss: 0.6723\n",
      "Epoch [5/30], Batch [10200/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [10210/20508], Loss: 0.6505\n",
      "Epoch [5/30], Batch [10220/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [10230/20508], Loss: 0.6923\n",
      "Epoch [5/30], Batch [10240/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [10250/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [10260/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [10270/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [10280/20508], Loss: 0.6869\n",
      "Epoch [5/30], Batch [10290/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [10300/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [10310/20508], Loss: 0.6805\n",
      "Epoch [5/30], Batch [10320/20508], Loss: 0.6885\n",
      "Epoch [5/30], Batch [10330/20508], Loss: 0.7075\n",
      "Epoch [5/30], Batch [10340/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [10350/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [10360/20508], Loss: 0.6758\n",
      "Epoch [5/30], Batch [10370/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [10380/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [10390/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [10400/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [10410/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [10420/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [10430/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [10440/20508], Loss: 0.7024\n",
      "Epoch [5/30], Batch [10450/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [10460/20508], Loss: 0.6987\n",
      "Epoch [5/30], Batch [10470/20508], Loss: 0.7012\n",
      "Epoch [5/30], Batch [10480/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [10490/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [10500/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [10510/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [10520/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [10530/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [10540/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [10550/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [10560/20508], Loss: 0.7088\n",
      "Epoch [5/30], Batch [10570/20508], Loss: 0.7004\n",
      "Epoch [5/30], Batch [10580/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [10590/20508], Loss: 0.6733\n",
      "Epoch [5/30], Batch [10600/20508], Loss: 0.7098\n",
      "Epoch [5/30], Batch [10610/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [10620/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [10630/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [10640/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [10650/20508], Loss: 0.6930\n",
      "Epoch [5/30], Batch [10660/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [10670/20508], Loss: 0.6601\n",
      "Epoch [5/30], Batch [10680/20508], Loss: 0.6764\n",
      "Epoch [5/30], Batch [10690/20508], Loss: 0.6696\n",
      "Epoch [5/30], Batch [10700/20508], Loss: 0.7111\n",
      "Epoch [5/30], Batch [10710/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [10720/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [10730/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [10740/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [10750/20508], Loss: 0.7095\n",
      "Epoch [5/30], Batch [10760/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [10770/20508], Loss: 0.6985\n",
      "Epoch [5/30], Batch [10780/20508], Loss: 0.6714\n",
      "Epoch [5/30], Batch [10790/20508], Loss: 0.7081\n",
      "Epoch [5/30], Batch [10800/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [10810/20508], Loss: 0.7039\n",
      "Epoch [5/30], Batch [10820/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [10830/20508], Loss: 0.6859\n",
      "Epoch [5/30], Batch [10840/20508], Loss: 0.7017\n",
      "Epoch [5/30], Batch [10850/20508], Loss: 0.6764\n",
      "Epoch [5/30], Batch [10860/20508], Loss: 0.7036\n",
      "Epoch [5/30], Batch [10870/20508], Loss: 0.6756\n",
      "Epoch [5/30], Batch [10880/20508], Loss: 0.6724\n",
      "Epoch [5/30], Batch [10890/20508], Loss: 0.6824\n",
      "Epoch [5/30], Batch [10900/20508], Loss: 0.6744\n",
      "Epoch [5/30], Batch [10910/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [10920/20508], Loss: 0.6662\n",
      "Epoch [5/30], Batch [10930/20508], Loss: 0.7011\n",
      "Epoch [5/30], Batch [10940/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [10950/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [10960/20508], Loss: 0.6637\n",
      "Epoch [5/30], Batch [10970/20508], Loss: 0.6831\n",
      "Epoch [5/30], Batch [10980/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [10990/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [11000/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [11010/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [11020/20508], Loss: 0.7012\n",
      "Epoch [5/30], Batch [11030/20508], Loss: 0.7055\n",
      "Epoch [5/30], Batch [11040/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [11050/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [11060/20508], Loss: 0.6779\n",
      "Epoch [5/30], Batch [11070/20508], Loss: 0.6659\n",
      "Epoch [5/30], Batch [11080/20508], Loss: 0.6719\n",
      "Epoch [5/30], Batch [11090/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [11100/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [11110/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [11120/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [11130/20508], Loss: 0.7219\n",
      "Epoch [5/30], Batch [11140/20508], Loss: 0.7112\n",
      "Epoch [5/30], Batch [11150/20508], Loss: 0.6992\n",
      "Epoch [5/30], Batch [11160/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [11170/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [11180/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [11190/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [11200/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [11210/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [11220/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [11230/20508], Loss: 0.6828\n",
      "Epoch [5/30], Batch [11240/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [11250/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [11260/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [11270/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [11280/20508], Loss: 0.6860\n",
      "Epoch [5/30], Batch [11290/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [11300/20508], Loss: 0.6834\n",
      "Epoch [5/30], Batch [11310/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [11320/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [11330/20508], Loss: 0.7021\n",
      "Epoch [5/30], Batch [11340/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [11350/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [11360/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [11370/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [11380/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [11390/20508], Loss: 0.6820\n",
      "Epoch [5/30], Batch [11400/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [11410/20508], Loss: 0.6990\n",
      "Epoch [5/30], Batch [11420/20508], Loss: 0.6735\n",
      "Epoch [5/30], Batch [11430/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [11440/20508], Loss: 0.6767\n",
      "Epoch [5/30], Batch [11450/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [11460/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [11470/20508], Loss: 0.7009\n",
      "Epoch [5/30], Batch [11480/20508], Loss: 0.6690\n",
      "Epoch [5/30], Batch [11490/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [11500/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [11510/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [11520/20508], Loss: 0.7190\n",
      "Epoch [5/30], Batch [11530/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [11540/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [11550/20508], Loss: 0.6873\n",
      "Epoch [5/30], Batch [11560/20508], Loss: 0.7174\n",
      "Epoch [5/30], Batch [11570/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [11580/20508], Loss: 0.7026\n",
      "Epoch [5/30], Batch [11590/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [11600/20508], Loss: 0.6901\n",
      "Epoch [5/30], Batch [11610/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [11620/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [11630/20508], Loss: 0.6988\n",
      "Epoch [5/30], Batch [11640/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [11650/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [11660/20508], Loss: 0.6988\n",
      "Epoch [5/30], Batch [11670/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [11680/20508], Loss: 0.7073\n",
      "Epoch [5/30], Batch [11690/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [11700/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [11710/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [11720/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [11730/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [11740/20508], Loss: 0.7126\n",
      "Epoch [5/30], Batch [11750/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [11760/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [11770/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [11780/20508], Loss: 0.6965\n",
      "Epoch [5/30], Batch [11790/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [11800/20508], Loss: 0.6724\n",
      "Epoch [5/30], Batch [11810/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [11820/20508], Loss: 0.7008\n",
      "Epoch [5/30], Batch [11830/20508], Loss: 0.6906\n",
      "Epoch [5/30], Batch [11840/20508], Loss: 0.7016\n",
      "Epoch [5/30], Batch [11850/20508], Loss: 0.6750\n",
      "Epoch [5/30], Batch [11860/20508], Loss: 0.6727\n",
      "Epoch [5/30], Batch [11870/20508], Loss: 0.6663\n",
      "Epoch [5/30], Batch [11880/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [11890/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [11900/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [11910/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [11920/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [11930/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [11940/20508], Loss: 0.6960\n",
      "Epoch [5/30], Batch [11950/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [11960/20508], Loss: 0.7016\n",
      "Epoch [5/30], Batch [11970/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [11980/20508], Loss: 0.6884\n",
      "Epoch [5/30], Batch [11990/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [12000/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [12010/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [12020/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [12030/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [12040/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [12050/20508], Loss: 0.7072\n",
      "Epoch [5/30], Batch [12060/20508], Loss: 0.6910\n",
      "Epoch [5/30], Batch [12070/20508], Loss: 0.6775\n",
      "Epoch [5/30], Batch [12080/20508], Loss: 0.6713\n",
      "Epoch [5/30], Batch [12090/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [12100/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [12110/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [12120/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [12130/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [12140/20508], Loss: 0.6868\n",
      "Epoch [5/30], Batch [12150/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [12160/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [12170/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [12180/20508], Loss: 0.6794\n",
      "Epoch [5/30], Batch [12190/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [12200/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [12210/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [12220/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [12230/20508], Loss: 0.6748\n",
      "Epoch [5/30], Batch [12240/20508], Loss: 0.6863\n",
      "Epoch [5/30], Batch [12250/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [12260/20508], Loss: 0.6882\n",
      "Epoch [5/30], Batch [12270/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [12280/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [12290/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [12300/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [12310/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [12320/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [12330/20508], Loss: 0.6695\n",
      "Epoch [5/30], Batch [12340/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [12350/20508], Loss: 0.6717\n",
      "Epoch [5/30], Batch [12360/20508], Loss: 0.7014\n",
      "Epoch [5/30], Batch [12370/20508], Loss: 0.7105\n",
      "Epoch [5/30], Batch [12380/20508], Loss: 0.6789\n",
      "Epoch [5/30], Batch [12390/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [12400/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [12410/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [12420/20508], Loss: 0.6740\n",
      "Epoch [5/30], Batch [12430/20508], Loss: 0.6771\n",
      "Epoch [5/30], Batch [12440/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [12450/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [12460/20508], Loss: 0.7023\n",
      "Epoch [5/30], Batch [12470/20508], Loss: 0.7015\n",
      "Epoch [5/30], Batch [12480/20508], Loss: 0.6930\n",
      "Epoch [5/30], Batch [12490/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [12500/20508], Loss: 0.6980\n",
      "Epoch [5/30], Batch [12510/20508], Loss: 0.6710\n",
      "Epoch [5/30], Batch [12520/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [12530/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [12540/20508], Loss: 0.6892\n",
      "Epoch [5/30], Batch [12550/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [12560/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [12570/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [12580/20508], Loss: 0.6761\n",
      "Epoch [5/30], Batch [12590/20508], Loss: 0.6693\n",
      "Epoch [5/30], Batch [12600/20508], Loss: 0.6930\n",
      "Epoch [5/30], Batch [12610/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [12620/20508], Loss: 0.6779\n",
      "Epoch [5/30], Batch [12630/20508], Loss: 0.6785\n",
      "Epoch [5/30], Batch [12640/20508], Loss: 0.7037\n",
      "Epoch [5/30], Batch [12650/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [12660/20508], Loss: 0.6923\n",
      "Epoch [5/30], Batch [12670/20508], Loss: 0.6774\n",
      "Epoch [5/30], Batch [12680/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [12690/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [12700/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [12710/20508], Loss: 0.6765\n",
      "Epoch [5/30], Batch [12720/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [12730/20508], Loss: 0.6825\n",
      "Epoch [5/30], Batch [12740/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [12750/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [12760/20508], Loss: 0.7033\n",
      "Epoch [5/30], Batch [12770/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [12780/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [12790/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [12800/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [12810/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [12820/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [12830/20508], Loss: 0.6767\n",
      "Epoch [5/30], Batch [12840/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [12850/20508], Loss: 0.7156\n",
      "Epoch [5/30], Batch [12860/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [12870/20508], Loss: 0.6764\n",
      "Epoch [5/30], Batch [12880/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [12890/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [12900/20508], Loss: 0.7077\n",
      "Epoch [5/30], Batch [12910/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [12920/20508], Loss: 0.7106\n",
      "Epoch [5/30], Batch [12930/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [12940/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [12950/20508], Loss: 0.6743\n",
      "Epoch [5/30], Batch [12960/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [12970/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [12980/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [12990/20508], Loss: 0.6809\n",
      "Epoch [5/30], Batch [13000/20508], Loss: 0.6804\n",
      "Epoch [5/30], Batch [13010/20508], Loss: 0.6937\n",
      "Epoch [5/30], Batch [13020/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [13030/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [13040/20508], Loss: 0.6730\n",
      "Epoch [5/30], Batch [13050/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [13060/20508], Loss: 0.6998\n",
      "Epoch [5/30], Batch [13070/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [13080/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [13090/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [13100/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [13110/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [13120/20508], Loss: 0.6990\n",
      "Epoch [5/30], Batch [13130/20508], Loss: 0.7050\n",
      "Epoch [5/30], Batch [13140/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [13150/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [13160/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [13170/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [13180/20508], Loss: 0.6787\n",
      "Epoch [5/30], Batch [13190/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [13200/20508], Loss: 0.7039\n",
      "Epoch [5/30], Batch [13210/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [13220/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [13230/20508], Loss: 0.6963\n",
      "Epoch [5/30], Batch [13240/20508], Loss: 0.7013\n",
      "Epoch [5/30], Batch [13250/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [13260/20508], Loss: 0.6967\n",
      "Epoch [5/30], Batch [13270/20508], Loss: 0.7108\n",
      "Epoch [5/30], Batch [13280/20508], Loss: 0.6550\n",
      "Epoch [5/30], Batch [13290/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [13300/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [13310/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [13320/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [13330/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [13340/20508], Loss: 0.6782\n",
      "Epoch [5/30], Batch [13350/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [13360/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [13370/20508], Loss: 0.6842\n",
      "Epoch [5/30], Batch [13380/20508], Loss: 0.6979\n",
      "Epoch [5/30], Batch [13390/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [13400/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [13410/20508], Loss: 0.6818\n",
      "Epoch [5/30], Batch [13420/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [13430/20508], Loss: 0.6664\n",
      "Epoch [5/30], Batch [13440/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [13450/20508], Loss: 0.7015\n",
      "Epoch [5/30], Batch [13460/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [13470/20508], Loss: 0.7008\n",
      "Epoch [5/30], Batch [13480/20508], Loss: 0.6680\n",
      "Epoch [5/30], Batch [13490/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [13500/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [13510/20508], Loss: 0.6822\n",
      "Epoch [5/30], Batch [13520/20508], Loss: 0.6818\n",
      "Epoch [5/30], Batch [13530/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [13540/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [13550/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [13560/20508], Loss: 0.7073\n",
      "Epoch [5/30], Batch [13570/20508], Loss: 0.7016\n",
      "Epoch [5/30], Batch [13580/20508], Loss: 0.7033\n",
      "Epoch [5/30], Batch [13590/20508], Loss: 0.7059\n",
      "Epoch [5/30], Batch [13600/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [13610/20508], Loss: 0.6845\n",
      "Epoch [5/30], Batch [13620/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [13630/20508], Loss: 0.6709\n",
      "Epoch [5/30], Batch [13640/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [13650/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [13660/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [13670/20508], Loss: 0.6660\n",
      "Epoch [5/30], Batch [13680/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [13690/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [13700/20508], Loss: 0.6765\n",
      "Epoch [5/30], Batch [13710/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [13720/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [13730/20508], Loss: 0.6988\n",
      "Epoch [5/30], Batch [13740/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [13750/20508], Loss: 0.6978\n",
      "Epoch [5/30], Batch [13760/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [13770/20508], Loss: 0.7119\n",
      "Epoch [5/30], Batch [13780/20508], Loss: 0.7039\n",
      "Epoch [5/30], Batch [13790/20508], Loss: 0.6807\n",
      "Epoch [5/30], Batch [13800/20508], Loss: 0.6897\n",
      "Epoch [5/30], Batch [13810/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [13820/20508], Loss: 0.7014\n",
      "Epoch [5/30], Batch [13830/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [13840/20508], Loss: 0.7066\n",
      "Epoch [5/30], Batch [13850/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [13860/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [13870/20508], Loss: 0.6842\n",
      "Epoch [5/30], Batch [13880/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [13890/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [13900/20508], Loss: 0.6894\n",
      "Epoch [5/30], Batch [13910/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [13920/20508], Loss: 0.7055\n",
      "Epoch [5/30], Batch [13930/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [13940/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [13950/20508], Loss: 0.6882\n",
      "Epoch [5/30], Batch [13960/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [13970/20508], Loss: 0.6822\n",
      "Epoch [5/30], Batch [13980/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [13990/20508], Loss: 0.6766\n",
      "Epoch [5/30], Batch [14000/20508], Loss: 0.7055\n",
      "Epoch [5/30], Batch [14010/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [14020/20508], Loss: 0.6703\n",
      "Epoch [5/30], Batch [14030/20508], Loss: 0.6709\n",
      "Epoch [5/30], Batch [14040/20508], Loss: 0.6786\n",
      "Epoch [5/30], Batch [14050/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [14060/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [14070/20508], Loss: 0.6698\n",
      "Epoch [5/30], Batch [14080/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [14090/20508], Loss: 0.6906\n",
      "Epoch [5/30], Batch [14100/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [14110/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [14120/20508], Loss: 0.6776\n",
      "Epoch [5/30], Batch [14130/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [14140/20508], Loss: 0.6851\n",
      "Epoch [5/30], Batch [14150/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [14160/20508], Loss: 0.6646\n",
      "Epoch [5/30], Batch [14170/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [14180/20508], Loss: 0.6776\n",
      "Epoch [5/30], Batch [14190/20508], Loss: 0.6750\n",
      "Epoch [5/30], Batch [14200/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [14210/20508], Loss: 0.7028\n",
      "Epoch [5/30], Batch [14220/20508], Loss: 0.7115\n",
      "Epoch [5/30], Batch [14230/20508], Loss: 0.6820\n",
      "Epoch [5/30], Batch [14240/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [14250/20508], Loss: 0.6809\n",
      "Epoch [5/30], Batch [14260/20508], Loss: 0.7104\n",
      "Epoch [5/30], Batch [14270/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [14280/20508], Loss: 0.6658\n",
      "Epoch [5/30], Batch [14290/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [14300/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [14310/20508], Loss: 0.6800\n",
      "Epoch [5/30], Batch [14320/20508], Loss: 0.6752\n",
      "Epoch [5/30], Batch [14330/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [14340/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [14350/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [14360/20508], Loss: 0.6683\n",
      "Epoch [5/30], Batch [14370/20508], Loss: 0.6802\n",
      "Epoch [5/30], Batch [14380/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [14390/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [14400/20508], Loss: 0.6608\n",
      "Epoch [5/30], Batch [14410/20508], Loss: 0.6817\n",
      "Epoch [5/30], Batch [14420/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [14430/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [14440/20508], Loss: 0.6863\n",
      "Epoch [5/30], Batch [14450/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [14460/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [14470/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [14480/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [14490/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [14500/20508], Loss: 0.6775\n",
      "Epoch [5/30], Batch [14510/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [14520/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [14530/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [14540/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [14550/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [14560/20508], Loss: 0.6985\n",
      "Epoch [5/30], Batch [14570/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [14580/20508], Loss: 0.6750\n",
      "Epoch [5/30], Batch [14590/20508], Loss: 0.6789\n",
      "Epoch [5/30], Batch [14600/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [14610/20508], Loss: 0.7126\n",
      "Epoch [5/30], Batch [14620/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [14630/20508], Loss: 0.6985\n",
      "Epoch [5/30], Batch [14640/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [14650/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [14660/20508], Loss: 0.6978\n",
      "Epoch [5/30], Batch [14670/20508], Loss: 0.6951\n",
      "Epoch [5/30], Batch [14680/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [14690/20508], Loss: 0.6763\n",
      "Epoch [5/30], Batch [14700/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [14710/20508], Loss: 0.6910\n",
      "Epoch [5/30], Batch [14720/20508], Loss: 0.6692\n",
      "Epoch [5/30], Batch [14730/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [14740/20508], Loss: 0.6983\n",
      "Epoch [5/30], Batch [14750/20508], Loss: 0.6825\n",
      "Epoch [5/30], Batch [14760/20508], Loss: 0.6654\n",
      "Epoch [5/30], Batch [14770/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [14780/20508], Loss: 0.6965\n",
      "Epoch [5/30], Batch [14790/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [14800/20508], Loss: 0.7181\n",
      "Epoch [5/30], Batch [14810/20508], Loss: 0.6888\n",
      "Epoch [5/30], Batch [14820/20508], Loss: 0.6831\n",
      "Epoch [5/30], Batch [14830/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [14840/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [14850/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [14860/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [14870/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [14880/20508], Loss: 0.6641\n",
      "Epoch [5/30], Batch [14890/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [14900/20508], Loss: 0.7075\n",
      "Epoch [5/30], Batch [14910/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [14920/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [14930/20508], Loss: 0.6699\n",
      "Epoch [5/30], Batch [14940/20508], Loss: 0.6889\n",
      "Epoch [5/30], Batch [14950/20508], Loss: 0.6826\n",
      "Epoch [5/30], Batch [14960/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [14970/20508], Loss: 0.6796\n",
      "Epoch [5/30], Batch [14980/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [14990/20508], Loss: 0.6855\n",
      "Epoch [5/30], Batch [15000/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [15010/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [15020/20508], Loss: 0.7002\n",
      "Epoch [5/30], Batch [15030/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [15040/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [15050/20508], Loss: 0.6764\n",
      "Epoch [5/30], Batch [15060/20508], Loss: 0.7033\n",
      "Epoch [5/30], Batch [15070/20508], Loss: 0.6789\n",
      "Epoch [5/30], Batch [15080/20508], Loss: 0.7027\n",
      "Epoch [5/30], Batch [15090/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [15100/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [15110/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [15120/20508], Loss: 0.6625\n",
      "Epoch [5/30], Batch [15130/20508], Loss: 0.6951\n",
      "Epoch [5/30], Batch [15140/20508], Loss: 0.6709\n",
      "Epoch [5/30], Batch [15150/20508], Loss: 0.6822\n",
      "Epoch [5/30], Batch [15160/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [15170/20508], Loss: 0.7082\n",
      "Epoch [5/30], Batch [15180/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [15190/20508], Loss: 0.6923\n",
      "Epoch [5/30], Batch [15200/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [15210/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [15220/20508], Loss: 0.7030\n",
      "Epoch [5/30], Batch [15230/20508], Loss: 0.7044\n",
      "Epoch [5/30], Batch [15240/20508], Loss: 0.6812\n",
      "Epoch [5/30], Batch [15250/20508], Loss: 0.7138\n",
      "Epoch [5/30], Batch [15260/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [15270/20508], Loss: 0.6745\n",
      "Epoch [5/30], Batch [15280/20508], Loss: 0.6700\n",
      "Epoch [5/30], Batch [15290/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [15300/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [15310/20508], Loss: 0.7117\n",
      "Epoch [5/30], Batch [15320/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [15330/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [15340/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [15350/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [15360/20508], Loss: 0.7066\n",
      "Epoch [5/30], Batch [15370/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [15380/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [15390/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [15400/20508], Loss: 0.6836\n",
      "Epoch [5/30], Batch [15410/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [15420/20508], Loss: 0.6637\n",
      "Epoch [5/30], Batch [15430/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [15440/20508], Loss: 0.6860\n",
      "Epoch [5/30], Batch [15450/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [15460/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [15470/20508], Loss: 0.7010\n",
      "Epoch [5/30], Batch [15480/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [15490/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [15500/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [15510/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [15520/20508], Loss: 0.7076\n",
      "Epoch [5/30], Batch [15530/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [15540/20508], Loss: 0.7175\n",
      "Epoch [5/30], Batch [15550/20508], Loss: 0.6828\n",
      "Epoch [5/30], Batch [15560/20508], Loss: 0.6786\n",
      "Epoch [5/30], Batch [15570/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [15580/20508], Loss: 0.6782\n",
      "Epoch [5/30], Batch [15590/20508], Loss: 0.7026\n",
      "Epoch [5/30], Batch [15600/20508], Loss: 0.7116\n",
      "Epoch [5/30], Batch [15610/20508], Loss: 0.6884\n",
      "Epoch [5/30], Batch [15620/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [15630/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [15640/20508], Loss: 0.6845\n",
      "Epoch [5/30], Batch [15650/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [15660/20508], Loss: 0.7054\n",
      "Epoch [5/30], Batch [15670/20508], Loss: 0.6798\n",
      "Epoch [5/30], Batch [15680/20508], Loss: 0.7037\n",
      "Epoch [5/30], Batch [15690/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [15700/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [15710/20508], Loss: 0.7175\n",
      "Epoch [5/30], Batch [15720/20508], Loss: 0.6656\n",
      "Epoch [5/30], Batch [15730/20508], Loss: 0.6995\n",
      "Epoch [5/30], Batch [15740/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [15750/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [15760/20508], Loss: 0.6914\n",
      "Epoch [5/30], Batch [15770/20508], Loss: 0.7011\n",
      "Epoch [5/30], Batch [15780/20508], Loss: 0.6696\n",
      "Epoch [5/30], Batch [15790/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [15800/20508], Loss: 0.7093\n",
      "Epoch [5/30], Batch [15810/20508], Loss: 0.6701\n",
      "Epoch [5/30], Batch [15820/20508], Loss: 0.7098\n",
      "Epoch [5/30], Batch [15830/20508], Loss: 0.6770\n",
      "Epoch [5/30], Batch [15840/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [15850/20508], Loss: 0.6906\n",
      "Epoch [5/30], Batch [15860/20508], Loss: 0.7078\n",
      "Epoch [5/30], Batch [15870/20508], Loss: 0.7002\n",
      "Epoch [5/30], Batch [15880/20508], Loss: 0.7071\n",
      "Epoch [5/30], Batch [15890/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [15900/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [15910/20508], Loss: 0.7081\n",
      "Epoch [5/30], Batch [15920/20508], Loss: 0.6826\n",
      "Epoch [5/30], Batch [15930/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [15940/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [15950/20508], Loss: 0.6777\n",
      "Epoch [5/30], Batch [15960/20508], Loss: 0.6850\n",
      "Epoch [5/30], Batch [15970/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [15980/20508], Loss: 0.7089\n",
      "Epoch [5/30], Batch [15990/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [16000/20508], Loss: 0.7050\n",
      "Epoch [5/30], Batch [16010/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [16020/20508], Loss: 0.6801\n",
      "Epoch [5/30], Batch [16030/20508], Loss: 0.6921\n",
      "Epoch [5/30], Batch [16040/20508], Loss: 0.6989\n",
      "Epoch [5/30], Batch [16050/20508], Loss: 0.6887\n",
      "Epoch [5/30], Batch [16060/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [16070/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [16080/20508], Loss: 0.7057\n",
      "Epoch [5/30], Batch [16090/20508], Loss: 0.7019\n",
      "Epoch [5/30], Batch [16100/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [16110/20508], Loss: 0.6961\n",
      "Epoch [5/30], Batch [16120/20508], Loss: 0.6734\n",
      "Epoch [5/30], Batch [16130/20508], Loss: 0.6929\n",
      "Epoch [5/30], Batch [16140/20508], Loss: 0.7104\n",
      "Epoch [5/30], Batch [16150/20508], Loss: 0.6827\n",
      "Epoch [5/30], Batch [16160/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [16170/20508], Loss: 0.6714\n",
      "Epoch [5/30], Batch [16180/20508], Loss: 0.6843\n",
      "Epoch [5/30], Batch [16190/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [16200/20508], Loss: 0.6868\n",
      "Epoch [5/30], Batch [16210/20508], Loss: 0.7063\n",
      "Epoch [5/30], Batch [16220/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [16230/20508], Loss: 0.6785\n",
      "Epoch [5/30], Batch [16240/20508], Loss: 0.6742\n",
      "Epoch [5/30], Batch [16250/20508], Loss: 0.6674\n",
      "Epoch [5/30], Batch [16260/20508], Loss: 0.6744\n",
      "Epoch [5/30], Batch [16270/20508], Loss: 0.6701\n",
      "Epoch [5/30], Batch [16280/20508], Loss: 0.6713\n",
      "Epoch [5/30], Batch [16290/20508], Loss: 0.6956\n",
      "Epoch [5/30], Batch [16300/20508], Loss: 0.6829\n",
      "Epoch [5/30], Batch [16310/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [16320/20508], Loss: 0.7035\n",
      "Epoch [5/30], Batch [16330/20508], Loss: 0.6927\n",
      "Epoch [5/30], Batch [16340/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [16350/20508], Loss: 0.6784\n",
      "Epoch [5/30], Batch [16360/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [16370/20508], Loss: 0.7030\n",
      "Epoch [5/30], Batch [16380/20508], Loss: 0.7112\n",
      "Epoch [5/30], Batch [16390/20508], Loss: 0.7036\n",
      "Epoch [5/30], Batch [16400/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [16410/20508], Loss: 0.6738\n",
      "Epoch [5/30], Batch [16420/20508], Loss: 0.6875\n",
      "Epoch [5/30], Batch [16430/20508], Loss: 0.7027\n",
      "Epoch [5/30], Batch [16440/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [16450/20508], Loss: 0.7281\n",
      "Epoch [5/30], Batch [16460/20508], Loss: 0.7062\n",
      "Epoch [5/30], Batch [16470/20508], Loss: 0.6904\n",
      "Epoch [5/30], Batch [16480/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [16490/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [16500/20508], Loss: 0.7173\n",
      "Epoch [5/30], Batch [16510/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [16520/20508], Loss: 0.7021\n",
      "Epoch [5/30], Batch [16530/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [16540/20508], Loss: 0.7086\n",
      "Epoch [5/30], Batch [16550/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [16560/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [16570/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [16580/20508], Loss: 0.6999\n",
      "Epoch [5/30], Batch [16590/20508], Loss: 0.6794\n",
      "Epoch [5/30], Batch [16600/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [16610/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [16620/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [16630/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [16640/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [16650/20508], Loss: 0.6693\n",
      "Epoch [5/30], Batch [16660/20508], Loss: 0.6729\n",
      "Epoch [5/30], Batch [16670/20508], Loss: 0.6979\n",
      "Epoch [5/30], Batch [16680/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [16690/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [16700/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [16710/20508], Loss: 0.6778\n",
      "Epoch [5/30], Batch [16720/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [16730/20508], Loss: 0.6976\n",
      "Epoch [5/30], Batch [16740/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [16750/20508], Loss: 0.6988\n",
      "Epoch [5/30], Batch [16760/20508], Loss: 0.6744\n",
      "Epoch [5/30], Batch [16770/20508], Loss: 0.6870\n",
      "Epoch [5/30], Batch [16780/20508], Loss: 0.6725\n",
      "Epoch [5/30], Batch [16790/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [16800/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [16810/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [16820/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [16830/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [16840/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [16850/20508], Loss: 0.6648\n",
      "Epoch [5/30], Batch [16860/20508], Loss: 0.6913\n",
      "Epoch [5/30], Batch [16870/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [16880/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [16890/20508], Loss: 0.7060\n",
      "Epoch [5/30], Batch [16900/20508], Loss: 0.6742\n",
      "Epoch [5/30], Batch [16910/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [16920/20508], Loss: 0.7079\n",
      "Epoch [5/30], Batch [16930/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [16940/20508], Loss: 0.6761\n",
      "Epoch [5/30], Batch [16950/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [16960/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [16970/20508], Loss: 0.6949\n",
      "Epoch [5/30], Batch [16980/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [16990/20508], Loss: 0.7023\n",
      "Epoch [5/30], Batch [17000/20508], Loss: 0.6697\n",
      "Epoch [5/30], Batch [17010/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [17020/20508], Loss: 0.6869\n",
      "Epoch [5/30], Batch [17030/20508], Loss: 0.6793\n",
      "Epoch [5/30], Batch [17040/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [17050/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [17060/20508], Loss: 0.6841\n",
      "Epoch [5/30], Batch [17070/20508], Loss: 0.7062\n",
      "Epoch [5/30], Batch [17080/20508], Loss: 0.6922\n",
      "Epoch [5/30], Batch [17090/20508], Loss: 0.6717\n",
      "Epoch [5/30], Batch [17100/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [17110/20508], Loss: 0.7203\n",
      "Epoch [5/30], Batch [17120/20508], Loss: 0.6989\n",
      "Epoch [5/30], Batch [17130/20508], Loss: 0.6915\n",
      "Epoch [5/30], Batch [17140/20508], Loss: 0.7023\n",
      "Epoch [5/30], Batch [17150/20508], Loss: 0.6760\n",
      "Epoch [5/30], Batch [17160/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [17170/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [17180/20508], Loss: 0.6736\n",
      "Epoch [5/30], Batch [17190/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [17200/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [17210/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [17220/20508], Loss: 0.6671\n",
      "Epoch [5/30], Batch [17230/20508], Loss: 0.6621\n",
      "Epoch [5/30], Batch [17240/20508], Loss: 0.6894\n",
      "Epoch [5/30], Batch [17250/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [17260/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [17270/20508], Loss: 0.6959\n",
      "Epoch [5/30], Batch [17280/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [17290/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [17300/20508], Loss: 0.6770\n",
      "Epoch [5/30], Batch [17310/20508], Loss: 0.7025\n",
      "Epoch [5/30], Batch [17320/20508], Loss: 0.6845\n",
      "Epoch [5/30], Batch [17330/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [17340/20508], Loss: 0.7009\n",
      "Epoch [5/30], Batch [17350/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [17360/20508], Loss: 0.7042\n",
      "Epoch [5/30], Batch [17370/20508], Loss: 0.6979\n",
      "Epoch [5/30], Batch [17380/20508], Loss: 0.6962\n",
      "Epoch [5/30], Batch [17390/20508], Loss: 0.6814\n",
      "Epoch [5/30], Batch [17400/20508], Loss: 0.7057\n",
      "Epoch [5/30], Batch [17410/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [17420/20508], Loss: 0.6964\n",
      "Epoch [5/30], Batch [17430/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [17440/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [17450/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [17460/20508], Loss: 0.7068\n",
      "Epoch [5/30], Batch [17470/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [17480/20508], Loss: 0.6938\n",
      "Epoch [5/30], Batch [17490/20508], Loss: 0.6946\n",
      "Epoch [5/30], Batch [17500/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [17510/20508], Loss: 0.7179\n",
      "Epoch [5/30], Batch [17520/20508], Loss: 0.6970\n",
      "Epoch [5/30], Batch [17530/20508], Loss: 0.7021\n",
      "Epoch [5/30], Batch [17540/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [17550/20508], Loss: 0.6755\n",
      "Epoch [5/30], Batch [17560/20508], Loss: 0.6855\n",
      "Epoch [5/30], Batch [17570/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [17580/20508], Loss: 0.6895\n",
      "Epoch [5/30], Batch [17590/20508], Loss: 0.6744\n",
      "Epoch [5/30], Batch [17600/20508], Loss: 0.6958\n",
      "Epoch [5/30], Batch [17610/20508], Loss: 0.6797\n",
      "Epoch [5/30], Batch [17620/20508], Loss: 0.6821\n",
      "Epoch [5/30], Batch [17630/20508], Loss: 0.6903\n",
      "Epoch [5/30], Batch [17640/20508], Loss: 0.7050\n",
      "Epoch [5/30], Batch [17650/20508], Loss: 0.6785\n",
      "Epoch [5/30], Batch [17660/20508], Loss: 0.6995\n",
      "Epoch [5/30], Batch [17670/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [17680/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [17690/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [17700/20508], Loss: 0.6920\n",
      "Epoch [5/30], Batch [17710/20508], Loss: 0.6811\n",
      "Epoch [5/30], Batch [17720/20508], Loss: 0.6848\n",
      "Epoch [5/30], Batch [17730/20508], Loss: 0.6649\n",
      "Epoch [5/30], Batch [17740/20508], Loss: 0.6706\n",
      "Epoch [5/30], Batch [17750/20508], Loss: 0.6994\n",
      "Epoch [5/30], Batch [17760/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [17770/20508], Loss: 0.6964\n",
      "Epoch [5/30], Batch [17780/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [17790/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [17800/20508], Loss: 0.6562\n",
      "Epoch [5/30], Batch [17810/20508], Loss: 0.6712\n",
      "Epoch [5/30], Batch [17820/20508], Loss: 0.6924\n",
      "Epoch [5/30], Batch [17830/20508], Loss: 0.6772\n",
      "Epoch [5/30], Batch [17840/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [17850/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [17860/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [17870/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [17880/20508], Loss: 0.6860\n",
      "Epoch [5/30], Batch [17890/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [17900/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [17910/20508], Loss: 0.6691\n",
      "Epoch [5/30], Batch [17920/20508], Loss: 0.6767\n",
      "Epoch [5/30], Batch [17930/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [17940/20508], Loss: 0.6717\n",
      "Epoch [5/30], Batch [17950/20508], Loss: 0.6845\n",
      "Epoch [5/30], Batch [17960/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [17970/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [17980/20508], Loss: 0.7054\n",
      "Epoch [5/30], Batch [17990/20508], Loss: 0.6853\n",
      "Epoch [5/30], Batch [18000/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [18010/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [18020/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [18030/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [18040/20508], Loss: 0.6909\n",
      "Epoch [5/30], Batch [18050/20508], Loss: 0.7128\n",
      "Epoch [5/30], Batch [18060/20508], Loss: 0.6789\n",
      "Epoch [5/30], Batch [18070/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [18080/20508], Loss: 0.7100\n",
      "Epoch [5/30], Batch [18090/20508], Loss: 0.6556\n",
      "Epoch [5/30], Batch [18100/20508], Loss: 0.6685\n",
      "Epoch [5/30], Batch [18110/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [18120/20508], Loss: 0.6822\n",
      "Epoch [5/30], Batch [18130/20508], Loss: 0.6940\n",
      "Epoch [5/30], Batch [18140/20508], Loss: 0.7083\n",
      "Epoch [5/30], Batch [18150/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [18160/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [18170/20508], Loss: 0.6921\n",
      "Epoch [5/30], Batch [18180/20508], Loss: 0.6914\n",
      "Epoch [5/30], Batch [18190/20508], Loss: 0.6855\n",
      "Epoch [5/30], Batch [18200/20508], Loss: 0.6982\n",
      "Epoch [5/30], Batch [18210/20508], Loss: 0.6994\n",
      "Epoch [5/30], Batch [18220/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [18230/20508], Loss: 0.7036\n",
      "Epoch [5/30], Batch [18240/20508], Loss: 0.6939\n",
      "Epoch [5/30], Batch [18250/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [18260/20508], Loss: 0.6919\n",
      "Epoch [5/30], Batch [18270/20508], Loss: 0.6928\n",
      "Epoch [5/30], Batch [18280/20508], Loss: 0.7140\n",
      "Epoch [5/30], Batch [18290/20508], Loss: 0.6934\n",
      "Epoch [5/30], Batch [18300/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [18310/20508], Loss: 0.6725\n",
      "Epoch [5/30], Batch [18320/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [18330/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [18340/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [18350/20508], Loss: 0.6846\n",
      "Epoch [5/30], Batch [18360/20508], Loss: 0.6883\n",
      "Epoch [5/30], Batch [18370/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [18380/20508], Loss: 0.6852\n",
      "Epoch [5/30], Batch [18390/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [18400/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [18410/20508], Loss: 0.6898\n",
      "Epoch [5/30], Batch [18420/20508], Loss: 0.6856\n",
      "Epoch [5/30], Batch [18430/20508], Loss: 0.6823\n",
      "Epoch [5/30], Batch [18440/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [18450/20508], Loss: 0.6843\n",
      "Epoch [5/30], Batch [18460/20508], Loss: 0.6715\n",
      "Epoch [5/30], Batch [18470/20508], Loss: 0.6718\n",
      "Epoch [5/30], Batch [18480/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [18490/20508], Loss: 0.6912\n",
      "Epoch [5/30], Batch [18500/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [18510/20508], Loss: 0.6783\n",
      "Epoch [5/30], Batch [18520/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [18530/20508], Loss: 0.6882\n",
      "Epoch [5/30], Batch [18540/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [18550/20508], Loss: 0.6730\n",
      "Epoch [5/30], Batch [18560/20508], Loss: 0.7080\n",
      "Epoch [5/30], Batch [18570/20508], Loss: 0.6838\n",
      "Epoch [5/30], Batch [18580/20508], Loss: 0.6694\n",
      "Epoch [5/30], Batch [18590/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [18600/20508], Loss: 0.6799\n",
      "Epoch [5/30], Batch [18610/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [18620/20508], Loss: 0.7019\n",
      "Epoch [5/30], Batch [18630/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [18640/20508], Loss: 0.6777\n",
      "Epoch [5/30], Batch [18650/20508], Loss: 0.6839\n",
      "Epoch [5/30], Batch [18660/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [18670/20508], Loss: 0.7001\n",
      "Epoch [5/30], Batch [18680/20508], Loss: 0.6861\n",
      "Epoch [5/30], Batch [18690/20508], Loss: 0.7091\n",
      "Epoch [5/30], Batch [18700/20508], Loss: 0.6960\n",
      "Epoch [5/30], Batch [18710/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [18720/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [18730/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [18740/20508], Loss: 0.7010\n",
      "Epoch [5/30], Batch [18750/20508], Loss: 0.6805\n",
      "Epoch [5/30], Batch [18760/20508], Loss: 0.6992\n",
      "Epoch [5/30], Batch [18770/20508], Loss: 0.6995\n",
      "Epoch [5/30], Batch [18780/20508], Loss: 0.7005\n",
      "Epoch [5/30], Batch [18790/20508], Loss: 0.6933\n",
      "Epoch [5/30], Batch [18800/20508], Loss: 0.6844\n",
      "Epoch [5/30], Batch [18810/20508], Loss: 0.6966\n",
      "Epoch [5/30], Batch [18820/20508], Loss: 0.6760\n",
      "Epoch [5/30], Batch [18830/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [18840/20508], Loss: 0.6955\n",
      "Epoch [5/30], Batch [18850/20508], Loss: 0.6810\n",
      "Epoch [5/30], Batch [18860/20508], Loss: 0.6869\n",
      "Epoch [5/30], Batch [18870/20508], Loss: 0.6866\n",
      "Epoch [5/30], Batch [18880/20508], Loss: 0.6902\n",
      "Epoch [5/30], Batch [18890/20508], Loss: 0.6987\n",
      "Epoch [5/30], Batch [18900/20508], Loss: 0.7009\n",
      "Epoch [5/30], Batch [18910/20508], Loss: 0.6720\n",
      "Epoch [5/30], Batch [18920/20508], Loss: 0.7017\n",
      "Epoch [5/30], Batch [18930/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [18940/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [18950/20508], Loss: 0.7055\n",
      "Epoch [5/30], Batch [18960/20508], Loss: 0.6957\n",
      "Epoch [5/30], Batch [18970/20508], Loss: 0.6818\n",
      "Epoch [5/30], Batch [18980/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [18990/20508], Loss: 0.6786\n",
      "Epoch [5/30], Batch [19000/20508], Loss: 0.7007\n",
      "Epoch [5/30], Batch [19010/20508], Loss: 0.6979\n",
      "Epoch [5/30], Batch [19020/20508], Loss: 0.6737\n",
      "Epoch [5/30], Batch [19030/20508], Loss: 0.6792\n",
      "Epoch [5/30], Batch [19040/20508], Loss: 0.6942\n",
      "Epoch [5/30], Batch [19050/20508], Loss: 0.7029\n",
      "Epoch [5/30], Batch [19060/20508], Loss: 0.6854\n",
      "Epoch [5/30], Batch [19070/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [19080/20508], Loss: 0.6885\n",
      "Epoch [5/30], Batch [19090/20508], Loss: 0.6874\n",
      "Epoch [5/30], Batch [19100/20508], Loss: 0.6760\n",
      "Epoch [5/30], Batch [19110/20508], Loss: 0.6936\n",
      "Epoch [5/30], Batch [19120/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [19130/20508], Loss: 0.6786\n",
      "Epoch [5/30], Batch [19140/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [19150/20508], Loss: 0.6802\n",
      "Epoch [5/30], Batch [19160/20508], Loss: 0.6746\n",
      "Epoch [5/30], Batch [19170/20508], Loss: 0.6984\n",
      "Epoch [5/30], Batch [19180/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [19190/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [19200/20508], Loss: 0.6972\n",
      "Epoch [5/30], Batch [19210/20508], Loss: 0.7025\n",
      "Epoch [5/30], Batch [19220/20508], Loss: 0.6750\n",
      "Epoch [5/30], Batch [19230/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [19240/20508], Loss: 0.7076\n",
      "Epoch [5/30], Batch [19250/20508], Loss: 0.7070\n",
      "Epoch [5/30], Batch [19260/20508], Loss: 0.6788\n",
      "Epoch [5/30], Batch [19270/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [19280/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [19290/20508], Loss: 0.6700\n",
      "Epoch [5/30], Batch [19300/20508], Loss: 0.6961\n",
      "Epoch [5/30], Batch [19310/20508], Loss: 0.6879\n",
      "Epoch [5/30], Batch [19320/20508], Loss: 0.6692\n",
      "Epoch [5/30], Batch [19330/20508], Loss: 0.6768\n",
      "Epoch [5/30], Batch [19340/20508], Loss: 0.6803\n",
      "Epoch [5/30], Batch [19350/20508], Loss: 0.6917\n",
      "Epoch [5/30], Batch [19360/20508], Loss: 0.6725\n",
      "Epoch [5/30], Batch [19370/20508], Loss: 0.6876\n",
      "Epoch [5/30], Batch [19380/20508], Loss: 0.6820\n",
      "Epoch [5/30], Batch [19390/20508], Loss: 0.6760\n",
      "Epoch [5/30], Batch [19400/20508], Loss: 0.6918\n",
      "Epoch [5/30], Batch [19410/20508], Loss: 0.6862\n",
      "Epoch [5/30], Batch [19420/20508], Loss: 0.7038\n",
      "Epoch [5/30], Batch [19430/20508], Loss: 0.6947\n",
      "Epoch [5/30], Batch [19440/20508], Loss: 0.6986\n",
      "Epoch [5/30], Batch [19450/20508], Loss: 0.6891\n",
      "Epoch [5/30], Batch [19460/20508], Loss: 0.6921\n",
      "Epoch [5/30], Batch [19470/20508], Loss: 0.6739\n",
      "Epoch [5/30], Batch [19480/20508], Loss: 0.6896\n",
      "Epoch [5/30], Batch [19490/20508], Loss: 0.6926\n",
      "Epoch [5/30], Batch [19500/20508], Loss: 0.6806\n",
      "Epoch [5/30], Batch [19510/20508], Loss: 0.7074\n",
      "Epoch [5/30], Batch [19520/20508], Loss: 0.6899\n",
      "Epoch [5/30], Batch [19530/20508], Loss: 0.6847\n",
      "Epoch [5/30], Batch [19540/20508], Loss: 0.6731\n",
      "Epoch [5/30], Batch [19550/20508], Loss: 0.6652\n",
      "Epoch [5/30], Batch [19560/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [19570/20508], Loss: 0.6900\n",
      "Epoch [5/30], Batch [19580/20508], Loss: 0.6981\n",
      "Epoch [5/30], Batch [19590/20508], Loss: 0.6843\n",
      "Epoch [5/30], Batch [19600/20508], Loss: 0.7046\n",
      "Epoch [5/30], Batch [19610/20508], Loss: 0.7099\n",
      "Epoch [5/30], Batch [19620/20508], Loss: 0.7010\n",
      "Epoch [5/30], Batch [19630/20508], Loss: 0.6954\n",
      "Epoch [5/30], Batch [19640/20508], Loss: 0.6878\n",
      "Epoch [5/30], Batch [19650/20508], Loss: 0.6886\n",
      "Epoch [5/30], Batch [19660/20508], Loss: 0.6830\n",
      "Epoch [5/30], Batch [19670/20508], Loss: 0.6925\n",
      "Epoch [5/30], Batch [19680/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [19690/20508], Loss: 0.6877\n",
      "Epoch [5/30], Batch [19700/20508], Loss: 0.6967\n",
      "Epoch [5/30], Batch [19710/20508], Loss: 0.6790\n",
      "Epoch [5/30], Batch [19720/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [19730/20508], Loss: 0.6893\n",
      "Epoch [5/30], Batch [19740/20508], Loss: 0.6975\n",
      "Epoch [5/30], Batch [19750/20508], Loss: 0.7017\n",
      "Epoch [5/30], Batch [19760/20508], Loss: 0.6720\n",
      "Epoch [5/30], Batch [19770/20508], Loss: 0.6973\n",
      "Epoch [5/30], Batch [19780/20508], Loss: 0.6979\n",
      "Epoch [5/30], Batch [19790/20508], Loss: 0.6872\n",
      "Epoch [5/30], Batch [19800/20508], Loss: 0.6890\n",
      "Epoch [5/30], Batch [19810/20508], Loss: 0.6932\n",
      "Epoch [5/30], Batch [19820/20508], Loss: 0.6948\n",
      "Epoch [5/30], Batch [19830/20508], Loss: 0.6707\n",
      "Epoch [5/30], Batch [19840/20508], Loss: 0.6977\n",
      "Epoch [5/30], Batch [19850/20508], Loss: 0.6795\n",
      "Epoch [5/30], Batch [19860/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [19870/20508], Loss: 0.6865\n",
      "Epoch [5/30], Batch [19880/20508], Loss: 0.6791\n",
      "Epoch [5/30], Batch [19890/20508], Loss: 0.6794\n",
      "Epoch [5/30], Batch [19900/20508], Loss: 0.7061\n",
      "Epoch [5/30], Batch [19910/20508], Loss: 0.6837\n",
      "Epoch [5/30], Batch [19920/20508], Loss: 0.6997\n",
      "Epoch [5/30], Batch [19930/20508], Loss: 0.6908\n",
      "Epoch [5/30], Batch [19940/20508], Loss: 0.6666\n",
      "Epoch [5/30], Batch [19950/20508], Loss: 0.6772\n",
      "Epoch [5/30], Batch [19960/20508], Loss: 0.6969\n",
      "Epoch [5/30], Batch [19970/20508], Loss: 0.7027\n",
      "Epoch [5/30], Batch [19980/20508], Loss: 0.6871\n",
      "Epoch [5/30], Batch [19990/20508], Loss: 0.7004\n",
      "Epoch [5/30], Batch [20000/20508], Loss: 0.6931\n",
      "Epoch [5/30], Batch [20010/20508], Loss: 0.7007\n",
      "Epoch [5/30], Batch [20020/20508], Loss: 0.6759\n",
      "Epoch [5/30], Batch [20030/20508], Loss: 0.6808\n",
      "Epoch [5/30], Batch [20040/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [20050/20508], Loss: 0.6943\n",
      "Epoch [5/30], Batch [20060/20508], Loss: 0.6757\n",
      "Epoch [5/30], Batch [20070/20508], Loss: 0.7076\n",
      "Epoch [5/30], Batch [20080/20508], Loss: 0.6655\n",
      "Epoch [5/30], Batch [20090/20508], Loss: 0.6884\n",
      "Epoch [5/30], Batch [20100/20508], Loss: 0.7000\n",
      "Epoch [5/30], Batch [20110/20508], Loss: 0.6816\n",
      "Epoch [5/30], Batch [20120/20508], Loss: 0.6911\n",
      "Epoch [5/30], Batch [20130/20508], Loss: 0.6840\n",
      "Epoch [5/30], Batch [20140/20508], Loss: 0.6993\n",
      "Epoch [5/30], Batch [20150/20508], Loss: 0.7048\n",
      "Epoch [5/30], Batch [20160/20508], Loss: 0.6767\n",
      "Epoch [5/30], Batch [20170/20508], Loss: 0.6952\n",
      "Epoch [5/30], Batch [20180/20508], Loss: 0.6868\n",
      "Epoch [5/30], Batch [20190/20508], Loss: 0.6916\n",
      "Epoch [5/30], Batch [20200/20508], Loss: 0.7006\n",
      "Epoch [5/30], Batch [20210/20508], Loss: 0.6907\n",
      "Epoch [5/30], Batch [20220/20508], Loss: 0.6950\n",
      "Epoch [5/30], Batch [20230/20508], Loss: 0.6781\n",
      "Epoch [5/30], Batch [20240/20508], Loss: 0.6968\n",
      "Epoch [5/30], Batch [20250/20508], Loss: 0.6858\n",
      "Epoch [5/30], Batch [20260/20508], Loss: 0.6805\n",
      "Epoch [5/30], Batch [20270/20508], Loss: 0.6994\n",
      "Epoch [5/30], Batch [20280/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [20290/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [20300/20508], Loss: 0.6778\n",
      "Epoch [5/30], Batch [20310/20508], Loss: 0.6857\n",
      "Epoch [5/30], Batch [20320/20508], Loss: 0.6813\n",
      "Epoch [5/30], Batch [20330/20508], Loss: 0.6849\n",
      "Epoch [5/30], Batch [20340/20508], Loss: 0.6849\n",
      "Epoch [5/30], Batch [20350/20508], Loss: 0.7047\n",
      "Epoch [5/30], Batch [20360/20508], Loss: 0.6945\n",
      "Epoch [5/30], Batch [20370/20508], Loss: 0.6807\n",
      "Epoch [5/30], Batch [20380/20508], Loss: 0.6881\n",
      "Epoch [5/30], Batch [20390/20508], Loss: 0.6944\n",
      "Epoch [5/30], Batch [20400/20508], Loss: 0.6957\n",
      "Epoch [5/30], Batch [20410/20508], Loss: 0.6905\n",
      "Epoch [5/30], Batch [20420/20508], Loss: 0.6864\n",
      "Epoch [5/30], Batch [20430/20508], Loss: 0.6644\n",
      "Epoch [5/30], Batch [20440/20508], Loss: 0.6953\n",
      "Epoch [5/30], Batch [20450/20508], Loss: 0.6832\n",
      "Epoch [5/30], Batch [20460/20508], Loss: 0.6867\n",
      "Epoch [5/30], Batch [20470/20508], Loss: 0.7045\n",
      "Epoch [5/30], Batch [20480/20508], Loss: 0.6819\n",
      "Epoch [5/30], Batch [20490/20508], Loss: 0.6910\n",
      "Epoch [5/30], Batch [20500/20508], Loss: 0.6802\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [5], Train Loss: 0.6889, Test Loss: 0.6872, Early Stopping Counter: 2\n",
      "\n",
      "\n",
      "\n",
      "Epoch [6/30], Batch [0/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [10/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [20/20508], Loss: 0.6738\n",
      "Epoch [6/30], Batch [30/20508], Loss: 0.6957\n",
      "Epoch [6/30], Batch [40/20508], Loss: 0.6986\n",
      "Epoch [6/30], Batch [50/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [60/20508], Loss: 0.6651\n",
      "Epoch [6/30], Batch [70/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [80/20508], Loss: 0.6935\n",
      "Epoch [6/30], Batch [90/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [100/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [110/20508], Loss: 0.6913\n",
      "Epoch [6/30], Batch [120/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [130/20508], Loss: 0.6672\n",
      "Epoch [6/30], Batch [140/20508], Loss: 0.6755\n",
      "Epoch [6/30], Batch [150/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [160/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [170/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [180/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [190/20508], Loss: 0.6799\n",
      "Epoch [6/30], Batch [200/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [210/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [220/20508], Loss: 0.6869\n",
      "Epoch [6/30], Batch [230/20508], Loss: 0.6781\n",
      "Epoch [6/30], Batch [240/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [250/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [260/20508], Loss: 0.7033\n",
      "Epoch [6/30], Batch [270/20508], Loss: 0.6777\n",
      "Epoch [6/30], Batch [280/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [290/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [300/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [310/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [320/20508], Loss: 0.6929\n",
      "Epoch [6/30], Batch [330/20508], Loss: 0.6734\n",
      "Epoch [6/30], Batch [340/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [350/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [360/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [370/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [380/20508], Loss: 0.6904\n",
      "Epoch [6/30], Batch [390/20508], Loss: 0.6989\n",
      "Epoch [6/30], Batch [400/20508], Loss: 0.6776\n",
      "Epoch [6/30], Batch [410/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [420/20508], Loss: 0.6970\n",
      "Epoch [6/30], Batch [430/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [440/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [450/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [460/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [470/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [480/20508], Loss: 0.6784\n",
      "Epoch [6/30], Batch [490/20508], Loss: 0.6852\n",
      "Epoch [6/30], Batch [500/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [510/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [520/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [530/20508], Loss: 0.6723\n",
      "Epoch [6/30], Batch [540/20508], Loss: 0.6930\n",
      "Epoch [6/30], Batch [550/20508], Loss: 0.6869\n",
      "Epoch [6/30], Batch [560/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [570/20508], Loss: 0.7088\n",
      "Epoch [6/30], Batch [580/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [590/20508], Loss: 0.6912\n",
      "Epoch [6/30], Batch [600/20508], Loss: 0.7118\n",
      "Epoch [6/30], Batch [610/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [620/20508], Loss: 0.6787\n",
      "Epoch [6/30], Batch [630/20508], Loss: 0.7091\n",
      "Epoch [6/30], Batch [640/20508], Loss: 0.6800\n",
      "Epoch [6/30], Batch [650/20508], Loss: 0.6713\n",
      "Epoch [6/30], Batch [660/20508], Loss: 0.6849\n",
      "Epoch [6/30], Batch [670/20508], Loss: 0.6733\n",
      "Epoch [6/30], Batch [680/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [690/20508], Loss: 0.6646\n",
      "Epoch [6/30], Batch [700/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [710/20508], Loss: 0.6777\n",
      "Epoch [6/30], Batch [720/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [730/20508], Loss: 0.6748\n",
      "Epoch [6/30], Batch [740/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [750/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [760/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [770/20508], Loss: 0.6741\n",
      "Epoch [6/30], Batch [780/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [790/20508], Loss: 0.6753\n",
      "Epoch [6/30], Batch [800/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [810/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [820/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [830/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [840/20508], Loss: 0.6783\n",
      "Epoch [6/30], Batch [850/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [860/20508], Loss: 0.6870\n",
      "Epoch [6/30], Batch [870/20508], Loss: 0.6778\n",
      "Epoch [6/30], Batch [880/20508], Loss: 0.7074\n",
      "Epoch [6/30], Batch [890/20508], Loss: 0.6741\n",
      "Epoch [6/30], Batch [900/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [910/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [920/20508], Loss: 0.6723\n",
      "Epoch [6/30], Batch [930/20508], Loss: 0.6804\n",
      "Epoch [6/30], Batch [940/20508], Loss: 0.6737\n",
      "Epoch [6/30], Batch [950/20508], Loss: 0.7179\n",
      "Epoch [6/30], Batch [960/20508], Loss: 0.7062\n",
      "Epoch [6/30], Batch [970/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [980/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [990/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [1000/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [1010/20508], Loss: 0.6903\n",
      "Epoch [6/30], Batch [1020/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [1030/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [1040/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [1050/20508], Loss: 0.7271\n",
      "Epoch [6/30], Batch [1060/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [1070/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [1080/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [1090/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [1100/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [1110/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [1120/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [1130/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [1140/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [1150/20508], Loss: 0.6788\n",
      "Epoch [6/30], Batch [1160/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [1170/20508], Loss: 0.6960\n",
      "Epoch [6/30], Batch [1180/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [1190/20508], Loss: 0.6913\n",
      "Epoch [6/30], Batch [1200/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [1210/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [1220/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [1230/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [1240/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [1250/20508], Loss: 0.6921\n",
      "Epoch [6/30], Batch [1260/20508], Loss: 0.6880\n",
      "Epoch [6/30], Batch [1270/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [1280/20508], Loss: 0.6913\n",
      "Epoch [6/30], Batch [1290/20508], Loss: 0.6964\n",
      "Epoch [6/30], Batch [1300/20508], Loss: 0.6903\n",
      "Epoch [6/30], Batch [1310/20508], Loss: 0.7085\n",
      "Epoch [6/30], Batch [1320/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [1330/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [1340/20508], Loss: 0.7062\n",
      "Epoch [6/30], Batch [1350/20508], Loss: 0.6999\n",
      "Epoch [6/30], Batch [1360/20508], Loss: 0.6989\n",
      "Epoch [6/30], Batch [1370/20508], Loss: 0.7042\n",
      "Epoch [6/30], Batch [1380/20508], Loss: 0.6765\n",
      "Epoch [6/30], Batch [1390/20508], Loss: 0.6645\n",
      "Epoch [6/30], Batch [1400/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [1410/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [1420/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [1430/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [1440/20508], Loss: 0.6794\n",
      "Epoch [6/30], Batch [1450/20508], Loss: 0.6981\n",
      "Epoch [6/30], Batch [1460/20508], Loss: 0.6880\n",
      "Epoch [6/30], Batch [1470/20508], Loss: 0.6895\n",
      "Epoch [6/30], Batch [1480/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [1490/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [1500/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [1510/20508], Loss: 0.6984\n",
      "Epoch [6/30], Batch [1520/20508], Loss: 0.6645\n",
      "Epoch [6/30], Batch [1530/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [1540/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [1550/20508], Loss: 0.7025\n",
      "Epoch [6/30], Batch [1560/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [1570/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [1580/20508], Loss: 0.7153\n",
      "Epoch [6/30], Batch [1590/20508], Loss: 0.6771\n",
      "Epoch [6/30], Batch [1600/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [1610/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [1620/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [1630/20508], Loss: 0.6782\n",
      "Epoch [6/30], Batch [1640/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [1650/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [1660/20508], Loss: 0.7135\n",
      "Epoch [6/30], Batch [1670/20508], Loss: 0.6613\n",
      "Epoch [6/30], Batch [1680/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [1690/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [1700/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [1710/20508], Loss: 0.6986\n",
      "Epoch [6/30], Batch [1720/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [1730/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [1740/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [1750/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [1760/20508], Loss: 0.6723\n",
      "Epoch [6/30], Batch [1770/20508], Loss: 0.7023\n",
      "Epoch [6/30], Batch [1780/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [1790/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [1800/20508], Loss: 0.7046\n",
      "Epoch [6/30], Batch [1810/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [1820/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [1830/20508], Loss: 0.6869\n",
      "Epoch [6/30], Batch [1840/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [1850/20508], Loss: 0.6898\n",
      "Epoch [6/30], Batch [1860/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [1870/20508], Loss: 0.6826\n",
      "Epoch [6/30], Batch [1880/20508], Loss: 0.6699\n",
      "Epoch [6/30], Batch [1890/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [1900/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [1910/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [1920/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [1930/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [1940/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [1950/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [1960/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [1970/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [1980/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [1990/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [2000/20508], Loss: 0.7045\n",
      "Epoch [6/30], Batch [2010/20508], Loss: 0.6871\n",
      "Epoch [6/30], Batch [2020/20508], Loss: 0.6856\n",
      "Epoch [6/30], Batch [2030/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [2040/20508], Loss: 0.6695\n",
      "Epoch [6/30], Batch [2050/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [2060/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [2070/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [2080/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [2090/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [2100/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [2110/20508], Loss: 0.7131\n",
      "Epoch [6/30], Batch [2120/20508], Loss: 0.7026\n",
      "Epoch [6/30], Batch [2130/20508], Loss: 0.7036\n",
      "Epoch [6/30], Batch [2140/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [2150/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [2160/20508], Loss: 0.6761\n",
      "Epoch [6/30], Batch [2170/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [2180/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [2190/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [2200/20508], Loss: 0.6972\n",
      "Epoch [6/30], Batch [2210/20508], Loss: 0.7224\n",
      "Epoch [6/30], Batch [2220/20508], Loss: 0.7025\n",
      "Epoch [6/30], Batch [2230/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [2240/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [2250/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [2260/20508], Loss: 0.6664\n",
      "Epoch [6/30], Batch [2270/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [2280/20508], Loss: 0.6745\n",
      "Epoch [6/30], Batch [2290/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [2300/20508], Loss: 0.7071\n",
      "Epoch [6/30], Batch [2310/20508], Loss: 0.6703\n",
      "Epoch [6/30], Batch [2320/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [2330/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [2340/20508], Loss: 0.6637\n",
      "Epoch [6/30], Batch [2350/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [2360/20508], Loss: 0.6699\n",
      "Epoch [6/30], Batch [2370/20508], Loss: 0.6952\n",
      "Epoch [6/30], Batch [2380/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [2390/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [2400/20508], Loss: 0.6785\n",
      "Epoch [6/30], Batch [2410/20508], Loss: 0.6938\n",
      "Epoch [6/30], Batch [2420/20508], Loss: 0.6742\n",
      "Epoch [6/30], Batch [2430/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [2440/20508], Loss: 0.7118\n",
      "Epoch [6/30], Batch [2450/20508], Loss: 0.6984\n",
      "Epoch [6/30], Batch [2460/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [2470/20508], Loss: 0.7074\n",
      "Epoch [6/30], Batch [2480/20508], Loss: 0.6733\n",
      "Epoch [6/30], Batch [2490/20508], Loss: 0.7011\n",
      "Epoch [6/30], Batch [2500/20508], Loss: 0.6997\n",
      "Epoch [6/30], Batch [2510/20508], Loss: 0.6912\n",
      "Epoch [6/30], Batch [2520/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [2530/20508], Loss: 0.7098\n",
      "Epoch [6/30], Batch [2540/20508], Loss: 0.6687\n",
      "Epoch [6/30], Batch [2550/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [2560/20508], Loss: 0.7041\n",
      "Epoch [6/30], Batch [2570/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [2580/20508], Loss: 0.7068\n",
      "Epoch [6/30], Batch [2590/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [2600/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [2610/20508], Loss: 0.6790\n",
      "Epoch [6/30], Batch [2620/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [2630/20508], Loss: 0.6970\n",
      "Epoch [6/30], Batch [2640/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [2650/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [2660/20508], Loss: 0.6935\n",
      "Epoch [6/30], Batch [2670/20508], Loss: 0.6962\n",
      "Epoch [6/30], Batch [2680/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [2690/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [2700/20508], Loss: 0.6768\n",
      "Epoch [6/30], Batch [2710/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [2720/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [2730/20508], Loss: 0.6636\n",
      "Epoch [6/30], Batch [2740/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [2750/20508], Loss: 0.7088\n",
      "Epoch [6/30], Batch [2760/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [2770/20508], Loss: 0.6913\n",
      "Epoch [6/30], Batch [2780/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [2790/20508], Loss: 0.6674\n",
      "Epoch [6/30], Batch [2800/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [2810/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [2820/20508], Loss: 0.6752\n",
      "Epoch [6/30], Batch [2830/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [2840/20508], Loss: 0.6763\n",
      "Epoch [6/30], Batch [2850/20508], Loss: 0.6989\n",
      "Epoch [6/30], Batch [2860/20508], Loss: 0.6899\n",
      "Epoch [6/30], Batch [2870/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [2880/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [2890/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [2900/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [2910/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [2920/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [2930/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [2940/20508], Loss: 0.7078\n",
      "Epoch [6/30], Batch [2950/20508], Loss: 0.7042\n",
      "Epoch [6/30], Batch [2960/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [2970/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [2980/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [2990/20508], Loss: 0.6675\n",
      "Epoch [6/30], Batch [3000/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [3010/20508], Loss: 0.7001\n",
      "Epoch [6/30], Batch [3020/20508], Loss: 0.6967\n",
      "Epoch [6/30], Batch [3030/20508], Loss: 0.7036\n",
      "Epoch [6/30], Batch [3040/20508], Loss: 0.7065\n",
      "Epoch [6/30], Batch [3050/20508], Loss: 0.6923\n",
      "Epoch [6/30], Batch [3060/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [3070/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [3080/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [3090/20508], Loss: 0.6999\n",
      "Epoch [6/30], Batch [3100/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [3110/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [3120/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [3130/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [3140/20508], Loss: 0.6815\n",
      "Epoch [6/30], Batch [3150/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [3160/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [3170/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [3180/20508], Loss: 0.6824\n",
      "Epoch [6/30], Batch [3190/20508], Loss: 0.6967\n",
      "Epoch [6/30], Batch [3200/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [3210/20508], Loss: 0.6960\n",
      "Epoch [6/30], Batch [3220/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [3230/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [3240/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [3250/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [3260/20508], Loss: 0.6849\n",
      "Epoch [6/30], Batch [3270/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [3280/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [3290/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [3300/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [3310/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [3320/20508], Loss: 0.7020\n",
      "Epoch [6/30], Batch [3330/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [3340/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [3350/20508], Loss: 0.7078\n",
      "Epoch [6/30], Batch [3360/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [3370/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [3380/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [3390/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [3400/20508], Loss: 0.6781\n",
      "Epoch [6/30], Batch [3410/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [3420/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [3430/20508], Loss: 0.6998\n",
      "Epoch [6/30], Batch [3440/20508], Loss: 0.6783\n",
      "Epoch [6/30], Batch [3450/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [3460/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [3470/20508], Loss: 0.6769\n",
      "Epoch [6/30], Batch [3480/20508], Loss: 0.6794\n",
      "Epoch [6/30], Batch [3490/20508], Loss: 0.6957\n",
      "Epoch [6/30], Batch [3500/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [3510/20508], Loss: 0.7025\n",
      "Epoch [6/30], Batch [3520/20508], Loss: 0.6710\n",
      "Epoch [6/30], Batch [3530/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [3540/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [3550/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [3560/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [3570/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [3580/20508], Loss: 0.7037\n",
      "Epoch [6/30], Batch [3590/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [3600/20508], Loss: 0.6971\n",
      "Epoch [6/30], Batch [3610/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [3620/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [3630/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [3640/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [3650/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [3660/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [3670/20508], Loss: 0.6742\n",
      "Epoch [6/30], Batch [3680/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [3690/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [3700/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [3710/20508], Loss: 0.7022\n",
      "Epoch [6/30], Batch [3720/20508], Loss: 0.6870\n",
      "Epoch [6/30], Batch [3730/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [3740/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [3750/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [3760/20508], Loss: 0.6914\n",
      "Epoch [6/30], Batch [3770/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [3780/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [3790/20508], Loss: 0.7000\n",
      "Epoch [6/30], Batch [3800/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [3810/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [3820/20508], Loss: 0.6799\n",
      "Epoch [6/30], Batch [3830/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [3840/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [3850/20508], Loss: 0.6795\n",
      "Epoch [6/30], Batch [3860/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [3870/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [3880/20508], Loss: 0.6989\n",
      "Epoch [6/30], Batch [3890/20508], Loss: 0.6720\n",
      "Epoch [6/30], Batch [3900/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [3910/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [3920/20508], Loss: 0.6680\n",
      "Epoch [6/30], Batch [3930/20508], Loss: 0.6990\n",
      "Epoch [6/30], Batch [3940/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [3950/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [3960/20508], Loss: 0.6818\n",
      "Epoch [6/30], Batch [3970/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [3980/20508], Loss: 0.6534\n",
      "Epoch [6/30], Batch [3990/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [4000/20508], Loss: 0.7038\n",
      "Epoch [6/30], Batch [4010/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [4020/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [4030/20508], Loss: 0.7022\n",
      "Epoch [6/30], Batch [4040/20508], Loss: 0.6982\n",
      "Epoch [6/30], Batch [4050/20508], Loss: 0.7023\n",
      "Epoch [6/30], Batch [4060/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [4070/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [4080/20508], Loss: 0.7095\n",
      "Epoch [6/30], Batch [4090/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [4100/20508], Loss: 0.6971\n",
      "Epoch [6/30], Batch [4110/20508], Loss: 0.6825\n",
      "Epoch [6/30], Batch [4120/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [4130/20508], Loss: 0.7072\n",
      "Epoch [6/30], Batch [4140/20508], Loss: 0.6754\n",
      "Epoch [6/30], Batch [4150/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [4160/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [4170/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [4180/20508], Loss: 0.6918\n",
      "Epoch [6/30], Batch [4190/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [4200/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [4210/20508], Loss: 0.6771\n",
      "Epoch [6/30], Batch [4220/20508], Loss: 0.6702\n",
      "Epoch [6/30], Batch [4230/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [4240/20508], Loss: 0.6742\n",
      "Epoch [6/30], Batch [4250/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [4260/20508], Loss: 0.7028\n",
      "Epoch [6/30], Batch [4270/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [4280/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [4290/20508], Loss: 0.6697\n",
      "Epoch [6/30], Batch [4300/20508], Loss: 0.6690\n",
      "Epoch [6/30], Batch [4310/20508], Loss: 0.6774\n",
      "Epoch [6/30], Batch [4320/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [4330/20508], Loss: 0.7151\n",
      "Epoch [6/30], Batch [4340/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [4350/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [4360/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [4370/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [4380/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [4390/20508], Loss: 0.6784\n",
      "Epoch [6/30], Batch [4400/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [4410/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [4420/20508], Loss: 0.7016\n",
      "Epoch [6/30], Batch [4430/20508], Loss: 0.6695\n",
      "Epoch [6/30], Batch [4440/20508], Loss: 0.6921\n",
      "Epoch [6/30], Batch [4450/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [4460/20508], Loss: 0.6874\n",
      "Epoch [6/30], Batch [4470/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [4480/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [4490/20508], Loss: 0.6818\n",
      "Epoch [6/30], Batch [4500/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [4510/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [4520/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [4530/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [4540/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [4550/20508], Loss: 0.6895\n",
      "Epoch [6/30], Batch [4560/20508], Loss: 0.6899\n",
      "Epoch [6/30], Batch [4570/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [4580/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [4590/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [4600/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [4610/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [4620/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [4630/20508], Loss: 0.6777\n",
      "Epoch [6/30], Batch [4640/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [4650/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [4660/20508], Loss: 0.7001\n",
      "Epoch [6/30], Batch [4670/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [4680/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [4690/20508], Loss: 0.6807\n",
      "Epoch [6/30], Batch [4700/20508], Loss: 0.7125\n",
      "Epoch [6/30], Batch [4710/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [4720/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [4730/20508], Loss: 0.6641\n",
      "Epoch [6/30], Batch [4740/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [4750/20508], Loss: 0.6747\n",
      "Epoch [6/30], Batch [4760/20508], Loss: 0.7090\n",
      "Epoch [6/30], Batch [4770/20508], Loss: 0.6726\n",
      "Epoch [6/30], Batch [4780/20508], Loss: 0.6964\n",
      "Epoch [6/30], Batch [4790/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [4800/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [4810/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [4820/20508], Loss: 0.6747\n",
      "Epoch [6/30], Batch [4830/20508], Loss: 0.7005\n",
      "Epoch [6/30], Batch [4840/20508], Loss: 0.6765\n",
      "Epoch [6/30], Batch [4850/20508], Loss: 0.6871\n",
      "Epoch [6/30], Batch [4860/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [4870/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [4880/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [4890/20508], Loss: 0.6673\n",
      "Epoch [6/30], Batch [4900/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [4910/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [4920/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [4930/20508], Loss: 0.6958\n",
      "Epoch [6/30], Batch [4940/20508], Loss: 0.6991\n",
      "Epoch [6/30], Batch [4950/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [4960/20508], Loss: 0.6781\n",
      "Epoch [6/30], Batch [4970/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [4980/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [4990/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [5000/20508], Loss: 0.6898\n",
      "Epoch [6/30], Batch [5010/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [5020/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [5030/20508], Loss: 0.6969\n",
      "Epoch [6/30], Batch [5040/20508], Loss: 0.6956\n",
      "Epoch [6/30], Batch [5050/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [5060/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [5070/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [5080/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [5090/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [5100/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [5110/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [5120/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [5130/20508], Loss: 0.6807\n",
      "Epoch [6/30], Batch [5140/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [5150/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [5160/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [5170/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [5180/20508], Loss: 0.6786\n",
      "Epoch [6/30], Batch [5190/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [5200/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [5210/20508], Loss: 0.7097\n",
      "Epoch [6/30], Batch [5220/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [5230/20508], Loss: 0.6895\n",
      "Epoch [6/30], Batch [5240/20508], Loss: 0.6905\n",
      "Epoch [6/30], Batch [5250/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [5260/20508], Loss: 0.7021\n",
      "Epoch [6/30], Batch [5270/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [5280/20508], Loss: 0.7044\n",
      "Epoch [6/30], Batch [5290/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [5300/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [5310/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [5320/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [5330/20508], Loss: 0.7052\n",
      "Epoch [6/30], Batch [5340/20508], Loss: 0.7161\n",
      "Epoch [6/30], Batch [5350/20508], Loss: 0.6959\n",
      "Epoch [6/30], Batch [5360/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [5370/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [5380/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [5390/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [5400/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [5410/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [5420/20508], Loss: 0.6969\n",
      "Epoch [6/30], Batch [5430/20508], Loss: 0.6796\n",
      "Epoch [6/30], Batch [5440/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [5450/20508], Loss: 0.6956\n",
      "Epoch [6/30], Batch [5460/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [5470/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [5480/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [5490/20508], Loss: 0.7030\n",
      "Epoch [6/30], Batch [5500/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [5510/20508], Loss: 0.6825\n",
      "Epoch [6/30], Batch [5520/20508], Loss: 0.6740\n",
      "Epoch [6/30], Batch [5530/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [5540/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [5550/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [5560/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [5570/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [5580/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [5590/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [5600/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [5610/20508], Loss: 0.6983\n",
      "Epoch [6/30], Batch [5620/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [5630/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [5640/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [5650/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [5660/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [5670/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [5680/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [5690/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [5700/20508], Loss: 0.6784\n",
      "Epoch [6/30], Batch [5710/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [5720/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [5730/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [5740/20508], Loss: 0.6746\n",
      "Epoch [6/30], Batch [5750/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [5760/20508], Loss: 0.6755\n",
      "Epoch [6/30], Batch [5770/20508], Loss: 0.6755\n",
      "Epoch [6/30], Batch [5780/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [5790/20508], Loss: 0.6882\n",
      "Epoch [6/30], Batch [5800/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [5810/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [5820/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [5830/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [5840/20508], Loss: 0.7054\n",
      "Epoch [6/30], Batch [5850/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [5860/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [5870/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [5880/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [5890/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [5900/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [5910/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [5920/20508], Loss: 0.7121\n",
      "Epoch [6/30], Batch [5930/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [5940/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [5950/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [5960/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [5970/20508], Loss: 0.6731\n",
      "Epoch [6/30], Batch [5980/20508], Loss: 0.7140\n",
      "Epoch [6/30], Batch [5990/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [6000/20508], Loss: 0.6661\n",
      "Epoch [6/30], Batch [6010/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [6020/20508], Loss: 0.7080\n",
      "Epoch [6/30], Batch [6030/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [6040/20508], Loss: 0.6981\n",
      "Epoch [6/30], Batch [6050/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [6060/20508], Loss: 0.6826\n",
      "Epoch [6/30], Batch [6070/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [6080/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [6090/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [6100/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [6110/20508], Loss: 0.6972\n",
      "Epoch [6/30], Batch [6120/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [6130/20508], Loss: 0.6882\n",
      "Epoch [6/30], Batch [6140/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [6150/20508], Loss: 0.6753\n",
      "Epoch [6/30], Batch [6160/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [6170/20508], Loss: 0.6682\n",
      "Epoch [6/30], Batch [6180/20508], Loss: 0.6803\n",
      "Epoch [6/30], Batch [6190/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [6200/20508], Loss: 0.6790\n",
      "Epoch [6/30], Batch [6210/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [6220/20508], Loss: 0.6664\n",
      "Epoch [6/30], Batch [6230/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [6240/20508], Loss: 0.7011\n",
      "Epoch [6/30], Batch [6250/20508], Loss: 0.7059\n",
      "Epoch [6/30], Batch [6260/20508], Loss: 0.6733\n",
      "Epoch [6/30], Batch [6270/20508], Loss: 0.6905\n",
      "Epoch [6/30], Batch [6280/20508], Loss: 0.6835\n",
      "Epoch [6/30], Batch [6290/20508], Loss: 0.6783\n",
      "Epoch [6/30], Batch [6300/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [6310/20508], Loss: 0.6962\n",
      "Epoch [6/30], Batch [6320/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [6330/20508], Loss: 0.6731\n",
      "Epoch [6/30], Batch [6340/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [6350/20508], Loss: 0.6764\n",
      "Epoch [6/30], Batch [6360/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [6370/20508], Loss: 0.6729\n",
      "Epoch [6/30], Batch [6380/20508], Loss: 0.6691\n",
      "Epoch [6/30], Batch [6390/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [6400/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [6410/20508], Loss: 0.6948\n",
      "Epoch [6/30], Batch [6420/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [6430/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [6440/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [6450/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [6460/20508], Loss: 0.6717\n",
      "Epoch [6/30], Batch [6470/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [6480/20508], Loss: 0.6743\n",
      "Epoch [6/30], Batch [6490/20508], Loss: 0.7001\n",
      "Epoch [6/30], Batch [6500/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [6510/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [6520/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [6530/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [6540/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [6550/20508], Loss: 0.6776\n",
      "Epoch [6/30], Batch [6560/20508], Loss: 0.6929\n",
      "Epoch [6/30], Batch [6570/20508], Loss: 0.6913\n",
      "Epoch [6/30], Batch [6580/20508], Loss: 0.7060\n",
      "Epoch [6/30], Batch [6590/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [6600/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [6610/20508], Loss: 0.6691\n",
      "Epoch [6/30], Batch [6620/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [6630/20508], Loss: 0.6958\n",
      "Epoch [6/30], Batch [6640/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [6650/20508], Loss: 0.6750\n",
      "Epoch [6/30], Batch [6660/20508], Loss: 0.6871\n",
      "Epoch [6/30], Batch [6670/20508], Loss: 0.6733\n",
      "Epoch [6/30], Batch [6680/20508], Loss: 0.6719\n",
      "Epoch [6/30], Batch [6690/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [6700/20508], Loss: 0.6931\n",
      "Epoch [6/30], Batch [6710/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [6720/20508], Loss: 0.6634\n",
      "Epoch [6/30], Batch [6730/20508], Loss: 0.6710\n",
      "Epoch [6/30], Batch [6740/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [6750/20508], Loss: 0.6789\n",
      "Epoch [6/30], Batch [6760/20508], Loss: 0.6812\n",
      "Epoch [6/30], Batch [6770/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [6780/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [6790/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [6800/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [6810/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [6820/20508], Loss: 0.6912\n",
      "Epoch [6/30], Batch [6830/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [6840/20508], Loss: 0.6693\n",
      "Epoch [6/30], Batch [6850/20508], Loss: 0.6759\n",
      "Epoch [6/30], Batch [6860/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [6870/20508], Loss: 0.6683\n",
      "Epoch [6/30], Batch [6880/20508], Loss: 0.6786\n",
      "Epoch [6/30], Batch [6890/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [6900/20508], Loss: 0.6973\n",
      "Epoch [6/30], Batch [6910/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [6920/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [6930/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [6940/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [6950/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [6960/20508], Loss: 0.6816\n",
      "Epoch [6/30], Batch [6970/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [6980/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [6990/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [7000/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [7010/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [7020/20508], Loss: 0.7054\n",
      "Epoch [6/30], Batch [7030/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [7040/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [7050/20508], Loss: 0.6987\n",
      "Epoch [6/30], Batch [7060/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [7070/20508], Loss: 0.6594\n",
      "Epoch [6/30], Batch [7080/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [7090/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [7100/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [7110/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [7120/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [7130/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [7140/20508], Loss: 0.6938\n",
      "Epoch [6/30], Batch [7150/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [7160/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [7170/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [7180/20508], Loss: 0.7035\n",
      "Epoch [6/30], Batch [7190/20508], Loss: 0.7027\n",
      "Epoch [6/30], Batch [7200/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [7210/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [7220/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [7230/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [7240/20508], Loss: 0.6625\n",
      "Epoch [6/30], Batch [7250/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [7260/20508], Loss: 0.6642\n",
      "Epoch [6/30], Batch [7270/20508], Loss: 0.7042\n",
      "Epoch [6/30], Batch [7280/20508], Loss: 0.6702\n",
      "Epoch [6/30], Batch [7290/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [7300/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [7310/20508], Loss: 0.6826\n",
      "Epoch [6/30], Batch [7320/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [7330/20508], Loss: 0.6624\n",
      "Epoch [6/30], Batch [7340/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [7350/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [7360/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [7370/20508], Loss: 0.6698\n",
      "Epoch [6/30], Batch [7380/20508], Loss: 0.6835\n",
      "Epoch [6/30], Batch [7390/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [7400/20508], Loss: 0.6833\n",
      "Epoch [6/30], Batch [7410/20508], Loss: 0.7052\n",
      "Epoch [6/30], Batch [7420/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [7430/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [7440/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [7450/20508], Loss: 0.6904\n",
      "Epoch [6/30], Batch [7460/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [7470/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [7480/20508], Loss: 0.6967\n",
      "Epoch [6/30], Batch [7490/20508], Loss: 0.7049\n",
      "Epoch [6/30], Batch [7500/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [7510/20508], Loss: 0.6657\n",
      "Epoch [6/30], Batch [7520/20508], Loss: 0.7100\n",
      "Epoch [6/30], Batch [7530/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [7540/20508], Loss: 0.7122\n",
      "Epoch [6/30], Batch [7550/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [7560/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [7570/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [7580/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [7590/20508], Loss: 0.6768\n",
      "Epoch [6/30], Batch [7600/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [7610/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [7620/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [7630/20508], Loss: 0.7109\n",
      "Epoch [6/30], Batch [7640/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [7650/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [7660/20508], Loss: 0.6938\n",
      "Epoch [6/30], Batch [7670/20508], Loss: 0.7132\n",
      "Epoch [6/30], Batch [7680/20508], Loss: 0.7142\n",
      "Epoch [6/30], Batch [7690/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [7700/20508], Loss: 0.6956\n",
      "Epoch [6/30], Batch [7710/20508], Loss: 0.6867\n",
      "Epoch [6/30], Batch [7720/20508], Loss: 0.6675\n",
      "Epoch [6/30], Batch [7730/20508], Loss: 0.6715\n",
      "Epoch [6/30], Batch [7740/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [7750/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [7760/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [7770/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [7780/20508], Loss: 0.7088\n",
      "Epoch [6/30], Batch [7790/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [7800/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [7810/20508], Loss: 0.6698\n",
      "Epoch [6/30], Batch [7820/20508], Loss: 0.6972\n",
      "Epoch [6/30], Batch [7830/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [7840/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [7850/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [7860/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [7870/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [7880/20508], Loss: 0.7013\n",
      "Epoch [6/30], Batch [7890/20508], Loss: 0.6752\n",
      "Epoch [6/30], Batch [7900/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [7910/20508], Loss: 0.7030\n",
      "Epoch [6/30], Batch [7920/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [7930/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [7940/20508], Loss: 0.7097\n",
      "Epoch [6/30], Batch [7950/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [7960/20508], Loss: 0.7130\n",
      "Epoch [6/30], Batch [7970/20508], Loss: 0.6721\n",
      "Epoch [6/30], Batch [7980/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [7990/20508], Loss: 0.6675\n",
      "Epoch [6/30], Batch [8000/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [8010/20508], Loss: 0.7004\n",
      "Epoch [6/30], Batch [8020/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [8030/20508], Loss: 0.6962\n",
      "Epoch [6/30], Batch [8040/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [8050/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [8060/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [8070/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [8080/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [8090/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [8100/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [8110/20508], Loss: 0.6998\n",
      "Epoch [6/30], Batch [8120/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [8130/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [8140/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [8150/20508], Loss: 0.6738\n",
      "Epoch [6/30], Batch [8160/20508], Loss: 0.6871\n",
      "Epoch [6/30], Batch [8170/20508], Loss: 0.6768\n",
      "Epoch [6/30], Batch [8180/20508], Loss: 0.7063\n",
      "Epoch [6/30], Batch [8190/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [8200/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [8210/20508], Loss: 0.6755\n",
      "Epoch [6/30], Batch [8220/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [8230/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [8240/20508], Loss: 0.6825\n",
      "Epoch [6/30], Batch [8250/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [8260/20508], Loss: 0.6952\n",
      "Epoch [6/30], Batch [8270/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [8280/20508], Loss: 0.7036\n",
      "Epoch [6/30], Batch [8290/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [8300/20508], Loss: 0.6938\n",
      "Epoch [6/30], Batch [8310/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [8320/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [8330/20508], Loss: 0.7050\n",
      "Epoch [6/30], Batch [8340/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [8350/20508], Loss: 0.6967\n",
      "Epoch [6/30], Batch [8360/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [8370/20508], Loss: 0.6791\n",
      "Epoch [6/30], Batch [8380/20508], Loss: 0.6827\n",
      "Epoch [6/30], Batch [8390/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [8400/20508], Loss: 0.6856\n",
      "Epoch [6/30], Batch [8410/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [8420/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [8430/20508], Loss: 0.7085\n",
      "Epoch [6/30], Batch [8440/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [8450/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [8460/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [8470/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [8480/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [8490/20508], Loss: 0.6785\n",
      "Epoch [6/30], Batch [8500/20508], Loss: 0.7054\n",
      "Epoch [6/30], Batch [8510/20508], Loss: 0.7080\n",
      "Epoch [6/30], Batch [8520/20508], Loss: 0.6986\n",
      "Epoch [6/30], Batch [8530/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [8540/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [8550/20508], Loss: 0.6765\n",
      "Epoch [6/30], Batch [8560/20508], Loss: 0.7066\n",
      "Epoch [6/30], Batch [8570/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [8580/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [8590/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [8600/20508], Loss: 0.6799\n",
      "Epoch [6/30], Batch [8610/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [8620/20508], Loss: 0.6963\n",
      "Epoch [6/30], Batch [8630/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [8640/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [8650/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [8660/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [8670/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [8680/20508], Loss: 0.6741\n",
      "Epoch [6/30], Batch [8690/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [8700/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [8710/20508], Loss: 0.6935\n",
      "Epoch [6/30], Batch [8720/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [8730/20508], Loss: 0.7046\n",
      "Epoch [6/30], Batch [8740/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [8750/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [8760/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [8770/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [8780/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [8790/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [8800/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [8810/20508], Loss: 0.6747\n",
      "Epoch [6/30], Batch [8820/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [8830/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [8840/20508], Loss: 0.6818\n",
      "Epoch [6/30], Batch [8850/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [8860/20508], Loss: 0.6815\n",
      "Epoch [6/30], Batch [8870/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [8880/20508], Loss: 0.6661\n",
      "Epoch [6/30], Batch [8890/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [8900/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [8910/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [8920/20508], Loss: 0.6787\n",
      "Epoch [6/30], Batch [8930/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [8940/20508], Loss: 0.7053\n",
      "Epoch [6/30], Batch [8950/20508], Loss: 0.6796\n",
      "Epoch [6/30], Batch [8960/20508], Loss: 0.6725\n",
      "Epoch [6/30], Batch [8970/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [8980/20508], Loss: 0.6929\n",
      "Epoch [6/30], Batch [8990/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [9000/20508], Loss: 0.6794\n",
      "Epoch [6/30], Batch [9010/20508], Loss: 0.6988\n",
      "Epoch [6/30], Batch [9020/20508], Loss: 0.7063\n",
      "Epoch [6/30], Batch [9030/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [9040/20508], Loss: 0.6931\n",
      "Epoch [6/30], Batch [9050/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [9060/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [9070/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [9080/20508], Loss: 0.7060\n",
      "Epoch [6/30], Batch [9090/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [9100/20508], Loss: 0.6918\n",
      "Epoch [6/30], Batch [9110/20508], Loss: 0.6748\n",
      "Epoch [6/30], Batch [9120/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [9130/20508], Loss: 0.6742\n",
      "Epoch [6/30], Batch [9140/20508], Loss: 0.6982\n",
      "Epoch [6/30], Batch [9150/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [9160/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [9170/20508], Loss: 0.7030\n",
      "Epoch [6/30], Batch [9180/20508], Loss: 0.6679\n",
      "Epoch [6/30], Batch [9190/20508], Loss: 0.6874\n",
      "Epoch [6/30], Batch [9200/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [9210/20508], Loss: 0.6988\n",
      "Epoch [6/30], Batch [9220/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [9230/20508], Loss: 0.6787\n",
      "Epoch [6/30], Batch [9240/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [9250/20508], Loss: 0.6763\n",
      "Epoch [6/30], Batch [9260/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [9270/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [9280/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [9290/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [9300/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [9310/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [9320/20508], Loss: 0.6903\n",
      "Epoch [6/30], Batch [9330/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [9340/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [9350/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [9360/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [9370/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [9380/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [9390/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [9400/20508], Loss: 0.6898\n",
      "Epoch [6/30], Batch [9410/20508], Loss: 0.7108\n",
      "Epoch [6/30], Batch [9420/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [9430/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [9440/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [9450/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [9460/20508], Loss: 0.6895\n",
      "Epoch [6/30], Batch [9470/20508], Loss: 0.7037\n",
      "Epoch [6/30], Batch [9480/20508], Loss: 0.6966\n",
      "Epoch [6/30], Batch [9490/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [9500/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [9510/20508], Loss: 0.6788\n",
      "Epoch [6/30], Batch [9520/20508], Loss: 0.7030\n",
      "Epoch [6/30], Batch [9530/20508], Loss: 0.6636\n",
      "Epoch [6/30], Batch [9540/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [9550/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [9560/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [9570/20508], Loss: 0.6963\n",
      "Epoch [6/30], Batch [9580/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [9590/20508], Loss: 0.6827\n",
      "Epoch [6/30], Batch [9600/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [9610/20508], Loss: 0.6984\n",
      "Epoch [6/30], Batch [9620/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [9630/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [9640/20508], Loss: 0.6713\n",
      "Epoch [6/30], Batch [9650/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [9660/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [9670/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [9680/20508], Loss: 0.6631\n",
      "Epoch [6/30], Batch [9690/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [9700/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [9710/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [9720/20508], Loss: 0.6997\n",
      "Epoch [6/30], Batch [9730/20508], Loss: 0.6826\n",
      "Epoch [6/30], Batch [9740/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [9750/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [9760/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [9770/20508], Loss: 0.6815\n",
      "Epoch [6/30], Batch [9780/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [9790/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [9800/20508], Loss: 0.6904\n",
      "Epoch [6/30], Batch [9810/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [9820/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [9830/20508], Loss: 0.6929\n",
      "Epoch [6/30], Batch [9840/20508], Loss: 0.6481\n",
      "Epoch [6/30], Batch [9850/20508], Loss: 0.6921\n",
      "Epoch [6/30], Batch [9860/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [9870/20508], Loss: 0.6665\n",
      "Epoch [6/30], Batch [9880/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [9890/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [9900/20508], Loss: 0.6987\n",
      "Epoch [6/30], Batch [9910/20508], Loss: 0.6921\n",
      "Epoch [6/30], Batch [9920/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [9930/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [9940/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [9950/20508], Loss: 0.7025\n",
      "Epoch [6/30], Batch [9960/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [9970/20508], Loss: 0.6957\n",
      "Epoch [6/30], Batch [9980/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [9990/20508], Loss: 0.6984\n",
      "Epoch [6/30], Batch [10000/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [10010/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [10020/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [10030/20508], Loss: 0.6754\n",
      "Epoch [6/30], Batch [10040/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [10050/20508], Loss: 0.6662\n",
      "Epoch [6/30], Batch [10060/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [10070/20508], Loss: 0.6732\n",
      "Epoch [6/30], Batch [10080/20508], Loss: 0.6754\n",
      "Epoch [6/30], Batch [10090/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [10100/20508], Loss: 0.6791\n",
      "Epoch [6/30], Batch [10110/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [10120/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [10130/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [10140/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [10150/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [10160/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [10170/20508], Loss: 0.7038\n",
      "Epoch [6/30], Batch [10180/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [10190/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [10200/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [10210/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [10220/20508], Loss: 0.6734\n",
      "Epoch [6/30], Batch [10230/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [10240/20508], Loss: 0.6969\n",
      "Epoch [6/30], Batch [10250/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [10260/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [10270/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [10280/20508], Loss: 0.6783\n",
      "Epoch [6/30], Batch [10290/20508], Loss: 0.6999\n",
      "Epoch [6/30], Batch [10300/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [10310/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [10320/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [10330/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [10340/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [10350/20508], Loss: 0.6683\n",
      "Epoch [6/30], Batch [10360/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [10370/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [10380/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [10390/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [10400/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [10410/20508], Loss: 0.6960\n",
      "Epoch [6/30], Batch [10420/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [10430/20508], Loss: 0.7064\n",
      "Epoch [6/30], Batch [10440/20508], Loss: 0.7109\n",
      "Epoch [6/30], Batch [10450/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [10460/20508], Loss: 0.6640\n",
      "Epoch [6/30], Batch [10470/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [10480/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [10490/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [10500/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [10510/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [10520/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [10530/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [10540/20508], Loss: 0.6678\n",
      "Epoch [6/30], Batch [10550/20508], Loss: 0.6812\n",
      "Epoch [6/30], Batch [10560/20508], Loss: 0.6750\n",
      "Epoch [6/30], Batch [10570/20508], Loss: 0.7031\n",
      "Epoch [6/30], Batch [10580/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [10590/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [10600/20508], Loss: 0.6719\n",
      "Epoch [6/30], Batch [10610/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [10620/20508], Loss: 0.7044\n",
      "Epoch [6/30], Batch [10630/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [10640/20508], Loss: 0.6962\n",
      "Epoch [6/30], Batch [10650/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [10660/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [10670/20508], Loss: 0.6804\n",
      "Epoch [6/30], Batch [10680/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [10690/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [10700/20508], Loss: 0.6765\n",
      "Epoch [6/30], Batch [10710/20508], Loss: 0.6923\n",
      "Epoch [6/30], Batch [10720/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [10730/20508], Loss: 0.6763\n",
      "Epoch [6/30], Batch [10740/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [10750/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [10760/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [10770/20508], Loss: 0.7062\n",
      "Epoch [6/30], Batch [10780/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [10790/20508], Loss: 0.7056\n",
      "Epoch [6/30], Batch [10800/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [10810/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [10820/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [10830/20508], Loss: 0.6958\n",
      "Epoch [6/30], Batch [10840/20508], Loss: 0.6835\n",
      "Epoch [6/30], Batch [10850/20508], Loss: 0.6777\n",
      "Epoch [6/30], Batch [10860/20508], Loss: 0.6995\n",
      "Epoch [6/30], Batch [10870/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [10880/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [10890/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [10900/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [10910/20508], Loss: 0.7017\n",
      "Epoch [6/30], Batch [10920/20508], Loss: 0.6788\n",
      "Epoch [6/30], Batch [10930/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [10940/20508], Loss: 0.6794\n",
      "Epoch [6/30], Batch [10950/20508], Loss: 0.6931\n",
      "Epoch [6/30], Batch [10960/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [10970/20508], Loss: 0.6914\n",
      "Epoch [6/30], Batch [10980/20508], Loss: 0.6716\n",
      "Epoch [6/30], Batch [10990/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [11000/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [11010/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [11020/20508], Loss: 0.6698\n",
      "Epoch [6/30], Batch [11030/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [11040/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [11050/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [11060/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [11070/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [11080/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [11090/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [11100/20508], Loss: 0.6755\n",
      "Epoch [6/30], Batch [11110/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [11120/20508], Loss: 0.7071\n",
      "Epoch [6/30], Batch [11130/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [11140/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [11150/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [11160/20508], Loss: 0.6833\n",
      "Epoch [6/30], Batch [11170/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [11180/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [11190/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [11200/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [11210/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [11220/20508], Loss: 0.6966\n",
      "Epoch [6/30], Batch [11230/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [11240/20508], Loss: 0.6682\n",
      "Epoch [6/30], Batch [11250/20508], Loss: 0.6987\n",
      "Epoch [6/30], Batch [11260/20508], Loss: 0.6705\n",
      "Epoch [6/30], Batch [11270/20508], Loss: 0.6746\n",
      "Epoch [6/30], Batch [11280/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [11290/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [11300/20508], Loss: 0.6678\n",
      "Epoch [6/30], Batch [11310/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [11320/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [11330/20508], Loss: 0.6783\n",
      "Epoch [6/30], Batch [11340/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [11350/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [11360/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [11370/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [11380/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [11390/20508], Loss: 0.6720\n",
      "Epoch [6/30], Batch [11400/20508], Loss: 0.6778\n",
      "Epoch [6/30], Batch [11410/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [11420/20508], Loss: 0.6998\n",
      "Epoch [6/30], Batch [11430/20508], Loss: 0.6750\n",
      "Epoch [6/30], Batch [11440/20508], Loss: 0.7058\n",
      "Epoch [6/30], Batch [11450/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [11460/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [11470/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [11480/20508], Loss: 0.6759\n",
      "Epoch [6/30], Batch [11490/20508], Loss: 0.6650\n",
      "Epoch [6/30], Batch [11500/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [11510/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [11520/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [11530/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [11540/20508], Loss: 0.7031\n",
      "Epoch [6/30], Batch [11550/20508], Loss: 0.6918\n",
      "Epoch [6/30], Batch [11560/20508], Loss: 0.7198\n",
      "Epoch [6/30], Batch [11570/20508], Loss: 0.6815\n",
      "Epoch [6/30], Batch [11580/20508], Loss: 0.6914\n",
      "Epoch [6/30], Batch [11590/20508], Loss: 0.6691\n",
      "Epoch [6/30], Batch [11600/20508], Loss: 0.7151\n",
      "Epoch [6/30], Batch [11610/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [11620/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [11630/20508], Loss: 0.7041\n",
      "Epoch [6/30], Batch [11640/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [11650/20508], Loss: 0.7066\n",
      "Epoch [6/30], Batch [11660/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [11670/20508], Loss: 0.6830\n",
      "Epoch [6/30], Batch [11680/20508], Loss: 0.7021\n",
      "Epoch [6/30], Batch [11690/20508], Loss: 0.6976\n",
      "Epoch [6/30], Batch [11700/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [11710/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [11720/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [11730/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [11740/20508], Loss: 0.6673\n",
      "Epoch [6/30], Batch [11750/20508], Loss: 0.6764\n",
      "Epoch [6/30], Batch [11760/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [11770/20508], Loss: 0.6903\n",
      "Epoch [6/30], Batch [11780/20508], Loss: 0.6962\n",
      "Epoch [6/30], Batch [11790/20508], Loss: 0.6771\n",
      "Epoch [6/30], Batch [11800/20508], Loss: 0.6867\n",
      "Epoch [6/30], Batch [11810/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [11820/20508], Loss: 0.6627\n",
      "Epoch [6/30], Batch [11830/20508], Loss: 0.7089\n",
      "Epoch [6/30], Batch [11840/20508], Loss: 0.6712\n",
      "Epoch [6/30], Batch [11850/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [11860/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [11870/20508], Loss: 0.6733\n",
      "Epoch [6/30], Batch [11880/20508], Loss: 0.7052\n",
      "Epoch [6/30], Batch [11890/20508], Loss: 0.7153\n",
      "Epoch [6/30], Batch [11900/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [11910/20508], Loss: 0.7014\n",
      "Epoch [6/30], Batch [11920/20508], Loss: 0.6714\n",
      "Epoch [6/30], Batch [11930/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [11940/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [11950/20508], Loss: 0.6833\n",
      "Epoch [6/30], Batch [11960/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [11970/20508], Loss: 0.6960\n",
      "Epoch [6/30], Batch [11980/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [11990/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [12000/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [12010/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [12020/20508], Loss: 0.6983\n",
      "Epoch [6/30], Batch [12030/20508], Loss: 0.7153\n",
      "Epoch [6/30], Batch [12040/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [12050/20508], Loss: 0.6856\n",
      "Epoch [6/30], Batch [12060/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [12070/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [12080/20508], Loss: 0.6800\n",
      "Epoch [6/30], Batch [12090/20508], Loss: 0.6634\n",
      "Epoch [6/30], Batch [12100/20508], Loss: 0.7092\n",
      "Epoch [6/30], Batch [12110/20508], Loss: 0.6721\n",
      "Epoch [6/30], Batch [12120/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [12130/20508], Loss: 0.6997\n",
      "Epoch [6/30], Batch [12140/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [12150/20508], Loss: 0.7130\n",
      "Epoch [6/30], Batch [12160/20508], Loss: 0.6904\n",
      "Epoch [6/30], Batch [12170/20508], Loss: 0.6852\n",
      "Epoch [6/30], Batch [12180/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [12190/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [12200/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [12210/20508], Loss: 0.7061\n",
      "Epoch [6/30], Batch [12220/20508], Loss: 0.6979\n",
      "Epoch [6/30], Batch [12230/20508], Loss: 0.6981\n",
      "Epoch [6/30], Batch [12240/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [12250/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [12260/20508], Loss: 0.7035\n",
      "Epoch [6/30], Batch [12270/20508], Loss: 0.6999\n",
      "Epoch [6/30], Batch [12280/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [12290/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [12300/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [12310/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [12320/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [12330/20508], Loss: 0.6737\n",
      "Epoch [6/30], Batch [12340/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [12350/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [12360/20508], Loss: 0.6786\n",
      "Epoch [6/30], Batch [12370/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [12380/20508], Loss: 0.6729\n",
      "Epoch [6/30], Batch [12390/20508], Loss: 0.6582\n",
      "Epoch [6/30], Batch [12400/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [12410/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [12420/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [12430/20508], Loss: 0.6694\n",
      "Epoch [6/30], Batch [12440/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [12450/20508], Loss: 0.6824\n",
      "Epoch [6/30], Batch [12460/20508], Loss: 0.6880\n",
      "Epoch [6/30], Batch [12470/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [12480/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [12490/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [12500/20508], Loss: 0.6652\n",
      "Epoch [6/30], Batch [12510/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [12520/20508], Loss: 0.6743\n",
      "Epoch [6/30], Batch [12530/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [12540/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [12550/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [12560/20508], Loss: 0.6646\n",
      "Epoch [6/30], Batch [12570/20508], Loss: 0.6788\n",
      "Epoch [6/30], Batch [12580/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [12590/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [12600/20508], Loss: 0.7046\n",
      "Epoch [6/30], Batch [12610/20508], Loss: 0.6973\n",
      "Epoch [6/30], Batch [12620/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [12630/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [12640/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [12650/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [12660/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [12670/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [12680/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [12690/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [12700/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [12710/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [12720/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [12730/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [12740/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [12750/20508], Loss: 0.6795\n",
      "Epoch [6/30], Batch [12760/20508], Loss: 0.7044\n",
      "Epoch [6/30], Batch [12770/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [12780/20508], Loss: 0.7003\n",
      "Epoch [6/30], Batch [12790/20508], Loss: 0.7009\n",
      "Epoch [6/30], Batch [12800/20508], Loss: 0.7003\n",
      "Epoch [6/30], Batch [12810/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [12820/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [12830/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [12840/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [12850/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [12860/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [12870/20508], Loss: 0.7004\n",
      "Epoch [6/30], Batch [12880/20508], Loss: 0.6918\n",
      "Epoch [6/30], Batch [12890/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [12900/20508], Loss: 0.6966\n",
      "Epoch [6/30], Batch [12910/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [12920/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [12930/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [12940/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [12950/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [12960/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [12970/20508], Loss: 0.6709\n",
      "Epoch [6/30], Batch [12980/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [12990/20508], Loss: 0.6915\n",
      "Epoch [6/30], Batch [13000/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [13010/20508], Loss: 0.6766\n",
      "Epoch [6/30], Batch [13020/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [13030/20508], Loss: 0.6759\n",
      "Epoch [6/30], Batch [13040/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [13050/20508], Loss: 0.6774\n",
      "Epoch [6/30], Batch [13060/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [13070/20508], Loss: 0.6758\n",
      "Epoch [6/30], Batch [13080/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [13090/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [13100/20508], Loss: 0.7052\n",
      "Epoch [6/30], Batch [13110/20508], Loss: 0.6799\n",
      "Epoch [6/30], Batch [13120/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [13130/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [13140/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [13150/20508], Loss: 0.6757\n",
      "Epoch [6/30], Batch [13160/20508], Loss: 0.7016\n",
      "Epoch [6/30], Batch [13170/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [13180/20508], Loss: 0.6797\n",
      "Epoch [6/30], Batch [13190/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [13200/20508], Loss: 0.6736\n",
      "Epoch [6/30], Batch [13210/20508], Loss: 0.6713\n",
      "Epoch [6/30], Batch [13220/20508], Loss: 0.6568\n",
      "Epoch [6/30], Batch [13230/20508], Loss: 0.6972\n",
      "Epoch [6/30], Batch [13240/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [13250/20508], Loss: 0.6984\n",
      "Epoch [6/30], Batch [13260/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [13270/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [13280/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [13290/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [13300/20508], Loss: 0.6935\n",
      "Epoch [6/30], Batch [13310/20508], Loss: 0.6730\n",
      "Epoch [6/30], Batch [13320/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [13330/20508], Loss: 0.6909\n",
      "Epoch [6/30], Batch [13340/20508], Loss: 0.6742\n",
      "Epoch [6/30], Batch [13350/20508], Loss: 0.6898\n",
      "Epoch [6/30], Batch [13360/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [13370/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [13380/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [13390/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [13400/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [13410/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [13420/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [13430/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [13440/20508], Loss: 0.6867\n",
      "Epoch [6/30], Batch [13450/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [13460/20508], Loss: 0.7088\n",
      "Epoch [6/30], Batch [13470/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [13480/20508], Loss: 0.7129\n",
      "Epoch [6/30], Batch [13490/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [13500/20508], Loss: 0.6903\n",
      "Epoch [6/30], Batch [13510/20508], Loss: 0.6769\n",
      "Epoch [6/30], Batch [13520/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [13530/20508], Loss: 0.6714\n",
      "Epoch [6/30], Batch [13540/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [13550/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [13560/20508], Loss: 0.6914\n",
      "Epoch [6/30], Batch [13570/20508], Loss: 0.6724\n",
      "Epoch [6/30], Batch [13580/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [13590/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [13600/20508], Loss: 0.6804\n",
      "Epoch [6/30], Batch [13610/20508], Loss: 0.6923\n",
      "Epoch [6/30], Batch [13620/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [13630/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [13640/20508], Loss: 0.6969\n",
      "Epoch [6/30], Batch [13650/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [13660/20508], Loss: 0.6619\n",
      "Epoch [6/30], Batch [13670/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [13680/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [13690/20508], Loss: 0.6674\n",
      "Epoch [6/30], Batch [13700/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [13710/20508], Loss: 0.6754\n",
      "Epoch [6/30], Batch [13720/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [13730/20508], Loss: 0.6963\n",
      "Epoch [6/30], Batch [13740/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [13750/20508], Loss: 0.6707\n",
      "Epoch [6/30], Batch [13760/20508], Loss: 0.6758\n",
      "Epoch [6/30], Batch [13770/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [13780/20508], Loss: 0.6957\n",
      "Epoch [6/30], Batch [13790/20508], Loss: 0.6782\n",
      "Epoch [6/30], Batch [13800/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [13810/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [13820/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [13830/20508], Loss: 0.7101\n",
      "Epoch [6/30], Batch [13840/20508], Loss: 0.7181\n",
      "Epoch [6/30], Batch [13850/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [13860/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [13870/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [13880/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [13890/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [13900/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [13910/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [13920/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [13930/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [13940/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [13950/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [13960/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [13970/20508], Loss: 0.7014\n",
      "Epoch [6/30], Batch [13980/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [13990/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [14000/20508], Loss: 0.6995\n",
      "Epoch [6/30], Batch [14010/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [14020/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [14030/20508], Loss: 0.6795\n",
      "Epoch [6/30], Batch [14040/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [14050/20508], Loss: 0.6960\n",
      "Epoch [6/30], Batch [14060/20508], Loss: 0.6871\n",
      "Epoch [6/30], Batch [14070/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [14080/20508], Loss: 0.7113\n",
      "Epoch [6/30], Batch [14090/20508], Loss: 0.6920\n",
      "Epoch [6/30], Batch [14100/20508], Loss: 0.6880\n",
      "Epoch [6/30], Batch [14110/20508], Loss: 0.6840\n",
      "Epoch [6/30], Batch [14120/20508], Loss: 0.6653\n",
      "Epoch [6/30], Batch [14130/20508], Loss: 0.6694\n",
      "Epoch [6/30], Batch [14140/20508], Loss: 0.6969\n",
      "Epoch [6/30], Batch [14150/20508], Loss: 0.6948\n",
      "Epoch [6/30], Batch [14160/20508], Loss: 0.6786\n",
      "Epoch [6/30], Batch [14170/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [14180/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [14190/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [14200/20508], Loss: 0.6912\n",
      "Epoch [6/30], Batch [14210/20508], Loss: 0.7139\n",
      "Epoch [6/30], Batch [14220/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [14230/20508], Loss: 0.6752\n",
      "Epoch [6/30], Batch [14240/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [14250/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [14260/20508], Loss: 0.7009\n",
      "Epoch [6/30], Batch [14270/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [14280/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [14290/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [14300/20508], Loss: 0.6745\n",
      "Epoch [6/30], Batch [14310/20508], Loss: 0.6973\n",
      "Epoch [6/30], Batch [14320/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [14330/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [14340/20508], Loss: 0.6818\n",
      "Epoch [6/30], Batch [14350/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [14360/20508], Loss: 0.6988\n",
      "Epoch [6/30], Batch [14370/20508], Loss: 0.7083\n",
      "Epoch [6/30], Batch [14380/20508], Loss: 0.7009\n",
      "Epoch [6/30], Batch [14390/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [14400/20508], Loss: 0.6925\n",
      "Epoch [6/30], Batch [14410/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [14420/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [14430/20508], Loss: 0.6695\n",
      "Epoch [6/30], Batch [14440/20508], Loss: 0.6738\n",
      "Epoch [6/30], Batch [14450/20508], Loss: 0.6616\n",
      "Epoch [6/30], Batch [14460/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [14470/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [14480/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [14490/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [14500/20508], Loss: 0.7054\n",
      "Epoch [6/30], Batch [14510/20508], Loss: 0.7011\n",
      "Epoch [6/30], Batch [14520/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [14530/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [14540/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [14550/20508], Loss: 0.7082\n",
      "Epoch [6/30], Batch [14560/20508], Loss: 0.6994\n",
      "Epoch [6/30], Batch [14570/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [14580/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [14590/20508], Loss: 0.7020\n",
      "Epoch [6/30], Batch [14600/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [14610/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [14620/20508], Loss: 0.6865\n",
      "Epoch [6/30], Batch [14630/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [14640/20508], Loss: 0.6991\n",
      "Epoch [6/30], Batch [14650/20508], Loss: 0.6803\n",
      "Epoch [6/30], Batch [14660/20508], Loss: 0.7036\n",
      "Epoch [6/30], Batch [14670/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [14680/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [14690/20508], Loss: 0.6812\n",
      "Epoch [6/30], Batch [14700/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [14710/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [14720/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [14730/20508], Loss: 0.6746\n",
      "Epoch [6/30], Batch [14740/20508], Loss: 0.6751\n",
      "Epoch [6/30], Batch [14750/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [14760/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [14770/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [14780/20508], Loss: 0.7065\n",
      "Epoch [6/30], Batch [14790/20508], Loss: 0.6721\n",
      "Epoch [6/30], Batch [14800/20508], Loss: 0.7065\n",
      "Epoch [6/30], Batch [14810/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [14820/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [14830/20508], Loss: 0.6764\n",
      "Epoch [6/30], Batch [14840/20508], Loss: 0.6854\n",
      "Epoch [6/30], Batch [14850/20508], Loss: 0.6795\n",
      "Epoch [6/30], Batch [14860/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [14870/20508], Loss: 0.6807\n",
      "Epoch [6/30], Batch [14880/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [14890/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [14900/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [14910/20508], Loss: 0.6807\n",
      "Epoch [6/30], Batch [14920/20508], Loss: 0.7028\n",
      "Epoch [6/30], Batch [14930/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [14940/20508], Loss: 0.6811\n",
      "Epoch [6/30], Batch [14950/20508], Loss: 0.6874\n",
      "Epoch [6/30], Batch [14960/20508], Loss: 0.6874\n",
      "Epoch [6/30], Batch [14970/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [14980/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [14990/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [15000/20508], Loss: 0.6981\n",
      "Epoch [6/30], Batch [15010/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [15020/20508], Loss: 0.7021\n",
      "Epoch [6/30], Batch [15030/20508], Loss: 0.6895\n",
      "Epoch [6/30], Batch [15040/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [15050/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [15060/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [15070/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [15080/20508], Loss: 0.6732\n",
      "Epoch [6/30], Batch [15090/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [15100/20508], Loss: 0.6815\n",
      "Epoch [6/30], Batch [15110/20508], Loss: 0.6794\n",
      "Epoch [6/30], Batch [15120/20508], Loss: 0.7013\n",
      "Epoch [6/30], Batch [15130/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [15140/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [15150/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [15160/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [15170/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [15180/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [15190/20508], Loss: 0.6923\n",
      "Epoch [6/30], Batch [15200/20508], Loss: 0.6735\n",
      "Epoch [6/30], Batch [15210/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [15220/20508], Loss: 0.7014\n",
      "Epoch [6/30], Batch [15230/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [15240/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [15250/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [15260/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [15270/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [15280/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [15290/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [15300/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [15310/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [15320/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [15330/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [15340/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [15350/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [15360/20508], Loss: 0.6728\n",
      "Epoch [6/30], Batch [15370/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [15380/20508], Loss: 0.6753\n",
      "Epoch [6/30], Batch [15390/20508], Loss: 0.6900\n",
      "Epoch [6/30], Batch [15400/20508], Loss: 0.6833\n",
      "Epoch [6/30], Batch [15410/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [15420/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [15430/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [15440/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [15450/20508], Loss: 0.6720\n",
      "Epoch [6/30], Batch [15460/20508], Loss: 0.7015\n",
      "Epoch [6/30], Batch [15470/20508], Loss: 0.6856\n",
      "Epoch [6/30], Batch [15480/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [15490/20508], Loss: 0.6982\n",
      "Epoch [6/30], Batch [15500/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [15510/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [15520/20508], Loss: 0.7013\n",
      "Epoch [6/30], Batch [15530/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [15540/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [15550/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [15560/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [15570/20508], Loss: 0.6754\n",
      "Epoch [6/30], Batch [15580/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [15590/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [15600/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [15610/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [15620/20508], Loss: 0.6631\n",
      "Epoch [6/30], Batch [15630/20508], Loss: 0.6726\n",
      "Epoch [6/30], Batch [15640/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [15650/20508], Loss: 0.6731\n",
      "Epoch [6/30], Batch [15660/20508], Loss: 0.6921\n",
      "Epoch [6/30], Batch [15670/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [15680/20508], Loss: 0.7137\n",
      "Epoch [6/30], Batch [15690/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [15700/20508], Loss: 0.7069\n",
      "Epoch [6/30], Batch [15710/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [15720/20508], Loss: 0.6775\n",
      "Epoch [6/30], Batch [15730/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [15740/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [15750/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [15760/20508], Loss: 0.6810\n",
      "Epoch [6/30], Batch [15770/20508], Loss: 0.7011\n",
      "Epoch [6/30], Batch [15780/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [15790/20508], Loss: 0.7002\n",
      "Epoch [6/30], Batch [15800/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [15810/20508], Loss: 0.6843\n",
      "Epoch [6/30], Batch [15820/20508], Loss: 0.6860\n",
      "Epoch [6/30], Batch [15830/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [15840/20508], Loss: 0.6931\n",
      "Epoch [6/30], Batch [15850/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [15860/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [15870/20508], Loss: 0.6875\n",
      "Epoch [6/30], Batch [15880/20508], Loss: 0.6709\n",
      "Epoch [6/30], Batch [15890/20508], Loss: 0.6949\n",
      "Epoch [6/30], Batch [15900/20508], Loss: 0.6972\n",
      "Epoch [6/30], Batch [15910/20508], Loss: 0.6938\n",
      "Epoch [6/30], Batch [15920/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [15930/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [15940/20508], Loss: 0.6955\n",
      "Epoch [6/30], Batch [15950/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [15960/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [15970/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [15980/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [15990/20508], Loss: 0.7091\n",
      "Epoch [6/30], Batch [16000/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [16010/20508], Loss: 0.6957\n",
      "Epoch [6/30], Batch [16020/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [16030/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [16040/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [16050/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [16060/20508], Loss: 0.6912\n",
      "Epoch [6/30], Batch [16070/20508], Loss: 0.6993\n",
      "Epoch [6/30], Batch [16080/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [16090/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [16100/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [16110/20508], Loss: 0.7003\n",
      "Epoch [6/30], Batch [16120/20508], Loss: 0.6948\n",
      "Epoch [6/30], Batch [16130/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [16140/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [16150/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [16160/20508], Loss: 0.6950\n",
      "Epoch [6/30], Batch [16170/20508], Loss: 0.6837\n",
      "Epoch [6/30], Batch [16180/20508], Loss: 0.6825\n",
      "Epoch [6/30], Batch [16190/20508], Loss: 0.6819\n",
      "Epoch [6/30], Batch [16200/20508], Loss: 0.7100\n",
      "Epoch [6/30], Batch [16210/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [16220/20508], Loss: 0.6958\n",
      "Epoch [6/30], Batch [16230/20508], Loss: 0.6729\n",
      "Epoch [6/30], Batch [16240/20508], Loss: 0.6944\n",
      "Epoch [6/30], Batch [16250/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [16260/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [16270/20508], Loss: 0.6887\n",
      "Epoch [6/30], Batch [16280/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [16290/20508], Loss: 0.6928\n",
      "Epoch [6/30], Batch [16300/20508], Loss: 0.6682\n",
      "Epoch [6/30], Batch [16310/20508], Loss: 0.6666\n",
      "Epoch [6/30], Batch [16320/20508], Loss: 0.6665\n",
      "Epoch [6/30], Batch [16330/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [16340/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [16350/20508], Loss: 0.6820\n",
      "Epoch [6/30], Batch [16360/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [16370/20508], Loss: 0.6772\n",
      "Epoch [6/30], Batch [16380/20508], Loss: 0.6718\n",
      "Epoch [6/30], Batch [16390/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [16400/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [16410/20508], Loss: 0.6723\n",
      "Epoch [6/30], Batch [16420/20508], Loss: 0.7051\n",
      "Epoch [6/30], Batch [16430/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [16440/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [16450/20508], Loss: 0.6774\n",
      "Epoch [6/30], Batch [16460/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [16470/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [16480/20508], Loss: 0.6763\n",
      "Epoch [6/30], Batch [16490/20508], Loss: 0.6721\n",
      "Epoch [6/30], Batch [16500/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [16510/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [16520/20508], Loss: 0.6905\n",
      "Epoch [6/30], Batch [16530/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [16540/20508], Loss: 0.6707\n",
      "Epoch [6/30], Batch [16550/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [16560/20508], Loss: 0.6709\n",
      "Epoch [6/30], Batch [16570/20508], Loss: 0.7000\n",
      "Epoch [6/30], Batch [16580/20508], Loss: 0.6948\n",
      "Epoch [6/30], Batch [16590/20508], Loss: 0.7028\n",
      "Epoch [6/30], Batch [16600/20508], Loss: 0.6743\n",
      "Epoch [6/30], Batch [16610/20508], Loss: 0.6835\n",
      "Epoch [6/30], Batch [16620/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [16630/20508], Loss: 0.6583\n",
      "Epoch [6/30], Batch [16640/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [16650/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [16660/20508], Loss: 0.6905\n",
      "Epoch [6/30], Batch [16670/20508], Loss: 0.7098\n",
      "Epoch [6/30], Batch [16680/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [16690/20508], Loss: 0.7042\n",
      "Epoch [6/30], Batch [16700/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [16710/20508], Loss: 0.6926\n",
      "Epoch [6/30], Batch [16720/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [16730/20508], Loss: 0.6753\n",
      "Epoch [6/30], Batch [16740/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [16750/20508], Loss: 0.7122\n",
      "Epoch [6/30], Batch [16760/20508], Loss: 0.6995\n",
      "Epoch [6/30], Batch [16770/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [16780/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [16790/20508], Loss: 0.6740\n",
      "Epoch [6/30], Batch [16800/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [16810/20508], Loss: 0.7022\n",
      "Epoch [6/30], Batch [16820/20508], Loss: 0.6978\n",
      "Epoch [6/30], Batch [16830/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [16840/20508], Loss: 0.6705\n",
      "Epoch [6/30], Batch [16850/20508], Loss: 0.6737\n",
      "Epoch [6/30], Batch [16860/20508], Loss: 0.6746\n",
      "Epoch [6/30], Batch [16870/20508], Loss: 0.6991\n",
      "Epoch [6/30], Batch [16880/20508], Loss: 0.6838\n",
      "Epoch [6/30], Batch [16890/20508], Loss: 0.6864\n",
      "Epoch [6/30], Batch [16900/20508], Loss: 0.6884\n",
      "Epoch [6/30], Batch [16910/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [16920/20508], Loss: 0.7085\n",
      "Epoch [6/30], Batch [16930/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [16940/20508], Loss: 0.6778\n",
      "Epoch [6/30], Batch [16950/20508], Loss: 0.6776\n",
      "Epoch [6/30], Batch [16960/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [16970/20508], Loss: 0.6867\n",
      "Epoch [6/30], Batch [16980/20508], Loss: 0.6758\n",
      "Epoch [6/30], Batch [16990/20508], Loss: 0.7015\n",
      "Epoch [6/30], Batch [17000/20508], Loss: 0.6931\n",
      "Epoch [6/30], Batch [17010/20508], Loss: 0.6934\n",
      "Epoch [6/30], Batch [17020/20508], Loss: 0.7006\n",
      "Epoch [6/30], Batch [17030/20508], Loss: 0.6996\n",
      "Epoch [6/30], Batch [17040/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [17050/20508], Loss: 0.6951\n",
      "Epoch [6/30], Batch [17060/20508], Loss: 0.6956\n",
      "Epoch [6/30], Batch [17070/20508], Loss: 0.7028\n",
      "Epoch [6/30], Batch [17080/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [17090/20508], Loss: 0.7041\n",
      "Epoch [6/30], Batch [17100/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [17110/20508], Loss: 0.6877\n",
      "Epoch [6/30], Batch [17120/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [17130/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [17140/20508], Loss: 0.6770\n",
      "Epoch [6/30], Batch [17150/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [17160/20508], Loss: 0.6992\n",
      "Epoch [6/30], Batch [17170/20508], Loss: 0.6791\n",
      "Epoch [6/30], Batch [17180/20508], Loss: 0.6958\n",
      "Epoch [6/30], Batch [17190/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [17200/20508], Loss: 0.7044\n",
      "Epoch [6/30], Batch [17210/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [17220/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [17230/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [17240/20508], Loss: 0.6859\n",
      "Epoch [6/30], Batch [17250/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [17260/20508], Loss: 0.6899\n",
      "Epoch [6/30], Batch [17270/20508], Loss: 0.6816\n",
      "Epoch [6/30], Batch [17280/20508], Loss: 0.6827\n",
      "Epoch [6/30], Batch [17290/20508], Loss: 0.7024\n",
      "Epoch [6/30], Batch [17300/20508], Loss: 0.7014\n",
      "Epoch [6/30], Batch [17310/20508], Loss: 0.6888\n",
      "Epoch [6/30], Batch [17320/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [17330/20508], Loss: 0.7060\n",
      "Epoch [6/30], Batch [17340/20508], Loss: 0.6979\n",
      "Epoch [6/30], Batch [17350/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [17360/20508], Loss: 0.6849\n",
      "Epoch [6/30], Batch [17370/20508], Loss: 0.6796\n",
      "Epoch [6/30], Batch [17380/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [17390/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [17400/20508], Loss: 0.6855\n",
      "Epoch [6/30], Batch [17410/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [17420/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [17430/20508], Loss: 0.6743\n",
      "Epoch [6/30], Batch [17440/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [17450/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [17460/20508], Loss: 0.6954\n",
      "Epoch [6/30], Batch [17470/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [17480/20508], Loss: 0.6717\n",
      "Epoch [6/30], Batch [17490/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [17500/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [17510/20508], Loss: 0.6873\n",
      "Epoch [6/30], Batch [17520/20508], Loss: 0.6963\n",
      "Epoch [6/30], Batch [17530/20508], Loss: 0.7032\n",
      "Epoch [6/30], Batch [17540/20508], Loss: 0.6786\n",
      "Epoch [6/30], Batch [17550/20508], Loss: 0.7010\n",
      "Epoch [6/30], Batch [17560/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [17570/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [17580/20508], Loss: 0.6821\n",
      "Epoch [6/30], Batch [17590/20508], Loss: 0.6862\n",
      "Epoch [6/30], Batch [17600/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [17610/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [17620/20508], Loss: 0.6681\n",
      "Epoch [6/30], Batch [17630/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [17640/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [17650/20508], Loss: 0.7067\n",
      "Epoch [6/30], Batch [17660/20508], Loss: 0.6792\n",
      "Epoch [6/30], Batch [17670/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [17680/20508], Loss: 0.6839\n",
      "Epoch [6/30], Batch [17690/20508], Loss: 0.6845\n",
      "Epoch [6/30], Batch [17700/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [17710/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [17720/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [17730/20508], Loss: 0.6952\n",
      "Epoch [6/30], Batch [17740/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [17750/20508], Loss: 0.6829\n",
      "Epoch [6/30], Batch [17760/20508], Loss: 0.6781\n",
      "Epoch [6/30], Batch [17770/20508], Loss: 0.6937\n",
      "Epoch [6/30], Batch [17780/20508], Loss: 0.6985\n",
      "Epoch [6/30], Batch [17790/20508], Loss: 0.6788\n",
      "Epoch [6/30], Batch [17800/20508], Loss: 0.7004\n",
      "Epoch [6/30], Batch [17810/20508], Loss: 0.6828\n",
      "Epoch [6/30], Batch [17820/20508], Loss: 0.6831\n",
      "Epoch [6/30], Batch [17830/20508], Loss: 0.6814\n",
      "Epoch [6/30], Batch [17840/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [17850/20508], Loss: 0.7070\n",
      "Epoch [6/30], Batch [17860/20508], Loss: 0.7095\n",
      "Epoch [6/30], Batch [17870/20508], Loss: 0.6800\n",
      "Epoch [6/30], Batch [17880/20508], Loss: 0.7003\n",
      "Epoch [6/30], Batch [17890/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [17900/20508], Loss: 0.6789\n",
      "Epoch [6/30], Batch [17910/20508], Loss: 0.6953\n",
      "Epoch [6/30], Batch [17920/20508], Loss: 0.6827\n",
      "Epoch [6/30], Batch [17930/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [17940/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [17950/20508], Loss: 0.7162\n",
      "Epoch [6/30], Batch [17960/20508], Loss: 0.7051\n",
      "Epoch [6/30], Batch [17970/20508], Loss: 0.6782\n",
      "Epoch [6/30], Batch [17980/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [17990/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [18000/20508], Loss: 0.6891\n",
      "Epoch [6/30], Batch [18010/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [18020/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [18030/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [18040/20508], Loss: 0.7044\n",
      "Epoch [6/30], Batch [18050/20508], Loss: 0.6767\n",
      "Epoch [6/30], Batch [18060/20508], Loss: 0.7053\n",
      "Epoch [6/30], Batch [18070/20508], Loss: 0.6738\n",
      "Epoch [6/30], Batch [18080/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [18090/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [18100/20508], Loss: 0.6749\n",
      "Epoch [6/30], Batch [18110/20508], Loss: 0.6982\n",
      "Epoch [6/30], Batch [18120/20508], Loss: 0.6961\n",
      "Epoch [6/30], Batch [18130/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [18140/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [18150/20508], Loss: 0.6719\n",
      "Epoch [6/30], Batch [18160/20508], Loss: 0.6998\n",
      "Epoch [6/30], Batch [18170/20508], Loss: 0.6979\n",
      "Epoch [6/30], Batch [18180/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [18190/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [18200/20508], Loss: 0.6670\n",
      "Epoch [6/30], Batch [18210/20508], Loss: 0.6679\n",
      "Epoch [6/30], Batch [18220/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [18230/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [18240/20508], Loss: 0.7038\n",
      "Epoch [6/30], Batch [18250/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [18260/20508], Loss: 0.7095\n",
      "Epoch [6/30], Batch [18270/20508], Loss: 0.7039\n",
      "Epoch [6/30], Batch [18280/20508], Loss: 0.7062\n",
      "Epoch [6/30], Batch [18290/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [18300/20508], Loss: 0.6896\n",
      "Epoch [6/30], Batch [18310/20508], Loss: 0.6804\n",
      "Epoch [6/30], Batch [18320/20508], Loss: 0.6995\n",
      "Epoch [6/30], Batch [18330/20508], Loss: 0.6729\n",
      "Epoch [6/30], Batch [18340/20508], Loss: 0.6719\n",
      "Epoch [6/30], Batch [18350/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [18360/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [18370/20508], Loss: 0.6849\n",
      "Epoch [6/30], Batch [18380/20508], Loss: 0.7012\n",
      "Epoch [6/30], Batch [18390/20508], Loss: 0.6866\n",
      "Epoch [6/30], Batch [18400/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [18410/20508], Loss: 0.7027\n",
      "Epoch [6/30], Batch [18420/20508], Loss: 0.6573\n",
      "Epoch [6/30], Batch [18430/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [18440/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [18450/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [18460/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [18470/20508], Loss: 0.6975\n",
      "Epoch [6/30], Batch [18480/20508], Loss: 0.7103\n",
      "Epoch [6/30], Batch [18490/20508], Loss: 0.7058\n",
      "Epoch [6/30], Batch [18500/20508], Loss: 0.6678\n",
      "Epoch [6/30], Batch [18510/20508], Loss: 0.6910\n",
      "Epoch [6/30], Batch [18520/20508], Loss: 0.6982\n",
      "Epoch [6/30], Batch [18530/20508], Loss: 0.6872\n",
      "Epoch [6/30], Batch [18540/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [18550/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [18560/20508], Loss: 0.6879\n",
      "Epoch [6/30], Batch [18570/20508], Loss: 0.7067\n",
      "Epoch [6/30], Batch [18580/20508], Loss: 0.6924\n",
      "Epoch [6/30], Batch [18590/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [18600/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [18610/20508], Loss: 0.6901\n",
      "Epoch [6/30], Batch [18620/20508], Loss: 0.6898\n",
      "Epoch [6/30], Batch [18630/20508], Loss: 0.6883\n",
      "Epoch [6/30], Batch [18640/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [18650/20508], Loss: 0.6942\n",
      "Epoch [6/30], Batch [18660/20508], Loss: 0.6778\n",
      "Epoch [6/30], Batch [18670/20508], Loss: 0.6716\n",
      "Epoch [6/30], Batch [18680/20508], Loss: 0.6869\n",
      "Epoch [6/30], Batch [18690/20508], Loss: 0.6808\n",
      "Epoch [6/30], Batch [18700/20508], Loss: 0.6760\n",
      "Epoch [6/30], Batch [18710/20508], Loss: 0.6799\n",
      "Epoch [6/30], Batch [18720/20508], Loss: 0.6893\n",
      "Epoch [6/30], Batch [18730/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [18740/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [18750/20508], Loss: 0.7057\n",
      "Epoch [6/30], Batch [18760/20508], Loss: 0.6801\n",
      "Epoch [6/30], Batch [18770/20508], Loss: 0.7017\n",
      "Epoch [6/30], Batch [18780/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [18790/20508], Loss: 0.6991\n",
      "Epoch [6/30], Batch [18800/20508], Loss: 0.7096\n",
      "Epoch [6/30], Batch [18810/20508], Loss: 0.6878\n",
      "Epoch [6/30], Batch [18820/20508], Loss: 0.6897\n",
      "Epoch [6/30], Batch [18830/20508], Loss: 0.7135\n",
      "Epoch [6/30], Batch [18840/20508], Loss: 0.6841\n",
      "Epoch [6/30], Batch [18850/20508], Loss: 0.6655\n",
      "Epoch [6/30], Batch [18860/20508], Loss: 0.7105\n",
      "Epoch [6/30], Batch [18870/20508], Loss: 0.6846\n",
      "Epoch [6/30], Batch [18880/20508], Loss: 0.6863\n",
      "Epoch [6/30], Batch [18890/20508], Loss: 0.6971\n",
      "Epoch [6/30], Batch [18900/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [18910/20508], Loss: 0.6768\n",
      "Epoch [6/30], Batch [18920/20508], Loss: 0.6974\n",
      "Epoch [6/30], Batch [18930/20508], Loss: 0.6729\n",
      "Epoch [6/30], Batch [18940/20508], Loss: 0.6793\n",
      "Epoch [6/30], Batch [18950/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [18960/20508], Loss: 0.6753\n",
      "Epoch [6/30], Batch [18970/20508], Loss: 0.6922\n",
      "Epoch [6/30], Batch [18980/20508], Loss: 0.6652\n",
      "Epoch [6/30], Batch [18990/20508], Loss: 0.6936\n",
      "Epoch [6/30], Batch [19000/20508], Loss: 0.6852\n",
      "Epoch [6/30], Batch [19010/20508], Loss: 0.6964\n",
      "Epoch [6/30], Batch [19020/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [19030/20508], Loss: 0.6737\n",
      "Epoch [6/30], Batch [19040/20508], Loss: 0.6917\n",
      "Epoch [6/30], Batch [19050/20508], Loss: 0.6824\n",
      "Epoch [6/30], Batch [19060/20508], Loss: 0.7048\n",
      "Epoch [6/30], Batch [19070/20508], Loss: 0.6800\n",
      "Epoch [6/30], Batch [19080/20508], Loss: 0.6825\n",
      "Epoch [6/30], Batch [19090/20508], Loss: 0.6791\n",
      "Epoch [6/30], Batch [19100/20508], Loss: 0.7003\n",
      "Epoch [6/30], Batch [19110/20508], Loss: 0.7099\n",
      "Epoch [6/30], Batch [19120/20508], Loss: 0.6851\n",
      "Epoch [6/30], Batch [19130/20508], Loss: 0.7020\n",
      "Epoch [6/30], Batch [19140/20508], Loss: 0.7009\n",
      "Epoch [6/30], Batch [19150/20508], Loss: 0.6773\n",
      "Epoch [6/30], Batch [19160/20508], Loss: 0.6868\n",
      "Epoch [6/30], Batch [19170/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [19180/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [19190/20508], Loss: 0.6907\n",
      "Epoch [6/30], Batch [19200/20508], Loss: 0.7020\n",
      "Epoch [6/30], Batch [19210/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [19220/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [19230/20508], Loss: 0.6744\n",
      "Epoch [6/30], Batch [19240/20508], Loss: 0.6724\n",
      "Epoch [6/30], Batch [19250/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [19260/20508], Loss: 0.6916\n",
      "Epoch [6/30], Batch [19270/20508], Loss: 0.6844\n",
      "Epoch [6/30], Batch [19280/20508], Loss: 0.7068\n",
      "Epoch [6/30], Batch [19290/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [19300/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [19310/20508], Loss: 0.6919\n",
      "Epoch [6/30], Batch [19320/20508], Loss: 0.6696\n",
      "Epoch [6/30], Batch [19330/20508], Loss: 0.6881\n",
      "Epoch [6/30], Batch [19340/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [19350/20508], Loss: 0.6971\n",
      "Epoch [6/30], Batch [19360/20508], Loss: 0.6732\n",
      "Epoch [6/30], Batch [19370/20508], Loss: 0.6727\n",
      "Epoch [6/30], Batch [19380/20508], Loss: 0.6779\n",
      "Epoch [6/30], Batch [19390/20508], Loss: 0.6736\n",
      "Epoch [6/30], Batch [19400/20508], Loss: 0.6930\n",
      "Epoch [6/30], Batch [19410/20508], Loss: 0.6719\n",
      "Epoch [6/30], Batch [19420/20508], Loss: 0.6804\n",
      "Epoch [6/30], Batch [19430/20508], Loss: 0.7028\n",
      "Epoch [6/30], Batch [19440/20508], Loss: 0.6622\n",
      "Epoch [6/30], Batch [19450/20508], Loss: 0.6816\n",
      "Epoch [6/30], Batch [19460/20508], Loss: 0.6939\n",
      "Epoch [6/30], Batch [19470/20508], Loss: 0.6746\n",
      "Epoch [6/30], Batch [19480/20508], Loss: 0.6991\n",
      "Epoch [6/30], Batch [19490/20508], Loss: 0.7041\n",
      "Epoch [6/30], Batch [19500/20508], Loss: 0.6911\n",
      "Epoch [6/30], Batch [19510/20508], Loss: 0.6947\n",
      "Epoch [6/30], Batch [19520/20508], Loss: 0.6848\n",
      "Epoch [6/30], Batch [19530/20508], Loss: 0.6886\n",
      "Epoch [6/30], Batch [19540/20508], Loss: 0.6780\n",
      "Epoch [6/30], Batch [19550/20508], Loss: 0.7057\n",
      "Epoch [6/30], Batch [19560/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [19570/20508], Loss: 0.6894\n",
      "Epoch [6/30], Batch [19580/20508], Loss: 0.6857\n",
      "Epoch [6/30], Batch [19590/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [19600/20508], Loss: 0.6892\n",
      "Epoch [6/30], Batch [19610/20508], Loss: 0.6809\n",
      "Epoch [6/30], Batch [19620/20508], Loss: 0.6968\n",
      "Epoch [6/30], Batch [19630/20508], Loss: 0.6946\n",
      "Epoch [6/30], Batch [19640/20508], Loss: 0.6880\n",
      "Epoch [6/30], Batch [19650/20508], Loss: 0.6759\n",
      "Epoch [6/30], Batch [19660/20508], Loss: 0.6905\n",
      "Epoch [6/30], Batch [19670/20508], Loss: 0.6847\n",
      "Epoch [6/30], Batch [19680/20508], Loss: 0.6952\n",
      "Epoch [6/30], Batch [19690/20508], Loss: 0.7075\n",
      "Epoch [6/30], Batch [19700/20508], Loss: 0.6832\n",
      "Epoch [6/30], Batch [19710/20508], Loss: 0.6705\n",
      "Epoch [6/30], Batch [19720/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [19730/20508], Loss: 0.6842\n",
      "Epoch [6/30], Batch [19740/20508], Loss: 0.6889\n",
      "Epoch [6/30], Batch [19750/20508], Loss: 0.6806\n",
      "Epoch [6/30], Batch [19760/20508], Loss: 0.6902\n",
      "Epoch [6/30], Batch [19770/20508], Loss: 0.6943\n",
      "Epoch [6/30], Batch [19780/20508], Loss: 0.7021\n",
      "Epoch [6/30], Batch [19790/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [19800/20508], Loss: 0.6956\n",
      "Epoch [6/30], Batch [19810/20508], Loss: 0.6705\n",
      "Epoch [6/30], Batch [19820/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [19830/20508], Loss: 0.6856\n",
      "Epoch [6/30], Batch [19840/20508], Loss: 0.6824\n",
      "Epoch [6/30], Batch [19850/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [19860/20508], Loss: 0.6813\n",
      "Epoch [6/30], Batch [19870/20508], Loss: 0.6932\n",
      "Epoch [6/30], Batch [19880/20508], Loss: 0.6899\n",
      "Epoch [6/30], Batch [19890/20508], Loss: 0.6724\n",
      "Epoch [6/30], Batch [19900/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [19910/20508], Loss: 0.6890\n",
      "Epoch [6/30], Batch [19920/20508], Loss: 0.6999\n",
      "Epoch [6/30], Batch [19930/20508], Loss: 0.6834\n",
      "Epoch [6/30], Batch [19940/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [19950/20508], Loss: 0.6836\n",
      "Epoch [6/30], Batch [19960/20508], Loss: 0.6758\n",
      "Epoch [6/30], Batch [19970/20508], Loss: 0.7019\n",
      "Epoch [6/30], Batch [19980/20508], Loss: 0.7083\n",
      "Epoch [6/30], Batch [19990/20508], Loss: 0.6726\n",
      "Epoch [6/30], Batch [20000/20508], Loss: 0.6853\n",
      "Epoch [6/30], Batch [20010/20508], Loss: 0.6759\n",
      "Epoch [6/30], Batch [20020/20508], Loss: 0.6802\n",
      "Epoch [6/30], Batch [20030/20508], Loss: 0.6876\n",
      "Epoch [6/30], Batch [20040/20508], Loss: 0.6822\n",
      "Epoch [6/30], Batch [20050/20508], Loss: 0.7061\n",
      "Epoch [6/30], Batch [20060/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [20070/20508], Loss: 0.7040\n",
      "Epoch [6/30], Batch [20080/20508], Loss: 0.6980\n",
      "Epoch [6/30], Batch [20090/20508], Loss: 0.6721\n",
      "Epoch [6/30], Batch [20100/20508], Loss: 0.7052\n",
      "Epoch [6/30], Batch [20110/20508], Loss: 0.6885\n",
      "Epoch [6/30], Batch [20120/20508], Loss: 0.6774\n",
      "Epoch [6/30], Batch [20130/20508], Loss: 0.6805\n",
      "Epoch [6/30], Batch [20140/20508], Loss: 0.7018\n",
      "Epoch [6/30], Batch [20150/20508], Loss: 0.7009\n",
      "Epoch [6/30], Batch [20160/20508], Loss: 0.6973\n",
      "Epoch [6/30], Batch [20170/20508], Loss: 0.6697\n",
      "Epoch [6/30], Batch [20180/20508], Loss: 0.6906\n",
      "Epoch [6/30], Batch [20190/20508], Loss: 0.6940\n",
      "Epoch [6/30], Batch [20200/20508], Loss: 0.6977\n",
      "Epoch [6/30], Batch [20210/20508], Loss: 0.6739\n",
      "Epoch [6/30], Batch [20220/20508], Loss: 0.6823\n",
      "Epoch [6/30], Batch [20230/20508], Loss: 0.6736\n",
      "Epoch [6/30], Batch [20240/20508], Loss: 0.6959\n",
      "Epoch [6/30], Batch [20250/20508], Loss: 0.7078\n",
      "Epoch [6/30], Batch [20260/20508], Loss: 0.6945\n",
      "Epoch [6/30], Batch [20270/20508], Loss: 0.7023\n",
      "Epoch [6/30], Batch [20280/20508], Loss: 0.6798\n",
      "Epoch [6/30], Batch [20290/20508], Loss: 0.6861\n",
      "Epoch [6/30], Batch [20300/20508], Loss: 0.7138\n",
      "Epoch [6/30], Batch [20310/20508], Loss: 0.6908\n",
      "Epoch [6/30], Batch [20320/20508], Loss: 0.6964\n",
      "Epoch [6/30], Batch [20330/20508], Loss: 0.6745\n",
      "Epoch [6/30], Batch [20340/20508], Loss: 0.6941\n",
      "Epoch [6/30], Batch [20350/20508], Loss: 0.6997\n",
      "Epoch [6/30], Batch [20360/20508], Loss: 0.6858\n",
      "Epoch [6/30], Batch [20370/20508], Loss: 0.7007\n",
      "Epoch [6/30], Batch [20380/20508], Loss: 0.6817\n",
      "Epoch [6/30], Batch [20390/20508], Loss: 0.6790\n",
      "Epoch [6/30], Batch [20400/20508], Loss: 0.6726\n",
      "Epoch [6/30], Batch [20410/20508], Loss: 0.6965\n",
      "Epoch [6/30], Batch [20420/20508], Loss: 0.6933\n",
      "Epoch [6/30], Batch [20430/20508], Loss: 0.6874\n",
      "Epoch [6/30], Batch [20440/20508], Loss: 0.6927\n",
      "Epoch [6/30], Batch [20450/20508], Loss: 0.6635\n",
      "Epoch [6/30], Batch [20460/20508], Loss: 0.6762\n",
      "Epoch [6/30], Batch [20470/20508], Loss: 0.6670\n",
      "Epoch [6/30], Batch [20480/20508], Loss: 0.6850\n",
      "Epoch [6/30], Batch [20490/20508], Loss: 0.6708\n",
      "Epoch [6/30], Batch [20500/20508], Loss: 0.6771\n",
      "GPU mem used: 1821.1MB\n",
      "Epoch [6], Train Loss: 0.6885, Test Loss: 0.6862, Early Stopping Counter: 0\n",
      "\n",
      "\n",
      "\n",
      "Early stopping：0 epochs 未改變\n",
      "評估模型...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAIjCAYAAAA3LxKwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABv80lEQVR4nO3de3zO9f/H8ce1sYOxzXEHOROWiaiZU8m+5liicipnSqOY48KIsiI5RHT6RkWhw5LDNBO+stCQQ8hhktgctzFsbNfvDz+fXG3YyuWzXM/79/a5fV2f9+vz/ryuq6bXXp/P531ZrFarFREREREREziZnYCIiIiIOC4VoyIiIiJiGhWjIiIiImIaFaMiIiIiYhoVoyIiIiJiGhWjIiIiImIaFaMiIiIiYhoVoyIiIiJiGhWjIiIiImIaFaMiclP79++nRYsWeHl5YbFYiI6Ovq3zHz58GIvFwrx5827rvP9mjzzyCI888ojZaYiI3BEqRkX+BQ4ePMhzzz1H5cqVcXNzw9PTk0aNGjFjxgwuXrxo13P36NGDnTt38tprr/HJJ59Qv359u57vTurZsycWiwVPT89cP8f9+/djsViwWCy8+eab+Z7/2LFjjB8/nu3bt9+GbEVE7k6FzE5ARG5u+fLlPPXUU7i6utK9e3dq1apFZmYmGzZsYPjw4ezevZv33nvPLue+ePEi8fHxjB49moEDB9rlHBUqVODixYsULlzYLvPfSqFChbhw4QLffvstTz/9tM3YggULcHNz49KlS39r7mPHjvHKK69QsWJF6tSpk+fjvvvuu791PhGRfyMVoyIFWGJiIp07d6ZChQqsWbMGPz8/YywsLIwDBw6wfPlyu53/5MmTAHh7e9vtHBaLBTc3N7vNfyuurq40atSIzz77LEcxunDhQtq0acOXX355R3K5cOECRYoUwcXF5Y6cT0SkINBlepECbPLkyZw/f54PP/zQphC9pmrVqrz00kvG6ytXrjBx4kSqVKmCq6srFStW5OWXXyYjI8PmuIoVK9K2bVs2bNjAQw89hJubG5UrV+bjjz82YsaPH0+FChUAGD58OBaLhYoVKwJXL29f+/P1xo8fj8VisdkXGxtL48aN8fb2pmjRolSvXp2XX37ZGL/RPaNr1qyhSZMmeHh44O3tzeOPP86ePXtyPd+BAwfo2bMn3t7eeHl50atXLy5cuHDjD/YvunbtysqVK0lJSTH2bdmyhf3799O1a9cc8WfOnGHYsGEEBgZStGhRPD09adWqFT///LMRs3btWh588EEAevXqZVzuv/Y+H3nkEWrVqkVCQgJNmzalSJEixufy13tGe/TogZubW473HxoaSvHixTl27Fie36uISEGjYlSkAPv222+pXLkyDRs2zFN83759iYyM5IEHHmDatGk8/PDDREVF0blz5xyxBw4c4Mknn+Q///kPU6dOpXjx4vTs2ZPdu3cD0KFDB6ZNmwZAly5d+OSTT5g+fXq+8t+9ezdt27YlIyODCRMmMHXqVB577DF++OGHmx63evVqQkNDOXHiBOPHjyc8PJyNGzfSqFEjDh8+nCP+6aef5ty5c0RFRfH0008zb948XnnllTzn2aFDBywWC1999ZWxb+HChdSoUYMHHnggR/yhQ4eIjo6mbdu2vPXWWwwfPpydO3fy8MMPG4VhzZo1mTBhAgD9+/fnk08+4ZNPPqFp06bGPKdPn6ZVq1bUqVOH6dOn06xZs1zzmzFjBqVLl6ZHjx5kZWUB8O677/Ldd9/x9ttv4+/vn+f3KiJS4FhFpEBKTU21AtbHH388T/Hbt2+3Ata+ffva7B82bJgVsK5Zs8bYV6FCBStgXb9+vbHvxIkTVldXV+vQoUONfYmJiVbAOmXKFJs5e/ToYa1QoUKOHMaNG2e9/q+VadOmWQHryZMnb5j3tXN89NFHxr46depYy5QpYz19+rSx7+eff7Y6OTlZu3fvnuN8vXv3tpnziSeesJYsWfKG57z+fXh4eFitVqv1ySeftDZv3txqtVqtWVlZVl9fX+srr7yS62dw6dIla1ZWVo734erqap0wYYKxb8uWLTne2zUPP/ywFbDOnTs317GHH37YZt+qVausgPXVV1+1Hjp0yFq0aFFr+/btb/keRUQKOnVGRQqotLQ0AIoVK5an+BUrVgAQHh5us3/o0KEAOe4tDQgIoEmTJsbr0qVLU716dQ4dOvS3c/6ra/eafvPNN2RnZ+fpmOPHj7N9+3Z69uxJiRIljP21a9fmP//5j/E+r/f888/bvG7SpAmnT582PsO86Nq1K2vXriUpKYk1a9aQlJSU6yV6uHqfqZPT1b8+s7KyOH36tHELwtatW/N8TldXV3r16pWn2BYtWvDcc88xYcIEOnTogJubG++++26ezyUiUlCpGBUpoDw9PQE4d+5cnuJ/++03nJycqFq1qs1+X19fvL29+e2332z2ly9fPsccxYsX5+zZs38z45w6depEo0aN6Nu3Lz4+PnTu3JnFixfftDC9lmf16tVzjNWsWZNTp06Rnp5us/+v76V48eIA+XovrVu3plixYixatIgFCxbw4IMP5vgsr8nOzmbatGlUq1YNV1dXSpUqRenSpdmxYwepqal5PmfZsmXz9bDSm2++SYkSJdi+fTszZ86kTJkyeT5WRKSgUjEqUkB5enri7+/Prl278nXcXx8guhFnZ+dc91ut1r99jmv3M17j7u7O+vXrWb16Nc8++yw7duygU6dO/Oc//8kR+0/8k/dyjaurKx06dGD+/Pl8/fXXN+yKAkyaNInw8HCaNm3Kp59+yqpVq4iNjeW+++7LcwcYrn4++bFt2zZOnDgBwM6dO/N1rIhIQaViVKQAa9u2LQcPHiQ+Pv6WsRUqVCA7O5v9+/fb7E9OTiYlJcV4Mv52KF68uM2T59f8tfsK4OTkRPPmzXnrrbf45ZdfeO2111izZg3ff/99rnNfy3Pfvn05xvbu3UupUqXw8PD4Z2/gBrp27cq2bds4d+5crg99XfPFF1/QrFkzPvzwQzp37kyLFi0ICQnJ8Znk9ReDvEhPT6dXr14EBATQv39/Jk+ezJYtW27b/CIiZlExKlKAjRgxAg8PD/r27UtycnKO8YMHDzJjxgzg6mVmIMcT72+99RYAbdq0uW15ValShdTUVHbs2GHsO378OF9//bVN3JkzZ3Ice23x978uN3WNn58fderUYf78+TbF3a5du/juu++M92kPzZo1Y+LEicyaNQtfX98bxjk7O+foui5ZsoQ//vjDZt+1ojm3wj2/Ro4cyZEjR5g/fz5vvfUWFStWpEePHjf8HEVE/i206L1IAValShUWLlxIp06dqFmzps03MG3cuJElS5bQs2dPAO6//3569OjBe++9R0pKCg8//DCbN29m/vz5tG/f/obLBv0dnTt3ZuTIkTzxxBO8+OKLXLhwgTlz5nDvvffaPMAzYcIE1q9fT5s2bahQoQInTpzgnXfe4Z577qFx48Y3nH/KlCm0atWK4OBg+vTpw8WLF3n77bfx8vJi/Pjxt+19/JWTkxNjxoy5ZVzbtm2ZMGECvXr1omHDhuzcuZMFCxZQuXJlm7gqVarg7e3N3LlzKVasGB4eHgQFBVGpUqV85bVmzRreeecdxo0bZyw19dFHH/HII48wduxYJk+enK/5REQKEnVGRQq4xx57jB07dvDkk0/yzTffEBYWxqhRozh8+DBTp05l5syZRuwHH3zAK6+8wpYtWxg8eDBr1qwhIiKCzz///LbmVLJkSb7++muKFCnCiBEjmD9/PlFRUbRr1y5H7uXLl+e///0vYWFhzJ49m6ZNm7JmzRq8vLxuOH9ISAgxMTGULFmSyMhI3nzzTRo0aMAPP/yQ70LOHl5++WWGDh3KqlWreOmll9i6dSvLly+nXLlyNnGFCxdm/vz5ODs78/zzz9OlSxfWrVuXr3OdO3eO3r17U7duXUaPHm3sb9KkCS+99BJTp07lxx9/vC3vS0TEDBZrfu7wFxERERG5jdQZFRERERHTqBgVEREREdOoGBURERER06gYFRERERHTqBgVEREREdOoGBURERER06gYFRERERHT3JXfwORed6DZKYiInZzdMsvsFETETtxMrErsWTtc3Ka/t25GnVERERERMY2KURERERGLk/22fDp37hyDBw+mQoUKuLu707BhQ7Zs2WKMW61WIiMj8fPzw93dnZCQEPbv328zx5kzZ+jWrRuenp54e3vTp08fzp8/bxOzY8cOmjRpgpubG+XKlWPy5Mk5clmyZAk1atTAzc2NwMBAVqxYYTOel1xuRcWoiIiIiMVivy2f+vbtS2xsLJ988gk7d+6kRYsWhISE8McffwAwefJkZs6cydy5c9m0aRMeHh6EhoZy6dIlY45u3bqxe/duYmNjWbZsGevXr6d///7GeFpaGi1atKBChQokJCQwZcoUxo8fz3vvvWfEbNy4kS5dutCnTx+2bdtG+/btad++Pbt27TJi8pLLLT/6u/G76XXPqMjdS/eMity9TL1ntN5Ldpv7YsKMvMdevEixYsX45ptvaNOmjbG/Xr16tGrViokTJ+Lv78/QoUMZNmwYAKmpqfj4+DBv3jw6d+7Mnj17CAgIYMuWLdSvXx+AmJgYWrduzdGjR/H392fOnDmMHj2apKQkXFxcABg1ahTR0dHs3bsXgE6dOpGens6yZcuMPBo0aECdOnWYO3cuVqv1lrnkhTqjIiIiIna8TJ+RkUFaWprNlpGRkWsaV65cISsrCzc3N5v97u7ubNiwgcTERJKSkggJCTHGvLy8CAoKIj4+HoD4+Hi8vb2NQhQgJCQEJycnNm3aZMQ0bdrUKEQBQkND2bdvH2fPnjVirj/PtZhr58lLLnmhYlRERETEjqKiovDy8rLZoqKico0tVqwYwcHBTJw4kWPHjpGVlcWnn35KfHw8x48fJykpCQAfHx+b43x8fIyxpKQkypQpYzNeqFAhSpQoYROT2xzXxm4Wc/34rXLJCxWjIiIiIna8ZzQiIoLU1FSbLSIi4oapfPLJJ1itVsqWLYurqyszZ86kS5cuODndnWXb3fmuRERERAoIV1dXPD09bTZXV9cbxlepUoV169Zx/vx5fv/9dzZv3szly5epXLkyvr6+ACQnJ9sck5ycbIz5+vpy4sQJm/ErV65w5swZm5jc5rg2drOY68dvlUteqBgVERERKUBLO13j4eGBn58fZ8+eZdWqVTz++ONUqlQJX19f4uLijLi0tDQ2bdpEcHAwAMHBwaSkpJCQkGDErFmzhuzsbIKCgoyY9evXc/nyZSMmNjaW6tWrU7x4cSPm+vNci7l2nrzkkhcqRkVEREQKkFWrVhETE0NiYiKxsbE0a9aMGjVq0KtXLywWC4MHD+bVV19l6dKl7Ny5k+7du+Pv70/79u0BqFmzJi1btqRfv35s3ryZH374gYEDB9K5c2f8/f0B6Nq1Ky4uLvTp04fdu3ezaNEiZsyYQXh4uJHHSy+9RExMDFOnTmXv3r2MHz+en376iYEDr65alJdc8uKu/DpQERERkXz5G+uB2su1e0qPHj1KiRIl6NixI6+99hqFCxcGYMSIEaSnp9O/f39SUlJo3LgxMTExNk/gL1iwgIEDB9K8eXOcnJzo2LEjM2fONMa9vLz47rvvCAsLo169epQqVYrIyEibtUgbNmzIwoULGTNmDC+//DLVqlUjOjqaWrVqGTF5yeVWtM6oiPyraJ1RkbuXqeuMNhhpt7kv/viG3ea+G+gyvYiIiIiYRpfpRURERArQZXpHo86oiIiIiJhGnVERERGRf7AEk/wz+uRFRERExDTqjIqIiIjonlHTqDMqIiIiIqZRZ1RERERE94yaRsWoiIiIiC7Tm0a/BoiIiIiIadQZFREREdFletPokxcRERER06gzKiIiIqLOqGn0yYuIiIiIadQZFREREXHS0/RmUWdUREREREyjzqiIiIiI7hk1jYpRERERES16bxr9GiAiIiIiplFnVERERESX6U2jT15ERERETKPOqIiIiIjuGTWNOqMiIiIiYhp1RkVERER0z6hp9MmLiIiIiGnUGRURERHRPaOmUTEqIiIiosv0ptEnLyIiIiKmUWdURERERJfpTaPOqIiIiIiYRp1REREREd0zahp98iIiIiJiGnVGRURERHTPqGnUGRURERER06gzKiIiIqJ7Rk2jYlRERERExahp9MmLiIiIiGnUGRURERHRA0ymUWdUREREREyjzqiIiIiI7hk1jT55ERERETGNOqMiIiIiumfUNOqMioiIiBQQWVlZjB07lkqVKuHu7k6VKlWYOHEiVqvViOnZsycWi8Vma9mypc08Z86coVu3bnh6euLt7U2fPn04f/68TcyOHTto0qQJbm5ulCtXjsmTJ+fIZ8mSJdSoUQM3NzcCAwNZsWKFzbjVaiUyMhI/Pz/c3d0JCQlh//79+XrPKkZFRERELE722/LhjTfeYM6cOcyaNYs9e/bwxhtvMHnyZN5++22buJYtW3L8+HFj++yzz2zGu3Xrxu7du4mNjWXZsmWsX7+e/v37G+NpaWm0aNGCChUqkJCQwJQpUxg/fjzvvfeeEbNx40a6dOlCnz592LZtG+3bt6d9+/bs2rXLiJk8eTIzZ85k7ty5bNq0CQ8PD0JDQ7l06VLeP3rr9aX2XcK97kCzUxAROzm7ZZbZKYiInbiZePOge4cP7Tb3xa/65Dm2bdu2+Pj48OGHf+bTsWNH3N3d+fTTT4GrndGUlBSio6NznWPPnj0EBASwZcsW6tevD0BMTAytW7fm6NGj+Pv7M2fOHEaPHk1SUhIuLi4AjBo1iujoaPbu3QtAp06dSE9PZ9myZcbcDRo0oE6dOsydOxer1Yq/vz9Dhw5l2LBhAKSmpuLj48O8efPo3Llznt6zOqMiIiIidpSRkUFaWprNlpGRkWtsw4YNiYuL49dffwXg559/ZsOGDbRq1combu3atZQpU4bq1aszYMAATp8+bYzFx8fj7e1tFKIAISEhODk5sWnTJiOmadOmRiEKEBoayr59+zh79qwRExISYnPe0NBQ4uPjAUhMTCQpKckmxsvLi6CgICMmL1SMioiIiMP76z2Yt3OLiorCy8vLZouKiso1j1GjRtG5c2dq1KhB4cKFqVu3LoMHD6Zbt25GTMuWLfn444+Ji4vjjTfeYN26dbRq1YqsrCwAkpKSKFOmjM28hQoVokSJEiQlJRkxPj4+NjHXXt8q5vrx64/LLSYv9DS9iIiIiB1FREQQHh5us8/V1TXX2MWLF7NgwQIWLlzIfffdx/bt2xk8eDD+/v706NEDwObyd2BgILVr16ZKlSqsXbuW5s2b2++N2ImKUREREXF4Fjsu7eTq6nrD4vOvhg8fbnRH4Wqx+dtvvxEVFWUUo39VuXJlSpUqxYEDB2jevDm+vr6cOHHCJubKlSucOXMGX19fAHx9fUlOTraJufb6VjHXj1/b5+fnZxNTp06dPL1f0GV6ERERkQLjwoULODnZlmfOzs5kZ2ff8JijR49y+vRpoyAMDg4mJSWFhIQEI2bNmjVkZ2cTFBRkxKxfv57Lly8bMbGxsVSvXp3ixYsbMXFxcTbnio2NJTg4GIBKlSrh6+trE5OWlsamTZuMmLxQMSoiIiJiseOWD+3ateO1115j+fLlHD58mK+//pq33nqLJ554AoDz588zfPhwfvzxRw4fPkxcXByPP/44VatWJTQ0FICaNWvSsmVL+vXrx+bNm/nhhx8YOHAgnTt3xt/fH4CuXbvi4uJCnz592L17N4sWLWLGjBk2txO89NJLxMTEMHXqVPbu3cv48eP56aefGDjw6qpFFouFwYMH8+qrr7J06VJ27txJ9+7d8ff3p3379nl+z7pMLyIiIlJAvP3224wdO5YXXniBEydO4O/vz3PPPUdkZCRwtUu6Y8cO5s+fT0pKCv7+/rRo0YKJEyfa3AqwYMECBg4cSPPmzXFycqJjx47MnDnTGPfy8uK7774jLCyMevXqUapUKSIjI23WIm3YsCELFy5kzJgxvPzyy1SrVo3o6Ghq1aplxIwYMYL09HT69+9PSkoKjRs3JiYmBjc3tzy/Z60zKiL/KlpnVOTuZeY6o0Wfnme3uc8v7mm3ue8G6oyKiIiIw7PnA0xyc7pnVERERERMo86oiIiIODx1Rs2jzqiIiIiImEadUREREXF46oyaR51RERERETGNOqMiIiIiaoyaRp1RERERETGNOqMiIiLi8HTPqHnUGRURERER06gzKiIiIg5PnVHzqBgVERERh6di1Dy6TC8iIiIiplFnVERERByeOqPmUWdUREREREyjzqiIiIiIGqOmUWdUREREREyjzqiIiIg4PN0zah51RkVERETENOqMioiIiMNTZ9Q8KkZFRETE4akYNY8u04uIiIiIadQZFREREVFj1DTqjIqIiIiIadQZFREREYene0bNo86oiIiIiJhGnVERERFxeOqMmsfUYjQzM5Po6Gji4+NJSkoCwNfXl4YNG/L444/j4uJiZnoiIiIiYmemXaY/cOAANWvWpEePHmzbto3s7Gyys7PZtm0b3bt357777uPAgQNmpSciIiIOxGKx2G2TmzOtMzpgwAACAwPZtm0bnp6eNmNpaWl0796dsLAwVq1aZVKGIiIi4ihUNJrHtGL0hx9+YPPmzTkKUQBPT08mTpxIUFCQCZmJiIiIyJ1i2mV6b29vDh8+fMPxw4cP4+3tfcfyEREREQdmseMmN2VaZ7Rv3750796dsWPH0rx5c3x8fABITk4mLi6OV199lUGDBpmVnoiIiIjcAaYVoxMmTMDDw4MpU6YwdOhQ414Nq9WKr68vI0eOZMSIEWalJyIiIg5E94yax9SlnUaOHMnIkSNJTEy0WdqpUqVKZqYlIiIiIndIgVj0vlKlSipARURExDTqjJpHXwcqIiIiIqYpEJ1RERERETOpM2oeFaMiIiIiqkVNo8v0IiIiImIa04vRmJgYNmzYYLyePXs2derUoWvXrpw9e9bEzERERMRR6LvpzWN6MTp8+HDS0tIA2LlzJ0OHDqV169YkJiYSHh5ucnYiIiIiYk+mF6OJiYkEBAQA8OWXX9K2bVsmTZrE7NmzWblypcnZiYiIiCMoKJ3RrKwsxo4dS6VKlXB3d6dKlSpMnDgRq9VqxFitViIjI/Hz88Pd3Z2QkBD2799vM8+ZM2fo1q0bnp6eeHt706dPH86fP28Ts2PHDpo0aYKbmxvlypVj8uTJOfJZsmQJNWrUwM3NjcDAQFasWGEznpdcbsX0YtTFxYULFy4AsHr1alq0aAFAiRIljI6piIiIiCN44403mDNnDrNmzWLPnj288cYbTJ48mbffftuImTx5MjNnzmTu3Lls2rQJDw8PQkNDuXTpkhHTrVs3du/eTWxsLMuWLWP9+vX079/fGE9LS6NFixZUqFCBhIQEpkyZwvjx43nvvfeMmI0bN9KlSxf69OnDtm3baN++Pe3bt2fXrl35yuVWLNbrS20TPPbYY2RmZtKoUSMmTpxIYmIiZcuW5bvvvmPgwIH8+uuv+Z7Tve5AO2Qqf1fRIq6Me6Etjz16P6WLF+XnfUcZNvkLEn45YsSMHdCGXk80xLuYO/E/H+LFSYs4eOSkMb53+StU8C9pM+/Ymd/w5kexAJT3K8G+FRNynPvh7m+yeedhAAoVcmJ47xY80zYI/zLe/PpbMmNmfEPsxj1GfL+nGtPvySZU8C8BwJ5DSUx6byXf/fDLbfs85J85u2WW2SnIDXz4/nvMnD6Vbs90Z0TEaP744yitWzTPNXbKW9NpEdoKgOPHjvHaxPFs2bwJ9yJFeOzx9rw4eCiFCl1d8GVrwk/MeOtNEhMTuXTpIn7+/jz5VGee7dHTmC/hpy3M+++H7PllFydPnmTazNk82jzkhrlOfCWSLxYvYvjICJ7p3vOGcXJnuZm4xk/Fl5bZbe7DM9rmObZt27b4+Pjw4YcfGvs6duyIu7s7n376KVarFX9/f4YOHcqwYcMASE1NxcfHh3nz5tG5c2f27NlDQEAAW7ZsoX79+sDVZ3Rat27N0aNH8ff3Z86cOYwePZqkpCRcXFwAGDVqFNHR0ezduxeATp06kZ6ezrJlf342DRo0oE6dOsydOzdPueSF6Z3RWbNmUahQIb744gvmzJlD2bJlAVi5ciUtW7Y0OTu5HeZEduXRBjXoPWY+9Z+exOr4vSyfOwj/0l4ADO0ZwgtdHubFSZ/TtPubpF/M5NvZYbi62P6t9Mo7y6gYEmFs73y2Lse5Wj030yZm654/C97xL7Sjb8fGhE9eQt2Or/LBFxtYNLUf91e/x4j5IzmFsW9/Q8Nuk2nUbQprN//Kkmn9qVnZ106fjsjdYdfOHXyx5HPuvbe6sc/X14+4tRtstgFhgyhSpAiNGzcFrl6SHPjCc1y+fJn5n37Oq5NeZ2n017wza6Yxj3uRInTu+gz//fhTvv52Bf2eG8Cst6fzxeJFRszFixeoXr06EWPG3TLXuNWx7Pz5Z0qXKXMbPwGRG8vIyCAtLc1my8jIyDW2YcOGxMXFGc24n3/+mQ0bNtCq1dVf3q59hXpIyJ+/bHl5eREUFER8fDwA8fHxeHt7G4UoQEhICE5OTmzatMmIadq0qVGIAoSGhrJv3z7jAfL4+Hib81yLuXaevOSSF6avM1q+fHmbivuaadOmmZCN3G5uroVp37wOTw15jx+2HgTgtXdX0LppLfo91YRX3llGWNdmvPH+Kpat3QlA37Ef89vqKB5rdj9LViUYc51Pv0Ty6XM3Pd+ZlPQbxnRt+xBvfLCKVRuudjnfX7KBR4Nq8NKzj9J7zMcArFi/y+aY8bO/pd9TjXmodiX2HEr6ex+CyF3uQno6ESOHM+6VV3n/3TnGfmdnZ0qVLm0TuyZuNS1atqKIhwcA8Rs3cOjgAd774CNKlioF1OSFQS8x4603GfDCQAq7uFCzZgA1awYYc5Qtew9xq2PZuvUnnny6EwCNmzxM4yYP3zLX5ORkXp80kTnvfcigAc/dhncvdwt7PvUeFRXFK6+8YrNv3LhxjB8/PkfsqFGjSEtLo0aNGjg7O5OVlcVrr71Gt27dAEhKuvrfIh8fH5vjfHx8jLGkpCTK/OWXrUKFClGiRAmbmL9+Ffu1OZOSkihevDhJSUm3PM+tcskL0zujW7duZefOncbrb775hvbt2/Pyyy+TmZlpYmZyOxRydqJQIWcuZV622X8p4zIN61ahYtmS+JX2Ys2mvcZY2vlLbNl1mKDaFW2OGdqrBUe/f4P4z0YypHtznJ1z/uv7xfTn+C0uirj/DqHNw4E2Yy6FC+XI4+KlTBrWrZJr7k5OFp4KrYeHuwubdiTm522LOJRJr06gadOHaRDc8KZxv+zexb69e3iiw5PGvp+3b6datXv/vxC9qmGjxpw/f54DBw/kOs+ePb/w87Zt1K//UL7yzM7OZvSo4fTs1YeqVavl61hxABb7bREREaSmptpsERERuaaxePFiFixYwMKFC9m6dSvz58/nzTffZP78+XZ762YzvTP63HPPMWrUKAIDAzl06BCdO3fmiSeeYMmSJVy4cIHp06ff9PiMjIwcrW5rdhYWJ2c7Zi15df5CBj/+fIiIfq3Yl5hM8uk0nm5Zn6DalTj4+0l8S3kCcOKMbTfzxOlz+JT0NF6/89k6tu35nbNp6TS4vzITBj2Gb2kvRk79CoD0ixmMnPoV8dsPkp1tpX1IHRa/1Y+nw99n+bqrv+ysjt/Di888yoatBzj0+ymaPVSdxx+tg7Oz7W/D91X1Z+38obi5FOL8xQw6DX2fveqKiuRq5Yrl7NnzCwsXfXHL2K+//ILKlatQp+4Dxr7Tp05RomQpm7iS///69KmTNvv/82hTzp45Q1ZWFs+/MJAOTz6Vr1w/+vB9nAsVousz3fN1nMg/5erqiqura55ihw8fzqhRo4z7LQMDA/ntt9+IioqiR48e+PpevW0sOTkZPz8/47jk5GTq1KkDgK+vLydOnLCZ98qVK5w5c8Y43tfXl+TkZJuYa69vFXP9+K1yyQvTO6O//vqrkfCSJUto2rQpCxcuZN68eXz55Ze3PD4qKgovLy+b7Upywi2Pkzun95iPsVjg0HevkbppOmFdHmZxzE9kZ+f92bmZn67hfwn72bX/GB98sYFRb33FgE4P41L46u9Tp1PSmfnpGrbs+o2EX44wduZSPluxhSHd/3x4YtiULzh45AQ/fzWWtM3TmTbqKT5e+mOOPH49nExQ5yiadn+T95ds4P0Jz1JD94yK5JB0/DiTX3+NqDem3PI/tJcuXWLlimW07/jkTeNu5qOPF/DZ4i8ZE/kKCz75mJXL8/7AyS+7d7Hgk4+Z+FqUFiGXXBWUpZ0uXLiAk5Nteebs7Ex2djYAlSpVwtfXl7i4OGM8LS2NTZs2ERwcDEBwcDApKSkkJPxZD61Zs4bs7GyCgoKMmPXr13P58p9XDGNjY6levTrFixc3Yq4/z7WYa+fJSy55YXpn1Gq1Gh/w6tWradv26hNn5cqV49SpU7c8PiIiIsfi+GWajLz9icrflnj0FC36zqCImwueRd1IOpXGJ6/3IvGPUySdurp8V5kSxYw/A5QpWYwd+47ecM4tOw9TuLAzFfxLsP+3EzeI+Y1Hg2oYr0+dPc/T4e/j6lKIkl4eHDuZyqsvPk7iH6dtjrt8JYtDv1/9d2/bnt+pd195wro8wqDXPv/bn4HI3eiXX3Zz5vRpOj/VwdiXlZVFwk9b+PyzBWzZthNn56tXqWK/i+HixUu0e6y9zRwlS5Vi184dNvtOnz71/2O295vec085AKrdW53Tp08x5523adUmb08pb034iTNnTtMypJlNrlOnvHG1sI1dk7c3LWJn7dq147XXXqN8+fLcd999bNu2jbfeeovevXsDV4vmwYMH8+qrr1KtWjUqVarE2LFj8ff3p3379gDUrFmTli1b0q9fP+bOncvly5cZOHAgnTt3xt/fH4CuXbvyyiuv0KdPH0aOHMmuXbuYMWOGzTM7L730Eg8//DBTp06lTZs2fP755/z000/G8k95ySUvTC9G69evz6uvvkpISAjr1q1jzpyrN78nJibmuCE2N7m1vnWJvmC6cCmTC5cy8S7mTkjDmoye/g2H/zjN8ZOpNAuqzo5f/wCgmIcbD9aqyPtLNtxwrvur30NWVjYnz9z4gaba1cvaFLjXZGRe4djJVAoVcqJ98zp8Gbv1pnk7WSw5nuwXEQhq0IAvor+12TdudAQVK1emV59+RiEKEP3VlzzS7FFKlChhE39/nTp88N5cTp8+TcmSV5dv+3HjRooWLUqVKlVveO7s7Gwu/+Ue8Jtp+9jjBP3lntYB/fvQtt3jtH+iww2OEkdSUDrmb7/9NmPHjuWFF17gxIkT+Pv789xzzxEZGWnEjBgxgvT0dPr3709KSgqNGzcmJiYGNzc3I2bBggUMHDiQ5s2b4+TkRMeOHZk5889VKry8vPjuu+8ICwujXr16lCpVisjISJu1SBs2bMjChQsZM2YML7/8MtWqVSM6OppatWrlK5dbMf2/sNOnT6dbt25ER0czevRoqla9+pfPF198QcOGN78ZXv4dQoJrYrHAr4dPUKVcaSYNac+vicl8vPTqsg+zF37PyL4tOXDkJIf/OM24F9pw/GQqS7//GYCg2pV4sFYF1v20n3Ppl2hQuxJvDOvIZyu2kHLuIgDd2gVx+fIVtu+92k19/NH76fF4MAMmLDTyeLBWBfzLePPzvqOULePN6Oda4+Rk4a15q42YCYMeY9UPu/n9+FmKebjRqVV9mtavRrsX3rlTH5fIv4aHR1GqVbvXZp97kSJ4e3nb7D/y228k/LSF2XPe++sUBDdsTOUqVRk9agRDhg7n1KmTzHp7Op26dDOWnPl84QJ8/fyoVLkycHVN0Y/n/Zeu3Z415rmQns6RI38u5fbH0aPs3bMHLy8v/Pz98fYujrd3cZtzFy5UmFKlSlGxUuV//mGI3CbFihVj+vTpN31mxmKxMGHCBCZMyLm+9jUlSpRg4cKFNxwHqF27Nv/73/9uGvPUU0/x1FM3vj87L7nciunFaO3atW2epr9mypQpNr9Vy7+XV1E3Jgx6jLI+3pxJvcA3cdsZN/tbrly5envG1HmrKeLuyqwxXfAu5s7G7Qd5LOwdMjKvAJCReZmnQusx+vnWuBYuxOFjp3l7wffM/MT2stqofi0p71eCK1ey+fVwMs+O+i9fr95ujLu6FmZcWFsqlS3F+QsZrPphN33Gfkzq+YtGTOkSRflwYnd8S3mSev4Su/b/QbsX3rF52l9E8if66y/x8fEluFHjHGPOzs68/c5cXpswnu7dOuHu7k67x5/ghYEvGjHZ1mxmTn+LP/44SiFnZ+4pV57B4cN48uk/F9TevXsXfXv9+WDSm5OjAHjs8SeYOOl1+705uWsUkMaoQzL9G5jsQd/AJHL30jcwidy9zPwGpqrDVtpt7gNvtrLb3HcD0zujWVlZTJs2jcWLF3PkyJEca4ueOXPGpMxERETEURSUe0YdkelLO73yyiu89dZbdOrUidTUVMLDw+nQoQNOTk65fjOBiIiIyO1msdhvk5szvRhdsGAB77//PkOHDqVQoUJ06dKFDz74gMjISH788Uez0xMREREROzK9GE1KSiIw8OrXNhYtWpTU1FQA2rZty/Lly81MTURERBxEQVn03hGZXozec889HD9+HIAqVarw3XffAbBly5Y8f3WWiIiIiPw7mV6MPvHEE8bXSA0aNIixY8dSrVo1unfvbnzbgIiIiIg96Z5R85j+NP3rr/+5/lunTp0oX7488fHxVKtWjXbt2pmYmYiIiIjYm+nF6F8FBwcTHBxsdhoiIiLiQJyc1MI0iynF6NKlS/Mc+9hjj9kxExERERExkynFaPv27fMUZ7FYyMrKsm8yIiIi4vB0b6d5TClGs7OzzTitiIiISK60BJN5TH+aXkREREQcl2nF6Jo1awgICCAtLS3HWGpqKvfddx/r1683ITMRERFxNFrayTymFaPTp0+nX79+eHp65hjz8vLiueeeY9q0aSZkJiIiIiJ3imnF6M8//0zLli1vON6iRQsSEhLuYEYiIiLiqPR1oOYxrRhNTk6mcOHCNxwvVKgQJ0+evIMZiYiIiMidZloxWrZsWXbt2nXD8R07duDn53cHMxIRERFHpc6oeUwrRlu3bs3YsWO5dOlSjrGLFy8ybtw42rZta0JmIiIiInKnmPZ1oGPGjOGrr77i3nvvZeDAgVSvXh2AvXv3Mnv2bLKyshg9erRZ6YmIiIgDUQPTPKYVoz4+PmzcuJEBAwYQERGB1WoFrrbJQ0NDmT17Nj4+PmalJyIiIg5El9PNY1oxClChQgVWrFjB2bNnOXDgAFarlWrVqlG8eHEz0xIRERGRO8TUYvSa4sWL8+CDD5qdhoiIiDgoNUbNo68DFRERERHTFIjOqIiIiIiZdM+oedQZFRERERHTqDMqIiIiDk+NUfOoMyoiIiIiplFnVERERBye7hk1jzqjIiIiImIadUZFRETE4akxah4VoyIiIuLwdJnePLpMLyIiIiKmUWdUREREHJ4ao+ZRZ1RERERETKPOqIiIiDg83TNqHnVGRURERMQ06oyKiIiIw1Nj1DzqjIqIiIiIadQZFREREYene0bNo2JUREREHJ5qUfPoMr2IiIhIAVGxYkUsFkuOLSwsDIBHHnkkx9jzzz9vM8eRI0do06YNRYoUoUyZMgwfPpwrV67YxKxdu5YHHngAV1dXqlatyrx583LkMnv2bCpWrIibmxtBQUFs3rzZZvzSpUuEhYVRsmRJihYtSseOHUlOTs73e1YxKiIiIg4vtwLwdm35sWXLFo4fP25ssbGxADz11FNGTL9+/WxiJk+ebIxlZWXRpk0bMjMz2bhxI/Pnz2fevHlERkYaMYmJibRp04ZmzZqxfft2Bg8eTN++fVm1apURs2jRIsLDwxk3bhxbt27l/vvvJzQ0lBMnThgxQ4YM4dtvv2XJkiWsW7eOY8eO0aFDh/x/9lar1Zrvowo497oDzU5BROzk7JZZZqcgInbiZuLNg02mbrDb3P8b2vhvHzt48GCWLVvG/v37sVgsPPLII9SpU4fp06fnGr9y5Uratm3LsWPH8PHxAWDu3LmMHDmSkydP4uLiwsiRI1m+fDm7du0yjuvcuTMpKSnExMQAEBQUxIMPPsisWVf/zs3OzqZcuXIMGjSIUaNGkZqaSunSpVm4cCFPPvkkAHv37qVmzZrEx8fToEGDPL9HdUZFRETE4dmzM5qRkUFaWprNlpGRccucMjMz+fTTT+ndu7dNh3XBggWUKlWKWrVqERERwYULF4yx+Ph4AgMDjUIUIDQ0lLS0NHbv3m3EhISE2JwrNDSU+Ph447wJCQk2MU5OToSEhBgxCQkJXL582SamRo0alC9f3ojJKxWjIiIiInYUFRWFl5eXzRYVFXXL46Kjo0lJSaFnz57Gvq5du/Lpp5/y/fffExERwSeffMIzzzxjjCclJdkUooDxOikp6aYxaWlpXLx4kVOnTpGVlZVrzPVzuLi44O3tfcOYvNLT9CIiIuLw7Pk0fUREBOHh4Tb7XF1db3nchx9+SKtWrfD39zf29e/f3/hzYGAgfn5+NG/enIMHD1KlSpXbl/QdpGJURERExI5cXV3zVHxe77fffmP16tV89dVXN40LCgoC4MCBA1SpUgVfX98cT71fe8Ld19fX+P+/PvWenJyMp6cn7u7uODs74+zsnGvM9XNkZmaSkpJi0x29PiavdJleREREHF5BeZr+mo8++ogyZcrQpk2bm8Zt374dAD8/PwCCg4PZuXOnzVPvsbGxeHp6EhAQYMTExcXZzBMbG0twcDAALi4u1KtXzyYmOzubuLg4I6ZevXoULlzYJmbfvn0cOXLEiMkrdUZFRETE4RWkRe+zs7P56KOP6NGjB4UK/VmqHTx4kIULF9K6dWtKlizJjh07GDJkCE2bNqV27doAtGjRgoCAAJ599lkmT55MUlISY8aMISwszOjOPv/888yaNYsRI0bQu3dv1qxZw+LFi1m+fLlxrvDwcHr06EH9+vV56KGHmD59Ounp6fTq1QsALy8v+vTpQ3h4OCVKlMDT05NBgwYRHBycryfpQcWoiIiISIGyevVqjhw5Qu/evW32u7i4sHr1aqMwLFeuHB07dmTMmDFGjLOzM8uWLWPAgAEEBwfj4eFBjx49mDBhghFTqVIlli9fzpAhQ5gxYwb33HMPH3zwAaGhoUZMp06dOHnyJJGRkSQlJVGnTh1iYmJsHmqaNm0aTk5OdOzYkYyMDEJDQ3nnnXfy/X61zqiI/KtonVGRu5eZ64w+OjN/yxHlx5oX83fZ2tHonlERERERMY0u04uIiIjDK0j3jDoadUZFRERExDTqjIqIiIjDc1Jr1DTqjIqIiIiIadQZFREREYenxqh5VIyKiIiIw/u735Qk/5wu04uIiIiIadQZFREREYfnpMaoadQZFRERERHTqDMqIiIiDk/3jJpHnVERERERMY06oyIiIuLw1Bg1jzqjIiIiImIadUZFRETE4VlQa9QsKkZFRETE4WlpJ/PoMr2IiIiImEadUREREXF4WtrJPOqMioiIiIhp1BkVERERh6fGqHnUGRURERER06gzKiIiIg7PSa1R06gzKiIiIiKmUWdUREREHJ4ao+ZRMSoiIiIOT0s7mUeX6UVERETENOqMioiIiMNTY9Q86oyKiIiIiGnUGRURERGHp6WdzKPOqIiIiIiYRp1RERERcXjqi5pHnVERERERMY06oyIiIuLwtM6oeVSMioiIiMNzUi1qGl2mFxERERHTqDMqIiIiDk+X6c2jzqiIiIiImEadUREREXF4aoyaR51RERERETGNOqMiIiLi8HTPqHnyVIwuXbo0zxM+9thjfzsZEREREXEseSpG27dvn6fJLBYLWVlZ/yQfERERkTtO64yaJ0/3jGZnZ+dpUyEqIiIi/0YWi8VuW35UrFgx1znCwsIAuHTpEmFhYZQsWZKiRYvSsWNHkpOTbeY4cuQIbdq0oUiRIpQpU4bhw4dz5coVm5i1a9fywAMP4OrqStWqVZk3b16OXGbPnk3FihVxc3MjKCiIzZs324znJZe80ANMIiIiIgXEli1bOH78uLHFxsYC8NRTTwEwZMgQvv32W5YsWcK6des4duwYHTp0MI7PysqiTZs2ZGZmsnHjRubPn8+8efOIjIw0YhITE2nTpg3NmjVj+/btDB48mL59+7Jq1SojZtGiRYSHhzNu3Di2bt3K/fffT2hoKCdOnDBibpVLXlmsVqs1vwelp6ezbt06jhw5QmZmps3Yiy++mO8kbjf3ugPNTkFE7OTslllmpyAiduJm4mPVvT/fabe5/9s58G8fO3jwYJYtW8b+/ftJS0ujdOnSLFy4kCeffBKAvXv3UrNmTeLj42nQoAErV66kbdu2HDt2DB8fHwDmzp3LyJEjOXnyJC4uLowcOZLly5eza9cu4zydO3cmJSWFmJgYAIKCgnjwwQeZNevq37nZ2dmUK1eOQYMGMWrUKFJTU2+ZS17l+x/7tm3baN26NRcuXCA9PZ0SJUpw6tQpoxVcEIpRERERkYIiIyODjIwMm32urq64urre9LjMzEw+/fRTwsPDsVgsJCQkcPnyZUJCQoyYGjVqUL58eaMAjI+PJzAw0ChEAUJDQxkwYAC7d++mbt26xMfH28xxLWbw4MHGeRMSEoiIiDDGnZycCAkJIT4+HiBPueRVvi/TDxkyhHbt2nH27Fnc3d358ccf+e2336hXrx5vvvlmfqcTERERMZ2TxWK3LSoqCi8vL5stKirqljlFR0eTkpJCz549AUhKSsLFxQVvb2+bOB8fH5KSkoyY6wvRa+PXxm4Wk5aWxsWLFzl16hRZWVm5xlw/x61yyat8d0a3b9/Ou+++i5OTE87OzmRkZFC5cmUmT55Mjx49/ta9AiIiIiJ3q4iICMLDw2323aorCvDhhx/SqlUr/P397ZVagZDvYrRw4cI4OV1tqJYpU4YjR45Qs2ZNvLy8+P333297giIiIiL2Zs817/NySf6vfvvtN1avXs1XX31l7PP19SUzM5OUlBSbjmRycjK+vr5GzF+fer/2hPv1MX996j05ORlPT0/c3d1xdnbG2dk515jr57hVLnmV78v0devWZcuWLQA8/PDDREZGsmDBAgYPHkytWrXyO52IiIiI/MVHH31EmTJlaNOmjbGvXr16FC5cmLi4OGPfvn37OHLkCMHBwQAEBwezc+dOm6feY2Nj8fT0JCAgwIi5fo5rMdfmcHFxoV69ejYx2dnZxMXFGTF5ySWv8t0ZnTRpEufOnQPgtddeo3v37gwYMIBq1arx3//+N7/TiYiIiJiuIH0daHZ2Nh999BE9evSgUKE/SzUvLy/69OlDeHg4JUqUwNPTk0GDBhEcHGw8MNSiRQsCAgJ49tlnmTx5MklJSYwZM4awsDCjO/v8888za9YsRowYQe/evVmzZg2LFy9m+fLlxrnCw8Pp0aMH9evX56GHHmL69Omkp6fTq1evPOeSV/kuRuvXr2/8uUyZMsYSACIiIiLyz61evZojR47Qu3fvHGPTpk3DycmJjh07kpGRQWhoKO+8844x7uzszLJlyxgwYADBwcF4eHjQo0cPJkyYYMRUqlSJ5cuXM2TIEGbMmME999zDBx98QGhoqBHTqVMnTp48SWRkJElJSdSpU4eYmBibh5pulUte/a11Rgs6rTMqcvfSOqMidy8z1xl97ovddpv73Sfvs9vcd4N8/2OvVKnSTVvZhw4d+kcJiYiIiNxpTgXoMr2jyXcxem1B1GsuX77Mtm3biImJYfjw4bcrLxERERFxAPkuRl966aVc98+ePZuffvrpHyckIiIicqepMWqefC/tdCOtWrXiyy+/vF3TiYiIiIgDuG23Cn/xxReUKFHidk0nIiIicscUpKWdHE2+i9G6deva/AOzWq0kJSVx8uTJv/U4v4iIiIg4rnwXo48//rhNMerk5ETp0qV55JFHqFGjxm1N7u9qNbCX2SmIiJ0cO3vJ7BRExE4ql3Yz7dy37b5Fybd8F6Pjx4+3QxoiIiIi4ojy/YuAs7OzzfedXnP69GmcnZ1vS1IiIiIid5LFYrHbJjeX787ojb6wKSMjAxcXl3+ckIiIiMid5qSa0TR5LkZnzpwJXP3N4YMPPqBo0aLGWFZWFuvXry8w94yKiIiIyL9DnovRadOmAVc7o3PnzrW5JO/i4kLFihWZO3fu7c9QRERExM7UGTVPnovRxMREAJo1a8ZXX31F8eLF7ZaUiIiIiDiGfN8z+v3339sjDxERERHT6EEj8+T7afqOHTvyxhtv5Ng/efJknnrqqduSlIiIiIg4hnwXo+vXr6d169Y59rdq1Yr169fflqRERERE7iQni/02ubl8F6Pnz5/PdQmnwoULk5aWdluSEhERERHHkO9iNDAwkEWLFuXY//nnnxMQEHBbkhIRERG5kywW+21yc/l+gGns2LF06NCBgwcP8uijjwIQFxfHwoUL+eKLL257giIiIiL25qSq0TT5LkbbtWtHdHQ0kyZN4osvvsDd3Z3777+fNWvWUKJECXvkKCIiIiJ3qXwXowBt2rShTZs2AKSlpfHZZ58xbNgwEhISyMrKuq0JioiIiNhbvu9blNvmb3/269evp0ePHvj7+zN16lQeffRRfvzxx9uZm4iIiIjc5fLVGU1KSmLevHl8+OGHpKWl8fTTT5ORkUF0dLQeXhIREZF/Ld0yap48d0bbtWtH9erV2bFjB9OnT+fYsWO8/fbb9sxNRERERO5yee6Mrly5khdffJEBAwZQrVo1e+YkIiIickfpaXrz5LkzumHDBs6dO0e9evUICgpi1qxZnDp1yp65iYiIiMhdLs/FaIMGDXj//fc5fvw4zz33HJ9//jn+/v5kZ2cTGxvLuXPn7JmniIiIiN1o0Xvz5Ptpeg8PD3r37s2GDRvYuXMnQ4cO5fXXX6dMmTI89thj9shRRERExK703fTm+UfLalWvXp3Jkydz9OhRPvvss9uVk4iIiIg4iL+16P1fOTs70759e9q3b387phMRERG5o/QAk3n0hQMiIiIiYprb0hkVERER+TdTY9Q86oyKiIiIiGnUGRURERGHp6fezaPOqIiIiIiYRp1RERERcXgW1Bo1i4pRERERcXi6TG8eXaYXEREREdOoMyoiIiIOT51R86gzKiIiIiKmUWdUREREHJ5Fq96bRp1RERERETGNilERERFxeE4W+2359ccff/DMM89QsmRJ3N3dCQwM5KeffjLGe/bsicVisdlatmxpM8eZM2fo1q0bnp6eeHt706dPH86fP28Ts2PHDpo0aYKbmxvlypVj8uTJOXJZsmQJNWrUwM3NjcDAQFasWGEzbrVaiYyMxM/PD3d3d0JCQti/f3++3q+KUREREZEC4uzZszRq1IjChQuzcuVKfvnlF6ZOnUrx4sVt4lq2bMnx48eN7bPPPrMZ79atG7t37yY2NpZly5axfv16+vfvb4ynpaXRokULKlSoQEJCAlOmTGH8+PG89957RszGjRvp0qULffr0Ydu2bbRv35727duza9cuI2by5MnMnDmTuXPnsmnTJjw8PAgNDeXSpUt5fs8Wq9Vqze8HVdB1+DDB7BRExE7efOw+s1MQETupXNrNtHO/tf6Q3eYOb1o5z7GjRo3ihx9+4H//+98NY3r27ElKSgrR0dG5ju/Zs4eAgAC2bNlC/fr1AYiJiaF169YcPXoUf39/5syZw+jRo0lKSsLFxcU4d3R0NHv37gWgU6dOpKens2zZMmPuBg0aUKdOHebOnYvVasXf35+hQ4cybNgwAFJTU/Hx8WHevHl07tw5T+9ZnVERERFxeE4Wi922jIwM0tLSbLaMjIxc81i6dCn169fnqaeeokyZMtStW5f3338/R9zatWspU6YM1atXZ8CAAZw+fdoYi4+Px9vb2yhEAUJCQnBycmLTpk1GTNOmTY1CFCA0NJR9+/Zx9uxZIyYkJMTmvKGhocTHxwOQmJhIUlKSTYyXlxdBQUFGTJ4++zxHioiIiEi+RUVF4eXlZbNFRUXlGnvo0CHmzJlDtWrVWLVqFQMGDODFF19k/vz5RkzLli35+OOPiYuL44033mDdunW0atWKrKwsAJKSkihTpozNvIUKFaJEiRIkJSUZMT4+PjYx117fKub68euPyy0mL7S0k4iIiDg8ey56HxERQXh4uM0+V1fXXGOzs7OpX78+kyZNAqBu3brs2rWLuXPn0qNHDwCby9+BgYHUrl2bKlWqsHbtWpo3b26nd2E/6oyKiIiI2JGrqyuenp42242KUT8/PwICAmz21axZkyNHjtxw/sqVK1OqVCkOHDgAgK+vLydOnLCJuXLlCmfOnMHX19eISU5Otom59vpWMdePX39cbjF5oWJUREREHJ7FYr8tPxo1asS+ffts9v36669UqFDhhsccPXqU06dP4+fnB0BwcDApKSkkJPz5QPeaNWvIzs4mKCjIiFm/fj2XL182YmJjY6levbrx5H5wcDBxcXE254qNjSU4OBiASpUq4evraxOTlpbGpk2bjJi8UDEqIiIiUkAMGTKEH3/8kUmTJnHgwAEWLlzIe++9R1hYGADnz59n+PDh/Pjjjxw+fJi4uDgef/xxqlatSmhoKHC1k9qyZUv69evH5s2b+eGHHxg4cCCdO3fG398fgK5du+Li4kKfPn3YvXs3ixYtYsaMGTa3E7z00kvExMQwdepU9u7dy/jx4/npp58YOHAgcPVbqwYPHsyrr77K0qVL2blzJ927d8ff35/27dvn+T3rnlERERFxeE4UjK8DffDBB/n666+JiIhgwoQJVKpUienTp9OtWzcAnJ2d2bFjB/PnzyclJQV/f39atGjBxIkTbS79L1iwgIEDB9K8eXOcnJzo2LEjM2fONMa9vLz47rvvCAsLo169epQqVYrIyEibtUgbNmzIwoULGTNmDC+//DLVqlUjOjqaWrVqGTEjRowgPT2d/v37k5KSQuPGjYmJicHNLe/LdGmdURH5V9E6oyJ3LzPXGZ39w2G7zR3WqKLd5r4bqDMqIiIiDi+/93bK7aNiVERERByePZd2kpvTA0wiIiIiYhp1RkVERMThOek6vWnUGRURERER06gzKiIiIg5PjVHzqDMqIiIiIqZRZ1REREQcnu4ZNY86oyIiIiJiGnVGRURExOGpMWoeFaMiIiLi8HSp2Dz67EVERETENOqMioiIiMOz6Dq9adQZFRERERHTqDMqIiIiDk99UfOoMyoiIiIiplFnVERERByeFr03jzqjIiIiImIadUZFRETE4akvah4VoyIiIuLwdJXePLpMLyIiIiKmUWdUREREHJ4WvTePOqMiIiIiYhp1RkVERMThqTtnHn32IiIiImIadUZFRETE4emeUfOoMyoiIiIiplFnVERERBye+qLmUWdUREREREyjzqiIiIg4PN0zah4VoyIiIuLwdKnYPPrsRURERMQ06oyKiIiIw9NlevOoMyoiIiIiplFnVERERBye+qLmUWdUREREREyjzqiIiIg4PN0yah51RkVERETENOqMioiIiMNz0l2jplExKiIiIg5Pl+nNo8v0IiIiImIadUZFRETE4Vl0md406oyKiIiIFCB//PEHzzzzDCVLlsTd3Z3AwEB++uknY9xqtRIZGYmfnx/u7u6EhISwf/9+mznOnDlDt27d8PT0xNvbmz59+nD+/HmbmB07dtCkSRPc3NwoV64ckydPzpHLkiVLqFGjBm5ubgQGBrJixQqb8bzkcisqRkVERMThWSz22/Lj7NmzNGrUiMKFC7Ny5Up++eUXpk6dSvHixY2YyZMnM3PmTObOncumTZvw8PAgNDSUS5cuGTHdunVj9+7dxMbGsmzZMtavX0///v2N8bS0NFq0aEGFChVISEhgypQpjB8/nvfee8+I2bhxI126dKFPnz5s27aN9u3b0759e3bt2pWvXG752VutVmv+PqaCr8OHCWanICJ28uZj95mdgojYSeXSbqade8XuE3abu/V9ZfIcO2rUKH744Qf+97//5TputVrx9/dn6NChDBs2DIDU1FR8fHyYN28enTt3Zs+ePQQEBLBlyxbq168PQExMDK1bt+bo0aP4+/szZ84cRo8eTVJSEi4uLsa5o6Oj2bt3LwCdOnUiPT2dZcuWGedv0KABderUYe7cuXnKJS/UGRURERGH54TFbltGRgZpaWk2W0ZGRq55LF26lPr16/PUU09RpkwZ6taty/vvv2+MJyYmkpSUREhIiLHPy8uLoKAg4uPjAYiPj8fb29soRAFCQkJwcnJi06ZNRkzTpk2NQhQgNDSUffv2cfbsWSPm+vNci7l2nrzkkrfPvoBKTk5mwoQJZqchIiIi8o9ERUXh5eVls0VFReUae+jQIebMmUO1atVYtWoVAwYM4MUXX2T+/PkAJCUlAeDj42NznI+PjzGWlJREmTK23dhChQpRokQJm5jc5rj+HDeKuX78VrnkRYF9mj4pKYlXXnmFyMhIs1MRERGRu5w91xmNiIggPDzcZp+rq2uusdnZ2dSvX59JkyYBULduXXbt2sXcuXPp0aOH/ZI0kWnF6I4dO246vm/fvjuUiYiIiDg6exajrq6uNyw+/8rPz4+AgACbfTVr1uTLL78EwNfXF7h6BdnPz8+ISU5Opk6dOkbMiRO298BeuXKFM2fOGMf7+vqSnJxsE3Pt9a1irh+/VS55Ydpl+jp16lC3bl3q1KmTY6tbt26eb3oVERERuVs0atQoR0Pu119/pUKFCgBUqlQJX19f4uLijPG0tDQ2bdpEcHAwAMHBwaSkpJCQ8OcD3WvWrCE7O5ugoCAjZv369Vy+fNmIiY2NpXr16saT+8HBwTbnuRZz7Tx5ySUvTCtGS5Qowfvvv09iYmKO7dChQzZPbomIiIjYk8WO/8uPIUOG8OOPPzJp0iQOHDjAwoULee+99wgLC7uap8XC4MGDefXVV1m6dCk7d+6ke/fu+Pv70759e+BqJ7Vly5b069ePzZs388MPPzBw4EA6d+6Mv78/AF27dsXFxYU+ffqwe/duFi1axIwZM2xuJ3jppZeIiYlh6tSp7N27l/Hjx/PTTz8xcODAPOeSF6Zdpq9Xrx7Hjh0zKv2/SklJ4S5cdUpERETkhh588EG+/vprIiIimDBhApUqVWL69Ol069bNiBkxYgTp6en079+flJQUGjduTExMDG5ufy6NtWDBAgYOHEjz5s1xcnKiY8eOzJw50xj38vLiu+++IywsjHr16lGqVCkiIyNt1iJt2LAhCxcuZMyYMbz88stUq1aN6OhoatWqla9cbsW0dUa//vpr0tPTeeaZZ3IdP3v2LEuXLv1bN+tqnVGRu5fWGRW5e5m5zmjc3lN2m7t5jVJ2m/tuYFpn9IknnrjpePHixe/ap8ZERERE5KoCu7STiIiIyJ2S33s75fYpsIvei4iIiMjdT51RERERcXj2XGdUbk7FqIiIiDg8XaY3jy7Ti4iIiIhpTC9GY2Ji2LBhg/F69uzZ1KlTh65du3L27FkTMxMRERFH4WSx3yY3Z3oxOnz4cNLS0gDYuXMnQ4cOpXXr1iQmJtp8C4CIiIiI3H1Mv2c0MTGRgIAAAL788kvatm3LpEmT2Lp1K61btzY5OxEREXEEumfUPKZ3Rl1cXLhw4QIAq1evpkWLFsDV766/1jEVERERkbuT6Z3Rxo0bEx4eTqNGjdi8eTOLFi0C4Ndff+Wee+4xOTv5p+Y+XYsyxVxz7F/5ywk+SzhG5wf8ub+sJ6WKupB26Qqbf0vhs4Q/uHA5G4CKJdx5orYvNX2KUsytECfPZ7Bq7ymW7z5hzHWfb1Emtqme4xy9F/5MysUrAHSo7UuDit6U9XIjMyubvSfS+WTLUY6lZhjxhZ0t9HzoHhpXLkEhZwvbj6bx3sYjpF66crs/FpG7wqcfzmHBR3Nt9t1TviLvL/yGc2mpfPLhO2zdHM/J5CS8vIsT3LQZ3fuG4VG0mM0xsSu+4atFn/DH779RpIgHTZq1IGzoywAkH/+Dnk/lvEr21txPqFmrNgAjBvZh5/afcsQ8GNyECVNmceXKZea/N4ufftzA8WNH8fAoRt36QfQa8BIlS5W5XR+H/MtpaSfzmF6Mzpo1ixdeeIEvvviCOXPmULZsWQBWrlxJy5YtTc5O/qkRS/fa3Lxdvrg741vdy8bEs5TwKEzxIoWZv/kov6dcpHRRV55vVJ4SRQozZc0hACqXLELqpctMX5fI6fRMqpcpyoDGFcjOtrJyz0mbc4Ut2cXFy1nG69SLfxaR9/kVZeWekxw4mY6zk4Vu9csyrmU1XvzyFzKuXC18ewWVo145L6asOcSFzCz6NSzHyJAqvLxsnx0/IZF/twqVqjBp+nvGa2dnZwBOnzrBmVMn6RsWTvlKVTiRdIxZU17l9KmTjHl1qhH/1ecf89XnH9PnhXCq3xdIxsWLJCcdy3GeSdPfo0KlKsZrTy8v489jJ73F5cuXjdfnUlN4odfTNGn2HwAyLl3i4K976dKjP5WrVedcWhrvzniDV0a+xMwPP7t9H4aI/C2mF6Ply5dn2bJlOfZPmzbNhGzkdkv7S1exQ20vjqddYnfSeQCj6ARIPpfJgp/+YPAjlXCyQLYV1uw/Dfu5LuYM1ct40KCid45iNPXSFS5kZpGbiasO2Lx+e/1h5nW7nyqlivBL0nmKFHai+b0lmb42kV3HzwEwa/1h3n6yFveW9uDXk+l/+zMQuZs5OxeiRMlSOfZXrFyNMa+9Zbz2L1uOHv0HMXniy2RduYJzoUKcS0vj4/dnM+6NmdStH2TEVqp6b475PL28cj0PQDFPL5vX6+JicHV1M4pRj6LFmDT9XZuYAeERDO7XjRNJxynj65f3Nyx3LTVGzWN6Mbp161YKFy5MYGAgAN988w0fffQRAQEBjB8/HhcXF5MzlNulkJOFplVL8u2u5BvGeLg4cyEzi2zrjecp4uLM+YycRedb7WtS2NmJI2cvsmjrMfaeuHEBWaTw1e7N+YyrxXLlUh4Udnbi52PnjJg/UjM4eT6De8uoGBW5kT+O/ka3x0NwcXGhRq376fXcizcs7tLTz1PEoyjOha7+p2fblniyrdmcPnmC/t3ac+FCOgG16tBv4FBK+/jaHPvKyJfIzMygbLkKPNWtFw0aP3LDnL5b9jUPN2+Jm3uRG8ZcOH8ei8WCR7FiN4wRx+Kk6/SmMf0Bpueee45ff/0VgEOHDtG5c2eKFCnCkiVLGDFixC2Pz8jIIC0tzWbLupxp77Tlb3iogjceLs5Xu525KObqzFN1/Yjdd+qGc1Qv40GjyiX4bt+fXdGzFy8zd8NvTI47xOS4g5xKz2RCm+pULume6xwWoHeDe9iTdJ4jZy8BUNy9EJezsnN0VlMuXqF4kcL5fKcijqF6QCBDX57Iq1PfYeCw0SQf/4PhYb24cCHnL2+pKWf5bN57tGrX0diXdOwo1uxsFn3yAc+9OJzRE6dyLi2Vl4c8Z1x2d3MvQr+BQ3l54hRemTKL+2rXZULEYH7csDbXnPb9spPDhw7Qst0TN8w7MyOD/86ZzsMhrfDwKPrPPgQR+cdML0Z//fVX6tSpA8CSJUto2rQpCxcuZN68eXz55Ze3PD4qKgovLy+b7dcVH9k5a/k7mt9bkq1HUzl74XKOMffCToxuUY3fz15i0dac94sBlC/uxqiQKizedoyf//izg3ksNYPv9p3i0OkL7DuRzuz//ca+5PO0reWT6zz9GpanfHF33vr+UK7jIpI3DwY3psmjLahU9V7qBTViwpRZnD9/jv+tWWUTl55+nnHDB1K+YmWe6fO8sT/bauXKlSs8P3gk9YIaUbNWbUaOf51jR4+wY+tmALy8i9Ohc3dq3Feb6jVr0XvAYB5t0YYvFs7LNadVy76mYpVqVA8IzHX8ypXLTIocjhUrA4eNvj0fhNwVLHbc5OZML0atVivZ2VcfIFm9erWxtmi5cuU4derGHbJrIiIiSE1Ntdnubd3LrjlL/pUu6kJtf09W59L1dCvsxNjQaly8nMUbcQfJyuUS/T3eboxvdS+x+07xxfakW55v/8l0/DxzPsXfN7gc9ct5EbniV05fVxSfvXiFws5OFHFxton3di+Ua/EsIjkVLeZJ2XIVOHb0d2PfhQvpjB36Au5FPBg7aRqFCv15peHaPaDlK/75YJJ38RJ4enlzIvnGP+fVAwI59sfvOfZfuniBdXGrCG2Te1f0ypXLTBo7nBNJx5k07V11RUUKCNOL0fr16/Pqq6/yySefsG7dOtq0aQNcXQzfxyf3ztb1XF1d8fT0tNmcC+s+04Lm0WolSbt0hYTfU232uxd2YlzLalzJthIVe4DLuVSi5bzdmND6Xr7ff5qFCbl3Tf+qUskiOYrIvsHlCKrgzbiVv3LivO2tHIdOpXM5K5va/n/eP+bv5Urpoq78epN7T0XkTxcvXOD4H78bRWZ6+nlGD3meQoUKM+6NGbi42v6CGBBYB4CjRw4b+86lpZKWmnLTh4oOHdiX68NM//s+lsuXM3k0tE2OsWuF6LGjR5g0/V08vbzz/wbl7qbWqGlMf4Bp+vTpdOvWjejoaEaPHk3VqlUB+OKLL2jYsKHJ2cntYAEevbck3+8/bfNg0rVC1KWQE9PXHqSIizPXHjdIu3SFbOvVS/OvtLqXbX+k8e2uZLzdr/4rm23980n9tveVIflcBr+fvYRLIQsh95aill8xJsT8+Rh+/4blaFK5BFGrD3LxcpYxz4XMLDKzrFy4nE3cr6fpFXQP5zOucCEzm77B5dibfF4PL4ncwPuzphLU6GF8fP04feokn344BydnZx4OaWUUohkZlxgeOYkL6elcSL/6s+TlXRxnZ2fuKV+R4CbNeHfGG7w4IpIiHh58NHcm95SvyP0PPAhA7MqlFC5UmCr31gDgh3VxfLc8mpdGjsuRz6plXxPcpFmOQvPKlcu8NmYYB37dwytvvE12djZnTl+9SlPM04vChXVfuIiZLFar9SbPLZvn0qVLODs7/62/JDp8mGCHjOTvur9sMca1vJewJbs4nvbnIvM3Wqwe4LlFOzl5PpNOdf3o9IB/jvET5zJ4fvEuANoH+vCfGqUoUcSFzCvZHD5zkSXbj7Hr+Hkj/qs+9XI9z9vrD/P9/z9QZSx6X6UEhZ0sbP/j6qL3KRe16H1B8uZj95mdgvy/qHEj2LV9K2lpKXh5F+e+2nXp0X8Q/mXLsWPrFka+2DfX4+YtWYGP39U1pdPTz/PezClsXBeHxcmJwDr1eP6lkcbT9LErl7JkwUecSDqGs3MhypWvSMeuPY1lm645euQw/bo+zmvT5vLAg8E2YzdaOB/gjZkfUPv/C18xX+XSbqade9PB1FsH/U1BVbxuHeTACmwx+k+oGBW5e6kYFbl7qRh1TKZfps/KymLatGksXryYI0eOkJlpey/fmTNnTMpMREREHIWWGTWP6Q8wvfLKK7z11lt06tSJ1NRUwsPD6dChA05OTowfP97s9ERERMQB6Pkl85hejC5YsID333+foUOHUqhQIbp06cIHH3xAZGQkP/74o9npiYiIiIgdmV6MJiUlGV8FWrRoUVJTr96z0bZtW5YvX25maiIiIuIo1Bo1jenF6D333MPx48cBqFKlCt999x0AW7ZswdU156LlIiIiInL3ML0YfeKJJ4iLiwNg0KBBjB07lmrVqtG9e3d69+5tcnYiIiLiCCx2/J/cnOlP07/++uvGnzt16kT58uWJj4+nWrVqtGvXzsTMRERERMTeTC9G/yo4OJjg4OBbB4qIiIjcJlrayTymFKNLly7Nc+xjjz1mx0xERERExEymFKPt27fPU5zFYiErK8u+yYiIiIjDU2PUPKYUo9nZ2WacVkRERCR3qkZNY/rT9CIiIiLiuEwrRtesWUNAQABpaWk5xlJTU7nvvvtYv369CZmJiIiIo9HSTuYxrRidPn06/fr1w9PTM8eYl5cXzz33HNOmTTMhMxERERG5U0wrRn/++Wdatmx5w/EWLVqQkJBwBzMSERERR2Wx2G+TmzOtGE1OTqZw4cI3HC9UqBAnT568gxmJiIiIyJ1mWjFatmxZdu3adcPxHTt24OfndwczEhEREUdlseMmN2daMdq6dWvGjh3LpUuXcoxdvHiRcePG0bZtWxMyExEREZE7xbSvAx0zZgxfffUV9957LwMHDqR69eoA7N27l9mzZ5OVlcXo0aPNSk9EREQciVqYpjGtGPXx8WHjxo0MGDCAiIgIrFYrcPVbl0JDQ5k9ezY+Pj5mpSciIiIOREswmce0YhSgQoUKrFixgrNnz3LgwAGsVivVqlWjePHiZqYlIiIiIndIgfgGpuLFi/Pggw/y0EMPqRAVERGRO66gLO00fvx4LBaLzVajRg1j/JFHHskx/vzzz9vMceTIEdq0aUORIkUoU6YMw4cP58qVKzYxa9eu5YEHHsDV1ZWqVasyb968HLnMnj2bihUr4ubmRlBQEJs3b7YZv3TpEmFhYZQsWZKiRYvSsWNHkpOT8/eGKSDFqIiIiIhcdd9993H8+HFj27Bhg814v379bMYnT55sjGVlZdGmTRsyMzPZuHEj8+fPZ968eURGRhoxiYmJtGnThmbNmrF9+3YGDx5M3759WbVqlRGzaNEiwsPDGTduHFu3buX+++8nNDSUEydOGDFDhgzh22+/ZcmSJaxbt45jx47RoUOHfL9fi/XazZp3kQ4farF8kbvVm4/dZ3YKImInlUu7mXbuXUfP223uWvcUzXPs+PHjiY6OZvv27bmOP/LII9SpU4fp06fnOr5y5Uratm3LsWPHjGdv5s6dy8iRIzl58iQuLi6MHDmS5cuX2yyx2blzZ1JSUoiJiQEgKCiIBx98kFmzZgGQnZ1NuXLlGDRoEKNGjSI1NZXSpUuzcOFCnnzySeDqQ+g1a9YkPj6eBg0a5Pk9qzMqIiIiYkcZGRmkpaXZbBkZGTeM379/P/7+/lSuXJlu3bpx5MgRm/EFCxZQqlQpatWqRUREBBcuXDDG4uPjCQwMtHkIPDQ0lLS0NHbv3m3EhISE2MwZGhpKfHw8AJmZmSQkJNjEODk5ERISYsQkJCRw+fJlm5gaNWpQvnx5IyavVIyKiIiI2HHV+6ioKLy8vGy2qKioXNMICgpi3rx5xMTEMGfOHBITE2nSpAnnzp0DoGvXrnz66ad8//33RERE8Mknn/DMM88YxyclJeVYjeja66SkpJvGpKWlcfHiRU6dOkVWVlauMdfP4eLigre39w1j8srUp+lFRERE7nYRERGEh4fb7HN1dc01tlWrVsafa9euTVBQEBUqVGDx4sX06dOH/v37G+OBgYH4+fnRvHlzDh48SJUqVezzBuxMxaiIiIg4PHuuM+rq6nrD4vNWvL29uffeezlw4ECu40FBQQAcOHCAKlWq4Ovrm+Op92tPuPv6+hr//9en3pOTk/H09MTd3R1nZ2ecnZ1zjbl+jszMTFJSUmy6o9fH5JUu04uIiIgUUOfPn+fgwYP4+fnlOn7tQadr48HBwezcudPmqffY2Fg8PT0JCAgwYuLi4mzmiY2NJTg4GAAXFxfq1atnE5OdnU1cXJwRU69ePQoXLmwTs2/fPo4cOWLE5JU6oyIiIuLw8rseqL0MGzaMdu3aUaFCBY4dO8a4ceNwdnamS5cuHDx4kIULF9K6dWtKlizJjh07GDJkCE2bNqV27doAtGjRgoCAAJ599lkmT55MUlISY8aMISwszOjOPv/888yaNYsRI0bQu3dv1qxZw+LFi1m+fLmRR3h4OD169KB+/fo89NBDTJ8+nfT0dHr16gWAl5cXffr0ITw8nBIlSuDp6cmgQYMIDg7O15P0oGJUREREpMB8GejRo0fp0qULp0+fpnTp0jRu3Jgff/yR0qVLc+nSJVavXm0UhuXKlaNjx46MGTPGON7Z2Zlly5YxYMAAgoOD8fDwoEePHkyYMMGIqVSpEsuXL2fIkCHMmDGDe+65hw8++IDQ0FAjplOnTpw8eZLIyEiSkpKoU6cOMTExNg81TZs2DScnJzp27EhGRgahoaG88847+X7PWmdURP5VtM6oyN3LzHVG9xxLt9vcNf097Db33UCdUREREZGC0hp1QHqASURERERMo86oiIiIODx7Lu0kN6fOqIiIiIiYRp1RERERcXgFZWknR6TOqIiIiIiYRp1RERERcXhqjJpHxaiIiIiIqlHT6DK9iIiIiJhGnVERERFxeFrayTzqjIqIiIiIadQZFREREYenpZ3Mo86oiIiIiJhGnVERERFxeGqMmkedURERERExjTqjIiIiImqNmkbFqIiIiDg8Le1kHl2mFxERERHTqDMqIiIiDk9LO5lHnVERERERMY06oyIiIuLw1Bg1jzqjIiIiImIadUZFRERE1Bo1jTqjIiIiImIadUZFRETE4WmdUfOoGBURERGHp6WdzKPL9CIiIiJiGnVGRURExOGpMWoedUZFRERExDTqjIqIiIjD0z2j5lFnVERERERMo86oiIiIiO4aNY06oyIiIiJiGnVGRURExOHpnlHzqBgVERERh6da1Dy6TC8iIiIiplFnVERERByeLtObR51RERERETGNOqMiIiLi8Cy6a9Q06oyKiIiIiGnUGRURERFRY9Q06oyKiIiIiGlUjIqIiIjDs9hxy4/x48djsVhstho1ahjjly5dIiwsjJIlS1K0aFE6duxIcnKyzRxHjhyhTZs2FClShDJlyjB8+HCuXLliE7N27VoeeOABXF1dqVq1KvPmzcuRy+zZs6lYsSJubm4EBQWxefNmm/G85JIXKkZFRETE4Vks9tvy67777uP48ePGtmHDBmNsyJAhfPvttyxZsoR169Zx7NgxOnToYIxnZWXRpk0bMjMz2bhxI/Pnz2fevHlERkYaMYmJibRp04ZmzZqxfft2Bg8eTN++fVm1apURs2jRIsLDwxk3bhxbt27l/vvvJzQ0lBMnTuQ5l7yyWK1Wa76PKuA6fJhgdgoiYidvPnaf2SmIiJ1ULu1m2rlPnLtst7nLFCuc59jx48cTHR3N9u3bc4ylpqZSunRpFi5cyJNPPgnA3r17qVmzJvHx8TRo0ICVK1fStm1bjh07ho+PDwBz585l5MiRnDx5EhcXF0aOHMny5cvZtWuXMXfnzp1JSUkhJiYGgKCgIB588EFmzZoFQHZ2NuXKlWPQoEGMGjUqT7nklTqjIiIi4vAsdvxfRkYGaWlpNltGRsYNc9m/fz/+/v5UrlyZbt26ceTIEQASEhK4fPkyISEhRmyNGjUoX7488fHxAMTHxxMYGGgUogChoaGkpaWxe/duI+b6Oa7FXJsjMzOThIQEmxgnJydCQkKMmLzkklcqRkVERETsKCoqCi8vL5stKioq19igoCDmzZtHTEwMc+bMITExkSZNmnDu3DmSkpJwcXHB29vb5hgfHx+SkpIASEpKsilEr41fG7tZTFpaGhcvXuTUqVNkZWXlGnP9HLfKJa+0tJOIiIiIHZd2ioiIIDw83Gafq6trrrGtWrUy/ly7dm2CgoKoUKECixcvxt3d3X5JmkidURERERE7cnV1xdPT02a7UTH6V97e3tx7770cOHAAX19fMjMzSUlJsYlJTk7G19cXAF9f3xxPtF97fasYT09P3N3dKVWqFM7OzrnGXD/HrXLJKxWjIiIi4vAKytJOf3X+/HkOHjyIn58f9erVo3DhwsTFxRnj+/bt48iRIwQHBwMQHBzMzp07bZ56j42NxdPTk4CAACPm+jmuxVybw8XFhXr16tnEZGdnExcXZ8TkJZe80mV6ERERkQJi2LBhtGvXjgoVKnDs2DHGjRuHs7MzXbp0wcvLiz59+hAeHk6JEiXw9PRk0KBBBAcHG0+vt2jRgoCAAJ599lkmT55MUlISY8aMISwszOjGPv/888yaNYsRI0bQu3dv1qxZw+LFi1m+fLmRR3h4OD169KB+/fo89NBDTJ8+nfT0dHr16gWQp1zySsWoiIiIOLy/sx6oPRw9epQuXbpw+vRpSpcuTePGjfnxxx8pXbo0ANOmTcPJyYmOHTuSkZFBaGgo77zzjnG8s7Mzy5YtY8CAAQQHB+Ph4UGPHj2YMGGCEVOpUiWWL1/OkCFDmDFjBvfccw8ffPABoaGhRkynTp04efIkkZGRJCUlUadOHWJiYmwearpVLnmldUZF5F9F64yK3L3MXGf0THqW3eYu4eFst7nvBrpnVERERERMo8v0IiIi4vAKymV6R6TOqIiIiIiYRsWoiIiIiJhGxaiIiIiImEb3jIqIiIjD0z2j5lFnVERERERMo86oiIiIODzLP/7iTvm7VIyKiIiIw9NlevPoMr2IiIiImEadUREREXF4aoyaR51RERERETGNOqMiIiIiao2aRp1RERERETGNOqMiIiLi8LS0k3nUGRURERER06gzKiIiIg5P64yaR51RERERETGNOqMiIiLi8NQYNY+KURERERFVo6bRZXoRERERMY06oyIiIuLwtLSTedQZFRERERHTqDMqIiIiDk9LO5lHnVERERERMY3FarVazU5C5O/KyMggKiqKiIgIXF1dzU5HRG4j/XyLOAYVo/KvlpaWhpeXF6mpqXh6epqdjojcRvr5FnEMukwvIiIiIqZRMSoiIiIiplExKiIiIiKmUTEq/2qurq6MGzdODzeI3IX08y3iGPQAk4iIiIiYRp1RERERETGNilERERERMY2KURERERExjYpRKTAsFgvR0dFmpyEidqCfbxG5ERWjckckJSUxaNAgKleujKurK+XKlaNdu3bExcWZnRoAVquVyMhI/Pz8cHd3JyQkhP3795udlsi/QkH/+f7qq69o0aIFJUuWxGKxsH37drNTEpHrqBgVuzt8+DD16tVjzZo1TJkyhZ07dxITE0OzZs0ICwszOz0AJk+ezMyZM5k7dy6bNm3Cw8OD0NBQLl26ZHZqIgXav+HnOz09ncaNG/PGG2+YnYqI5MYqYmetWrWyli1b1nr+/PkcY2fPnjX+DFi//vpr4/WIESOs1apVs7q7u1srVapkHTNmjDUzM9MY3759u/WRRx6xFi1a1FqsWDHrAw88YN2yZYvVarVaDx8+bG3btq3V29vbWqRIEWtAQIB1+fLlueaXnZ1t9fX1tU6ZMsXYl5KSYnV1dbV+9tln//Ddi9zdCvrP9/USExOtgHXbtm1/+/2KyO1XyORaWO5yZ86cISYmhtdeew0PD48c497e3jc8tlixYsybNw9/f3927txJv379KFasGCNGjACgW7du1K1blzlz5uDs7Mz27dspXLgwAGFhYWRmZrJ+/Xo8PDz45ZdfKFq0aK7nSUxMJCkpiZCQEGOfl5cXQUFBxMfH07lz53/wCYjcvf4NP98iUvCpGBW7OnDgAFarlRo1auT72DFjxhh/rlixIsOGDePzzz83/mN15MgRhg8fbsxdrVo1I/7IkSN07NiRwMBAACpXrnzD8yQlJQHg4+Njs9/Hx8cYE5Gc/g0/3yJS8OmeUbEr6z/4gq9FixbRqFEjfH19KVq0KGPGjOHIkSPGeHh4OH379iUkJITXX3+dgwcPGmMvvvgir776Ko0aNWLcuHHs2LHjH70PEclJP98icjuoGBW7qlatGhaLhb179+bruPj4eLp160br1q1ZtmwZ27ZtY/To0WRmZhox48ePZ/fu3bRp04Y1a9YQEBDA119/DUDfvn05dOgQzz77LDt37qR+/fq8/fbbuZ7L19cXgOTkZJv9ycnJxpiI5PRv+PkWkX8Bc29ZFUfQsmXLfD/g8Oabb1orV65sE9unTx+rl5fXDc/TuXNna7t27XIdGzVqlDUwMDDXsWsPML355pvGvtTUVD3AJJIHBf3n+3p6gEmkYFJnVOxu9uzZZGVl8dBDD/Hll1+yf/9+9uzZw8yZMwkODs71mGrVqnHkyBE+//xzDh48yMyZM42uCMDFixcZOHAga9eu5bfffuOHH35gy5Yt1KxZE4DBgwezatUqEhMT2bp1K99//70x9lcWi4XBgwfz6quvsnTpUnbu3En37t3x9/enffv2t/3zELmbFPSfb7j6oNX27dv55ZdfANi3bx/bt2/XPeEiBYXZ1bA4hmPHjlnDwsKsFSpUsLq4uFjLli1rfeyxx6zff/+9EcNfln4ZPny4tWTJktaiRYtaO3XqZJ02bZrROcnIyLB27tzZWq5cOauLi4vV39/fOnDgQOvFixetVqvVOnDgQGuVKlWsrq6u1tKlS1ufffZZ66lTp26YX3Z2tnXs2LFWHx8fq6urq7V58+bWffv22eOjELnrFPSf748++sgK5NjGjRtnh09DRPLLYrX+gzvQRURERET+AV2mFxERERHTqBgVEREREdOoGBURERER06gYFRERERHTqBgVEREREdOoGBURERER06gYFRERERHTqBgVEREREdOoGBWRAqtnz542X8n6yCOPMHjw4Duex9q1a7FYLKSkpNzxc4uI3O1UjIpIvvXs2ROLxYLFYsHFxYWqVasyYcIErly5YtfzfvXVV0ycODFPsSogRUT+HQqZnYCI/Du1bNmSjz76iIyMDFasWEFYWBiFCxcmIiLCJi4zMxMXF5fbcs4SJUrclnlERKTgUGdURP4WV1dXfH19qVChAgMGDCAkJISlS5cal9Zfe+01/P39qV69OgC///47Tz/9NN7e3pQoUYLHH3+cw4cPG/NlZWURHh6Ot7c3JUuWZMSIEVitVptz/vUyfUZGBiNHjqRcuXK4urpStWpVPvzwQw4fPkyzZs0AKF68OBaLhZ49ewKQnZ1NVFQUlSpVwt3dnfvvv58vvvjC5jwrVqzg3nvvxd3dnWbNmtnkKSIit5eKURG5Ldzd3cnMzAQgLi6Offv2ERsby7Jly7h8+TKhoaEUK1aM//3vf/zwww8ULVqUli1bGsdMnTqVefPm8d///pcNGzZw5swZvv7665ues3v37nz22WfMnDmTPXv28O6771K0aFHKlSvHl19+CcC+ffs4fvw4M2bMACAqKoqPP/6YuXPnsnv3boYMGcIzzzzDunXrgKtFc4cOHWjXrh3bt2+nb9++jBo1yl4fm4iIw9NlehH5R6xWK3FxcaxatYpBgwZx8uRJPDw8+OCDD4zL859++inZ2dl88MEHWCwWAD766CO8vb1Zu3YtLVq0YPr06URERNChQwcA5s6dy6pVq2543l9//ZXFixcTGxtLSEgIAJUrVzbGr13SL1OmDN7e3sDVTuqkSZNYvXo1wcHBxjEbNmzg3Xff5eGHH2bOnDlUqVKFqVOnAlC9enV27tzJG2+8cRs/NRERuUbFqIj8LcuWLaNo0aJcvnyZ7Oxsunbtyvjx4wkLCyMwMNDmPtGff/6ZAwcOUKxYMZs5Ll26xMGDB0lNTeX48eMEBQUZY4UKFaJ+/fo5LtVfs337dpydnXn44YfznPOBAwe4cOEC//nPf2z2Z2ZmUrduXQD27NljkwdgFK4iInL7qRgVkb+lWbNmzJkzBxcXF/z9/SlU6M+/Tjw8PGxiz58/T7169ViwYEGOeUqXLv23zu/u7p7vY86fPw/A8uXLKVu2rM2Yq6vr38pDRET+GRWjIvK3eHh4ULVq1TzFPvDAAyxatIgyZcrg6emZa4yfnx+bNm2iadOmAFy5coWEhAQeeOCBXOMDAwPJzs5m3bp1xmX6613rzGZlZRn7AgICcHV15ciRIzfsqNasWZOlS5fa7Pvxxx9v/SZFRORv0QNMImJ33bp1o1SpUjz++OP873//IzExkbVr1/Liiy9y9OhRAF566SVef/11oqOj2bt3Ly+88MJN1witWLEiPXr0oHfv3kRHRxtzLl68GIAKFSpgsVhYtmwZJ0+e5Pz58xQrVoxhw4YxZMgQ5s+fz8GDB9m6dStvv/028+fPB+D5559n//79DB8+nH379rFw4ULmzZtn749IRMRhqRgVEbsrUqQI69evp3z58nTo0IGaNWvSp08fLl26ZHRKhw4dyrPPPkuPHj0IDg6mWLFiPPHEEzedd86cOTz55JO88MIL1KhRg379+pGeng5A2bJleeWVVxg1ahQ+Pj4MHDgQgIkTJzJ27FiioqKoWbMmLVu2ZPny5VSqVAmA8uXL8+WXXxIdHc3999/P3LlzmTRpkh0/HRERx2ax3ujpABERERERO1NnVERERERMo2JUREREREyjYlRERERETKNiVERERERMo2JUREREREyjYlRERERETKNiVERERERMo2JUREREREyjYlRERERETKNiVERERERMo2JUREREREzzf+uOGvduMtdbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分類結果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.56      0.66      0.60   1375907\n",
      "     Class 1       0.53      0.42      0.47   1249092\n",
      "\n",
      "    accuracy                           0.55   2624999\n",
      "   macro avg       0.54      0.54      0.54   2624999\n",
      "weighted avg       0.54      0.55      0.54   2624999\n",
      "\n",
      "\n",
      "機率分布統計:\n",
      "\n",
      "Class 0 的機率分布:\n",
      "平均機率: [0.5204534 0.4795457]\n",
      "機率標準差: [0.04870907 0.04870906]\n",
      "\n",
      "Class 1 的機率分布:\n",
      "平均機率: [0.5098463 0.4901592]\n",
      "機率標準差: [0.04830735 0.04830731]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型ACC : 0.5456\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        device = setup_gpu()\n",
    "        print(f\"使用設備: {device}\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # DATA dir\n",
    "        img_dir = 'C:\\\\Users\\\\user\\\\Desktop\\\\Leet\\\\finance\\\\data\\\\pred_5_to_5\\\\5_5'\n",
    "        labels_file = 'C:\\\\Users\\\\user\\\\Desktop\\\\Leet\\\\finance\\\\data\\\\pred_5_to_5\\\\5_5.xlsx'\n",
    "\n",
    "        print(\"Data loading...\")\n",
    "        dataset = CustomImageDataset(img_dir=img_dir, labels_file=labels_file)\n",
    "\n",
    "        # data split\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) if Config.USE_RANDOM_SPLIT else (dataset, dataset)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE,\n",
    "                                  shuffle=True, num_workers=0, pin_memory=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE,\n",
    "                                 shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        print(\"初始化模型...\")\n",
    "        model = CNN5d()\n",
    "\n",
    "        # Check if best_model.pth exists before trying to load\n",
    "        import os\n",
    "        if os.path.exists('best_model.pth'):\n",
    "            try:\n",
    "                # best model loading with new load_model function\n",
    "                model, optimizer_state, epoch, loss = load_model(model, 'best_model.pth')\n",
    "                print(f\"Loaded model from epoch {epoch} with loss {loss}\")\n",
    "            except Exception as load_error:\n",
    "                print(f\"Error loading model: {load_error}. Proceeding with initial model.\")\n",
    "        else:\n",
    "            print(\"No saved model found. Training from scratch.\")\n",
    "\n",
    "        if Config.USE_DATAPARALLEL and torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        # If no model was successfully loaded, train the model\n",
    "        if not hasattr(model, 'trained'):\n",
    "            print(\"Training model...\")\n",
    "            train_model(model, train_loader, test_loader, device)\n",
    "\n",
    "        print(\"評估模型...\")\n",
    "        accuracy = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"錯誤: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
